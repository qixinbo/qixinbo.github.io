<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"qixinbo.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="参考文档：0、1、2  简介 PyTorch Image Models (timm)是Ross Wightman创建的深度学习库，是一个大型集合，包括了SOTA计算机视觉模型、神经网络层、实用函数、优化器、调度器、数据加载器、数据增强器以及训练&#x2F;验证脚本等。  安装 1   pip install timm   示例数据集（可选） 在演示之前，先下载一些流行的数据集作为示范。在这里，Chris H">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch图像模型库timm解析">
<meta property="og:url" content="http://qixinbo.github.io/2022/06/25/timm/index.html">
<meta property="og:site_name" content="数字旗手">
<meta property="og:description" content="参考文档：0、1、2  简介 PyTorch Image Models (timm)是Ross Wightman创建的深度学习库，是一个大型集合，包括了SOTA计算机视觉模型、神经网络层、实用函数、优化器、调度器、数据加载器、数据增强器以及训练&#x2F;验证脚本等。  安装 1   pip install timm   示例数据集（可选） 在演示之前，先下载一些流行的数据集作为示范。在这里，Chris H">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-06-24T16:00:00.000Z">
<meta property="article:modified_time" content="2022-06-24T15:38:18.294Z">
<meta property="article:author" content="Xin-Bo Qi(亓欣波)">
<meta property="article:tag" content="PyTorch">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://qixinbo.github.io/2022/06/25/timm/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>PyTorch图像模型库timm解析 | 数字旗手</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="数字旗手" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">数字旗手</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">电气化、自动化、数字化、智能化、智慧化</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-scholar">

    <a href="/scholar/" rel="section"><i class="fa fa-chart-bar fa-fw"></i>scholar</a>

  </li>
        <li class="menu-item menu-item-sources">

    <a href="/sources/" rel="section"><i class="fa fa-rss fa-fw"></i>sources</a>

  </li>
        <li class="menu-item menu-item-gallery">

    <a href="/gallery/" rel="section"><i class="fa fa-file-image fa-fw"></i>gallery</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404.html" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://qixinbo.github.io/2022/06/25/timm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Xin-Bo Qi(亓欣波)">
      <meta itemprop="description" content="Digitize everything to realize Digitalization!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数字旗手">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PyTorch图像模型库timm解析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-25 00:00:00" itemprop="dateCreated datePublished" datetime="2022-06-25T00:00:00+08:00">2022-06-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-24 23:38:18" itemprop="dateModified" datetime="2022-06-24T23:38:18+08:00">2022-06-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2022/06/25/timm/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2022/06/25/timm/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>参考文档：<a target="_blank" rel="noopener" href="https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055">0</a>、<a target="_blank" rel="noopener" href="https://timm.fast.ai/">1</a>、<a target="_blank" rel="noopener" href="https://rwightman.github.io/pytorch-image-models/">2</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><a target="_blank" rel="noopener" href="https://github.com/rwightman/pytorch-image-models"><code>PyTorch Image Models (timm)</code></a>是<a target="_blank" rel="noopener" href="https://twitter.com/wightmanr"><code>Ross Wightman</code></a>创建的深度学习库，是一个大型集合，包括了<code>SOTA</code>计算机视觉模型、神经网络层、实用函数、优化器、调度器、数据加载器、数据增强器以及训练/验证脚本等。</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install timm</span><br></pre></td></tr></table></figure>
<h2 id="示例数据集（可选）"><a href="#示例数据集（可选）" class="headerlink" title="示例数据集（可选）"></a>示例数据集（可选）</h2><p>在演示之前，先下载一些流行的数据集作为示范。在这里，<a target="_blank" rel="noopener" href="https://medium.com/@chris.p.hughes10">Chris Hughes</a>使用了两个数据集：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.robots.ox.ac.uk/~vgg/data/pets/">牛津大学<code>IIIT</code>宠物数据集</a>，该数据集有<code>37</code>个类别，每个类别大约有<code>200</code>张图片</li>
<li><a target="_blank" rel="noopener" href="https://github.com/fastai/imagenette"><code>Imagenette</code></a>，这是<code>Imagenet</code>中<code>10</code>个容易分类的类别的一个子集。</li>
</ul>
<p>(1)<code>IIIT</code>宠物数据集<br>下载并解压：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz -P pets</span><br><span class="line">tar zxf pets/images.tar.gz -C pets</span><br></pre></td></tr></table></figure></p>
<p>（2）<code>Imagenette</code>数据集<br>下载并解压：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-<span class="number">320.</span>tgz -P imagenette</span><br><span class="line">tar zxf imagenette/imagenette2-<span class="number">320.</span>tgz -C imagenette</span><br><span class="line">gzip -d imagenette/imagenette2-<span class="number">320.</span>tgz</span><br></pre></td></tr></table></figure></p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p><code>timm</code>最受欢迎的功能之一是其庞大且不断增长的模型架构集合。其中大部分模型包含预训练的权重——这些权重要么是在<code>PyTorch</code>中原生训练的，要么是从<code>Jax</code>和<code>TensorFlow</code>等其他库中移植的——可以轻松下载和使用。</p>
<h2 id="列出可用模型"><a href="#列出可用模型" class="headerlink" title="列出可用模型"></a>列出可用模型</h2><p>列出所有可用模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> timm</span><br><span class="line">timm.list_models()</span><br></pre></td></tr></table></figure><br>列出所有可用的预训练模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timm.list_models(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>通过通配符搜索特定模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_densenet_models = timm.list_models(<span class="string">&#x27;*densenet*&#x27;</span>)</span><br></pre></td></tr></table></figure><br><code>timm</code>中有几百个模型，且该数字还在不断增长，如果你觉得选择困难的话，可以参考<code>Papers with code</code>上的<a target="_blank" rel="noopener" href="https://paperswithcode.com/lib/timm">总结页</a>，它包含了<code>timm</code>中许多模型的基准和原始论文的链接。</p>
<h2 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h2><h3 id="常规用法"><a href="#常规用法" class="headerlink" title="常规用法"></a>常规用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> timm </span><br><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>使用<code>timm</code>创建模型非常简单。<code>create_model</code>是一个用来可以创建超过<code>300</code>个模型的工厂函数。<br>创建一个预训练模型，则仅需额外传递一个参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>为了进一步了解如何使用这个模型，可以访问它的配置：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.default_cfg</span><br></pre></td></tr></table></figure><br>其中包含的信息有：应该用来归一化输入数据的统计数据<code>mean</code>和<code>std</code>、输出类别的数目<code>num_classes</code>和网络中分类器的名称<code>classifier</code>等信息。<br>也可以直接打印出整个模型的架构：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure></p>
<h3 id="创建可变输入通道数目的图像的预训练模型"><a href="#创建可变输入通道数目的图像的预训练模型" class="headerlink" title="创建可变输入通道数目的图像的预训练模型"></a>创建可变输入通道数目的图像的预训练模型</h3><p><code>timm</code>模型有一个不太为人所知、但却非常有用的特点，那就是它们能够处理具有不同通道数的输入图像，这对大多数其他库来说都是一个问题；<a target="_blank" rel="noopener" href="https://timm.fast.ai/models#So-how-is-timm-able-to-load-these-weights?">这里</a>给出了一个关于这个工作原理的出色解释。直观地说，<code>timm</code>通过对少于3个通道的初始卷积层的权重进行求和，或者智能地将这些权重复制到所需的通道数上，来实现这一目的。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, pretrained=<span class="literal">True</span>, in_chans=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><br>值得注意的是，虽然这使我们能够使用一个预训练的模型，但输入的图像与模型训练所基于的图像有很大的不同。正因为如此，我们不应该期待同样的性能水平，在将模型用于任务之前，应该在新的数据集上对其进行微调。</p>
<h2 id="定制化模型"><a href="#定制化模型" class="headerlink" title="定制化模型"></a>定制化模型</h2><p>除了用现有架构创建模型外，<code>create_model</code>还支持一些参数，使我们能够为特定的任务定制一个模型。<br>不过需要注意的是，支持的参数可能取决于底层的模型架构。</p>
<ul>
<li>一些参数，如<code>global_pool</code>就是与具体模型相关，该参会决定全局池化的类型，它在类<code>ResNet</code>的模型中是有效的，但就不适用于比如<code>ViT</code>这样的模型，因为<code>ViT</code>不使用平均池化。</li>
<li>另一些参数，如丢弃率<code>drop_rate</code>和输出类别数<code>num_classes</code>就适用于大多数模型。</li>
</ul>
<p>所以提前查看当前模型的默认架构是非常有必要的。</p>
<p>以之前的<code>resnet34</code>为例，看如何定制模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>其默认配置为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model.default_cfg</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;num_classes&#x27;</span>: <span class="number">1000</span>,</span><br><span class="line"> <span class="string">&#x27;input_size&#x27;</span>: (<span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line"> <span class="string">&#x27;pool_size&#x27;</span>: (<span class="number">7</span>, <span class="number">7</span>),</span><br><span class="line"> <span class="string">&#x27;crop_pct&#x27;</span>: <span class="number">0.875</span>,</span><br><span class="line"> <span class="string">&#x27;interpolation&#x27;</span>: <span class="string">&#x27;bilinear&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;mean&#x27;</span>: (<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>),</span><br><span class="line"> <span class="string">&#x27;std&#x27;</span>: (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>),</span><br><span class="line"> <span class="string">&#x27;first_conv&#x27;</span>: <span class="string">&#x27;conv1&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;classifier&#x27;</span>: <span class="string">&#x27;fc&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;architecture&#x27;</span>: <span class="string">&#x27;resnet34&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="改变输出类别数量"><a href="#改变输出类别数量" class="headerlink" title="改变输出类别数量"></a>改变输出类别数量</h3><p>由上面的模型配置可以看出，网络的分类器名字是<code>fc</code>。可以用它来直接访问相应的模块：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.fc</span><br><span class="line"></span><br><span class="line">Linear(in_features=<span class="number">512</span>, out_features=<span class="number">1000</span>, bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>然而，这个名字很可能会根据使用的模型架构而改变。为了给不同的模型提供一个一致的接口，<code>timm</code>模型有<code>get_classifier</code>方法，我们可以用它来获得分类器，而不需要查询模块名称：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.get_classifier()</span><br></pre></td></tr></table></figure><br>由于这个模型是在<code>ImageNet</code>上预训练的，我们可以看到最后一层输出<code>1000</code>个类。可以通过<code>num_classes</code>参数来改变这一点。<br>创建一个自定义类别数目的模型，仅需额外传递一个参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, num_classes=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><br>此时查看该模型的分类器，可以看到，<code>timm</code>已经用一个新的、未经训练的、具有所需类别数的线性层替换了最后一层；然后就可以在自己的数据集上进行微调。</p>
<p>如果想完全避免创建最后一层，可以将类的数量设置为<code>0</code>，这将创建一个以<code>Identity()</code>恒等函数为最后一层的模型；这对检查倒数第二层的输出很有用。</p>
<h3 id="全局池化"><a href="#全局池化" class="headerlink" title="全局池化"></a>全局池化</h3><p>依然从上面的模型配置中可以看到<code>pool_size</code>参数，表明在分类器之前由一个全局池化层。可以通过如下命令查看：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.global_pool</span><br><span class="line"></span><br><span class="line">SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>))</span><br></pre></td></tr></table></figure><br>可以看到，返回了一个<code>SelectAdaptivePool2d</code>实例， 这是一个由<code>timm</code>提供的自定义层，支持不同的池化和压平配置，包括：</p>
<ul>
<li><code>avg</code>：平均池化</li>
<li><code>max</code>：最大池化</li>
<li><code>avgmax</code>：平均池化和最大池化的和，然后<code>0.5</code>倍缩放</li>
<li><code>catavgmax</code>：沿着特征维度将平均池化和最大池化的输出连接起来。注意，这将使特征维度增加一倍。</li>
<li><code>&#39;&#39;</code>：不使用池化，池化层倍一个<code>Indentity</code>恒等函数所替代</li>
</ul>
<p>通过以下代码查看一下不同池化选项的效果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">pool_types = [<span class="string">&#x27;avg&#x27;</span>, <span class="string">&#x27;max&#x27;</span>, <span class="string">&#x27;avgmax&#x27;</span>, <span class="string">&#x27;catavgmax&#x27;</span>, <span class="string">&#x27;&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pool <span class="keyword">in</span> pool_types:</span><br><span class="line">    <span class="comment"># 这里一定要设置num_classes=0，</span></span><br><span class="line">    <span class="comment"># 否则在catavgmax和&#x27;&#x27;两种情形下都会报错，因为它改变了原来模型架构，无法与分类器正确连接</span></span><br><span class="line">    <span class="comment"># 这里设置了num_classes=0，实际就是查看倒数第二层（即全局池化层）的输出形状</span></span><br><span class="line">    model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, pretrained=<span class="literal">True</span>, num_classes=<span class="number">0</span>, global_pool=pool)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    feature_output = model(torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">    <span class="built_in">print</span>(feature_output.shape)</span><br></pre></td></tr></table></figure></p>
<h3 id="修改已有模型"><a href="#修改已有模型" class="headerlink" title="修改已有模型"></a>修改已有模型</h3><p>可以通过<code>reset_classifier</code>方法来修改已有模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Original pooling: <span class="subst">&#123;model.global_pool&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Original classifier: <span class="subst">&#123;model.get_classifier()&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;--------------&#x27;</span>)</span><br><span class="line">model.reset_classifier(<span class="number">10</span>, <span class="string">&#x27;max&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Modified pooling: <span class="subst">&#123;model.global_pool&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Modified classifier: <span class="subst">&#123;model.get_classifier()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Original pooling: SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>))</span><br><span class="line">Original classifier: Linear(in_features=<span class="number">512</span>, out_features=<span class="number">1000</span>, bias=<span class="literal">True</span>)</span><br><span class="line">--------------</span><br><span class="line">Modified pooling: SelectAdaptivePool2d (pool_type=<span class="built_in">max</span>, flatten=Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>))</span><br><span class="line">Modified classifier: Linear(in_features=<span class="number">512</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="创建新的分类器"><a href="#创建新的分类器" class="headerlink" title="创建新的分类器"></a>创建新的分类器</h3><p>虽然已经证明使用单一的线性层作为分类器足以取得良好的效果，但在下游任务上微调模型时，<a target="_blank" rel="noopener" href="https://medium.com/@chris.p.hughes10">Chris Hughes</a>发现使用一个稍大的头可以导致性能的提高。<br>接下来探讨一下如何进一步修改之前的<code>ResNet</code>模型。<br>首先，以前一样创建<code>ResNet</code>模型，指定需要<code>10</code>个输出类别。由于使用的是一个较大的头，这里使用<code>catavgmax</code>来进行池化，这样就可以提供更多的信息作为分类器的输入。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, pretrained=<span class="literal">True</span>, num_classes=<span class="number">10</span>, global_pool=<span class="string">&#x27;catavgmax&#x27;</span>)</span><br></pre></td></tr></table></figure><br>对于该模型的已有分类器，看一下它的输入特征：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">num_in_features = model.get_classifier().in_features</span><br><span class="line">num_in_features</span><br><span class="line"></span><br><span class="line"><span class="number">1024</span></span><br></pre></td></tr></table></figure><br>下面用一个自定义的分类器来直接替换原来的分类器：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">model.fc = nn.Sequential(</span><br><span class="line">    nn.BatchNorm1d(num_in_features),</span><br><span class="line">    nn.Linear(in_features=num_in_features, out_features=<span class="number">512</span>, bias=<span class="literal">False</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.BatchNorm1d(<span class="number">512</span>),</span><br><span class="line">    nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">    nn.Linear(in_features=<span class="number">512</span>, out_features=<span class="number">10</span>, bias=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>使用一个模拟数据来测试一下新分类器的输出：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">model(torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)).shape</span><br><span class="line"></span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure><br>可以看出，结果符合预期，经过修改后的模型可以用来训练了。</p>
<h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><p><code>timm</code>模型有一套统一的机制来获得各种类型的中间特征，这对于将一个架构作为下游任务的特征提取器是非常有用的。<br>这一部分使用宠物数据集中的图像作为一个例子。<br>在程序中加载<code>IIIT</code>宠物数据集：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line">pets_path = Path(<span class="string">&#x27;pets/images&#x27;</span>)</span><br><span class="line">pets_image_paths = <span class="built_in">list</span>(pets_path.iterdir())</span><br></pre></td></tr></table></figure><br>选取其中一张图像，并转为<code>PyTorch</code>期望的数据格式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">image = Image.<span class="built_in">open</span>(pets_image_paths[<span class="number">1</span>])</span><br><span class="line">image = torch.as_tensor(np.array(image, dtype=np.float32)).transpose(<span class="number">2</span>, <span class="number">0</span>)[<span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">image.shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">3</span>, <span class="number">500</span>, <span class="number">375</span>])</span><br></pre></td></tr></table></figure><br>使用<code>timm</code>常规用法创建一个模型（这里换成了<code>resnet50d</code>）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet50d&#x27;</span>, pretrained=<span class="literal">True</span>)</span><br><span class="line">model.default_cfg</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet50d_ra2-464e36ba.pth&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;num_classes&#x27;</span>: <span class="number">1000</span>,</span><br><span class="line"> <span class="string">&#x27;input_size&#x27;</span>: (<span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line"> <span class="string">&#x27;pool_size&#x27;</span>: (<span class="number">7</span>, <span class="number">7</span>),</span><br><span class="line"> <span class="string">&#x27;crop_pct&#x27;</span>: <span class="number">0.875</span>,</span><br><span class="line"> <span class="string">&#x27;interpolation&#x27;</span>: <span class="string">&#x27;bicubic&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;mean&#x27;</span>: (<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>),</span><br><span class="line"> <span class="string">&#x27;std&#x27;</span>: (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>),</span><br><span class="line"> <span class="string">&#x27;first_conv&#x27;</span>: <span class="string">&#x27;conv1.0&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;classifier&#x27;</span>: <span class="string">&#x27;fc&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;architecture&#x27;</span>: <span class="string">&#x27;resnet50d&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><br>如果我们只对最终的特征图感兴趣——也就是本例中池化之前的最终卷积层的输出——可以使用<code>forward_features</code>方法来绕过全局池化和分类层：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">feature_output = model.forward_features(image)</span><br></pre></td></tr></table></figure><br>可以对它可视化一下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_feature_output</span>(<span class="params">t</span>):</span></span><br><span class="line">    plt.imshow(feature_output[<span class="number">0</span>].transpose(<span class="number">0</span>, <span class="number">2</span>).<span class="built_in">sum</span>(-<span class="number">1</span>).detach().numpy())</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">visualize_feature_output(feature_output)</span><br></pre></td></tr></table></figure></p>
<h3 id="多个特征输出"><a href="#多个特征输出" class="headerlink" title="多个特征输出"></a>多个特征输出</h3><p>虽然<code>forward_features</code>方法可以方便地获得最终的特征图，但<code>timm</code>也提供了一些功能，使得可以将模型作为特征骨干，输出选定层次的特征图。<br>先看一个之前模型中的特征信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model.feature_info</span><br><span class="line"></span><br><span class="line">[&#123;<span class="string">&#x27;num_chs&#x27;</span>: <span class="number">64</span>, <span class="string">&#x27;reduction&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;module&#x27;</span>: <span class="string">&#x27;act1&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;num_chs&#x27;</span>: <span class="number">64</span>, <span class="string">&#x27;reduction&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;module&#x27;</span>: <span class="string">&#x27;layer1&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;num_chs&#x27;</span>: <span class="number">128</span>, <span class="string">&#x27;reduction&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;module&#x27;</span>: <span class="string">&#x27;layer2&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;num_chs&#x27;</span>: <span class="number">256</span>, <span class="string">&#x27;reduction&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;module&#x27;</span>: <span class="string">&#x27;layer3&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;num_chs&#x27;</span>: <span class="number">512</span>, <span class="string">&#x27;reduction&#x27;</span>: <span class="number">32</span>, <span class="string">&#x27;module&#x27;</span>: <span class="string">&#x27;layer4&#x27;</span>&#125;]</span><br></pre></td></tr></table></figure><br>以上是常规创建的模型的输出信息。<br>实际上，在创建模型时，可以添加参数<code>features_only=True</code>来指定所使用模型作为特征骨干，即：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet50d&#x27;</span>, pretrained=<span class="literal">True</span>, features_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model</span><br><span class="line"></span><br><span class="line">FeatureListNet(</span><br><span class="line">  (conv1): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">1</span>): BatchNorm2d(<span class="number">32</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">3</span>): Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">4</span>): BatchNorm2d(<span class="number">32</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">5</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">6</span>): Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">..............</span><br></pre></td></tr></table></figure><br>此时生成的模型是<code>FeatureListNet</code>类型。<br>如下所示，可以得到更多关于返回的特征的信息，如具体的模块名称，特征的减少量和通道的数量：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.feature_info.module_name()</span><br><span class="line">[<span class="string">&#x27;act1&#x27;</span>, <span class="string">&#x27;layer1&#x27;</span>, <span class="string">&#x27;layer2&#x27;</span>, <span class="string">&#x27;layer3&#x27;</span>, <span class="string">&#x27;layer4&#x27;</span>]</span><br><span class="line"></span><br><span class="line">model.feature_info.reduction()</span><br><span class="line">[<span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>]</span><br><span class="line"></span><br><span class="line">model.feature_info.channels()</span><br><span class="line">[<span class="number">64</span>, <span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>]</span><br></pre></td></tr></table></figure><br>默认情况下，大多数模型将输出<code>5</code>层（并非所有模型都有这么多步长），第一层从<code>2</code>开始（但有些从<code>1</code>或<code>4</code>开始）。<br>可以使用<code>out_indices</code>和<code>output_stride</code>参数来修改特征层的索引和数量，如<a target="_blank" rel="noopener" href="https://rwightman.github.io/pytorch-image-models/feature_extraction/#multi-scale-feature-maps-feature-pyramid">文档</a>中所示。<br>将图像传入该特征提取模型中，看一下它的输出：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">out = model(image)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> o <span class="keyword">in</span> out:</span><br><span class="line">    <span class="built_in">print</span>(o.shape)</span><br><span class="line"></span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">250</span>, <span class="number">188</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">125</span>, <span class="number">94</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">512</span>, <span class="number">63</span>, <span class="number">47</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">1024</span>, <span class="number">32</span>, <span class="number">24</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">2048</span>, <span class="number">16</span>, <span class="number">12</span>])</span><br></pre></td></tr></table></figure><br>可以看出，能返回<code>5</code>个特征图，以及形状和通道数都符合预期。<br>还可以具体可视化一下特征图：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> o <span class="keyword">in</span> out:</span><br><span class="line">    plt.imshow(o[<span class="number">0</span>].transpose(<span class="number">0</span>, <span class="number">2</span>).<span class="built_in">sum</span>(-<span class="number">1</span>).detach().numpy())</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p>
<h3 id="使用Torch-FX"><a href="#使用Torch-FX" class="headerlink" title="使用Torch FX"></a>使用Torch FX</h3><p><code>TorchVision</code>最近发布了一个名为<code>FX</code>的新工具，它可以更容易地访问<code>PyTorch Module</code>正向传递过程中的输入的中间转换。具体是通过符号性地运行前向方法来产生一个图<code>graph</code>，其中每个节点代表一个操作。由于节点被赋予了人类可读的名称，所以很容易准确地指定我们要访问的节点。<code>FX</code>在<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/fx.html#module-torch.fx">这篇文档</a>和<a target="_blank" rel="noopener" href="https://pytorch.org/blog/FX-feature-extraction-torchvision/">这篇博文</a>中有更详细的描述。<br>注意：<code>Chris Hughes</code>在撰写<a target="_blank" rel="noopener" href="https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055#0583">本教程</a>时，使用<code>FX</code>时，动态控制流还不能用静态图来表示。<br>由于<code>timm</code>中几乎所有的模型都可以用符号追踪，我们可以用<code>FX</code>来操作这些模型。<br>下面来探讨一下如何使用<code>FX</code>从<code>timm</code>模型中提取特征。<br>（1）获取节点：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入fx必要的包</span></span><br><span class="line"><span class="keyword">from</span> torchvision.models.feature_extraction <span class="keyword">import</span> get_graph_node_names, create_feature_extractor</span><br><span class="line"><span class="comment"># 在创建模型时指定exportable参数，使得模型可被追踪</span></span><br><span class="line">model = timm.create_model(<span class="string">&#x27;resnet50d&#x27;</span>, pretrained=<span class="literal">True</span>, exportable=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 获得节点</span></span><br><span class="line"><span class="comment"># 因为模型分别以train和evel模式都执行一次，所以两种模式下的节点名称都会返回。</span></span><br><span class="line">nodes, _ = get_graph_node_names(model)</span><br><span class="line"></span><br><span class="line">nodes</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;x&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;conv1.0&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;conv1.1&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;conv1.2&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;conv1.3&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;conv1.4&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;conv1.5&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;conv1.6&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;bn1&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;act1&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;maxpool&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;layer1.0.conv1&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;layer1.0.bn1&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;layer1.0.act1&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;layer1.0.conv2&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;layer1.0.bn2&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;layer1.0.act2&#x27;</span>,</span><br><span class="line"> ............</span><br></pre></td></tr></table></figure><br>（2）特征提取器：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用FX可以很容易地获得任意节点的输出</span></span><br><span class="line"><span class="comment"># 这里以选择layer1的第二个激活函数为例</span></span><br><span class="line">features = &#123;<span class="string">&#x27;layer1.0.act2&#x27;</span>: <span class="string">&#x27;out&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用create_feature_extractor可以在这个点上切断整个模型</span></span><br><span class="line">feature_extractor = create_feature_extractor(model, return_nodes=features)</span><br><span class="line"><span class="comment"># 切断后的模型如下</span></span><br><span class="line">feature_extractor</span><br><span class="line"></span><br><span class="line">ResNet(</span><br><span class="line">  (conv1): Module(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">1</span>): BatchNorm2d(<span class="number">32</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">3</span>): Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">4</span>): BatchNorm2d(<span class="number">32</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">5</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">6</span>): Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">  (act1): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (layer1): Module(</span><br><span class="line">    (<span class="number">0</span>): Module(</span><br><span class="line">      (conv1): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (act1): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">      (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (act2): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>（3）提取特征：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入图像，返回特征</span></span><br><span class="line">out = feature_extractor(image)</span><br><span class="line"><span class="comment"># 可视化一下</span></span><br><span class="line">plt.imshow(out[<span class="string">&#x27;out&#x27;</span>][<span class="number">0</span>].transpose(<span class="number">0</span>, <span class="number">2</span>).<span class="built_in">sum</span>(-<span class="number">1</span>).detach().numpy())</span><br></pre></td></tr></table></figure></p>
<h2 id="模型导出"><a href="#模型导出" class="headerlink" title="模型导出"></a>模型导出</h2><p>训练结束后，通常建议将模型导出为优化的格式，以便进行推理；<code>PyTorch</code>有多种导出选项可以做到这一点。由于几乎所有的<code>timm</code>模型都是可编写脚本和可追踪的，因此可以利用这些格式。</p>
<h3 id="导出为TorchScript"><a href="#导出为TorchScript" class="headerlink" title="导出为TorchScript"></a>导出为TorchScript</h3><p><code>TorchScript</code>是一种从<code>PyTorch</code>代码中创建可序列化和可优化的模型的方法；任何<code>TorchScript</code>程序都可以从<code>Python</code>进程中保存，并在没有<code>Python</code>依赖性的进程中加载。<br>可以通过两种不同的方式将一个模型转换为<code>TorchScript</code>。</p>
<ul>
<li>追踪：运行代码，记录发生的操作，并构造一个包含这些操作的<code>ScriptModule</code>。控制流或动态行为（如<code>if/else</code>语句）会被抹去。</li>
<li>脚本化：使用脚本编译器对<code>Python</code>源代码进行直接分析，将其转化为<code>TorchScript</code>。这保留了动态控制流，对不同大小的输入都有效。</li>
</ul>
<p>关于<code>TorchScript</code>的更多信息可以在<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/jit.html">该文档</a>和<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">该教程</a>中看到。<br>由于大多数<code>timm</code>模型是可编写脚本的，这里使用脚本来导出上面的<code>ResNet-D</code>模型。可以在创建模型时使用<code>scriptable</code>参数来使模型是<code>jit</code>可脚本化。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet50d&#x27;</span>, pretrained=<span class="literal">True</span>, scriptable=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><br>在导出模型之前调用<code>model.eval()</code>是非常重要的，这样可以使模型进入推理模式，因为诸如<code>dropout</code>和<code>batchnorm</code>这样的运算符在不同的模式下表现不同。<br>确认一下可以脚本化模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">scripted_model = torch.jit.script(model)</span><br><span class="line"></span><br><span class="line">scripted_model</span><br><span class="line"></span><br><span class="line">RecursiveScriptModule(</span><br><span class="line">  original_name=ResNet</span><br><span class="line">  (conv1): RecursiveScriptModule(</span><br><span class="line">    original_name=Sequential</span><br><span class="line">    (<span class="number">0</span>): RecursiveScriptModule(original_name=Conv2d)</span><br><span class="line">    (<span class="number">1</span>): RecursiveScriptModule(original_name=BatchNorm2d)</span><br><span class="line">    (<span class="number">2</span>): RecursiveScriptModule(original_name=ReLU)</span><br><span class="line">    (<span class="number">3</span>): RecursiveScriptModule(original_name=Conv2d)</span><br><span class="line">    (<span class="number">4</span>): RecursiveScriptModule(original_name=BatchNorm2d)</span><br><span class="line">    (<span class="number">5</span>): RecursiveScriptModule(original_name=ReLU)</span><br><span class="line">    (<span class="number">6</span>): RecursiveScriptModule(original_name=Conv2d)</span><br><span class="line">  )</span><br></pre></td></tr></table></figure><br>同时模型也能正常使用：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scripted_model(torch.rand(<span class="number">8</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)).shape</span><br><span class="line"></span><br><span class="line">torch.Size([<span class="number">8</span>, <span class="number">1000</span>])</span><br></pre></td></tr></table></figure></p>
<h3 id="导出为ONNX"><a href="#导出为ONNX" class="headerlink" title="导出为ONNX"></a>导出为ONNX</h3><p><a target="_blank" rel="noopener" href="https://onnx.ai/"><code>Open Neural Network eXchange(ONNX)</code></a>是一种表示机器学习模型的开放标准格式。<br>可以使用<code>torch.onnx</code>模块将<code>timm</code>模型导出到<code>ONNX</code>，使它们能够被任何支持<code>ONNX</code>的运行时<code>runtimes</code>所使用。如果调用<code>torch.onnx.export()</code>的模块不是<code>ScriptModule</code>，它首先会做相当于<code>torch.jit.trace()</code>的工作；用给定的<code>args</code>执行一次模型，并记录执行期间发生的所有操作。这意味着，如果模型是动态的，例如，根据输入数据改变行为，导出的模型将不能捕捉到这种动态行为。同样，跟踪可能只对特定的输入尺寸有效。<br>关于<code>ONNX</code>的更多细节可以在<a target="_blank" rel="noopener" href="https://pytorch.org/docs/master/onnx.html">该文档</a>中找到。<br>为了能够以<code>ONNX</code>格式导出一个<code>timm</code>模型，可以在创建模型时使用<code>exportable</code>参数，以确保模型是可追踪的：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = timm.create_model(<span class="string">&#x27;resnet50d&#x27;</span>, pretrained=<span class="literal">True</span>, exportable=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><br>然后使用<code>torch.onnx.export</code>来追踪和导出模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">torch_out = model(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Export the model</span></span><br><span class="line">torch.onnx.export(model,                                       <span class="comment"># model being run</span></span><br><span class="line">                  x,                                           <span class="comment"># model input (or a tuple for multiple inputs)</span></span><br><span class="line">                  <span class="string">&quot;resnet50d.onnx&quot;</span>,                            <span class="comment"># where to save the model (can be a file or file-like object)</span></span><br><span class="line">                  export_params=<span class="literal">True</span>,                          <span class="comment"># store the trained parameter weights inside the model file</span></span><br><span class="line">                  opset_version=<span class="number">10</span>,                            <span class="comment"># the ONNX version to export the model to</span></span><br><span class="line">                  do_constant_folding=<span class="literal">True</span>,                    <span class="comment"># whether to execute constant folding for optimization</span></span><br><span class="line">                  input_names = [<span class="string">&#x27;input&#x27;</span>],                     <span class="comment"># the model&#x27;s input names</span></span><br><span class="line">                  output_names = [<span class="string">&#x27;output&#x27;</span>],                   <span class="comment"># the model&#x27;s output names</span></span><br><span class="line">                  dynamic_axes=&#123;<span class="string">&#x27;input&#x27;</span> : &#123;<span class="number">0</span> : <span class="string">&#x27;batch_size&#x27;</span>&#125;,  <span class="comment"># variable length axes</span></span><br><span class="line">                                <span class="string">&#x27;output&#x27;</span>: &#123;<span class="number">0</span> : <span class="string">&#x27;batch_size&#x27;</span>&#125;&#125;)</span><br></pre></td></tr></table></figure><br>使用<code>check_model</code>验证一下模型是否有效：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"></span><br><span class="line">onnx_model = onnx.load(<span class="string">&quot;resnet50d.onnx&quot;</span>)</span><br><span class="line">onnx.checker.check_model(onnx_model)</span><br></pre></td></tr></table></figure><br>由于已经指定模型应该是可追踪的，也可以手动进行追踪，如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">traced_model = torch.jit.trace(model, torch.rand(<span class="number">8</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">traced_model(torch.rand(<span class="number">8</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)).shape</span><br></pre></td></tr></table></figure></p>
<h1 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h1><p><code>timm</code>包括很多数据增强变换，它们可以被串联起来组成增强管道；与<code>TorchVision</code>类似，这些管道需要一个<code>PIL</code>图像作为输入。<br>最简单的方法是使用<code>create_transform</code>工厂函数，下面探索如何使用它。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> timm.data.transforms_factory <span class="keyword">import</span> create_transform</span><br><span class="line"></span><br><span class="line">create_transform(<span class="number">224</span>,)</span><br><span class="line"></span><br><span class="line">Compose(</span><br><span class="line">    Resize(size=<span class="number">256</span>, interpolation=bilinear, max_size=<span class="literal">None</span>, antialias=<span class="literal">None</span>)</span><br><span class="line">    CenterCrop(size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">    ToTensor()</span><br><span class="line">    Normalize(mean=tensor([<span class="number">0.4850</span>, <span class="number">0.4560</span>, <span class="number">0.4060</span>]), std=tensor([<span class="number">0.2290</span>, <span class="number">0.2240</span>, <span class="number">0.2250</span>]))</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>可以看到，<code>create_transform</code>已经创建了一些基本的增强管道，包括调整大小、归一化和将图像转换为张量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">create_transform(<span class="number">224</span>, is_training=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">Compose(</span><br><span class="line">    RandomResizedCropAndInterpolation(size=(<span class="number">224</span>, <span class="number">224</span>), scale=(<span class="number">0.08</span>, <span class="number">1.0</span>), ratio=(<span class="number">0.75</span>, <span class="number">1.3333</span>), interpolation=bilinear)</span><br><span class="line">    RandomHorizontalFlip(p=<span class="number">0.5</span>)</span><br><span class="line">    ColorJitter(brightness=[<span class="number">0.6</span>, <span class="number">1.4</span>], contrast=[<span class="number">0.6</span>, <span class="number">1.4</span>], saturation=[<span class="number">0.6</span>, <span class="number">1.4</span>], hue=<span class="literal">None</span>)</span><br><span class="line">    ToTensor()</span><br><span class="line">    Normalize(mean=tensor([<span class="number">0.4850</span>, <span class="number">0.4560</span>, <span class="number">0.4060</span>]), std=tensor([<span class="number">0.2290</span>, <span class="number">0.2240</span>, <span class="number">0.2250</span>]))</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>正如所期望的那样，可以看到，当设置<code>is_training=True</code>时，额外的转换，如水平翻转和颜色抖动，也包括在内。这些增强方式的数值大小可以通过参数<code>hflip</code>、<code>vflip</code>和<code>color_jitter</code>来控制。<br>还可以看到，用于调整图像大小的方法也因是否是模型训练而不同。在验证期间使用标准的<code>Resize</code>和<code>CenterCrop</code>，而在训练期间则使用<code>RandomResizedCropAndInterpolation</code>。<br>通过下面的代码可以看看<code>RandomResizedCropAndInterpolation</code>具体干了什么。由于<code>timm</code>中这个变换的实现使我们能够设置不同的图像插值方法；在这里我们选择插值是<code>random</code>，即随机选择。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">image = Image.<span class="built_in">open</span>(pets_image_paths[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> timm.data.transforms <span class="keyword">import</span> RandomResizedCropAndInterpolation</span><br><span class="line">tfm = RandomResizedCropAndInterpolation(size=<span class="number">350</span>, interpolation=<span class="string">&#x27;random&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, ax = plt.subplots(<span class="number">2</span>, <span class="number">4</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> idx, im <span class="keyword">in</span> <span class="built_in">enumerate</span>([tfm(image) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)]):</span><br><span class="line">    ax[<span class="number">0</span>, idx].imshow(im)   </span><br><span class="line"><span class="keyword">for</span> idx, im <span class="keyword">in</span> <span class="built_in">enumerate</span>([tfm(image) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)]):</span><br><span class="line">    ax[<span class="number">1</span>, idx].imshow(im)</span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><br>多次运行该转换，可以观察到对图像进行了不同的剪裁。虽然这在训练过程中是有益的，但在评估过程中可能会增加任务的难度。根据图片的类型，这种类型的转换可能会导致图片的主体被裁剪掉。如果这种情况不常发生，这应该不是一个大问题，可以通过调整比例参数来避免这种情况。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tfm = RandomResizedCropAndInterpolation(size=<span class="number">224</span>, scale=(<span class="number">0.8</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure></p>
<h2 id="RandAugment"><a href="#RandAugment" class="headerlink" title="RandAugment"></a>RandAugment</h2><p>当开始一个新的任务时，可能很难知道要使用哪些增强，以及以何种顺序使用；由于现在有大量的增强，组合的数量是巨大的。<br>通常，一个好的开始是使用一个在其他任务上表现出良好性能的增强管道。<code>RandAugment</code>就是这样一个策略，它是一种自动化的数据增强方法，从一组增强中统一采样操作——如均衡化、旋转、过曝、颜色抖动、海报化、改变对比度、改变亮度、改变锐度、剪切和平移——并按顺序应用其中的一些；更多信息请参见<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.13719">原始论文</a>。<br>然而，在<code>timm</code>中提供的实现有几个关键的区别，这些区别由<code>timm</code>的创造者<code>Ross Wightman</code>在<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2110.00476v1.pdf"><code>ResNets Strike Back</code></a>论文的附录中做了最好的描述，将其转述如下：</p>
<blockquote>
<p>原始的<code>RandAugment</code>规范有两个超参数，即<code>M</code>和<code>N</code>；其中<code>M</code>是变换幅度，<code>N</code>是每幅图像统一采样和应用的变换数量。<code>RandAugment</code>的目标是，<code>M</code>和<code>N</code>都是人类可以解释的。<br>然而，[在最初的实施中]M的情况最终并非如此。一些增强随着数值变大却是倒退的，或者在范围内不是单调增加的，因此增加<code>M</code>并不能增加所有增强的效果。<br><code>timm</code>的实现试图通过增加一个<code>increasing</code>模式（默认启用）来改善这种情况，在这种模式下，所有的增强的效果都会随着幅度的增加而增加。<br>此外，<code>timm</code>增加了一个<code>MSTD</code>参数，它在每个变换的<code>M</code>值中增加了具有指定标准偏差的高斯噪声。如果<code>MSTD</code>被设置为<code>&#39;-inf&#39;</code>，则每次变换时，<code>M</code>会从<code>0-M</code>中均匀地取样。<br><code>timm</code>的<code>RandAugment</code>会注意减少对图像平均值的影响，归一化参数可以作为一个参数传递，这样所有可能引入边界像素的增强可以使用指定的平均值，而不是像其他实现那样默认为<code>0</code>或一个硬编码的元组。<br>最后，默认情况下不包括<code>Cutout</code>，以支持单独使用<code>timm</code>的随机擦除实现，这对平均数和标准偏差的影响较小。</p>
</blockquote>
<p>随机擦除的实现可以查看<a target="_blank" rel="noopener" href="https://timm.fast.ai/RandomErase">该文章</a>。<br>现在了解了什么是<code>RandAugment</code>，再看看如何在增强管道中使用它。<br>在<code>timm</code>中，通过使用配置字符串来定义<code>RandAugment</code>策略的参数；它由多个部分组成，以破折号（<code>-</code>）分隔：第一个部分定义了<code>RandAugment</code>的具体变体（目前只支持<code>Rand</code>），其余部分可以按任何顺序排列，它们是：</p>
<ul>
<li><code>m</code>：整型，增强的强度</li>
<li><code>n</code>：整型，每张图像选择的变换的数目，可选，默认设置为<code>2</code></li>
<li><code>mstd</code>：浮点型，施加的幅度噪声的标准差</li>
<li><code>mmax</code>：整型，设置幅度的上限，默认为<code>10</code></li>
<li><code>w</code>：整型，概率权重指数（影响操作选择的一组权重的指数）</li>
<li><code>inc</code>：布尔型，是否使用随幅度增加而增加的增强，这是可选的，默认为<code>0</code></li>
</ul>
<p>比如：</p>
<ul>
<li><code>rand-m9-n3-mstd0.5</code>：幅度为<code>9</code>、每张图像有<code>3</code>个增强操作、噪声标准差为<code>0.5</code>的随机增强</li>
<li><code>rand-mstd1-w0</code>：噪声标准差<code>1.0</code>、概率权重指数<code>0</code>、默认强度最大值为<code>10</code>、每张图像有<code>2</code>个增强操作</li>
</ul>
<p>向<code>create_transform</code>传递一个配置字符串，如下可以看到这是由<code>RandAugment</code>对象处理，而且可以看到所有可用的操作的名称：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">create_transform(<span class="number">224</span>, is_training=<span class="literal">True</span>, auto_augment=<span class="string">&#x27;rand-m9-mstd0.5&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Compose(</span><br><span class="line">    RandomResizedCropAndInterpolation(size=(<span class="number">224</span>, <span class="number">224</span>), scale=(<span class="number">0.08</span>, <span class="number">1.0</span>), ratio=(<span class="number">0.75</span>, <span class="number">1.3333</span>), interpolation=bilinear)</span><br><span class="line">    RandomHorizontalFlip(p=<span class="number">0.5</span>)</span><br><span class="line">    RandAugment(n=<span class="number">2</span>, ops=</span><br><span class="line">    AugmentOp(name=AutoContrast, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Equalize, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Invert, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Rotate, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Posterize, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Solarize, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=SolarizeAdd, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Color, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Contrast, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Brightness, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Sharpness, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=ShearX, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=ShearY, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=TranslateXRel, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=TranslateYRel, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>))</span><br><span class="line">    ToTensor()</span><br><span class="line">    Normalize(mean=tensor([<span class="number">0.4850</span>, <span class="number">0.4560</span>, <span class="number">0.4060</span>]), std=tensor([<span class="number">0.2290</span>, <span class="number">0.2240</span>, <span class="number">0.2250</span>]))</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>还可以直接通过使用<code>rand_augment_transform</code>函数来创建这个<code>RandAugment</code>对象：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.data.auto_augment <span class="keyword">import</span> rand_augment_transform</span><br><span class="line"></span><br><span class="line">tfm = rand_augment_transform(</span><br><span class="line">    config_str=<span class="string">&#x27;rand-m9-mstd0.5&#x27;</span>, </span><br><span class="line">    hparams=&#123;<span class="string">&#x27;img_mean&#x27;</span>: (<span class="number">124</span>, <span class="number">116</span>, <span class="number">104</span>)&#125;</span><br><span class="line">)</span><br><span class="line">tfm</span><br><span class="line"></span><br><span class="line">RandAugment(n=<span class="number">2</span>, ops=</span><br><span class="line">    AugmentOp(name=AutoContrast, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Equalize, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Invert, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Rotate, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Posterize, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Solarize, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=SolarizeAdd, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Color, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Contrast, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Brightness, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=Sharpness, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=ShearX, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=ShearY, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=TranslateXRel, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>)</span><br><span class="line">    AugmentOp(name=TranslateYRel, p=<span class="number">0.5</span>, m=<span class="number">9</span>, mstd=<span class="number">0.5</span>))</span><br></pre></td></tr></table></figure><br>可以将该增强策略应用到图像上，看看其效果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">2</span>, <span class="number">4</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, im <span class="keyword">in</span> <span class="built_in">enumerate</span>([tfm(image) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)]):</span><br><span class="line">    ax[<span class="number">0</span>, idx].imshow(im)</span><br><span class="line"><span class="keyword">for</span> idx, im <span class="keyword">in</span> <span class="built_in">enumerate</span>([tfm(image) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)]):</span><br><span class="line">    ax[<span class="number">1</span>, idx].imshow(im)</span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="CutMix和Mixup"><a href="#CutMix和Mixup" class="headerlink" title="CutMix和Mixup"></a>CutMix和Mixup</h2><p><code>timm</code>使用它的<code>Mixup</code>类为<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.04899"><code>CutMix</code></a>和<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.09412"><code>Mixup</code></a>增强功能提供了一个灵活的实现，它可以处理这两种增强功能并提供在它们之间切换的选项。<br>通过使用<code>Mixup</code>，可以从各种不同的混合策略中进行选择：</p>
<ul>
<li><code>batch</code>：在每个批次上进行<code>CutMix</code>与<code>Mixup</code>的选择、<code>lambda</code>和<code>CutMix</code>区域采样</li>
<li><code>pair</code>：在一个批次内的取样对上进行混合、<code>lambda</code>和区域取样。</li>
<li><code>elem</code>：在批次内的每个图像上进行混合、<code>lambda</code>和区域取样。</li>
<li><code>half</code>：与<code>elementwise</code>相同，但每个混合对中的一个被丢弃，这样每个样本在每个<code>epoch</code>中被看到一次</li>
</ul>
<p>下面看一下具体是怎样工作的。<br>首先得需要创建一个数据加载器、迭代器，然后才能将这些增强施加到<code>batch</code>上。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.data <span class="keyword">import</span> ImageDataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataloader_iterator</span>():</span></span><br><span class="line">    dataset = ImageDataset(<span class="string">&#x27;pets/images&#x27;</span>, transform=create_transform(<span class="number">224</span>))</span><br><span class="line">    dl = <span class="built_in">iter</span>(DataLoader(dataset, batch_size=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> dl</span><br><span class="line"></span><br><span class="line">dataloader = create_dataloader_iterator()</span><br><span class="line">inputs, classes = <span class="built_in">next</span>(dataloader)</span><br></pre></td></tr></table></figure><br>这里再创建一个可视化函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Taken from timmdocs https://fastai.github.io/timmdocs/mixup_cutmix</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span>(<span class="params">inp, title=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span></span><br><span class="line">    inp = inp.cpu().numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">    mean = np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">    std = np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(<span class="number">0.001</span>)  <span class="comment"># pause a bit so that plots are updated</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line">imshow(out, title=[x.item() <span class="keyword">for</span> x <span class="keyword">in</span> classes])</span><br></pre></td></tr></table></figure><br>下面创建<code>Mixup</code>变换，其支持如下参数：</p>
<ul>
<li><code>mixup_alpha</code>：浮点型，<code>mixup</code>的<code>alpha</code>值，如果大于<code>0</code>，<code>mixup</code>将被激活（默认为<code>1</code>）</li>
<li><code>cutmix_alpha</code>：浮点型，<code>cutmix</code>的<code>alpha</code>值，如果大于<code>0</code>，则<code>cutmix</code>激活（默认是<code>0</code>）。</li>
<li><code>cutmix_minmax</code>：<code>List[float])</code>型，<code>cutmix</code>的最小/最大图像比例，如果不是<code>None</code>，<code>cutmix</code>将被激活并使用这个与<code>alpha</code>的比值。</li>
<li><code>prob</code>：<code>float</code>型， 每个批次或元素应用<code>mixup</code>或<code>cutmix</code>的概率（默认是<code>1</code>）。</li>
<li><code>switch_prob</code>：<code>float</code>型，当两者都激活时，切换到<code>cutmix</code>而不是<code>mixup</code>的概率（默认是<code>0.5</code>）。</li>
<li><code>mode</code>：<code>str</code>型， 如何应用<code>mixup/cutmix</code>参数（默认是<code>batch</code>）</li>
<li><code>label_smoothing</code>：浮点型，应用于混合目标张量的标签平滑量（默认是<code>0.1</code>）</li>
<li><code>num_classes</code>：<code>int</code>型，目标变量的类别数量。</li>
</ul>
<p>创建一个<code>Mixup</code>变换：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.data.mixup <span class="keyword">import</span> Mixup</span><br><span class="line"></span><br><span class="line">mixup_args = &#123;</span><br><span class="line">    <span class="string">&#x27;mixup_alpha&#x27;</span>: <span class="number">1.</span>,</span><br><span class="line">    <span class="string">&#x27;cutmix_alpha&#x27;</span>: <span class="number">1.</span>,</span><br><span class="line">    <span class="string">&#x27;prob&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;switch_prob&#x27;</span>: <span class="number">0.5</span>,</span><br><span class="line">    <span class="string">&#x27;mode&#x27;</span>: <span class="string">&#x27;batch&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;label_smoothing&#x27;</span>: <span class="number">0.1</span>,</span><br><span class="line">    <span class="string">&#x27;num_classes&#x27;</span>: <span class="number">2</span>&#125;</span><br><span class="line">mixup_fn = Mixup(**mixup_args)</span><br></pre></td></tr></table></figure><br>由于<code>mixup</code>和<code>cutmix</code>是在一批次图像上进行的，可以在应用增强之前将这批图像放在<code>GPU</code>上，以加快进度：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mixed_inputs, mixed_classes = mixup_fn(inputs.to(torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)), classes.to(torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)))</span><br><span class="line">out = torchvision.utils.make_grid(mixed_inputs)</span><br><span class="line">imshow(out, title=mixed_classes)</span><br></pre></td></tr></table></figure></p>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p><code>timm</code>提供了许多有用的工具来处理不同类型的数据集。最简单的入门方法是使用<code>create_dataset</code>函数，它将为我们创建一个合适的数据集。<br><code>create_dataset</code>需要有两个参数：</p>
<ul>
<li><code>name</code>：要加载的数据集的名称</li>
<li><code>root</code>：数据集在本地文件系统中的根文件夹。</li>
</ul>
<p>也可以有额外的关键字参数用于指定选项，如是否要加载训练集或验证集。<br>还可以使用<code>create_dataset</code>来加载来自不同地方的数据：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/vision/main/datasets.html"><code>TorchVision</code></a>数据集</li>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/datasets"><code>TensorFlow</code></a>数据集</li>
<li>存储在本地文件夹中的数据集</li>
</ul>
<h2 id="加载TorchVision数据集"><a href="#加载TorchVision数据集" class="headerlink" title="加载TorchVision数据集"></a>加载TorchVision数据集</h2><p>要加载<code>TorchVision</code>包含的数据集，只需在希望加载的数据集的名称前指定前缀<code>torch/</code>。如果数据在文件系统中不存在，可以通过设置<code>download=True</code>来下载这些数据。此外，还可以使用<code>split</code>参数来指定加载训练数据集。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.data <span class="keyword">import</span> create_dataset</span><br><span class="line">ds = create_dataset(<span class="string">&#x27;torch/cifar10&#x27;</span>, <span class="string">&#x27;cifar10&#x27;</span>, download=<span class="literal">True</span>, split=<span class="string">&#x27;train&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="加载TensorFlow数据集"><a href="#加载TensorFlow数据集" class="headerlink" title="加载TensorFlow数据集"></a>加载TensorFlow数据集</h2><p><code>timm</code>还可以使得从<code>TensorFlow</code>数据集中下载和使用数据集；同时封装了底层的<code>tfds</code>对象。<br>当加载<code>TensorFlow</code>数据集时，在数据集的名称前加上<code>tfds/</code>。此时建议设置几个额外的参数，这些参数对于本地或<code>TorchVision</code>数据集来说是不需要的。</p>
<ul>
<li><code>batch_size</code>：这是用来确保在分布式训练过程中，样本总数划分到所有节点上能整除批处理大小。</li>
<li><code>is_training</code>：如果设置了，数据集将被打乱。注意，这与设置<code>split</code>是不同的。</li>
</ul>
<p>虽然这个封装从<code>TFDS</code>数据集中返回解压缩的图像示例，但需要的任何增强和批处理仍然由<code>PyTorch</code>处理。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ds = create_dataset(<span class="string">&#x27;tfds/beans&#x27;</span>, <span class="string">&#x27;beans&#x27;</span>, download=<span class="literal">True</span>, split=<span class="string">&#x27;train[:10%]&#x27;</span>, batch_size=<span class="number">2</span>, is_training=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="加载本地数据"><a href="#加载本地数据" class="headerlink" title="加载本地数据"></a>加载本地数据</h2><p>也可以从本地文件夹加载数据，在这种情况下，只需使用一个空字符串（<code>&#39;&#39;</code>）作为数据集名称。<br>除了能够从<code>ImageNet</code>风格的文件夹层次中加载数据外，<code>create_dataset</code>还可以让我们从一个或多个<code>tar</code>档案中提取数据；可以用它来避免解开档案的麻烦。<br>作为一个例子，可以在<code>Imagenette</code>数据集上试试这个方法。<br>此外，到目前为止，一直在加载原始图像，所以这里也使用变换参数来应用一些变换：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ds = create_dataset(name=<span class="string">&#x27;&#x27;</span>, root=<span class="string">&#x27;imagenette/imagenette2-320.tar&#x27;</span>, transform=create_transform(<span class="number">224</span>))</span><br></pre></td></tr></table></figure></p>
<h2 id="ImageDataset类"><a href="#ImageDataset类" class="headerlink" title="ImageDataset类"></a>ImageDataset类</h2><p>如上所述，<code>create_dataset</code>函数为处理不同类型的数据提供了很多选择。<code>timm</code>之所以能够提供这样的灵活性，是通过尽可能地使用<code>TorchVision</code>中提供的现有数据集类，以及提供一些额外的实现——<code>ImageDataset</code>和<code>IterableImageDataset</code>，它们可用于广泛的场景。<br>从本质上讲，<code>create_dataset</code>通过选择一个合适的类为我们简化了这个过程，但有时我们可能希望直接与底层组件一起工作。<br><code>Chris Hughes</code>最常使用的实现是<code>ImageDataset</code>，它类似于<code>torchvision.datasets.ImageFolder</code>，但有一些附加功能。<br>下面探讨一下如何使用它来加载之前解压缩的<code>imagenette</code>数据集：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.data <span class="keyword">import</span> ImageDataset</span><br><span class="line">imagenette_ds = ImageDataset(<span class="string">&#x27;imagenette/imagenette2-320/train&#x27;</span>)</span><br></pre></td></tr></table></figure><br><code>ImageDataset</code>的灵活性的关键在于，它索引和加载样本的方式被抽象成一个解析器对象<code>parser</code>。<br><code>timm</code>中包含了多个解析器，包括从文件夹、<code>tar</code>文件和<code>tensorflow</code>数据集读取图像的解析器。解析器可以作为一个参数传递给数据集，可以直接访问解析器。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imagenette_ds.parser</span><br><span class="line"></span><br><span class="line">&lt;timm.data.parsers.parser_image_folder.ParserImageFolder at <span class="number">0x7f66e8146ee0</span>&gt;</span><br></pre></td></tr></table></figure><br>可以看到，默认的解析器是<code>ParserImageFolder</code>的一个实例。解析器还包含有用的信息，比如类别查找，如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">imagenette_ds.parser.class_to_idx</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;n01440764&#x27;</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="string">&#x27;n02102040&#x27;</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">&#x27;n02979186&#x27;</span>: <span class="number">2</span>,</span><br><span class="line"> <span class="string">&#x27;n03000684&#x27;</span>: <span class="number">3</span>,</span><br><span class="line"> <span class="string">&#x27;n03028079&#x27;</span>: <span class="number">4</span>,</span><br><span class="line"> <span class="string">&#x27;n03394916&#x27;</span>: <span class="number">5</span>,</span><br><span class="line"> <span class="string">&#x27;n03417042&#x27;</span>: <span class="number">6</span>,</span><br><span class="line"> <span class="string">&#x27;n03425413&#x27;</span>: <span class="number">7</span>,</span><br><span class="line"> <span class="string">&#x27;n03445777&#x27;</span>: <span class="number">8</span>,</span><br><span class="line"> <span class="string">&#x27;n03888257&#x27;</span>: <span class="number">9</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="手动选择解析器——以tar包为例"><a href="#手动选择解析器——以tar包为例" class="headerlink" title="手动选择解析器——以tar包为例"></a>手动选择解析器——以tar包为例</h3><p>因此，除了选择一个合适的数据集类之外，<code>create_dataset</code>还负责选择正确的解析器。<br>再次考虑压缩的<code>Imagenette</code>数据集，可以通过手动选择<code>ParserImageInTarparser</code>并覆盖<code>ImageDataset</code>的默认解析器来实现同样的结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.data.parsers.parser_image_in_tar <span class="keyword">import</span> ParserImageInTar</span><br><span class="line"></span><br><span class="line">data_path = <span class="string">&#x27;imagenette&#x27;</span></span><br><span class="line">ds = ImageDataset(data_path, parser=ParserImageInTar(data_path))</span><br></pre></td></tr></table></figure></p>
<h3 id="自定义解析器——以pets数据集为例"><a href="#自定义解析器——以pets数据集为例" class="headerlink" title="自定义解析器——以pets数据集为例"></a>自定义解析器——以pets数据集为例</h3><p>遗憾的是，数据集的结构并不总是像<code>ImageNet</code>那样；也就是说，具有以下结构：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root/class_1/xx1.jpg</span><br><span class="line">root/class_1/xx2.jpg</span><br><span class="line">root/class_2/xx1.jpg</span><br><span class="line">root/class_2/xx2.jpg</span><br></pre></td></tr></table></figure><br>对于这些数据集，<code>ImageDataset</code>不会开箱即用。虽然我们总是可以实现一个自定义的数据集来处理这个问题，但这可能是一个挑战，取决于数据的存储方式。另一个选择是编写一个与<code>ImageDataset</code>配合使用的自定义解析器。<br>作为一个例子，考虑前面牛津大学的宠物数据集，其中所有的图片都位于一个文件夹中，而类的名称——在这种情况下是每个品种的名称——包含在文件名中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ls pets/images/</span><br><span class="line"></span><br><span class="line">Abyssinian_100.jpg*                 keeshond_186.jpg*</span><br><span class="line">Abyssinian_100.mat                  keeshond_187.jpg*</span><br><span class="line">Abyssinian_101.jpg*                 keeshond_188.jpg*</span><br><span class="line">Abyssinian_101.mat                  keeshond_189.jpg*</span><br><span class="line">Abyssinian_102.jpg*                 keeshond_18.jpg*</span><br><span class="line">Abyssinian_102.mat                  keeshond_190.jpg*</span><br><span class="line">Abyssinian_103.jpg*                 keeshond_191.jpg*</span><br><span class="line">Abyssinian_104.jpg*                 keeshond_192.jpg*</span><br><span class="line">Abyssinian_105.jpg*                 keeshond_193.jpg*</span><br><span class="line">Abyssinian_106.jpg*                 keeshond_194.jpg*</span><br><span class="line">................</span><br></pre></td></tr></table></figure><br>在这种情况下，由于我们仍然是从本地文件系统加载图片，所以只需对<code>ParserImageFolder</code>稍作调整。<br>先看看<code>ParserImageFolder</code>是如何实现的，以获得启发：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">??timm.data.parsers.parser_image_folder.ParserImageFolder</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ParserImageFolder</span>(<span class="params">Parser</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">            self,</span></span></span><br><span class="line"><span class="function"><span class="params">            root,</span></span></span><br><span class="line"><span class="function"><span class="params">            class_map=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.root = root</span><br><span class="line">        class_to_idx = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> class_map:</span><br><span class="line">            class_to_idx = load_class_map(class_map, root)</span><br><span class="line">        self.samples, self.class_to_idx = find_images_and_targets(root, class_to_idx=class_to_idx)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.samples) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(</span><br><span class="line">                <span class="string">f&#x27;Found 0 images in subfolders of <span class="subst">&#123;root&#125;</span>. Supported image extensions are <span class="subst">&#123;<span class="string">&quot;, &quot;</span>.join(IMG_EXTENSIONS)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        path, target = self.samples[index]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">open</span>(path, <span class="string">&#x27;rb&#x27;</span>), target</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.samples)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_filename</span>(<span class="params">self, index, basename=<span class="literal">False</span>, absolute=<span class="literal">False</span></span>):</span></span><br><span class="line">        filename = self.samples[index][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> basename:</span><br><span class="line">            filename = os.path.basename(filename)</span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> absolute:</span><br><span class="line">            filename = os.path.relpath(filename, self.root)</span><br><span class="line">        <span class="keyword">return</span> filename</span><br></pre></td></tr></table></figure><br>可以看到，<code>ParserImageFolder</code>做了几件事：</p>
<ul>
<li>为类别创建一个映射<code>class_map</code></li>
<li>实现<code>__len__</code>以返回样本的数量</li>
<li>实现<code>__filename</code>来返回样本的文件名，通过选项来决定它应该是绝对路径还是相对路径</li>
<li>实现<code>__getitem__</code>以返回样本和目标。</li>
</ul>
<p>现在理解了必须实现的方法，可以在此基础上创建自定义的实现。此处使用了标准库中的<code>pathlib</code>来提取类别名并处理路径（可能比<code>os</code>更容易操作）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> timm.data.parsers.parser <span class="keyword">import</span> Parser</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ParserImageName</span>(<span class="params">Parser</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root, class_to_idx=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.root = Path(root)</span><br><span class="line">        self.samples = <span class="built_in">list</span>(self.root.glob(<span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> class_to_idx:</span><br><span class="line">            self.class_to_idx = class_to_idx</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            classes = <span class="built_in">sorted</span>(</span><br><span class="line">                <span class="built_in">set</span>([self.__extract_label_from_path(p) <span class="keyword">for</span> p <span class="keyword">in</span> self.samples]),</span><br><span class="line">                key=<span class="keyword">lambda</span> s: s.lower(),</span><br><span class="line">            )</span><br><span class="line">            self.class_to_idx = &#123;c: idx <span class="keyword">for</span> idx, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__extract_label_from_path</span>(<span class="params">self, path</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;_&quot;</span>.join(path.parts[-<span class="number">1</span>].split(<span class="string">&quot;_&quot;</span>)[<span class="number">0</span>:-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        path = self.samples[index]</span><br><span class="line">        target = self.class_to_idx[self.__extract_label_from_path(path)]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">open</span>(path, <span class="string">&quot;rb&quot;</span>), target</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.samples)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_filename</span>(<span class="params">self, index, basename=<span class="literal">False</span>, absolute=<span class="literal">False</span></span>):</span></span><br><span class="line">        filename = self.samples[index][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> basename:</span><br><span class="line">            filename = filename.parts[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> absolute:</span><br><span class="line">            filename = filename.absolute()</span><br><span class="line">        <span class="keyword">return</span> filename</span><br></pre></td></tr></table></figure><br>现在就可以把解析器的一个实例传递给<code>ImageDataset</code>，应该能使它正确地加载宠物数据集：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data_path = Path(<span class="string">&#x27;pets/images&#x27;</span>)</span><br><span class="line">ds = ImageDataset(<span class="built_in">str</span>(data_path), parser=ParserImageName(data_path))</span><br><span class="line">ds[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">(&lt;PIL.Image.Image image mode=RGB size=500x332&gt;, <span class="number">9</span>)</span><br></pre></td></tr></table></figure><br>此外，与默认的解析器一样，可以查看类别与索引之间的映射：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">ds.parser.class_to_idx</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;Abyssinian&#x27;</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="string">&#x27;american_bulldog&#x27;</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">&#x27;american_pit_bull_terrier&#x27;</span>: <span class="number">2</span>,</span><br><span class="line"> <span class="string">&#x27;basset_hound&#x27;</span>: <span class="number">3</span>,</span><br><span class="line"> <span class="string">&#x27;beagle&#x27;</span>: <span class="number">4</span>,</span><br><span class="line"> <span class="string">&#x27;Bengal&#x27;</span>: <span class="number">5</span>,</span><br><span class="line"> <span class="string">&#x27;Birman&#x27;</span>: <span class="number">6</span>,</span><br><span class="line"> <span class="string">&#x27;Bombay&#x27;</span>: <span class="number">7</span>,</span><br><span class="line"> <span class="string">&#x27;boxer&#x27;</span>: <span class="number">8</span>,</span><br><span class="line"> <span class="string">&#x27;British_Shorthair&#x27;</span>: <span class="number">9</span>,</span><br><span class="line"> <span class="string">&#x27;chihuahua&#x27;</span>: <span class="number">10</span>,</span><br><span class="line"> <span class="string">&#x27;Egyptian_Mau&#x27;</span>: <span class="number">11</span>,</span><br><span class="line"> <span class="string">&#x27;english_cocker_spaniel&#x27;</span>: <span class="number">12</span>,</span><br><span class="line"> <span class="string">&#x27;english_setter&#x27;</span>: <span class="number">13</span>,</span><br><span class="line"> <span class="string">&#x27;german_shorthaired&#x27;</span>: <span class="number">14</span>,</span><br><span class="line"> <span class="string">&#x27;great_pyrenees&#x27;</span>: <span class="number">15</span>,</span><br><span class="line"> <span class="string">&#x27;havanese&#x27;</span>: <span class="number">16</span>,</span><br><span class="line"> <span class="string">&#x27;japanese_chin&#x27;</span>: <span class="number">17</span>,</span><br><span class="line"> <span class="string">&#x27;keeshond&#x27;</span>: <span class="number">18</span>,</span><br><span class="line"> <span class="string">&#x27;leonberger&#x27;</span>: <span class="number">19</span>,</span><br><span class="line"> <span class="string">&#x27;Maine_Coon&#x27;</span>: <span class="number">20</span>,</span><br><span class="line"> <span class="string">&#x27;miniature_pinscher&#x27;</span>: <span class="number">21</span>,</span><br><span class="line"> <span class="string">&#x27;newfoundland&#x27;</span>: <span class="number">22</span>,</span><br><span class="line"> <span class="string">&#x27;Persian&#x27;</span>: <span class="number">23</span>,</span><br><span class="line"> <span class="string">&#x27;pomeranian&#x27;</span>: <span class="number">24</span>,</span><br><span class="line"> <span class="string">&#x27;pug&#x27;</span>: <span class="number">25</span>,</span><br><span class="line"> <span class="string">&#x27;Ragdoll&#x27;</span>: <span class="number">26</span>,</span><br><span class="line"> <span class="string">&#x27;Russian_Blue&#x27;</span>: <span class="number">27</span>,</span><br><span class="line"> <span class="string">&#x27;saint_bernard&#x27;</span>: <span class="number">28</span>,</span><br><span class="line"> <span class="string">&#x27;samoyed&#x27;</span>: <span class="number">29</span>,</span><br><span class="line"> <span class="string">&#x27;scottish_terrier&#x27;</span>: <span class="number">30</span>,</span><br><span class="line"> <span class="string">&#x27;shiba_inu&#x27;</span>: <span class="number">31</span>,</span><br><span class="line"> <span class="string">&#x27;Siamese&#x27;</span>: <span class="number">32</span>,</span><br><span class="line"> <span class="string">&#x27;Sphynx&#x27;</span>: <span class="number">33</span>,</span><br><span class="line"> <span class="string">&#x27;staffordshire_bull_terrier&#x27;</span>: <span class="number">34</span>,</span><br><span class="line"> <span class="string">&#x27;wheaten_terrier&#x27;</span>: <span class="number">35</span>,</span><br><span class="line"> <span class="string">&#x27;yorkshire_terrier&#x27;</span>: <span class="number">36</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h1><p><code>timm</code>具有大量的优化器，其中一些是<code>PyTorch</code>所不具备的。除了使人们能够方便地使用<code>SGD</code>、<code>Adam</code>和<code>AdamW</code>等熟悉的优化器外，还有一些值得注意的优化器有：</p>
<ul>
<li><code>AdamP</code>：见<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.08217">该论文</a></li>
<li><code>RMSPropTF</code>：基于原始<code>TensorFlow</code>实现的<code>RMSProp</code>的实现，以及<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/23796">这里</a>讨论的其他小的调整。根据<code>Chris Hughes</code>的经验，这通常会产生比<code>PyTorch</code>版本更稳定的训练效果。</li>
<li><code>LAMB</code>：来自<code>Apex</code>的<code>FusedLAMB</code>优化器的纯<code>pytorch</code>变体，在使用<code>PyTorch XLA</code>时，它与<code>TPU</code>兼容。</li>
<li><code>AdaBelief</code>：见<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.07468">该论文</a>。关于设置超参数的指导可在<a target="_blank" rel="noopener" href="https://github.com/juntang-zhuang/Adabelief-Optimizer#quick-guide">此</a>获得。</li>
<li><code>MADGRAD</code>：见<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2101.11075">该论文</a></li>
<li><code>AdaHessian</code>：自适应二阶优化器，见<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.00719">该论文</a>。</li>
</ul>
<p><code>timm</code>中的优化器支持与<code>torch.optim</code>中的优化器相同的接口，在大多数情况下，可以简单地放入训练脚本中，不需要做任何改动。<br>要查看<code>timm</code>实现的所有优化器，可以查看<code>timm.opt</code>模块：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line"><span class="keyword">import</span> timm.optim</span><br><span class="line"></span><br><span class="line">[cls_name <span class="keyword">for</span> cls_name, cls_obj <span class="keyword">in</span> inspect.getmembers(timm.optim) <span class="keyword">if</span> inspect.isclass(cls_obj) <span class="keyword">if</span> cls_name !=<span class="string">&#x27;Lookahead&#x27;</span>]</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;AdaBelief&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Adafactor&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Adahessian&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;AdamP&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;AdamW&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Lamb&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Lars&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;MADGRAD&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Nadam&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;NvNovoGrad&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;RAdam&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;RMSpropTF&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;SGDP&#x27;</span>]</span><br></pre></td></tr></table></figure><br>创建一个优化器的最简单方法是使用<code>create_optimizer_v2</code>工厂函数，该函数期望得到以下信息：</p>
<ul>
<li>一个模型，或一组参数</li>
<li>优化器的名称</li>
<li>任何要传递给优化器的参数</li>
</ul>
<p>可以使用这个函数来创建基于<code>timm</code>的优化器，以及来自<code>torch.optimizer</code>的优化器和来自<code>Apex</code>的<a target="_blank" rel="noopener" href="https://nvidia.github.io/apex/optimizers.html">融合优化器</a>（如果已安装）的任意的优化器。</p>
<p>看一下一些例子。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(<span class="number">2</span>, <span class="number">1</span>),</span><br><span class="line">    torch.nn.Flatten(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line">optimizer = timm.optim.create_optimizer_v2(model, opt=<span class="string">&#x27;sgd&#x27;</span>, lr=<span class="number">0.01</span>, momentum=<span class="number">0.8</span>); </span><br><span class="line"></span><br><span class="line">optimizer, <span class="built_in">type</span>(optimizer)</span><br><span class="line"></span><br><span class="line">(SGD (</span><br><span class="line"> Parameter Group <span class="number">0</span></span><br><span class="line">     dampening: <span class="number">0</span></span><br><span class="line">     lr: <span class="number">0.01</span></span><br><span class="line">     momentum: <span class="number">0.8</span></span><br><span class="line">     nesterov: <span class="literal">True</span></span><br><span class="line">     weight_decay: <span class="number">0.0</span></span><br><span class="line"> ),</span><br><span class="line"> torch.optim.sgd.SGD)</span><br></pre></td></tr></table></figure><br>可以看到，由于<code>timm</code>不包含<code>SGD</code>的实现，上述代码使用<code>torch.optim</code>的实现来创建了优化器。<br>再试着创建一个在<code>timm</code>中实现的优化器：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">optimizer = timm.optim.create_optimizer_v2(model, </span><br><span class="line">                                           opt=<span class="string">&#x27;lamb&#x27;</span>,</span><br><span class="line">                                           lr=<span class="number">0.01</span>,</span><br><span class="line">                                           weight_decay=<span class="number">0.01</span>)</span><br><span class="line">optimizer, <span class="built_in">type</span>(optimizer)</span><br><span class="line"></span><br><span class="line">(Lamb (</span><br><span class="line"> Parameter Group <span class="number">0</span></span><br><span class="line">     always_adapt: <span class="literal">False</span></span><br><span class="line">     betas: (<span class="number">0.9</span>, <span class="number">0.999</span>)</span><br><span class="line">     bias_correction: <span class="literal">True</span></span><br><span class="line">     eps: <span class="number">1e-06</span></span><br><span class="line">     grad_averaging: <span class="literal">True</span></span><br><span class="line">     lr: <span class="number">0.01</span></span><br><span class="line">     max_grad_norm: <span class="number">1.0</span></span><br><span class="line">     trust_clip: <span class="literal">False</span></span><br><span class="line">     weight_decay: <span class="number">0.0</span></span><br><span class="line"> </span><br><span class="line"> Parameter Group <span class="number">1</span></span><br><span class="line">     always_adapt: <span class="literal">False</span></span><br><span class="line">     betas: (<span class="number">0.9</span>, <span class="number">0.999</span>)</span><br><span class="line">     bias_correction: <span class="literal">True</span></span><br><span class="line">     eps: <span class="number">1e-06</span></span><br><span class="line">     grad_averaging: <span class="literal">True</span></span><br><span class="line">     lr: <span class="number">0.01</span></span><br><span class="line">     max_grad_norm: <span class="number">1.0</span></span><br><span class="line">     trust_clip: <span class="literal">False</span></span><br><span class="line">     weight_decay: <span class="number">0.01</span></span><br><span class="line"> ),</span><br><span class="line"> timm.optim.lamb.Lamb)</span><br></pre></td></tr></table></figure><br>当然，如果不愿意使用<code>create_optimizer_v2</code>，所有这些优化器都可以用常规的方式创建。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = timm.optim.RMSpropTF(model.parameters(), lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h2><p>大部分的优化器用法如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># replace </span></span><br><span class="line"><span class="comment"># optimizer = torch.optim.Adam(model.parameters(), lr=0.01)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># with</span></span><br><span class="line">optimizer = timm.optim.AdamP(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> num_epochs:</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> training_dataloader:</span><br><span class="line">        inputs, targets = batch</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = loss_function(outputs, targets)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br></pre></td></tr></table></figure><br>截至当前，唯一的例外是二阶<code>Adahessian</code>优化器，它在执行反向传播步骤时需要一个小的调整；类似的调整可能需要用于未来可能添加的其他二阶优化器。即：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">optimizer = timm.optim.Adahessian(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">is_second_order = <span class="built_in">hasattr</span>(optimizer, <span class="string">&#x27;is_second_order&#x27;</span>) <span class="keyword">and</span> optimizer.is_second_order <span class="comment"># True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> num_epochs:</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> training_dataloader:</span><br><span class="line">        inputs, targets = batch</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = loss_function(outputs, targets)</span><br><span class="line"></span><br><span class="line">        loss.backward(create_graph=second_order)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br></pre></td></tr></table></figure></p>
<h2 id="Lookahead"><a href="#Lookahead" class="headerlink" title="Lookahead"></a>Lookahead</h2><p><code>timm</code>也使我们能够将<code>lookahead</code>算法应用于优化器；参考资料比如<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=TxGxiDK0Ccc">这个视频</a>。<code>Lookahead</code>可以提高学习的稳定性并降低其内部优化器的方差，其计算和内存成本可以忽略不计。<br>可以通过在优化器名称前加上<code>lookahead_</code>来将<code>Lookahead</code>应用到优化器中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = timm.optim.create_optimizer_v2(model.parameters(), opt=<span class="string">&#x27;lookahead_adam&#x27;</span>, lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><br>或由<code>timm</code>的<code>Lookahead</code>类中的优化器实例进行包装：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timm.optim.Lookahead(optimizer, alpha=<span class="number">0.5</span>, k=<span class="number">6</span>)</span><br></pre></td></tr></table></figure><br>当使用<code>Lookahead</code>时，需要更新训练脚本，加入以下一行，以更新慢的权重：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer.sync_lookahead()</span><br></pre></td></tr></table></figure><br>一个例子如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">optimizer = timm.optim.AdamP(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">optimizer = timm.optim.Lookahead(optimizer)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> num_epochs:</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> training_dataloader:</span><br><span class="line">        inputs, targets = batch</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = loss_function(outputs, targets)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    optimizer.sync_lookahead()</span><br></pre></td></tr></table></figure></p>
<h1 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h1><p><code>timm</code>包含以下调度器</p>
<ul>
<li><code>StepLRScheduler</code>：学习率每<code>n</code>步衰减；类似于<code>torch.optim.lr_scheduler.StepLR</code></li>
<li><code>MultiStepLRScheduler</code>：一个支持多个目标里程碑的步进调度器，在这些里程碑上降低学习率；类似于<code>torch.optim.lr_scheduler.MultiStepLR</code></li>
<li><code>PlateauLRScheduler</code>：在每次指定的指标出现高原期时，以指定的系数降低学习率；类似于<code>`torch.optim.lr_scheduler.ReduceLROnPlateau</code></li>
<li><code>CosineLRScheduler</code>：具有重启功能的余弦衰减调度器；类似于<code>torch.optim.lr_scheduler.CosineAnnealingWarmRestarts</code></li>
<li><code>TanhLRScheduler</code>：带重启的双曲正切衰变调度器</li>
<li><code>PolyLRScheduler</code>：多项式衰变调度器。</li>
</ul>
<p>虽然许多在<code>timm</code>中实现的调度器在<code>PyTorch</code>中也有对应的调度器，但<code>timm</code>版本通常有不同的默认超参数，并提供额外的选项和灵活性；所有<code>timm</code>调度器都有预热<code>epochs</code>，以及在调度中添加随机噪声的选项。此外，<code>CosineLRScheduler</code>和<code>PolyLRScheduler</code>支持被称为<code>k-decay</code>的衰减选项。</p>
<h2 id="应用案例-1"><a href="#应用案例-1" class="headerlink" title="应用案例"></a>应用案例</h2><p>在研究这些调度器提供的一些选项之前，首先探讨一下如何在自定义训练脚本中使用<code>timm</code>的调度器。<br>与<code>PyTorch</code>中包含的调度器不同，在每个<code>epoch</code>中更新两次<code>timm</code>调度器是最佳实践。</p>
<ul>
<li><code>.step_update</code>方法应该在每次优化器更新后被调用，并给出下一次更新的索引；这就是<code>PyTorch</code>调度器调用<code>.step</code>的地方</li>
<li><code>.step</code>方法应该在每个<code>epoch</code>结束时被调用，并标明下一个<code>epoch</code>的索引。</li>
</ul>
<p>通过明确提供更新次数和<code>epoch</code>索引，这使得<code>timm</code>调度器能够消除在<code>PyTorch</code>调度器中观察到的混乱的 <code>last_epoch</code>和<code>-1</code>行为。一个例子如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">training_epochs = <span class="number">300</span></span><br><span class="line">cooldown_epochs = <span class="number">10</span></span><br><span class="line">num_epochs = training_epochs + cooldown_epochs</span><br><span class="line"></span><br><span class="line">optimizer = timm.optim.AdamP(my_model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">scheduler = timm.scheduler.CosineLRScheduler(optimizer, t_initial=training_epochs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line"></span><br><span class="line">    num_steps_per_epoch = <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">    num_updates = epoch * num_steps_per_epoch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> training_dataloader:</span><br><span class="line">        inputs, targets = batch</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = loss_function(outputs, targets)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        scheduler.step_update(num_updates=num_updates)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    scheduler.step(epoch + <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="调节学习率调度器"><a href="#调节学习率调度器" class="headerlink" title="调节学习率调度器"></a>调节学习率调度器</h2><p>为了展示<code>timm</code>提供的一些选项，探索一些可用的超参数，以及修改这些参数对学习率调度的影响。<br>在这里，将专注于<code>CosineLRScheduler</code>，因为这是<code>timm</code>训练脚本中默认使用的调度器。然而，如上所述，添加预热和噪声等功能存在于上述所有的调度器中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scheduler = timm.scheduler.CosineLRScheduler(optimizer,</span><br><span class="line">                                            t_initial=num_epoch_repeat*num_steps_per_epoch,</span><br><span class="line">                                            lr_min=<span class="number">1e-6</span>,</span><br><span class="line">                                            cycle_limit=num_epoch_repeat+<span class="number">1</span>,</span><br><span class="line">                                            t_in_epochs=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="指数滑动平均模型"><a href="#指数滑动平均模型" class="headerlink" title="指数滑动平均模型"></a>指数滑动平均模型</h1><p>在训练一个模型时，通过对整个训练过程中观察到的参数进行移动平均来设置模型的权重值，而不是使用最后一次增量更新后得到的参数，这样做是有益的。在实践中，这通常是通过维护<code>EMA</code>模型来实现的，<code>EMA</code>模型是我们正在训练的模型的一个副本。然而，我们不是在每个更新步骤后更新这个模型的所有参数，而是使用现有参数值和更新值的线性组合来设置这些参数。<br>为了理解为什么这可能是有益的，让我们考虑这样的情况：我们的模型，在训练的早期阶段，在一批数据上表现得特别差。这可能会导致对参数进行大量更新，过度补偿所获得的高损失，这对接下来的批次是不利的。通过只纳入最新参数的一小部分，大的更新将被 “平滑”，对模型的权重产生较小的整体影响。<br>有时，这些平均的参数在评估过程中有时会产生明显更好的结果，这种技术已经被用于流行模型的一些训练方案中，如训练<code>MNASNet</code>、<code>MobileNet-V3</code>和<code>EfficientNet</code>。使用<code>timm</code>中实现的<code>ModelEmaV2</code>模块，可以复制这种行为，并将同样的做法应用于自己的训练脚本。<br>（具体技术细节不再详述）</p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechat_reward.png" alt="Xin-Bo Qi(亓欣波) WeChat Pay">
        <p>WeChat Pay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/06/19/node_red/" rel="prev" title="物联网应用的低代码开发工具Node-RED上手及案例">
      <i class="fa fa-chevron-left"></i> 物联网应用的低代码开发工具Node-RED上手及案例
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/06/26/pytorch-accelerated_5/" rel="next" title="轻量级PyTorch通用训练模板pytorch-accelerated解析：5 -- Trainer运行及案例赏析">
      轻量级PyTorch通用训练模板pytorch-accelerated解析：5 -- Trainer运行及案例赏析 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%89%E8%A3%85"><span class="nav-number">2.</span> <span class="nav-text">安装</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%89"><span class="nav-number">2.1.</span> <span class="nav-text">示例数据集（可选）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%97%E5%87%BA%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.1.</span> <span class="nav-text">列出可用模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.</span> <span class="nav-text">创建模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E8%A7%84%E7%94%A8%E6%B3%95"><span class="nav-number">3.2.1.</span> <span class="nav-text">常规用法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E5%8F%AF%E5%8F%98%E8%BE%93%E5%85%A5%E9%80%9A%E9%81%93%E6%95%B0%E7%9B%AE%E7%9A%84%E5%9B%BE%E5%83%8F%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.2.</span> <span class="nav-text">创建可变输入通道数目的图像的预训练模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9A%E5%88%B6%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.3.</span> <span class="nav-text">定制化模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%B9%E5%8F%98%E8%BE%93%E5%87%BA%E7%B1%BB%E5%88%AB%E6%95%B0%E9%87%8F"><span class="nav-number">3.3.1.</span> <span class="nav-text">改变输出类别数量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E6%B1%A0%E5%8C%96"><span class="nav-number">3.3.2.</span> <span class="nav-text">全局池化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E5%B7%B2%E6%9C%89%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.3.3.</span> <span class="nav-text">修改已有模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E6%96%B0%E7%9A%84%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">3.3.4.</span> <span class="nav-text">创建新的分类器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-number">3.4.</span> <span class="nav-text">特征提取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E4%B8%AA%E7%89%B9%E5%BE%81%E8%BE%93%E5%87%BA"><span class="nav-number">3.4.1.</span> <span class="nav-text">多个特征输出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Torch-FX"><span class="nav-number">3.4.2.</span> <span class="nav-text">使用Torch FX</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA"><span class="nav-number">3.5.</span> <span class="nav-text">模型导出</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%BC%E5%87%BA%E4%B8%BATorchScript"><span class="nav-number">3.5.1.</span> <span class="nav-text">导出为TorchScript</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%BC%E5%87%BA%E4%B8%BAONNX"><span class="nav-number">3.5.2.</span> <span class="nav-text">导出为ONNX</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="nav-number">4.</span> <span class="nav-text">数据增强</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#RandAugment"><span class="nav-number">4.1.</span> <span class="nav-text">RandAugment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CutMix%E5%92%8CMixup"><span class="nav-number">4.2.</span> <span class="nav-text">CutMix和Mixup</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">5.</span> <span class="nav-text">数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A0%E8%BD%BDTorchVision%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">5.1.</span> <span class="nav-text">加载TorchVision数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A0%E8%BD%BDTensorFlow%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">5.2.</span> <span class="nav-text">加载TensorFlow数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A0%E8%BD%BD%E6%9C%AC%E5%9C%B0%E6%95%B0%E6%8D%AE"><span class="nav-number">5.3.</span> <span class="nav-text">加载本地数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ImageDataset%E7%B1%BB"><span class="nav-number">5.4.</span> <span class="nav-text">ImageDataset类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E9%80%89%E6%8B%A9%E8%A7%A3%E6%9E%90%E5%99%A8%E2%80%94%E2%80%94%E4%BB%A5tar%E5%8C%85%E4%B8%BA%E4%BE%8B"><span class="nav-number">5.4.1.</span> <span class="nav-text">手动选择解析器——以tar包为例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E8%A7%A3%E6%9E%90%E5%99%A8%E2%80%94%E2%80%94%E4%BB%A5pets%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%BA%E4%BE%8B"><span class="nav-number">5.4.2.</span> <span class="nav-text">自定义解析器——以pets数据集为例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="nav-number">6.</span> <span class="nav-text">优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="nav-number">6.1.</span> <span class="nav-text">应用案例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lookahead"><span class="nav-number">6.2.</span> <span class="nav-text">Lookahead</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%B0%83%E5%BA%A6%E5%99%A8"><span class="nav-number">7.</span> <span class="nav-text">调度器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B-1"><span class="nav-number">7.1.</span> <span class="nav-text">应用案例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B0%83%E8%8A%82%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E5%BA%A6%E5%99%A8"><span class="nav-number">7.2.</span> <span class="nav-text">调节学习率调度器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8C%87%E6%95%B0%E6%BB%91%E5%8A%A8%E5%B9%B3%E5%9D%87%E6%A8%A1%E5%9E%8B"><span class="nav-number">8.</span> <span class="nav-text">指数滑动平均模型</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xin-Bo Qi(亓欣波)"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Xin-Bo Qi(亓欣波)</p>
  <div class="site-description" itemprop="description">Digitize everything to realize Digitalization!</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">167</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">56</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/qixinbo" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:qixinbo@gmail.com" title="E-Mail → mailto:qixinbo@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/qixinbo" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fas fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.tsinghua.edu.cn/" title="https:&#x2F;&#x2F;www.tsinghua.edu.cn" rel="noopener" target="_blank">THU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.imr.cas.cn/" title="http:&#x2F;&#x2F;www.imr.cas.cn" rel="noopener" target="_blank">IMR</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.sdu.edu.cn/" title="http:&#x2F;&#x2F;www.sdu.edu.cn" rel="noopener" target="_blank">SDU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://liam0205.me/" title="http:&#x2F;&#x2F;liam0205.me&#x2F;" rel="noopener" target="_blank">黄晨成</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xin-Bo Qi(亓欣波)</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://qixinbo.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://qixinbo.github.io/2022/06/25/timm/";
    this.page.identifier = "2022/06/25/timm/";
    this.page.title = "PyTorch图像模型库timm解析";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://qixinbo.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
