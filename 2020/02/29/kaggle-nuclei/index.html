<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"qixinbo.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="从2015年开始，Kaggle每年都举办一次Data Science Bowl，旨在召集众多力量开发算法，来解决当前某一特定领域的迫切问题。2018年的数据碗的任务是识别细胞的细胞核nuclei，从而使得更加方便地进行药物测试，使得新药的上市时间缩短。  Yun Chen分享了他的使用PyTorch&#x2F;UNet算法的notebook，见这里，本文是对该notebook代码的详细解析和再现，并适当做了">
<meta property="og:type" content="article">
<meta property="og:title" content="Kaggle细胞赛：基于PyTorch&#x2F;UNet算法的细胞核识别">
<meta property="og:url" content="http://qixinbo.github.io/2020/02/29/kaggle-nuclei/index.html">
<meta property="og:site_name" content="数字旗手">
<meta property="og:description" content="从2015年开始，Kaggle每年都举办一次Data Science Bowl，旨在召集众多力量开发算法，来解决当前某一特定领域的迫切问题。2018年的数据碗的任务是识别细胞的细胞核nuclei，从而使得更加方便地进行药物测试，使得新药的上市时间缩短。  Yun Chen分享了他的使用PyTorch&#x2F;UNet算法的notebook，见这里，本文是对该notebook代码的详细解析和再现，并适当做了">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/75554371-2b28f780-5a75-11ea-9357-928dde25f866.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/75554405-3d0a9a80-5a75-11ea-9663-e85c11cf5df3.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/75503501-bde37b00-5a10-11ea-99ac-9c9015aa1bb0.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/75505152-71e70500-5a15-11ea-9784-2b27b6731e80.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/75517269-49710200-5a39-11ea-8ae3-7316d43727cf.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/75517361-76bdb000-5a39-11ea-85a2-a869f7443195.png">
<meta property="article:published_time" content="2020-02-28T16:00:00.000Z">
<meta property="article:modified_time" content="2021-03-26T07:45:50.149Z">
<meta property="article:author" content="Xin-Bo Qi(亓欣波)">
<meta property="article:tag" content="kaggle">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://user-images.githubusercontent.com/6218739/75554371-2b28f780-5a75-11ea-9357-928dde25f866.png">

<link rel="canonical" href="http://qixinbo.github.io/2020/02/29/kaggle-nuclei/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Kaggle细胞赛：基于PyTorch/UNet算法的细胞核识别 | 数字旗手</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="数字旗手" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">数字旗手</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">电气化、自动化、数字化、智能化、智慧化</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-scholar">

    <a href="/scholar/" rel="section"><i class="fa fa-chart-bar fa-fw"></i>scholar</a>

  </li>
        <li class="menu-item menu-item-sources">

    <a href="/sources/" rel="section"><i class="fa fa-rss fa-fw"></i>sources</a>

  </li>
        <li class="menu-item menu-item-gallery">

    <a href="/gallery/" rel="section"><i class="fa fa-file-image fa-fw"></i>gallery</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404.html" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://qixinbo.github.io/2020/02/29/kaggle-nuclei/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Xin-Bo Qi(亓欣波)">
      <meta itemprop="description" content="Digitize everything to realize Digitalization!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数字旗手">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kaggle细胞赛：基于PyTorch/UNet算法的细胞核识别
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-29 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-29T00:00:00+08:00">2020-02-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-26 15:45:50" itemprop="dateModified" datetime="2021-03-26T15:45:50+08:00">2021-03-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/02/29/kaggle-nuclei/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/02/29/kaggle-nuclei/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>从2015年开始，Kaggle每年都举办一次Data Science Bowl，旨在召集众多力量开发算法，来解决当前某一特定领域的迫切问题。2018年的数据碗的任务是识别细胞的细胞核nuclei，从而使得更加方便地进行药物测试，使得新药的上市时间缩短。</p>
<p>Yun Chen分享了他的使用PyTorch/UNet算法的notebook，见<a target="_blank" rel="noopener" href="https://www.kaggle.com/cloudfall/pytorch-tutorials-on-dsb2018">这里</a>，本文是对该notebook代码的详细解析和再现，并适当做了一些修改。</p>
<p>再分享一篇挺好的背景文章：<br><a target="_blank" rel="noopener" href="https://www.zybuluo.com/Team/note/1205894">基于深度学习的图像语义分割算法综述</a></p>
<h1 id="数据集分析"><a href="#数据集分析" class="headerlink" title="数据集分析"></a>数据集分析</h1><h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!kaggle competitions download -c data-science-bowl-<span class="number">2018</span></span><br></pre></td></tr></table></figure>
<h2 id="解压并迁移数据"><a href="#解压并迁移数据" class="headerlink" title="解压并迁移数据"></a>解压并迁移数据</h2><p>解压数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">!unzip stage1_sample_submission.csv.<span class="built_in">zip</span></span><br><span class="line">!unzip stage1_solution.csv.<span class="built_in">zip</span></span><br><span class="line">!unzip stage1_train_labels.csv.<span class="built_in">zip</span></span><br><span class="line">!unzip stage2_sample_submission_final.csv.<span class="built_in">zip</span></span><br><span class="line"> </span><br><span class="line">!mkdir stage1_test</span><br><span class="line">!unzip stage1_test.<span class="built_in">zip</span> -d stage1_test</span><br><span class="line"></span><br><span class="line">!mkdir stage1_train</span><br><span class="line">!unzip stage1_train.<span class="built_in">zip</span> -d stage1_train</span><br><span class="line"></span><br><span class="line">!mkdir stage2_test_final</span><br><span class="line">!unzip stage2_test_final.<span class="built_in">zip</span> -d stage2_test_final</span><br></pre></td></tr></table></figure>

<p>迁移数据到Google Drive：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">!mkdir nuclei</span><br><span class="line">!mv stage1_test nuclei</span><br><span class="line">!mv stage1_train nuclei</span><br><span class="line">!mv stage2_test_final/ nuclei</span><br><span class="line">!mv *.csv nuclei</span><br><span class="line">!mv nuclei /content/drive/My\ Drive</span><br></pre></td></tr></table></figure>
<p>这样就做到了持久化，防止notebook重启时数据丢失。</p>
<h2 id="数据文件描述"><a href="#数据文件描述" class="headerlink" title="数据文件描述"></a>数据文件描述</h2><p>（1）/stage1_train/*：该文件夹是训练集，包含训练用的图像及其掩膜图像<br>（2）/stage1_test/*：该文件夹是测试集，仅包含图像<br>（3）/stage2_test/*：这是第二阶段的测试集，仅包含图像<br>（4）stage1_sample_submission.csv：在第一阶段需要提交的文件格式<br>（5）stage2_sample_submission.csv：在第二阶段需要提交的文件格式<br>（6）stage1_train_labels.csv：该文件是训练集中的掩膜图像的游程编码RLE</p>
<h1 id="加载必要的Python包"><a href="#加载必要的Python包" class="headerlink" title="加载必要的Python包"></a>加载必要的Python包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line">TRAIN_PATH = <span class="string">&#x27;./train.pth&#x27;</span></span><br><span class="line">TEST_PATH = <span class="string">&#x27;./test.tph&#x27;</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<h1 id="数据集加载"><a href="#数据集加载" class="headerlink" title="数据集加载"></a>数据集加载</h1><p>数据集加载是至关重要的一步，也是非常繁琐的一步。因为这一步无法标准化，必须针对特定的数据集进行解析。</p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>下面是对该竞赛的数据集的处理方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span>(<span class="params">file_path, has_mask=<span class="literal">True</span></span>):</span></span><br><span class="line">  file_path = Path(file_path)</span><br><span class="line">  files = <span class="built_in">sorted</span>(<span class="built_in">list</span>(file_path.iterdir()))</span><br><span class="line">  datas = []</span><br><span class="line">  <span class="keyword">for</span> file <span class="keyword">in</span> tqdm(files):</span><br><span class="line">    item = &#123;&#125;</span><br><span class="line">    imgs = []</span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> (file/<span class="string">&#x27;images&#x27;</span>).iterdir():</span><br><span class="line">      img = io.imread(image)</span><br><span class="line">      imgs.append(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(imgs) == <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> img.shape[<span class="number">2</span>] &gt; <span class="number">3</span>:</span><br><span class="line">      <span class="keyword">assert</span> (img[:, :, <span class="number">3</span>]!=<span class="number">255</span>).<span class="built_in">sum</span>() == <span class="number">0</span></span><br><span class="line">    img = img[:, :, :<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> has_mask:</span><br><span class="line">      mask_files = <span class="built_in">list</span>((file/<span class="string">&#x27;masks&#x27;</span>).iterdir())</span><br><span class="line">      masks = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> i, mask <span class="keyword">in</span> <span class="built_in">enumerate</span>(mask_files):</span><br><span class="line">        mask = io.imread(mask)</span><br><span class="line">        <span class="keyword">assert</span> (mask[(mask!=<span class="number">0</span>)] == <span class="number">255</span>).<span class="built_in">all</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> masks <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">          H, W = mask.shape</span><br><span class="line">          masks = np.zeros((<span class="built_in">len</span>(mask_files), H, W))</span><br><span class="line">        masks[i] = mask</span><br><span class="line"></span><br><span class="line">      total_mask = masks.<span class="built_in">sum</span>(<span class="number">0</span>)</span><br><span class="line">           <span class="keyword">assert</span> (total_mask[(total_mask!=<span class="number">0</span>)] == <span class="number">255</span>).<span class="built_in">all</span>()</span><br><span class="line"></span><br><span class="line">      item[<span class="string">&#x27;mask&#x27;</span>] = torch.from_numpy(total_mask)</span><br><span class="line"></span><br><span class="line">    item[<span class="string">&#x27;name&#x27;</span>] = <span class="built_in">str</span>(file).split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">    item[<span class="string">&#x27;img&#x27;</span>] = torch.from_numpy(img)</span><br><span class="line">    datas.append(item)</span><br><span class="line">    <span class="keyword">return</span> datas</span><br><span class="line"> </span><br><span class="line">test = process(<span class="string">&quot;/content/drive/My Drive/nuclei/stage1_test&quot;</span>, <span class="literal">False</span>)</span><br><span class="line">torch.save(test, TEST_PATH)</span><br><span class="line">train = process(<span class="string">&quot;/content/drive/My Drive/nuclei/stage1_train&quot;</span>)</span><br><span class="line">torch.save(train, TRAIN_PATH)</span><br></pre></td></tr></table></figure>

<p>具体来看：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file_path = Path(file_path)</span><br><span class="line">files = <span class="built_in">sorted</span>(<span class="built_in">list</span>(file_path.iterdir()))</span><br></pre></td></tr></table></figure>
<p>这里用了Python3的pathlib库来读入文件夹路径，之前大家常用的是os.path，但现在普遍推荐使用pathlib库来替代os.path，因为其采用面向对象的方式，且用法更简单，参加资料如下：<br><a target="_blank" rel="noopener" href="https://xin053.github.io/2016/07/03/pathlib%E8%B7%AF%E5%BE%84%E5%BA%93%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/">pathlib路径库使用详解</a></p>
<p>然后再用list转换一下，是为了下面使用tqdm库来可视化进度条。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> image <span class="keyword">in</span> (file/<span class="string">&#x27;images&#x27;</span>).iterdir():</span><br><span class="line">  img = io.imread(image)</span><br><span class="line">  imgs.append(img)</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(imgs) == <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> img.shape[<span class="number">2</span>] &gt; <span class="number">3</span>:</span><br><span class="line">  <span class="keyword">assert</span> (img[:, :, <span class="number">3</span>]!=<span class="number">255</span>).<span class="built_in">sum</span>() == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">img = img[:, :, :<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p>这一部分是读取具体的图像，但这里注意两点：<br>（1）首先对每一子文件夹下的图像数量进行判断，确保只有一张图像；<br>（2）这个数据集中的图像有个特点，它是4通道的，最后一个通道的值都是255，所以这里会有shape的判断，并且使用了assert来确保最后一个通道值都是255。<br>最后取原图像的前三个通道存入新图像中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> has_mask:</span><br><span class="line">  mask_files = <span class="built_in">list</span>((file/<span class="string">&#x27;masks&#x27;</span>).iterdir())</span><br><span class="line">  masks = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i, mask <span class="keyword">in</span> <span class="built_in">enumerate</span>(mask_files):</span><br><span class="line">    mask = io.imread(mask)</span><br><span class="line">    <span class="keyword">assert</span> (mask[(mask!=<span class="number">0</span>)] == <span class="number">255</span>).<span class="built_in">all</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> masks <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">      H, W = mask.shape</span><br><span class="line">      masks = np.zeros((<span class="built_in">len</span>(mask_files), H, W))</span><br><span class="line"></span><br><span class="line">    masks[i] = mask</span><br></pre></td></tr></table></figure>
<p>这一步是逐个读取掩膜文件，其中的assert语句是保证mask确实是0和255二值的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmp_mask = masks.<span class="built_in">sum</span>(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">assert</span> (tmp_mask[(tmp_mask!=<span class="number">0</span>)] == <span class="number">255</span>).<span class="built_in">all</span>()</span><br></pre></td></tr></table></figure>
<p>这一步是将masks中的同一位置上的元素进行加和，然后通过assert语句保证加和后不为0的元素都是255，这一步是保证每个像素上都最多只有一个掩膜值，即两个掩膜没有重叠。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_mask = masks.<span class="built_in">sum</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>因为masks变量实际有多个通道，即多个掩膜，这一步是将每个通道上的掩膜值根据序号重新赋值，然后组合在一起，使得所有掩膜都在一张图像上。(这一步与原notebook不同，原notebook是不同的掩膜有不一样的值)</p>
<p>比如这张细胞核图像：<br><img src="https://user-images.githubusercontent.com/6218739/75554371-2b28f780-5a75-11ea-9357-928dde25f866.png" alt="1f84ac0d-1df9-42c9-b4ee-ca08102cd715"><br>它的掩膜就是：<br><img src="https://user-images.githubusercontent.com/6218739/75554405-3d0a9a80-5a75-11ea-9663-e85c11cf5df3.png" alt="012a8162-4eaa-489c-8f35-e196651a8071"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  item[<span class="string">&#x27;mask&#x27;</span>] = torch.from_numpy(total_mask)</span><br><span class="line"></span><br><span class="line">item[<span class="string">&#x27;name&#x27;</span>] = <span class="built_in">str</span>(file).split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">item[<span class="string">&#x27;img&#x27;</span>] = torch.from_numpy(img)</span><br><span class="line">datas.append(item)</span><br></pre></td></tr></table></figure>
<p>然后将图像img、文件名name和掩膜mask（如果有的话）以字典的形式存入datas这个列表中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test = process(<span class="string">&quot;/content/drive/My Drive/nuclei/stage1_test&quot;</span>, <span class="literal">False</span>)</span><br><span class="line">torch.save(test, TEST_PATH)</span><br><span class="line">train = process(<span class="string">&quot;/content/drive/My Drive/nuclei/stage1_train&quot;</span>)</span><br><span class="line">torch.save(train, TRAIN_PATH)</span><br></pre></td></tr></table></figure>
<p>最后，将这个列表用PyTorch存储模型的方式持久化存储下来。<br>这一步需要的时间很长，所以最好是将这个存储数据的列表持久化后，将其挪动到Google Drive中，防止下次重启丢失。<br>但实际操作下来，发现过程不是那么美好，首先是Google Colab给分配的RAM有点小，而训练集中的数据特别多，尤其是mask分开存储的方式，使得数据量巨多，后期直接把内存撑爆了，而且执行速度非常慢，于是将代码稍微改了以下，每隔5步就torch save一下，然后将datas清零，这样就能保证及时释放内存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> k % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">  torch.save(datas, name + np.<span class="built_in">str</span>(k)+<span class="string">&quot;.pt&quot;</span>)</span><br><span class="line">  datas = []</span><br></pre></td></tr></table></figure>
<p>然后再把所有save的数据load以后串接起来就行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_catenate</span>(<span class="params">file_path</span>):</span></span><br><span class="line">    path = Path(file_path)</span><br><span class="line">    data = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(path.iterdir()):</span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        temp = torch.load(i)</span><br><span class="line">        data += temp</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>

<h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><p>首先定义数据集格式，自定义的数据集格式需要继承torch.utils.data.Dataset，然后重载以下两个方法：<br>（1）__len__：这样len(dataset)就可以返回整个数据集的大小，<br>（2）__getitem__：这样就可以使用dataset[i]来对数据进行索引。<br>针对这里的具体训练数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainDataset</span>(<span class="params">data.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data, source_transform, target_transform</span>):</span></span><br><span class="line">        self.datas = data</span><br><span class="line">        self.s_transform = source_transform</span><br><span class="line">        self.t_transform = target_transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        data = self.datas[index]</span><br><span class="line">        img = data[<span class="string">&#x27;img&#x27;</span>].numpy()</span><br><span class="line">        mask = data[<span class="string">&#x27;mask&#x27;</span>][:, :, <span class="literal">None</span>].byte().numpy()</span><br><span class="line">        img = self.s_transform(img)</span><br><span class="line">        mask = self.t_transform(mask)</span><br><span class="line">        <span class="keyword">return</span> img, mask</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.datas)</span><br></pre></td></tr></table></figure>
<p>可以看出，对img和mask分别又做了一些变换。<br>对于这些变换操作来说，最佳实践是不要写函数，而是写可调用的类，这样参数就不必每次都要传递。因此，只需实现__call__方法和__init__方法（如有必要）。然后如下调用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tsfm = Transform(params)</span><br><span class="line">transformed_sample = tsfm(sample)</span><br></pre></td></tr></table></figure>
<p>这里因为所有的变换在torchvision的transforms中是自带的，所以不需要自定义变换，只调用即可，而且使用了Compose将这些变换组合起来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> PIL</span><br><span class="line">s_trans = transforms.Compose([</span><br><span class="line">                              transforms.ToPILImage(),</span><br><span class="line">                              transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">                              transforms.ToTensor(),</span><br><span class="line">                              transforms.Normalize(mean=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], std=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">t_trans = transforms.Compose([</span><br><span class="line">                              transforms.ToPILImage(),</span><br><span class="line">                              transforms.Resize((<span class="number">128</span>, <span class="number">128</span>), interpolation=PIL.Image.NEAREST),</span><br><span class="line">                              transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>然后将变换规则传入数据集中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = TrainDataset(train, s_trans, t_trans)</span><br></pre></td></tr></table></figure>

<p>具体使用该数据集时，可以使用for循环来逐个读取数据，但这样势必会丧失一些功能：<br>（1）批量处理数据；<br>（2）打乱数据顺序；<br>（3）并行加载数据。<br>因此，PyTorch提供了torch.utils.data.DataLoader类作为迭代器，提供上述功能。<br>将数据集放入DataLoader中，并指定参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataloader = data.DataLoader(train_dataset, num_workers=<span class="number">2</span>, batch_size=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<h1 id="UNet网络结构"><a href="#UNet网络结构" class="headerlink" title="UNet网络结构"></a>UNet网络结构</h1><p>崔家华的一篇博文对UNet的网络结构和代码实现讲得挺好，见<a target="_blank" rel="noopener" href="https://cuijiahua.com/blog/2019/12/dl-15.html">这里</a>。<br>本部分是对崔同学的博文的摘抄学习，代码部分中的参数是结合上面的notebook中的参数进行了修改。</p>
<h2 id="网络结构原理"><a href="#网络结构原理" class="headerlink" title="网络结构原理"></a>网络结构原理</h2><blockquote>
<p>UNet最早发表在2015的MICCAI会议上，5年多的时间，论文引用量已经达到了接近12000次。<br>UNet成为了大多做医疗影像语义分割任务的baseline，同时也启发了大量研究者对于U型网络结构的研究，发表了一批基于UNet网络结构的改进方法的论文。<br>UNet网络结构，最主要的两个特点是：U型网络结构和Skip Connection跳层连接。</p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/6218739/75503501-bde37b00-5a10-11ea-99ac-9c9015aa1bb0.png" alt="image"></p>
<blockquote>
<p>UNet是一个对称的网络结构，左侧为下采样，右侧为上采样。<br>按照功能可以将左侧的一系列下采样操作称为encoder，将右侧的一系列上采样操作称为decoder。<br>Skip Connection中间四条灰色的平行线，Skip Connection就是在上采样的过程中，融合下采样过过程中的feature map。<br>Skip Connection用到的融合的操作也很简单，就是将feature map的通道进行叠加，俗称Concat。</p>
</blockquote>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>将整个UNet结构拆分为多个模块进行分析。（后面的文字依然是摘抄自崔家华博客，不再加引用标识，见谅）</p>
<h3 id="DoubleConv模块"><a href="#DoubleConv模块" class="headerlink" title="DoubleConv模块"></a>DoubleConv模块</h3><p>从UNet网络中可以看出，不管是下采样过程还是上采样过程，每一层都会连续进行两次卷积操作，这种操作在UNet网络中重复很多次，可以单独写一个DoubleConv模块。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubleConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;(convolution =&gt; [BN] =&gt; ReLU) * 2&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.double_conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.double_conv(x)</span><br></pre></td></tr></table></figure>
<p>上述的Pytorch代码：torch.nn.Sequential是一个时序容器，Modules 会以它们传入的顺序被添加到容器中。比如上述代码的操作顺序：卷积-&gt;BN-&gt;ReLU-&gt;卷积-&gt;BN-&gt;ReLU。<br>DoubleConv模块的in_channels和out_channels可以灵活设定，以便扩展使用。<br>输出矩阵的高度和宽度（即输出的特征图feature map）这两个维度的尺寸由输入矩阵、卷积核、扫描方式所共同决定，计算公式为：<br><img src="https://user-images.githubusercontent.com/6218739/75505152-71e70500-5a15-11ea-9784-2b27b6731e80.png" alt="image"></p>
<h3 id="Down模块"><a href="#Down模块" class="headerlink" title="Down模块"></a>Down模块</h3><p>UNet网络一共有4次下采样过程，模块化代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Down</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Downscaling with maxpool then double conv&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool_conv = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            DoubleConv(in_channels, out_channels)</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.maxpool_conv(x)</span><br></pre></td></tr></table></figure>
<p>这里的代码很简单，就是一个maxpool池化层，进行下采样，然后接一个DoubleConv模块。<br>其中，池化层选的是2乘以2的窗口大小，那么默认获得的也是这样大小的填充步长，池化以后的feature map的大小计算方式跟上面卷积的相同。</p>
<p>至此，UNet网络的左半部分的下采样过程的代码都写好了，接下来是右半部分的上采样过程。</p>
<h3 id="Up模块"><a href="#Up模块" class="headerlink" title="Up模块"></a>Up模块</h3><p>上采样过程用到的最多的当然就是上采样了，除了常规的上采样操作，还有进行特征的融合。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Up</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Upscaling then double conv&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, bilinear=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if bilinear, use the normal convolutions to reduce the number of channels</span></span><br><span class="line">        <span class="keyword">if</span> bilinear:</span><br><span class="line">            self.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.up = nn.ConvTranspose2d(in_channels, in_channels // <span class="number">2</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.conv = DoubleConv(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x1, x2</span>):</span></span><br><span class="line">        x1 = self.up(x1)</span><br><span class="line">        <span class="comment"># input is CHW</span></span><br><span class="line">        diffY = torch.tensor([x2.size()[<span class="number">2</span>] - x1.size()[<span class="number">2</span>]])</span><br><span class="line">        diffX = torch.tensor([x2.size()[<span class="number">3</span>] - x1.size()[<span class="number">3</span>]])</span><br><span class="line">        x1 = F.pad(x1, [diffX // <span class="number">2</span>, diffX - diffX // <span class="number">2</span>,</span><br><span class="line">                        diffY // <span class="number">2</span>, diffY - diffY // <span class="number">2</span>])</span><br><span class="line">        <span class="comment"># if you have padding issues, see</span></span><br><span class="line">        <span class="comment"># https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a</span></span><br><span class="line">        <span class="comment"># https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd</span></span><br><span class="line">        x = torch.cat([x2, x1], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure>
<p>代码复杂一些，我们可以分开来看。<br>首先是__init__初始化函数里定义的上采样方法以及卷积采用DoubleConv。<br>上采样，定义了两种方法：Upsample和ConvTranspose2d，也就是双线性插值和反卷积。<br>双线性插值很好理解，示意图：<br><img src="https://user-images.githubusercontent.com/6218739/75517269-49710200-5a39-11ea-8ae3-7316d43727cf.png" alt="image"></p>
<p>简单地讲：已知Q11、Q12、Q21、Q22四个点坐标，通过Q11和Q21求R1，再通过Q12和Q22求R2，最后通过R1和R2求P，这个过程就是双线性插值。对于一个feature map而言，其实就是在像素点中间补点，补的点的值是多少，是由相邻像素点的值决定的。<br>反卷积，顾名思义，就是反着卷积。卷积是让featuer map越来越小，反卷积就是让feature map越来越大，示意图：</p>
<p><img src="https://user-images.githubusercontent.com/6218739/75517361-76bdb000-5a39-11ea-85a2-a869f7443195.png" alt="image"></p>
<p>下面蓝色为原始图片，周围白色的虚线方块为padding结果，通常为0，上面绿色为卷积后的图片。 这个示意图，就是一个从2<em>2的feature map-&gt;4</em>4的feature map过程。<br>在forward前向传播函数中，x1接收的是上采样的数据，x2接收的是特征融合的数据。<br>如果两个feature map大小不同，那么特征融合方法可以有两种：<br>（1）将大的feature进行裁剪，再进行concat；<br>（2）将小的feature进行填充，再进行concat。</p>
<p>这里是使用的第二种，先对小的feature map进行padding，再进行concat。</p>
<h3 id="OutConv模块"><a href="#OutConv模块" class="headerlink" title="OutConv模块"></a>OutConv模块</h3><p>用上述的DoubleConv模块、Down模块、Up模块就可以拼出UNet的主体网络结构了。UNet网络的输出需要根据分割数量，整合输出通道。具体操作就是channel的变换：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OutConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(OutConv, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure>
<p>需要注意的是原notebook中没有加入Sigmoid层，但实测加入后精度提高很多。这样得到的就是一个0到1的概率分布。</p>
<h3 id="UNet网络"><a href="#UNet网络" class="headerlink" title="UNet网络"></a>UNet网络</h3><p>这一部分是将上面的模块组合起来形成整个UNet网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; Full assembly of the parts to form the complete network &quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;Refer https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_model.py&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, bilinear=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(UNet, self).__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.bilinear = bilinear</span><br><span class="line">        self.inc = DoubleConv(n_channels, <span class="number">64</span>)</span><br><span class="line">        self.down1 = Down(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.down2 = Down(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.down3 = Down(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        self.down4 = Down(<span class="number">512</span>, <span class="number">1024</span>)</span><br><span class="line">        self.up1 = Up(<span class="number">1024</span>, <span class="number">512</span>, bilinear)</span><br><span class="line">        self.up2 = Up(<span class="number">512</span>, <span class="number">256</span>, bilinear)</span><br><span class="line">        self.up3 = Up(<span class="number">256</span>, <span class="number">128</span>, bilinear)</span><br><span class="line">        self.up4 = Up(<span class="number">128</span>, <span class="number">64</span>, bilinear)</span><br><span class="line">        self.outc = OutConv(<span class="number">64</span>, n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x1 = self.inc(x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)</span><br><span class="line">        x5 = self.down4(x4)</span><br><span class="line">        x = self.up1(x5, x4)</span><br><span class="line">        x = self.up2(x, x3)</span><br><span class="line">        x = self.up3(x, x2)</span><br><span class="line">        x = self.up4(x, x1)</span><br><span class="line">        logits = self.outc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">model = UNet(n_channels=<span class="number">1</span>, n_classes=<span class="number">1</span>).cuda()</span><br></pre></td></tr></table></figure>
<p>这里还有另外一位网友写的UNet网络进行辅助理解，<a target="_blank" rel="noopener" href="https://github.com/JavisPeng/u_net_liver/blob/master/unet.py">点击这里</a>。</p>
<h1 id="定义损失函数和优化器"><a href="#定义损失函数和优化器" class="headerlink" title="定义损失函数和优化器"></a>定义损失函数和优化器</h1><p>这里使用Dice系数定义损失：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">soft_dice_loss</span>(<span class="params">inputs, targets</span>):</span></span><br><span class="line">        num = targets.size(<span class="number">0</span>)</span><br><span class="line">        m1  = inputs.view(num,-<span class="number">1</span>)</span><br><span class="line">        m2  = targets.view(num,-<span class="number">1</span>)</span><br><span class="line">        intersection = (m1 * m2)</span><br><span class="line">        score = <span class="number">2.</span> * (intersection.<span class="built_in">sum</span>(<span class="number">1</span>)+<span class="number">1</span>) / (m1.<span class="built_in">sum</span>(<span class="number">1</span>) + m2.<span class="built_in">sum</span>(<span class="number">1</span>)+<span class="number">1</span>)</span><br><span class="line">        score = <span class="number">1</span> - score.<span class="built_in">sum</span>()/num</span><br><span class="line">        <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure>

<p>具体的原理可以参见如下一篇博客：<br><a target="_blank" rel="noopener" href="https://www.aiuai.cn/aifarm1159.html">医学图像分割之 Dice Loss</a></p>
<p>优化器选择Adam：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.Adam(model.parameters(),lr = <span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure>

<h1 id="训练和保存模型"><a href="#训练和保存模型" class="headerlink" title="训练和保存模型"></a>训练和保存模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader, <span class="number">0</span>):</span><br><span class="line">        x_train, y_train = data</span><br><span class="line">        x_train = x_train.cuda()</span><br><span class="line">        y_train = y_train.cuda()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        predict = model(x_train)</span><br><span class="line">        loss = soft_dice_loss(predict, y_train)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">19</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">20</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Finish training&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>这里在GPU上进行训练。<br>训练完后及时地将模型保存下来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MODEL_PATH = <span class="string">&#x27;model.pth&#x27;</span></span><br><span class="line">torch.save(model.state_dict(), MODEL_PATH)</span><br></pre></td></tr></table></figure>

<p>#测试</p>
<h2 id="创建测试数据集和加载器"><a href="#创建测试数据集和加载器" class="headerlink" title="创建测试数据集和加载器"></a>创建测试数据集和加载器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestDataset</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, path, source_transform</span>):</span></span><br><span class="line">        self.datas = torch.load(path)</span><br><span class="line">        self.s_transform = source_transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        data = self.datas[index]</span><br><span class="line">        img = data[<span class="string">&#x27;img&#x27;</span>].numpy()</span><br><span class="line">        img = self.s_transform(img)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.datas)</span><br><span class="line"></span><br><span class="line">test_dataset = TestDataset(TEST_PATH, s_trans)</span><br><span class="line">test_dataloader = data.DataLoader(test_dataset,num_workers=<span class="number">2</span>,batch_size=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h2 id="查看一下测试集"><a href="#查看一下测试集" class="headerlink" title="查看一下测试集"></a>查看一下测试集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataiter = <span class="built_in">iter</span>(test_dataloader)</span><br><span class="line">imgs = dataiter.<span class="built_in">next</span>()</span><br></pre></td></tr></table></figure>
<p>注意上面的imgs的size()是这样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">2</span>, <span class="number">1</span>, <span class="number">128</span>, <span class="number">128</span>])</span><br></pre></td></tr></table></figure>
<p>最前面的2是batch size，说明dataloader中一个元素包含两张图像，所以保存时需要这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">io.imsave(<span class="string">&quot;1.png&quot;</span>, imgs[<span class="number">0</span>][<span class="number">0</span>].data.numpy())</span><br></pre></td></tr></table></figure>

<h2 id="加载模型（可选）"><a href="#加载模型（可选）" class="headerlink" title="加载模型（可选）"></a>加载模型（可选）</h2><p>如有必要的话，先从模型文件中加载模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = UNet(<span class="number">1</span>, <span class="number">1</span>).cuda()</span><br><span class="line">model.load_state_dict(torch.load(MODEL_PATH))</span><br></pre></td></tr></table></figure>

<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">output = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">        data = data.cuda()</span><br><span class="line">        <span class="comment"># io.imsave(&quot;train.png&quot;, data[1][0].data.cpu().numpy())</span></span><br><span class="line">        predict = model(data)</span><br><span class="line">        <span class="comment"># io.imsave(&quot;test.png&quot;, o[1][0].data.cpu().numpy())</span></span><br><span class="line">        output.append(predict)</span><br><span class="line"></span><br><span class="line">    result = torch.cat(output, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>然后得到的result可以通过设置阈值来二值化显示最终结果，比如第i张图像：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pred = result[i][<span class="number">0</span>].data.cpu().numpy()</span><br><span class="line">pred[pred&gt;<span class="number">0.7</span>] = <span class="number">255</span></span><br><span class="line">pred[pred&lt;=<span class="number">0.7</span>] = <span class="number">0</span></span><br><span class="line">io.imsave(<span class="string">&quot;i.png&quot;</span>, pred)</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechat_reward.png" alt="Xin-Bo Qi(亓欣波) WeChat Pay">
        <p>WeChat Pay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/kaggle/" rel="tag"># kaggle</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/26/ImagePy_17/" rel="prev" title="ImagePy解析：17 -- 重构版ImagePy解析">
      <i class="fa fa-chevron-left"></i> ImagePy解析：17 -- 重构版ImagePy解析
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/03/08/dive-into-dl/" rel="next" title="《动手学深度学习》PyTorch版学习笔记">
      《动手学深度学习》PyTorch版学习笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90"><span class="nav-number">1.</span> <span class="nav-text">数据集分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">1.1.</span> <span class="nav-text">下载数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%A3%E5%8E%8B%E5%B9%B6%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE"><span class="nav-number">1.2.</span> <span class="nav-text">解压并迁移数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0"><span class="nav-number">1.3.</span> <span class="nav-text">数据文件描述</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8A%A0%E8%BD%BD%E5%BF%85%E8%A6%81%E7%9A%84Python%E5%8C%85"><span class="nav-number">2.</span> <span class="nav-text">加载必要的Python包</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8A%A0%E8%BD%BD"><span class="nav-number">3.</span> <span class="nav-text">数据集加载</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">3.1.</span> <span class="nav-text">数据预处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="nav-number">3.2.</span> <span class="nav-text">数据加载</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#UNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-number">4.</span> <span class="nav-text">UNet网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8E%9F%E7%90%86"><span class="nav-number">4.1.</span> <span class="nav-text">网络结构原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">4.2.</span> <span class="nav-text">代码实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DoubleConv%E6%A8%A1%E5%9D%97"><span class="nav-number">4.2.1.</span> <span class="nav-text">DoubleConv模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Down%E6%A8%A1%E5%9D%97"><span class="nav-number">4.2.2.</span> <span class="nav-text">Down模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Up%E6%A8%A1%E5%9D%97"><span class="nav-number">4.2.3.</span> <span class="nav-text">Up模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OutConv%E6%A8%A1%E5%9D%97"><span class="nav-number">4.2.4.</span> <span class="nav-text">OutConv模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#UNet%E7%BD%91%E7%BB%9C"><span class="nav-number">4.2.5.</span> <span class="nav-text">UNet网络</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8"><span class="nav-number">5.</span> <span class="nav-text">定义损失函数和优化器</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E5%92%8C%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="nav-number">6.</span> <span class="nav-text">训练和保存模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E5%8A%A0%E8%BD%BD%E5%99%A8"><span class="nav-number">6.1.</span> <span class="nav-text">创建测试数据集和加载器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E4%B8%80%E4%B8%8B%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="nav-number">6.2.</span> <span class="nav-text">查看一下测试集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%89"><span class="nav-number">6.3.</span> <span class="nav-text">加载模型（可选）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95"><span class="nav-number">6.4.</span> <span class="nav-text">测试</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xin-Bo Qi(亓欣波)"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Xin-Bo Qi(亓欣波)</p>
  <div class="site-description" itemprop="description">Digitize everything to realize Digitalization!</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">124</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/qixinbo" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:qixinbo@gmail.com" title="E-Mail → mailto:qixinbo@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/qixinbo" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fas fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.tsinghua.edu.cn/" title="https:&#x2F;&#x2F;www.tsinghua.edu.cn" rel="noopener" target="_blank">THU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.imr.cas.cn/" title="http:&#x2F;&#x2F;www.imr.cas.cn" rel="noopener" target="_blank">IMR</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.sdu.edu.cn/" title="http:&#x2F;&#x2F;www.sdu.edu.cn" rel="noopener" target="_blank">SDU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://liam0205.me/" title="http:&#x2F;&#x2F;liam0205.me&#x2F;" rel="noopener" target="_blank">黄晨成</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xin-Bo Qi(亓欣波)</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://qixinbo.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://qixinbo.github.io/2020/02/29/kaggle-nuclei/";
    this.page.identifier = "2020/02/29/kaggle-nuclei/";
    this.page.title = "Kaggle细胞赛：基于PyTorch/UNet算法的细胞核识别";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://qixinbo.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
