<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"qixinbo.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Attention预警！： 时刻铭记“Garbage in, garbage out!”，因此，涉及到data时，一定注意实际查看，确保计算时Input和Output的一致性和准确性。  原书MXNet版在这里。 PyTorch版在这里。  深度学习简介 目前的机器学习和深度学习应用共同的核心思想：用数据编程。 通俗来说，机器学习是一门讨论各式各样的适用于不同问题的函数形式，以及如何使用数据来有效">
<meta property="og:type" content="article">
<meta property="og:title" content="《动手学深度学习》PyTorch版学习笔记">
<meta property="og:url" content="http://qixinbo.github.io/2020/03/08/dive-into-dl/index.html">
<meta property="og:site_name" content="数字旗手">
<meta property="og:description" content="Attention预警！： 时刻铭记“Garbage in, garbage out!”，因此，涉及到data时，一定注意实际查看，确保计算时Input和Output的一致性和准确性。  原书MXNet版在这里。 PyTorch版在这里。  深度学习简介 目前的机器学习和深度学习应用共同的核心思想：用数据编程。 通俗来说，机器学习是一门讨论各式各样的适用于不同问题的函数形式，以及如何使用数据来有效">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/75660181-4d558c00-5ca6-11ea-95a8-a343ea73ad35.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/75971838-4e3c2700-5f0d-11ea-8d34-cbe8e187f07b.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/76134337-5bb1f800-6058-11ea-908d-a03ebaa1a44f.png">
<meta property="article:published_time" content="2020-03-07T16:00:00.000Z">
<meta property="article:modified_time" content="2021-03-26T06:51:51.770Z">
<meta property="article:author" content="Xin-Bo Qi(亓欣波)">
<meta property="article:tag" content="PyTorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://user-images.githubusercontent.com/6218739/75660181-4d558c00-5ca6-11ea-95a8-a343ea73ad35.png">

<link rel="canonical" href="http://qixinbo.github.io/2020/03/08/dive-into-dl/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>《动手学深度学习》PyTorch版学习笔记 | 数字旗手</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="数字旗手" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">数字旗手</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">电气化、自动化、数字化、智能化、智慧化</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-scholar">

    <a href="/scholar/" rel="section"><i class="fa fa-chart-bar fa-fw"></i>scholar</a>

  </li>
        <li class="menu-item menu-item-sources">

    <a href="/sources/" rel="section"><i class="fa fa-rss fa-fw"></i>sources</a>

  </li>
        <li class="menu-item menu-item-gallery">

    <a href="/gallery/" rel="section"><i class="fa fa-file-image fa-fw"></i>gallery</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404.html" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://qixinbo.github.io/2020/03/08/dive-into-dl/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Xin-Bo Qi(亓欣波)">
      <meta itemprop="description" content="Digitize everything to realize Digitalization!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数字旗手">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《动手学深度学习》PyTorch版学习笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-08 00:00:00" itemprop="dateCreated datePublished" datetime="2020-03-08T00:00:00+08:00">2020-03-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-26 14:51:51" itemprop="dateModified" datetime="2021-03-26T14:51:51+08:00">2021-03-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/03/08/dive-into-dl/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/03/08/dive-into-dl/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Attention预警！：<br>时刻铭记“Garbage in, garbage out!”，因此，涉及到data时，一定注意实际查看，确保计算时Input和Output的一致性和准确性。</p>
<p>原书MXNet版在<a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh">这里</a>。<br>PyTorch版在<a target="_blank" rel="noopener" href="https://github.com/ShusenTang/Dive-into-DL-PyTorch">这里</a>。</p>
<h1 id="深度学习简介"><a href="#深度学习简介" class="headerlink" title="深度学习简介"></a>深度学习简介</h1><p>目前的机器学习和深度学习应用共同的核心思想：用数据编程。<br>通俗来说，机器学习是一门讨论各式各样的适用于不同问题的函数形式，以及如何使用数据来有效地获取函数参数具体值的学科。<br>深度学习是具有多级表示的表征学习方法（表征学习关注如何自动找出表示数据的合适方式，以便更好地将输入变换为正确的输出）。在每一级（从原始数据开始），深度学习通过简单的函数将该级的表示变换为更高级的表示。因此，深度学习模型也可以看作是由许多简单函数复合而成的函数。当这些复合的函数足够多时，深度学习模型就可以表达非常复杂的变换。值得一提的是，作为表征学习的一种，深度学习将自动找出每一级表示数据的合适方式。<br>（1）深度学习的一个外在特点是端到端的训练。也就是说，并不是将单独调试的部分拼凑起来组成一个系统，而是将整个系统组建好之后一起训练。比如说，计算机视觉科学家之前曾一度将特征抽取与机器学习模型的构建分开处理，像是Canny边缘探测和SIFT特征提取曾占据统治性地位达10年以上，但这也就是人类能找到的最好方法了。当深度学习进入这个领域后，这些特征提取方法就被性能更强的自动优化的逐级过滤器替代了。<br>（2）除端到端的训练以外，我们也正在经历从含参数统计模型转向完全无参数的模型。当数据非常稀缺时，我们需要通过简化对现实的假设来得到实用的模型。当数据充足时，我们就可以用能更好地拟合现实的无参数模型来替代这些含参数模型。这也使我们可以得到更精确的模型，尽管需要牺牲一些可解释性。</p>
<h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><h2 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h2><p>在PyTorch中，torch.Tensor是存储和变换数据的主要工具。Tensor和NumPy的多维数组非常类似。然而，Tensor提供GPU计算和自动求梯度等更多功能，这些使Tensor更加适合深度学习。</p>
<h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>) <span class="comment"># 创建一个5x3的未初始化的Tensor</span></span><br><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>) <span class="comment"># 创建一个5x3的随机初始化的Tensor</span></span><br><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long) <span class="comment"># 创建一个5x3的long型全0的Tensor</span></span><br><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>]) <span class="comment"># 接根据数据创建</span></span><br><span class="line">x = x.new_ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.float64) <span class="comment"># 可以通过现有的Tensor来创建，此方法会默认重用输入Tensor的一些属性，例如torch.dtype和torch.device</span></span><br><span class="line">x = torch.randn_like(x, dtype=torch.<span class="built_in">float</span>) <span class="comment"># 除非自定义数据类型</span></span><br><span class="line"><span class="built_in">print</span>(x.shape) <span class="comment"># 可以通过shape或者size()来获取Tensor的形状</span></span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># 注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。</span></span><br></pre></td></tr></table></figure>
<p>还有很多函数可以创建Tensor，如eye、arange、linspace，这些创建方法都可以在创建的时候指定数据类型dtype和存放device(cpu/gpu)。</p>
<h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><p>（1）算术操作，以加法为例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x + y) <span class="comment"># 加法形式一</span></span><br><span class="line"><span class="built_in">print</span>(torch.add(x, y)) <span class="comment"># 加法形式二</span></span><br><span class="line">result = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">torch.add(x, y, out=result) <span class="comment"># 可以指定输出</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line">y.add_(x) <span class="comment"># 加法形式三 inplace，PyTorch操作inplace版本都有后缀_</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure></p>
<p>（2）索引<br>可以使用类似NumPy的索引操作来访问Tensor的一部分，需要注意的是：索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = x[<span class="number">0</span>, :]</span><br><span class="line">y += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">0</span>, :])</span><br></pre></td></tr></table></figure><br>PyTorch还提供了一些高级的选择函数，如index_select、masked_select等。<br>（3）改变形状<br>用view()来改变Tensor的形状：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = x.view(<span class="number">15</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>, <span class="number">5</span>) <span class="comment"># -1所指的维度可以根据其他维度的值推出来</span></span><br><span class="line"><span class="built_in">print</span>(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure><br>注意view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变)<br>另外注意：虽然view返回的Tensor与源Tensor是共享data的，但是依然是一个新的Tensor（因为Tensor除了包含data外还有一些其他属性），二者id（内存地址）并不一致。<br>所以如果我们想返回一个真正新的副本（即不共享data内存）该怎么办呢？Pytorch还提供了一个reshape()可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。推荐先用clone创造一个副本然后再使用view。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_cp = x.clone().view(<span class="number">15</span>)</span><br><span class="line">x -= <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x_cp)</span><br></pre></td></tr></table></figure><br>使用clone还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源Tensor。<br>另外一个常用的函数就是item(), 它可以将一个标量Tensor转换成一个Python number：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.item())</span><br></pre></td></tr></table></figure><br>PyTorch中的Tensor支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等，具体可参考官方API。</p>
<h3 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h3><p>当对两个形状不同的Tensor按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个Tensor形状相同后再按元素运算。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">1</span>, <span class="number">3</span>).view(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">y = torch.arange(<span class="number">1</span>, <span class="number">4</span>).view(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br></pre></td></tr></table></figure><br>这部分的广播机制可以参照numpy的广播来理解。</p>
<h3 id="运算的内存开销"><a href="#运算的内存开销" class="headerlink" title="运算的内存开销"></a>运算的内存开销</h3><p>前面说了，索引操作是不会开辟新内存的，而像y = x + y这样的运算是会新开内存的，然后将y指向新内存。可以使用Python自带的id函数来验证：如果两个实例的ID一致，那么它们所对应的内存地址相同；反之则不同。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">y = torch.tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">id_before = <span class="built_in">id</span>(y)</span><br><span class="line">y = x + y</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(y) == id_before)</span><br></pre></td></tr></table></figure><br>如果想指定结果到原来的y的内存，可以使用前面介绍的索引来进行替换操作，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">y = torch.tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">id_before = <span class="built_in">id</span>(y)</span><br><span class="line">y[:] = x + y</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(y) == id_before)</span><br></pre></td></tr></table></figure><br>还可以使用运算符全名函数中的out参数或者自加运算符+=(也即add_())达到上述效果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">y = torch.tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">id_before = <span class="built_in">id</span>(y)</span><br><span class="line"><span class="comment"># torch.add(x, y, out = y) </span></span><br><span class="line"><span class="comment"># y += x</span></span><br><span class="line">y.add_(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(y) == id_before)</span><br></pre></td></tr></table></figure></p>
<h3 id="Tensor和Numpy相互转换"><a href="#Tensor和Numpy相互转换" class="headerlink" title="Tensor和Numpy相互转换"></a>Tensor和Numpy相互转换</h3><p>我们很容易用numpy()和from_numpy()将Tensor和NumPy中的数组相互转换。但是需要注意的一点是： 这两个函数所产生的的Tensor和NumPy中的数组共享相同的内存（所以他们之间的转换很快），改变其中一个时另一个也会改变！！！<br>还有一个常用的将NumPy中的array转换成Tensor的方法就是torch.tensor(), 需要注意的是，此方法总是会进行数据拷贝（就会消耗更多的时间和空间），所以返回的Tensor和原来的数据不再共享内存。<br>（1）Tensor转Numpy<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">b = a.numpy()</span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br><span class="line">a += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br><span class="line">b += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br></pre></td></tr></table></figure></p>
<p>（2）Numpy转Tensor<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.ones(<span class="number">5</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br><span class="line">a += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br><span class="line">b += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br></pre></td></tr></table></figure><br>所有在CPU上的Tensor（除了CharTensor）都支持与NumPy数组相互转换。</p>
<h3 id="Tensor-on-GPU"><a href="#Tensor-on-GPU" class="headerlink" title="Tensor on GPU"></a>Tensor on GPU</h3><p>用方法to()可以将Tensor在CPU和GPU（需要硬件支持）之间相互移动。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    y = torch.ones_like(x, device=device) <span class="comment"># 直接创建一个在GPU上的Tensor</span></span><br><span class="line">    x = x.to(device)  <span class="comment"># 等价于.to(&#x27;cuda&#x27;)</span></span><br><span class="line">    z = x + y</span><br><span class="line">    <span class="built_in">print</span>(z)</span><br><span class="line">    <span class="built_in">print</span>(z.to(<span class="string">&#x27;cpu&#x27;</span>), torch.double)</span><br></pre></td></tr></table></figure></p>
<h2 id="自动求梯度"><a href="#自动求梯度" class="headerlink" title="自动求梯度"></a>自动求梯度</h2><p>PyTorch提供的autograd包能够根据输入和前向传播过程自动构建计算图，并执行反向传播。</p>
<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>Tensor是autograd包的核心类，如果将其属性.requires_grad设置为True，它将开始追踪(track)在其上的所有操作（这样就可以利用链式法则进行梯度传播了）。完成计算后，可以调用.backward()来完成所有梯度计算。此Tensor的梯度将累积到.grad属性中。<br>注意在y.backward()时，如果y是标量，则不需要为backward()传入任何参数；否则，需要传入一个与y同形的Tensor。<br>如果不想要被继续追踪，可以调用.detach()将其从追踪记录中分离出来，这样就可以防止将来的计算被追踪，这样梯度就传不过去了。此外，还可以用with torch.no_grad()将不想被追踪的操作代码块包裹起来，这种方法在评估模型的时候很常用，因为在评估模型时，我们并不需要计算可训练参数（requires_grad=True）的梯度。</p>
<p>Function是另外一个很重要的类。Tensor和Function互相结合就可以构建一个记录有整个计算过程的有向无环图（DAG）。每个Tensor都有一个.grad_fn属性，该属性即创建该Tensor的Function, 就是说该Tensor是不是通过某些运算得到的，若是，则grad_fn返回一个与这些运算相关的对象，否则是None。</p>
<h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>) <span class="comment"># 创建一个Tensor并设置requires_grad=True</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.grad_fn) <span class="comment"># None, x是直接创建的，所以它没有grad_fn</span></span><br><span class="line">y = x + <span class="number">2</span> </span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(y.grad_fn) <span class="comment"># y是通过一个加法操作创建的，所以它有一个为&lt;AddBackward&gt;的grad_fn</span></span><br><span class="line"><span class="built_in">print</span>(x.is_leaf, y.is_leaf) <span class="comment"># 像x这种直接创建的称为叶子节点，叶子节点对应的grad_fn是None</span></span><br><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"><span class="built_in">print</span>(z, out) <span class="comment"># z的grad_fn是MulBackward，out的grad_fn是MeanBackward</span></span><br><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>) <span class="comment"># 缺失情况下默认 requires_grad = False</span></span><br><span class="line">a = ((a * <span class="number">3</span>) / (a - <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(a.requires_grad)</span><br><span class="line">a.requires_grad_(<span class="literal">True</span>) <span class="comment"># 通过.requires_grad_()来用in-place的方式改变requires_grad属性</span></span><br><span class="line"><span class="built_in">print</span>(a.requires_grad)</span><br><span class="line">b = (a * a).<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(b.grad_fn) <span class="comment"># b的grad_fn是SumBackward</span></span><br></pre></td></tr></table></figure>
<h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">out.backward() <span class="comment"># 因为out是一个标量，所以调用backward()时不需要指定求导变量</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">out2 = x.<span class="built_in">sum</span>()</span><br><span class="line">out2.backward() <span class="comment"># grad在反向传播过程中是累加的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">out3 = x.<span class="built_in">sum</span>()</span><br><span class="line">x.grad.data.zero_() <span class="comment"># 所以一般在反向传播之前需把梯度清零</span></span><br><span class="line">out3.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure>
<p>首先，有一个向量x，它经过某个运算得到了向量y，那么y对x的导数就是一个Jacobian矩阵，记为J。<br>再者，始终记着，且抛开诸如神经网络等所有的知识点，从计算上来说，torch.autograd就是一个纯粹的计算引擎，它是计算向量与Jacobian矩阵的乘积的一个运算库（Jacobian矩阵是在底层计算的），即vector-Jabobian product计算引擎。这个vector可以是任意向量，记为v，注意是任意的。<br>最后，向量y经过运算又得到了标量l。此时，如果上面的向量v恰好是l对y的导数，那么根据链式法则，autograd所计算的vector-Jacobian product恰好就是标量l对向量x的导数。所以，autograd的效果就是只要知道y=f(x)和l=g(y)或者l对y的导数v，就可以得到l对x的导数。</p>
<p>那么，具体来说，autograd在反向传播计算梯度时，out.backward()其实是需要一个grad_tensors，就是上面那个向量v，则有两种情形：<br>（1）如果out是标量，该参数就可以为空，此时out就是l。因为通常是最后的损失函数调用backward()，而损失函数又通常是标量，所以此时backward()不需要参数。<br>（2）如果out不是标量，比如上面的y，y.backward(v)，那么就需要指定这个v，而这个v是与y同型的，这是为了让y乘以v是一个标量，这样就保证了始终是标量对张量求导。再说一遍，这个v可以是任意的，但如果恰巧是未知的标量l对y的导数，这样往前计算的梯度就有了意义，比如x中的梯度就是遥远的l对x的梯度。<br>那么，总的计算梯度的方式就是这样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x -&gt; y -&gt; z -&gt; m -&gt; n -&gt; l</span><br><span class="line">设l就是一个标量，那么：</span><br><span class="line">l.backward()</span><br><span class="line">就会先计算dl/dn, 然后：</span><br><span class="line">n.backward(dl/dn)</span><br><span class="line">这样，仍然n*dl/dn是一个标量，就是l，那么继续往前传，先得到dl/dm，再传入：</span><br><span class="line">m.backward(dl/dm)</span><br><span class="line">所以，每一次backward()时总是一个标量，而且是l，所以，传到最后，就可以得到：</span><br><span class="line">dl/dx</span><br></pre></td></tr></table></figure></p>
<p>如果我们想要修改tensor的数值，但是又不希望被autograd记录（即不会影响反向传播），那么我们可以对tensor.data进行操作。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(x.data) <span class="comment"># 还是一个Tensor</span></span><br><span class="line"><span class="built_in">print</span>(x.data.requires_grad) <span class="comment"># False，此时x已经独立于计算图以外</span></span><br><span class="line"></span><br><span class="line">y = <span class="number">2</span> * x</span><br><span class="line">x.data *= <span class="number">100</span> <span class="comment"># 只改变了值，不会记录在计算图中，所以不会影响梯度传播</span></span><br><span class="line">y.backward()</span><br><span class="line"><span class="built_in">print</span>(x) <span class="comment"># x的值会发生变化</span></span><br><span class="line"><span class="built_in">print</span>(x.grad) <span class="comment"># 但梯度不变</span></span><br></pre></td></tr></table></figure></p>
<h1 id="深度学习基础"><a href="#深度学习基础" class="headerlink" title="深度学习基础"></a>深度学习基础</h1><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>线性回归输出是一个连续值，因此适用于回归问题。<br>与回归问题不同，分类问题中模型的最终输出是一个离散值。softmax回归则适用于分类问题。</p>
<h2 id="线性回归的从零开始实现"><a href="#线性回归的从零开始实现" class="headerlink" title="线性回归的从零开始实现"></a>线性回归的从零开始实现</h2><p>尽管强大的深度学习框架可以减少大量重复性工作，但若过于依赖它提供的便利，会导致我们很难深入理解深度学习是如何工作的。因此，本节将介绍如何只利用Tensor和autograd来实现一个线性回归的训练。<br>首先，导入本节中实验所需的包或模块，其中的matplotlib包可用于作图，且设置成嵌入显示。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br></pre></td></tr></table></figure></p>
<h3 id="生成数据集"><a href="#生成数据集" class="headerlink" title="生成数据集"></a>生成数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个简单的人工训练数据集，它可以使我们能够直观比较学到的参数和真实的模型参数的区别</span></span><br><span class="line">num_inputs = <span class="number">2</span> <span class="comment"># 输入特征数为2</span></span><br><span class="line">num_examples = <span class="number">100</span> <span class="comment"># 训练集样本数为100</span></span><br><span class="line">true_w = [<span class="number">2</span>, -<span class="number">3.4</span>] <span class="comment"># 真实的权重</span></span><br><span class="line">true_b = <span class="number">4.2</span> <span class="comment"># 真实的偏差</span></span><br><span class="line"></span><br><span class="line">features = torch.randn(num_examples, num_inputs, dtype=torch.float32) <span class="comment"># 根据训练集个数生成随机的批量样本</span></span><br><span class="line">labels = true_w[<span class="number">0</span>]*features[:, <span class="number">0</span>] + true_w[<span class="number">1</span>]*features[:, <span class="number">1</span>] + true_b <span class="comment"># 真实的标签</span></span><br><span class="line">labels += torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=labels.size()), dtype=torch.float32) <span class="comment"># 在真实标签上加上服从正态分布的噪声项</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(features[<span class="number">0</span>], labels[<span class="number">0</span>]) <span class="comment"># 打印第一个样本的输入特征和标签</span></span><br><span class="line"></span><br><span class="line">plt.scatter(features[:, <span class="number">1</span>].numpy(), labels.numpy(), <span class="number">1</span>) <span class="comment"># 将第二个特征与标签进行作图，看一下它们的线性关系</span></span><br></pre></td></tr></table></figure>
<h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><p>在训练模型的时候，我们需要遍历数据集并不断读取小批量数据样本。这里我们定义一个函数：它每次返回batch_size（批量大小）个随机样本的特征和标签。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span></span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples)) <span class="comment"># 生成读取索引</span></span><br><span class="line">    random.shuffle(indices) <span class="comment"># 打乱索引顺序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        j = torch.LongTensor(indices[i:<span class="built_in">min</span>(i+batch_size, num_examples)]) <span class="comment"># 将索引包装成一个Tensor，同时注意最后一次可能不足一个batch，要取实际的大小</span></span><br><span class="line">        <span class="keyword">yield</span> features.index_select(<span class="number">0</span>, j), labels.index_select(<span class="number">0</span>, j) <span class="comment"># yield关键字将data_iter()函数做成了一个迭代器</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">    <span class="built_in">print</span>(X, y)</span><br><span class="line">    <span class="keyword">break</span> <span class="comment"># 读取第一个小批量数据样本并打印。每个批量的特征形状为(10, 2)，分别对应批量大小和输入个数；标签形状为批量大小。</span></span><br></pre></td></tr></table></figure><br>对这里面用的yield用法，可以参看这篇博文辅助理解：<a target="_blank" rel="noopener" href="https://blog.csdn.net/mieleizhi0522/article/details/82142856">python中yield的用法详解——最简单，最清晰的解释</a></p>
<h3 id="初始化模型参数"><a href="#初始化模型参数" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">w = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_inputs, <span class="number">1</span>)), dtype=torch.float32) <span class="comment"># 将权重初始化为均值为0、标准差为0.01的正态随机数</span></span><br><span class="line">b = torch.zeros(<span class="number">1</span>, dtype=torch.float32) <span class="comment"># 将偏差初始化为0</span></span><br><span class="line">w.requires_grad_(requires_grad=<span class="literal">True</span>) <span class="comment"># 模型训练过程中需要对这些参数求梯度来迭代取值，所以需要将requires_grad置为True</span></span><br><span class="line">b.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linreg</span>(<span class="params">X, w, b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.mm(X, w) + b <span class="comment"># 线性回归的矢量计算表达式</span></span><br></pre></td></tr></table></figure>
<h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_loss</span>(<span class="params">y_hat, y</span>):</span></span><br><span class="line">    <span class="comment"># 注意这里返回的是向量，把y变成了y_hat的样子，注意这个地方与PyTorch中MSELoss不同</span></span><br><span class="line">       <span class="comment"># MSELoss返回的是标量，即将这里的向量再做一个操作，默认是取平均值，也可以取和</span></span><br><span class="line">    <span class="keyword">return</span>(y_hat - y.view(y_hat.size())) ** <span class="number">2</span> / <span class="number">2</span></span><br></pre></td></tr></table></figure>
<h3 id="定义优化算法"><a href="#定义优化算法" class="headerlink" title="定义优化算法"></a>定义优化算法</h3><p>以下的sgd函数实现了小批量随机梯度下降算法，它通过不断迭代模型参数来优化损失函数。这里自动求梯度模块计算得来的梯度是一个批量样本的梯度和（这是因为上面的损失函数是带小批量的，后面的loss.sum()会将这一批样本上的损失都加和，如果是像PyTorch的MSELoss取平均值的话，这里就不需要除以批量大小），将它除以批量大小来得到平均值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">params, lr, batch_size</span>):</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.data -= lr * param.grad / batch_size <span class="comment"># 注意这里更改param用的是param.data</span></span><br></pre></td></tr></table></figure><br>下图的计算公式一目了然：<br><img src="https://user-images.githubusercontent.com/6218739/75660181-4d558c00-5ca6-11ea-95a8-a343ea73ad35.png" alt="image"></p>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>在训练中，我们将多次迭代模型参数。在每次迭代中，我们根据当前读取的小批量数据样本（特征X和标签y），通过调用反向函数backward计算小批量随机梯度，并调用优化算法sgd迭代模型参数。由于我们之前设批量大小batch_size为10，每个小批量的损失l的形状为(10, 1)。由于变量l并不是一个标量，所以我们可以调用.sum()将其求和得到一个标量，再运行l.backward()得到该变量有关模型参数的梯度。注意在每次更新完参数后不要忘了将参数的梯度清零。<br>在一个迭代周期（epoch）中，我们将完整遍历一遍data_iter函数，并对训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。这里的迭代周期个数num_epochs和学习率lr都是超参数，分别设3和0.03。在实践中，大多超参数都需要通过反复试错来不断调节。虽然迭代周期数设得越大模型可能越有效，但是训练时间可能过长。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.03</span> <span class="comment"># 学习率</span></span><br><span class="line">num_epochs = <span class="number">30</span> <span class="comment"># 迭代次数</span></span><br><span class="line">net = linreg <span class="comment"># 线性回归模型</span></span><br><span class="line">loss = squared_loss <span class="comment"># 平方损失</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">        l = loss(net(X, w, b), y).<span class="built_in">sum</span>() <span class="comment"># l是有关小批量X和y的损失</span></span><br><span class="line">        l.backward() <span class="comment"># 小批量的损失对模型参数求梯度</span></span><br><span class="line">        sgd([w, b], lr, batch_size) <span class="comment"># 使用小批量随机梯度下降迭代模型参数</span></span><br><span class="line">        w.grad.data.zero_()</span><br><span class="line">        b.grad.data.zero_()</span><br><span class="line"></span><br><span class="line">    train_l = loss(net(features, w, b), labels) <span class="comment"># 每次迭代后都将模型测试一下</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %f&#x27;</span> % (epoch + <span class="number">1</span>, train_l.mean().item()))</span><br></pre></td></tr></table></figure><br>打印一下最终的参数，它们应该很接近于真实的参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(true_w, <span class="string">&#x27;\n&#x27;</span>, w)</span><br><span class="line"><span class="built_in">print</span>(true_b, <span class="string">&#x27;\n&#x27;</span>, b)</span><br></pre></td></tr></table></figure></p>
<h2 id="线性回归的简洁实现"><a href="#线性回归的简洁实现" class="headerlink" title="线性回归的简洁实现"></a>线性回归的简洁实现</h2><p>在本节中，将介绍如何使用PyTorch更方便地实现线性回归的训练。</p>
<h3 id="生成数据集-1"><a href="#生成数据集-1" class="headerlink" title="生成数据集"></a>生成数据集</h3><p>这一步跟上面的相同，不再赘述。</p>
<h3 id="读取数据-1"><a href="#读取数据-1" class="headerlink" title="读取数据"></a>读取数据</h3><p>PyTorch提供了data包来读取数据。由于data常用作变量名，将导入的data模块用Data代替。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line">batch_size = <span class="number">10</span> <span class="comment"># 一个小批量设为10个</span></span><br><span class="line">dataset = Data.TensorDataset(features, labels) <span class="comment"># 将训练数据的特征和标签组合</span></span><br><span class="line">data_iter = Data.DataLoader(dataset, batch_size, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>这里data_iter的使用跟上一节中的一样。让我们读取并打印第一个小批量数据样本。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">    <span class="built_in">print</span>(X, y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure></p>
<h3 id="定义模型-1"><a href="#定义模型-1" class="headerlink" title="定义模型"></a>定义模型</h3><p>首先，导入torch.nn模块。实际上，“nn”是neural networks（神经网络）的缩写。顾名思义，该模块定义了大量神经网络的层。之前我们已经用过了autograd，而nn就是利用autograd来定义模型。nn的核心数据结构是Module，它是一个抽象概念，既可以表示神经网络中的某个层（layer），也可以表示一个包含很多层的神经网络。在实际使用中，最常见的做法是继承nn.Module，撰写自己的网络/层。一个nn.Module实例应该包含一些层以及返回输出的前向传播（forward）方法。下面先来看看如何用nn.Module实现一个线性回归模型。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_feature</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LinearNet, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_feature, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span> <span class="comment"># 定义前向传播</span></span><br><span class="line">        y = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">net = LinearNet(num_inputs)</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure><br>事实上我们还可以用nn.Sequential来更加方便地搭建网络，Sequential是一个有序的容器，网络层将按照在传入Sequential的顺序依次被添加到计算图中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写法一</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Linear(num_inputs, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 还可以再添加层</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 写法二</span></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add_module(<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 写法三</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net = nn.Sequential(OrderedDict([</span><br><span class="line">                                 (<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="number">1</span>))</span><br><span class="line">                                 <span class="comment"># 还可以再添加层</span></span><br><span class="line">]))</span><br><span class="line"><span class="built_in">print</span>(net) <span class="comment"># 注意这个地方的输出与前面自定义net的不同</span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">0</span>]) <span class="comment"># 这里的net是Sequential实例，所以需要加索引</span></span><br></pre></td></tr></table></figure>
<p>可以通过net.parameters()来查看模型所有的可学习参数，此函数将返回一个生成器。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> net.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param) <span class="comment"># 这里面的参数的个数和尺寸是根据网络层的结构及输入输出自动确定的。</span></span><br></pre></td></tr></table></figure><br>注意：torch.nn仅支持输入一个batch的样本不支持单个样本输入，如果只有单个样本，可使用input.unsqueeze(0)来添加一维。</p>
<h3 id="初始化模型参数-1"><a href="#初始化模型参数-1" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>在使用net前，我们需要初始化模型参数，如线性回归模型中的权重和偏差。PyTorch在init模块中提供了多种参数初始化方法。这里的init是initializer的缩写形式。我们通过init.normal_将权重参数每个元素初始化为随机采样于均值为0、标准差为0.01的正态分布。偏差会初始化为零。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="comment"># net[0]这样根据下标访问子模块的写法只有当net是个ModuleList或者Sequential实例时才可以</span></span><br><span class="line"><span class="comment"># 如果net是像第一种那样自定义的，需要将索引去掉</span></span><br><span class="line"></span><br><span class="line">init.normal_(net[<span class="number">0</span>].weight, mean=<span class="number">0</span>, std=<span class="number">0.1</span>)</span><br><span class="line">init.constant_(net[<span class="number">0</span>].bias, val=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="定义损失函数-1"><a href="#定义损失函数-1" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><p>PyTorch在nn模块中提供了各种损失函数，这些损失函数可看作是一种特殊的层，PyTorch也将这些损失函数实现为nn.Module的子类。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss() <span class="comment"># 使用均方误差损失作为损失函数</span></span><br></pre></td></tr></table></figure></p>
<h3 id="定义优化算法-1"><a href="#定义优化算法-1" class="headerlink" title="定义优化算法"></a>定义优化算法</h3><p>同样，我们也无须自己实现小批量随机梯度下降算法。torch.optim模块提供了很多常用的优化算法比如SGD、Adam和RMSProp等。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.03</span>) <span class="comment"># 设置学习率为0.03</span></span><br><span class="line"><span class="built_in">print</span>(optimizer)</span><br></pre></td></tr></table></figure><br>还可以为不同子网络设置不同的学习率，这在finetune时经常用到。例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里不能直接运行，因为subnet1都是假的</span></span><br><span class="line">optimizer = optim.SGD([</span><br><span class="line">                       &#123;<span class="string">&#x27;params&#x27;</span>: net.subnet1.parameters()&#125;, <span class="comment"># 如果对某个参数不指定学习率，就使用最外层的默认学习率</span></span><br><span class="line">                       &#123;<span class="string">&#x27;params&#x27;</span>: net.subnet2.parameters(), <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.01</span>&#125;</span><br><span class="line">], lr=<span class="number">0.03</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>有时候我们不想让学习率固定成一个常数，那如何调整学习率呢？主要有两种做法。一种是修改optimizer.param_groups中对应的学习率，另一种是更简单也是较为推荐的做法——新建优化器，由于optimizer十分轻量级，构建开销很小，故而可以构建新的optimizer。但是后者对于使用动量的优化器（如Adam），会丢失动量等状态信息，可能会造成损失函数的收敛出现震荡等情况。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">    param_group[<span class="string">&#x27;lr&#x27;</span>] *= <span class="number">0.1</span> <span class="comment"># 学习率调整为之前的0.1倍</span></span><br></pre></td></tr></table></figure></p>
<h3 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h3><p>通过调用optim实例的step函数来迭代模型参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, num_epochs+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        output = net(X)</span><br><span class="line">        l = loss(output, y.view(-<span class="number">1</span>, <span class="number">1</span>)) <span class="comment"># output的size是[10, 1]，而y的size是[10]，所以y要改变一下形状</span></span><br><span class="line">        <span class="comment"># 同时，这里的l是算的这一批次上的样本的损失的平均值</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment"># 梯度清零， 等价于net.zero_grad()</span></span><br><span class="line">        l.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %f&#x27;</span> % (epoch, l.item()))</span><br></pre></td></tr></table></figure><br>将学习到的权重和偏差与真实值进行一下对比：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(true_w, net[<span class="number">0</span>].weight)</span><br><span class="line"><span class="built_in">print</span>(true_b, net[<span class="number">0</span>].bias)</span><br></pre></td></tr></table></figure></p>
<h2 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h2><p>前几节介绍的线性回归模型适用于输出为连续值的情景。在另一类情景中，模型输出可以是一个像图像类别这样的离散值。对于这样的离散值预测问题，我们可以使用诸如softmax回归在内的分类模型。和线性回归不同，softmax回归的输出单元从一个变成了多个，且引入了softmax运算使输出更适合离散值的预测和训练。</p>
<p>虽然我们仍然可以使用回归模型来进行建模，并将预测值就近定点化到1、2和3这样的离散值之一，但这种连续值到离散值的转化通常会影响到分类质量。因此我们一般使用更加适合离散值输出的模型来解决分类问题。<br>（1）softmax运算的必要性<br>既然分类问题需要得到离散的预测输出，一个简单的办法是将输出值当作预测类别是i的置信度，并将值最大的输出所对应的类作为预测输出。然而，直接使用输出层的输出有两个问题。一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。<br>softmax运算符（softmax operator）解决了以上两个问题。它通过softmax操作将输出值变换成值为正且和为1的概率分布，这样某一概率大了，也等价于它的输出是大的，这样就不改变预测类别输出。<br>（2）交叉熵损失函数<br>softmax运算将输出变换成一个合法的类别预测分布。另一方面，真实标签也可以用类别分布表达，比如构造一个向量，使其第i个元素为1，其余为0，就代表样本i类别的离散数值。这样，训练目标就可以设为预测概率分布尽可能接近于真实的标签概率分布。<br>因此，就是寻找适合衡量两个概率分布差异的测量函数，其中，交叉熵（cross entropy）是一个常用的衡量方法，它只关心对正确类别的预测概率，只要其值足够大，就可以确保分类结果正确，因为如果不是正确类别，这个交叉熵就是0。<br>（3）模型预测及评价<br>在训练好softmax回归模型后，给定任一样本特征，就可以预测每个输出类别的概率。通常把预测概率最大的类别作为输出类别。如果它与真实类别（标签）一致，说明这次预测是正确的。下面将使用准确率（accuracy）来评价模型的表现。它等于正确预测数量与总预测数量之比。</p>
<h2 id="图像分类数据集Fashion-MNIST"><a href="#图像分类数据集Fashion-MNIST" class="headerlink" title="图像分类数据集Fashion-MNIST"></a>图像分类数据集Fashion-MNIST</h2><p>本节将使用torchvision包来加载Fashion-MNIST数据集，<br>它是服务于PyTorch深度学习框架的，主要用来构建计算机视觉模型。torchvision主要由以下几部分构成：<br>torchvision.datasets: 一些加载数据的函数及常用的数据集接口；<br>torchvision.models: 包含常用的模型结构（含预训练模型），例如AlexNet、VGG、ResNet等；<br>torchvision.transforms: 常用的图片变换，例如裁剪、旋转等；<br>torchvision.utils: 其他的一些有用的方法。</p>
<h3 id="获取数据集"><a href="#获取数据集" class="headerlink" title="获取数据集"></a>获取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过train参数指定获取训练集或测试集，download指定是否下载</span></span><br><span class="line"><span class="comment"># transforms.ToTensor()使所有数据转换为Tensor，如果不进行转换则返回的是PIL图片</span></span><br><span class="line">mnist_train = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line">mnist_test = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br></pre></td></tr></table></figure>
<p>transforms.ToTensor()将尺寸为 (H x W x C) 且数据位于[0, 255]的PIL图片或者数据类型为np.uint8的NumPy数组转换为尺寸为(C x H x W)且数据类型为torch.float32且位于[0.0, 1.0]的Tensor。<br>这个地方有个坑：如果输入的数组是0到255之间，但数据类型不是np.uint8，那么ToTensor()只会更改通道顺序，而不会除以255变换到0到1之间，所以，如果用像素值(0-255整数)表示图片数据，那么一律将其类型设置成uint8，避免不必要的bug。一定要确保input和output都是心里有数的。</p>
<p>见如下几篇相关帖子：<br><a target="_blank" rel="noopener" href="https://discuss.pytorch.org/t/bugs-with-torchvision-transforms-topilimage/26109">Bugs with torchvision.transforms.ToPILImage()?</a><br><a target="_blank" rel="noopener" href="https://tangshusen.me/2018/12/05/kaggle-doodle-reco/">2.2.4 图像数据的一个坑</a></p>
<p>查看数据集中的数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> img_as_ubyte</span><br><span class="line"><span class="comment"># mnist_train和mnist_test都是torch.utils.data.Dataset的子类</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(mnist_train))</span><br><span class="line">feature, label = mnist_train[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(feature.shape, label) <span class="comment"># shape是通道*高*宽</span></span><br><span class="line">io.imsave(<span class="string">&quot;1.png&quot;</span>, img_as_ubyte(feature.view((<span class="number">28</span>, <span class="number">28</span>)).numpy()))</span><br></pre></td></tr></table></figure><br>feature中的图像已经是[0.0, 1.0]范围，所以需要转化成[0, 255]范围才能正常显示。<br>参考见<a target="_blank" rel="noopener" href="https://www.cnblogs.com/denny402/p/5122328.html">这篇文章</a>。</p>
<p>将数值标签与文本标签对应起来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_fashion_mnist_labels</span>(<span class="params">labels</span>):</span></span><br><span class="line">    text_labels = [<span class="string">&#x27;t-shirt&#x27;</span>, <span class="string">&#x27;trouser&#x27;</span>, <span class="string">&#x27;pullover&#x27;</span>, <span class="string">&#x27;dress&#x27;</span>, <span class="string">&#x27;coat&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;sandal&#x27;</span>, <span class="string">&#x27;shirt&#x27;</span>, <span class="string">&#x27;sneaker&#x27;</span>, <span class="string">&#x27;bag&#x27;</span>, <span class="string">&#x27;ankle boot&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> [text_labels[<span class="built_in">int</span>(i)] <span class="keyword">for</span> i <span class="keyword">in</span> labels]</span><br></pre></td></tr></table></figure></p>
<h3 id="读取小批量"><a href="#读取小批量" class="headerlink" title="读取小批量"></a>读取小批量</h3><p>在实践中，数据读取经常是训练的性能瓶颈，特别当模型较简单或者计算硬件性能较高时。PyTorch的DataLoader中一个很方便的功能是允许使用多进程来加速数据读取。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">num_workers = <span class="number">4</span></span><br><span class="line"><span class="comment"># mnist_train是torch.utils.data.Dataset的子类，所以我们可以将其传入torch.utils.data.DataLoader来创建一个读取小批量数据样本的DataLoader实例</span></span><br><span class="line"><span class="comment"># 通过参数num_workers来设置4个进程读取数据</span></span><br><span class="line">train_iter = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers)</span><br><span class="line">test_iter = torch.utils.data.DataLoader(mnist_test, batch_size = batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br></pre></td></tr></table></figure><br>查看一下，读取一遍训练数据需要的时间：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%.2f sec&#x27;</span> % (time.time()-start))</span><br></pre></td></tr></table></figure></p>
<h2 id="softmax回归的从零开始实现"><a href="#softmax回归的从零开始实现" class="headerlink" title="softmax回归的从零开始实现"></a>softmax回归的从零开始实现</h2><h3 id="获取和读取数据"><a href="#获取和读取数据" class="headerlink" title="获取和读取数据"></a>获取和读取数据</h3><p>这一步就是按照上一节中下载和小批量读取Fashion-MNIST数据集的方式。</p>
<h3 id="初始化模型参数-2"><a href="#初始化模型参数-2" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>跟线性回归中的例子一样，我们将使用向量表示每个样本。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">num_inputs = <span class="number">784</span> <span class="comment"># 这里用向量来表示图像，28*28=784，相当于784个输入特征</span></span><br><span class="line">num_outputs = <span class="number">10</span> <span class="comment"># 输出为10个类别</span></span><br><span class="line">W = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_inputs, num_outputs)), dtype=torch.<span class="built_in">float</span>) <span class="comment"># 权重为784*10，初始为正态分布</span></span><br><span class="line">b = torch.tensor(np.zeros(num_outputs), dtype=torch.<span class="built_in">float</span>) <span class="comment"># 偏差为10， 初始为0</span></span><br><span class="line">W.requires_grad_(requires_grad=<span class="literal">True</span>) <span class="comment"># 设置需要计算梯度</span></span><br><span class="line">b.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="实现softmax运算"><a href="#实现softmax运算" class="headerlink" title="实现softmax运算"></a>实现softmax运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先演示一下怎样对多维Tensor按维度进行操作</span></span><br><span class="line">X = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(X.<span class="built_in">sum</span>(dim = <span class="number">0</span>, keepdim=<span class="literal">True</span>)) <span class="comment"># tensor([[5, 7, 9]])，对同一列的元素求和，并保持原来的维度</span></span><br><span class="line"><span class="built_in">print</span>(X.<span class="built_in">sum</span>(dim = <span class="number">1</span>, keepdim=<span class="literal">True</span>)) <span class="comment"># tensor([[6], [15]])，对同一行的元素求和，并保持原来的维度</span></span><br><span class="line"><span class="comment"># 定义softmax运算</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">X</span>):</span> <span class="comment"># 矩阵X的行数是样本数，列数是输出个数</span></span><br><span class="line">    X_exp = X.exp() <span class="comment"># 先对每个元素做指数运算</span></span><br><span class="line">    partition = X_exp.<span class="built_in">sum</span>(dim = <span class="number">1</span>, keepdim = <span class="literal">True</span>) <span class="comment"># 然后对exp矩阵同一行的元素求和</span></span><br><span class="line">    <span class="keyword">return</span> X_exp / partition <span class="comment"># 最后令exp矩阵的每行各元素与该行元素之和相除，最终使得每行元素的和为1且非负，所以每行都是合法的概率分布</span></span><br><span class="line">    <span class="comment"># 这个除法也应用了广播机制</span></span><br></pre></td></tr></table></figure>
<h3 id="定义模型-2"><a href="#定义模型-2" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">net</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="comment"># 注意，这里需要使用view函数将图像转换为向量</span></span><br><span class="line">    <span class="keyword">return</span> softmax(torch.mm(X.view((-<span class="number">1</span>, num_inputs)), W) + b)</span><br></pre></td></tr></table></figure>
<h3 id="定义损失函数-2"><a href="#定义损失函数-2" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先演示一下gather函数的用法</span></span><br><span class="line">y_hat = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.6</span>], [<span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.5</span>]]) <span class="comment"># 这是虚构的两个样本在3个类别下的预测概率</span></span><br><span class="line">y = torch.LongTensor([<span class="number">0</span>, <span class="number">2</span>]) <span class="comment"># 这是虚构的两个样本的标签类别</span></span><br><span class="line">y_hat.gather(<span class="number">1</span>, y.view(-<span class="number">1</span>, <span class="number">1</span>)) <span class="comment"># tensor([[0.1000], [0.5000]]) 这样就得到了两个样本的标签的预测概率</span></span><br></pre></td></tr></table></figure>
<p>关于gather函数，其实就是索引，具体解析可以参看<a target="_blank" rel="noopener" href="https://www.cnblogs.com/HongjianChen/p/9451526.html">这篇博文</a>。<br>那么交叉熵损失函数就是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy</span>(<span class="params">y_hat, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> - torch.log(y_hat.gather(<span class="number">1</span>, y.view(-<span class="number">1</span>, <span class="number">1</span>)))</span><br></pre></td></tr></table></figure></p>
<h3 id="计算分类准确率"><a href="#计算分类准确率" class="headerlink" title="计算分类准确率"></a>计算分类准确率</h3><p>给定一个类别的预测概率分布y_hat，我们把预测概率最大的类别作为输出类别。如果它与真实类别y一致，说明这次预测是正确的。分类准确率即正确预测数量与总预测数量之比。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">y_hat, y</span>):</span></span><br><span class="line">    <span class="comment"># argmax返回矩阵y_hat每行中最大元素的索引，且返回结果与变量y形状相同</span></span><br><span class="line">    <span class="comment"># 相等条件判断式(y_hat.argmax(dim=1) == y)是一个类型为ByteTensor的Tensor</span></span><br><span class="line">    <span class="comment"># 用float()将其转换为值为0（相等为假）或1（相等为真）的浮点型Tensor</span></span><br><span class="line">    <span class="keyword">return</span> (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">float</span>().mean().item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy(y_hat, y))</span><br><span class="line"><span class="comment"># 继续使用在演示gather函数时定义的变量y_hat和y，并将它们分别作为预测概率分布和标签</span></span><br><span class="line"><span class="comment"># 可以看到，第一个样本预测类别为2（该行最大元素0.6在本行的索引为2），与真实标签0不一致</span></span><br><span class="line"><span class="comment"># 第二个样本预测类别为2（该行最大元素0.5在本行的索引为2），与真实标签2一致</span></span><br><span class="line"><span class="comment"># 因此，这两个样本上的分类准确率为0.5。</span></span><br></pre></td></tr></table></figure></p>
<p>评价模型net在数据集data_iter上的准确率：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">data_iter, net</span>):</span></span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        acc_sum += (net(X).argmax(dim=<span class="number">1</span>)==y).<span class="built_in">float</span>().<span class="built_in">sum</span>().item() <span class="comment"># 注意这个地方先求和</span></span><br><span class="line">        n +=  y.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> acc_sum /n <span class="comment"># 再求平均</span></span><br></pre></td></tr></table></figure></p>
<h3 id="训练模型-2"><a href="#训练模型-2" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, lr = <span class="number">5</span>, <span class="number">0.1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">params, lr, batch_size</span>):</span> <span class="comment"># 定义优化算法</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.data -= lr * param.grad / batch_size </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch3</span>(<span class="params">net, train_iter, test_iter, loss, num_epochs, batch_size, params=<span class="literal">None</span>, lr=<span class="literal">None</span>, optimizer=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y).<span class="built_in">sum</span>() <span class="comment"># 这个地方是求和，所以后面的SGD算法中除以batch size</span></span><br><span class="line">            <span class="keyword">if</span> optimizer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment"># 这里看是否传入了优化器，默认是不传入</span></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">            <span class="keyword">elif</span> params <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> params[<span class="number">0</span>].grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment"># 如果不传入优化器，就显式地对参数梯度置为0</span></span><br><span class="line">                <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">                    param.grad.data.zero_()</span><br><span class="line"></span><br><span class="line">            l.backward()</span><br><span class="line">            <span class="keyword">if</span> optimizer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                sgd(params, lr, batch_size)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                optimizer.step()</span><br><span class="line"></span><br><span class="line">            train_l_sum += l.item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %.4f, train acc %.3f, test acc %.3f&#x27;</span> </span><br><span class="line">              % (epoch+<span class="number">1</span>, train_l_sum/n, train_acc_sum/n, test_acc))</span><br><span class="line"></span><br><span class="line">train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)</span><br></pre></td></tr></table></figure>
<h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X, y = <span class="built_in">iter</span>(test_iter).<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(net(X).argmax(dim=<span class="number">1</span>)[:<span class="number">10</span>], y[:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<h2 id="softmax回归的简洁实现"><a href="#softmax回归的简洁实现" class="headerlink" title="softmax回归的简洁实现"></a>softmax回归的简洁实现</h2><h3 id="获取和读取数据-1"><a href="#获取和读取数据-1" class="headerlink" title="获取和读取数据"></a>获取和读取数据</h3><p>与上一节相同</p>
<h3 id="定义和初始化模型"><a href="#定义和初始化模型" class="headerlink" title="定义和初始化模型"></a>定义和初始化模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">num_inputs = <span class="number">784</span></span><br><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_inputs, num_outputs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LinearNet, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(num_inputs, num_outputs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span> <span class="comment"># x的形状是(batch, 1, 28, 28)，所以要view一下</span></span><br><span class="line">        y = self.linear(x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">net = LinearNet(num_inputs, num_outputs)</span><br></pre></td></tr></table></figure>
<p>还可以将形状转换这一块单独提出来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlattenLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    OrderedDict([</span><br><span class="line">                 (<span class="string">&#x27;flatten&#x27;</span>, FlattenLayer()),</span><br><span class="line">                 (<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, num_outputs))</span><br><span class="line">    ])</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>然后，我们使用均值为0、标准差为0.01的正态分布随机初始化模型的权重参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line">init.normal_(net.linear.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant_(net.linear.bias, val=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="softmax和交叉熵损失函数"><a href="#softmax和交叉熵损失函数" class="headerlink" title="softmax和交叉熵损失函数"></a>softmax和交叉熵损失函数</h3><p>在上一节的练习中，分开定义softmax运算和交叉熵损失函数可能会造成数值不稳定。因此，PyTorch提供了一个包括softmax运算和交叉熵损失计算的函数。它的数值稳定性更好。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure></p>
<h3 id="定义优化算法-2"><a href="#定义优化算法-2" class="headerlink" title="定义优化算法"></a>定义优化算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="训练模型-3"><a href="#训练模型-3" class="headerlink" title="训练模型"></a>训练模型</h3><p>使用上一节定义的训练函数，只是传入不同的参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, <span class="literal">None</span>, <span class="literal">None</span>, optimizer)</span><br></pre></td></tr></table></figure></p>
<h2 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h2><p>多层感知机在单层神经网络的基础上引入了一到多个隐藏层（hidden layer）。隐藏层位于输入层和输出层之间。<br>由于输入层不涉及计算，因此，多层感知机的层数等于隐藏层的层数加上输出层。<br>全连接层只是对数据做仿射变换（affine transformation），而多个仿射变换的叠加仍然是一个仿射变换。<br>（1）激活函数<br>对隐藏变量使用按元素运算的非线性函数进行变换，然后再作为下一个全连接层的输入。这个非线性函数被称为激活函数（activation function）。<br>常用的激活函数包括ReLU函数、sigmoid函数和tanh函数。<br>（2）多层感知机<br>多层感知机就是含有至少一个隐藏层的由全连接层组成的神经网络，且每个隐藏层的输出通过激活函数进行变换。<br>多层感知机的层数和各隐藏层中隐藏单元个数都是超参数。</p>
<h2 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h2><p>过拟合现象，即模型的训练误差远小于它在测试集上的误差。虽然增大训练数据集可能会减轻过拟合，但是获取额外的训练数据往往代价高昂。<br>应对过拟合问题的常用方法：权重衰减（weight decay）和丢弃法（Dropout，下一节介绍）。<br>权重衰减等价于L2范数正则化（regularization）。正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对过拟合的常用手段。<br>L2范数正则化在模型原损失函数基础上添加L2范数惩罚项，从而得到训练所需要最小化的函数。L2范数惩罚项指的是模型权重参数每个元素的平方和与一个正的常数的乘积。<br>L2范数正则化令权重先自乘小于1的数，再减去不含惩罚项的梯度。因此，L2范数正则化又叫权重衰减。<br>权重衰减通过惩罚绝对值较大的模型参数为需要学习的模型增加了限制，这可能对过拟合有效。实际场景中，我们有时也在惩罚项中添加偏差元素的平方和。<br>可以直接在构造优化器实例时通过weight_decay参数来指定权重衰减超参数。默认下，PyTorch会对权重和偏差同时衰减。我们可以分别对权重和偏差构造优化器实例，从而只对权重衰减。</p>
<h2 id="丢弃法"><a href="#丢弃法" class="headerlink" title="丢弃法"></a>丢弃法</h2><p>当对某隐藏层使用丢弃法时，该层的隐藏单元将有一定概率被丢弃掉。<br>丢弃概率是丢弃法的超参数。<br>丢弃法不改变其输入的期望值。<br>在测试模型时，我们为了拿到更加确定性的结果，一般不使用丢弃法。<br>在PyTorch中，我们只需要在全连接层后添加Dropout层并指定丢弃概率。在训练模型时，Dropout层将以指定的丢弃概率随机丢弃上一层的输出元素；在测试模型时（即model.eval()后），Dropout层并不发挥作用。</p>
<h2 id="正向传播、反向传播和计算图"><a href="#正向传播、反向传播和计算图" class="headerlink" title="正向传播、反向传播和计算图"></a>正向传播、反向传播和计算图</h2><p>正向传播是指对神经网络沿着从输入层到输出层的顺序，依次计算并存储模型的中间变量（包括输出）。<br>我们通常绘制计算图来可视化运算符和变量在计算中的依赖关系，其中方框代表变量，圆圈代表运算符，箭头表示从输入到输出之间的依赖关系。<br>反向传播指的是计算神经网络参数梯度的方法。总的来说，反向传播依据微积分中的链式法则，沿着从输出层到输入层的顺序，依次计算并存储目标函数有关神经网络各层的中间变量以及参数的梯度。</p>
<p>在训练深度学习模型时，正向传播和反向传播之间相互依赖：<br>一方面，正向传播的计算可能依赖于模型参数的当前值，而这些模型参数是在反向传播的梯度计算后通过优化算法迭代的；<br>另一方面，反向传播的梯度计算可能依赖于各变量的当前值，而这些变量的当前值是通过正向传播计算得到的。</p>
<p>因此，在模型参数初始化完成后，我们交替地进行正向传播和反向传播，并根据反向传播计算的梯度迭代模型参数。既然我们在反向传播中使用了正向传播中计算得到的中间变量来避免重复计算，那么这个复用也导致正向传播结束后不能立即释放中间变量内存。这也是训练要比预测占用更多内存的一个重要原因。另外需要指出的是，这些中间变量的个数大体上与网络层数线性相关，每个变量的大小跟批量大小和输入个数也是线性相关的，它们是导致较深的神经网络使用较大批量训练时更容易超内存的主要原因。</p>
<h2 id="数值稳定性和模型初始化"><a href="#数值稳定性和模型初始化" class="headerlink" title="数值稳定性和模型初始化"></a>数值稳定性和模型初始化</h2><p>深度模型有关数值稳定性的典型问题是衰减（vanishing）和爆炸（explosion）。<br>在神经网络中，通常需要随机初始化模型参数。<br>随机初始化模型参数的方法有很多。之前的实现中，我们使用torch.nn.init.normal_()使模型net的权重参数采用正态分布的随机初始化方式。不过，PyTorch中nn.Module的模块参数都采取了较为合理的初始化策略（不同类型的layer具体采样的哪一种初始化方法的可参考源代码），因此一般不用我们考虑。</p>
<p>还有一种比较常用的随机初始化方法叫作Xavier随机初始化，它的设计主要考虑到，模型参数初始化后，每层输出的方差不该受该层输入个数影响，且每层梯度的方差也不该受该层输出个数影响。</p>
<h1 id="深度学习计算"><a href="#深度学习计算" class="headerlink" title="深度学习计算"></a>深度学习计算</h1><h2 id="模型构造"><a href="#模型构造" class="headerlink" title="模型构造"></a>模型构造</h2><p>有多种模型构造的方法：</p>
<h3 id="继承Module类来构造模型"><a href="#继承Module类来构造模型" class="headerlink" title="继承Module类来构造模型"></a>继承Module类来构造模型</h3><p>Module类是nn模块里提供的一个模型构造类，是所有神经网络模块的基类，我们可以继承它来定义我们想要的模型。</p>
<h3 id="Module的子类"><a href="#Module的子类" class="headerlink" title="Module的子类"></a>Module的子类</h3><p>Module类是一个通用的部件。事实上，PyTorch还实现了继承自Module的可以方便构建模型的类: 如Sequential、ModuleList和ModuleDict等等。不过虽然Sequential等类可以使模型构造更加简单，但直接继承Module类可以极大地拓展模型构造的灵活性。<br>（1）Sequential类：当模型的前向计算为简单串联各个层的计算时，Sequential类可以通过更加简单的方式定义模型。这正是Sequential类的目的：它可以接收一个子模块的有序字典（OrderedDict）或者一系列子模块作为参数来逐一添加Module的实例，而模型的前向计算就是将这些实例按添加的顺序逐一计算。<br>（2）ModuleList类：ModuleList接收一个子模块的列表作为输入，然后也可以类似List那样进行append和extend操作。<br>既然Sequential和ModuleList都可以进行列表化构造网络，那二者区别是什么呢。ModuleList仅仅是一个储存各种模块的列表，这些模块之间没有联系也没有顺序（所以不用保证相邻层的输入输出维度匹配），而且没有实现forward功能需要自己实现；而Sequential内的模块需要按照顺序排列，要保证相邻层的输入输出大小相匹配，内部forward功能已经实现。<br>ModuleList的出现只是让网络定义前向传播时更加灵活；另外，ModuleList不同于一般的Python的list，加入到ModuleList里面的所有模块的参数会被自动添加到整个网络中。<br>（3）ModuleDict类：ModuleDict接收一个子模块的字典作为输入, 然后也可以类似字典那样进行添加访问操作；和ModuleList一样，ModuleDict实例仅仅是存放了一些模块的字典，并没有定义forward函数需要自己定义。同样，ModuleDict也与Python的Dict有所不同，ModuleDict里的所有模块的参数会被自动添加到整个网络中。</p>
<h2 id="模型参数的访问、初始化和共享"><a href="#模型参数的访问、初始化和共享" class="headerlink" title="模型参数的访问、初始化和共享"></a>模型参数的访问、初始化和共享</h2><h3 id="访问模型参数"><a href="#访问模型参数" class="headerlink" title="访问模型参数"></a>访问模型参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Linear(<span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">) <span class="comment"># Pytorch 已进行默认初始化</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line">X = torch.rand(<span class="number">2</span>, <span class="number">4</span>) <span class="comment"># 构造数据集的输入</span></span><br><span class="line">Y = net(X).<span class="built_in">sum</span>() <span class="comment"># 根据默认初始化的参数计算输出</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过Module类的parameters()或者named_parameters方法来访问所有参数（以迭代器的形式返回）</span></span><br><span class="line"><span class="comment"># 后者除了返回参数Tensor外还会返回其名字</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(net.named_parameters()))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(name, param.size()) <span class="comment"># 返回的名字自动加上了层数的索引作为前缀</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于使用Sequential类构造的神经网络，可以通过方括号[]来访问网络的任一层。</span></span><br><span class="line"><span class="comment"># 索引0表示隐藏层为Sequential实例最先添加的层。</span></span><br><span class="line"><span class="comment"># 返回的param的类型为torch.nn.parameter.Parameter，其实这是Tensor的子类</span></span><br><span class="line"><span class="comment"># 和Tensor不同的是如果一个Tensor是Parameter，那么它会自动被添加到模型的参数列表里</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net[<span class="number">0</span>].named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(name, param.size(), <span class="built_in">type</span>(param)) <span class="comment"># 这里是单层的参数，所以名字中没有层数索引的前缀</span></span><br><span class="line"></span><br><span class="line">weight_0 = <span class="built_in">list</span>(net[<span class="number">0</span>].parameters())[<span class="number">0</span>] <span class="comment"># 要使用list将这个迭代器转化一下</span></span><br><span class="line"><span class="comment"># 因为Parameter是Tensor，即Tensor拥有的属性它都有，比如可以根据data来访问参数数值，用grad来访问参数梯度。</span></span><br><span class="line"><span class="built_in">print</span>(weight_0.data)</span><br><span class="line"><span class="built_in">print</span>(weight_0.grad) <span class="comment"># 反向传播前梯度为None</span></span><br><span class="line">Y.backward()</span><br><span class="line"><span class="built_in">print</span>(weight_0.grad)</span><br></pre></td></tr></table></figure>
<h3 id="初始化模型参数-3"><a href="#初始化模型参数-3" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>PyTorch中nn.Module的模块参数采取了默认的较为合理的初始化策略（不同类型的layer具体采样的哪一种初始化方法的可参考源代码）。但我们经常需要使用其他方法来初始化权重。PyTorch的init模块里提供了多种预设的初始化方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;weight&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        init.normal_(param, mean=<span class="number">0</span>, std=<span class="number">0.01</span>) <span class="comment"># 用正态分布初始化权重</span></span><br><span class="line">        <span class="built_in">print</span>(name, param.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;bias&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        init.constant_(param, val=<span class="number">0</span>) <span class="comment"># 将偏差置0</span></span><br><span class="line">        <span class="built_in">print</span>(name, param.data)</span><br></pre></td></tr></table></figure></p>
<h3 id="自定义初始化方法"><a href="#自定义初始化方法" class="headerlink" title="自定义初始化方法"></a>自定义初始化方法</h3><p>有时候我们需要的初始化方法并没有在init模块中提供。这时，可以实现一个初始化方法，从而能够像使用其他初始化方法那样使用它。在这之前我们先来看看PyTorch是怎么实现这些初始化方法的，例如torch.nn.init.normal_：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normal_</span>(<span class="params">tensor, mean=<span class="number">0</span>, std=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">return</span> tensor.normal_(mean, std)</span><br></pre></td></tr></table></figure><br>可以看到这就是一个inplace改变Tensor值的函数，而且这个过程是不记录梯度的。 类似的我们来实现一个自定义的初始化方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_weight_</span>(<span class="params">tensor</span>):</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        tensor.uniform_(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">        tensor *= (tensor.<span class="built_in">abs</span>() &gt;= <span class="number">5</span>).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;weight&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        init_weight_(param)</span><br><span class="line">        <span class="built_in">print</span>(name, param.data)</span><br></pre></td></tr></table></figure><br>还可以通过改变这些参数的data来改写模型参数值同时不会影响梯度：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;bias&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        param.data += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(name, param.data)</span><br></pre></td></tr></table></figure></p>
<h3 id="共享模型参数"><a href="#共享模型参数" class="headerlink" title="共享模型参数"></a>共享模型参数</h3><p>在有些情况下，我们希望在多个层之间共享模型参数。共享模型参数的方式有: Module类的forward函数里多次调用同一个层。此外，如果我们传入Sequential的模块是同一个Module实例的话参数也是共享的。<br>不过注意，因为模型参数里包含了梯度，所以在反向传播计算时，这些共享的参数的梯度是累加的。</p>
<h2 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a>自定义层</h2><p>虽然PyTorch提供了大量常用的层，但有时候我们依然希望自定义层。本节将介绍如何使用Module来自定义层，从而可以被重复调用。</p>
<h3 id="不含模型参数的自定义层"><a href="#不含模型参数的自定义层" class="headerlink" title="不含模型参数的自定义层"></a>不含模型参数的自定义层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CenteredLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CenteredLayer, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将计算放在了forward函数里，所以，该自定义层没有模型参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x - x.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以实例化这个层，然后做前向计算</span></span><br><span class="line">layer = CenteredLayer()</span><br><span class="line">layer(torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], dtype=torch.<span class="built_in">float</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以用它来构造更复杂的模型</span></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">8</span>, <span class="number">128</span>), CenteredLayer())</span><br><span class="line">y = net(torch.rand(<span class="number">4</span>, <span class="number">8</span>))</span><br><span class="line">y.mean().item()</span><br></pre></td></tr></table></figure>
<h3 id="含模型参数的自定义层"><a href="#含模型参数的自定义层" class="headerlink" title="含模型参数的自定义层"></a>含模型参数的自定义层</h3><p>我们还可以自定义含模型参数的自定义层。其中的模型参数可以通过训练学出。<br>之前介绍了Parameter类其实是Tensor的子类，如果一个Tensor是Parameter，那么它会自动被添加到模型的参数列表里。所以在自定义含模型参数的层时，我们应该将参数定义成Parameter，除了像之前那样直接定义成Parameter类外，还可以使用ParameterList和ParameterDict分别定义参数的列表和字典。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ParameterList接收一个Parameter实例的列表作为输入然后得到一个参数列表，使用的时候可以用索引来访问某个参数</span></span><br><span class="line"><span class="comment"># 另外也可以使用append和extend在列表后面新增参数。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.params = nn.ParameterList([nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)])</span><br><span class="line">        self.params.append(nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>)))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.params)):</span><br><span class="line">            x = torch.mm(x, self.params[i])</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = MyDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"><span class="comment"># 而ParameterDict接收一个Parameter实例的字典作为输入然后得到一个参数字典，然后可以按照字典的规则使用了。</span></span><br><span class="line"><span class="comment"># 例如使用update()新增参数，使用keys()返回所有键值，使用items()返回所有键值对等等</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDictDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.params = nn.ParameterDict(&#123;</span><br><span class="line">            <span class="string">&#x27;linear1&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)),</span><br><span class="line">            <span class="string">&#x27;linear2&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        self.params.update(&#123;<span class="string">&#x27;linear3&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">2</span>))&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, choice=<span class="string">&#x27;linear1&#x27;</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mm(x, self.params[choice])</span><br><span class="line"></span><br><span class="line">net = MyDictDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这样就可以根据传入的键值来进行不同的前向传播</span></span><br><span class="line">x = torch.ones(<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(net(x, <span class="string">&#x27;linear1&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(net(x, <span class="string">&#x27;linear2&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(net(x, <span class="string">&#x27;linear3&#x27;</span>))</span><br><span class="line"><span class="comment"># 可以使用自定义层构造模型。它和PyTorch的其他层在使用上很类似</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    MyDictDense(),</span><br><span class="line">    MyDense()</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"><span class="built_in">print</span>(net(x))</span><br></pre></td></tr></table></figure></p>
<h2 id="读取和存储"><a href="#读取和存储" class="headerlink" title="读取和存储"></a>读取和存储</h2><p>在实际中，我们有时需要把训练好的模型部署到很多不同的设备。在这种情况下，我们可以把内存中训练好的模型参数存储在硬盘上供后续读取使用。</p>
<h3 id="读写Tensor"><a href="#读写Tensor" class="headerlink" title="读写Tensor"></a>读写Tensor</h3><p>我们可以直接使用save函数和load函数分别存储和读取Tensor。save使用Python的pickle实用程序将对象进行序列化，然后将序列化的对象保存到disk，使用save可以保存各种对象,包括模型、张量和字典等。而load使用pickle unpickle工具将pickle的对象文件反序列化为内存。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">3</span>)</span><br><span class="line">torch.save(x, <span class="string">&#x27;x.pt&#x27;</span>) <span class="comment"># 保存到文件</span></span><br><span class="line">x2 = torch.load(<span class="string">&#x27;x.pt&#x27;</span>) <span class="comment"># 读取文件数据到内存</span></span><br><span class="line">y = torch.zeros(<span class="number">4</span>)</span><br><span class="line">torch.save([x, y], <span class="string">&#x27;xy.pt&#x27;</span>) <span class="comment"># 存储一个Tensor列表</span></span><br><span class="line"></span><br><span class="line">xy_list = torch.load(<span class="string">&#x27;xy.pt&#x27;</span>) <span class="comment"># 读取该Tensor列表</span></span><br><span class="line">torch.save(&#123;<span class="string">&#x27;x&#x27;</span>:x, <span class="string">&#x27;y&#x27;</span>:y&#125;, <span class="string">&#x27;xy_dict.pt&#x27;</span>) <span class="comment"># 存储一个从字符串映射到Tensor的字典</span></span><br><span class="line"></span><br><span class="line">xy_dict = torch.load(<span class="string">&#x27;xy_dict.pt&#x27;</span>)</span><br><span class="line">xy_dict</span><br></pre></td></tr></table></figure></p>
<h3 id="读写模型"><a href="#读写模型" class="headerlink" title="读写模型"></a>读写模型</h3><p>在PyTorch中，Module的可学习参数，即权重和偏差，模块模型包含在参数中(通过model.parameters()访问)。state_dict是一个从参数名称隐射到参数Tesnor的字典对象。<br>注意，只有具有可学习参数的层(卷积层、线性层等)才有state_dict中的条目。优化器(optim)也有一个state_dict，其中包含关于优化器状态以及所使用的超参数的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.output = nn.Linear(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        a = self.relu(self.hidden(X))</span><br><span class="line">        <span class="keyword">return</span> self.output(a)</span><br><span class="line"></span><br><span class="line">net = MLP()</span><br><span class="line">net.state_dict() <span class="comment"># relu层没有可学习的参数</span></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">optimizer.state_dict()</span><br></pre></td></tr></table></figure>
<p>PyTorch中保存和加载训练模型有两种常见的方法:<br>（1） 仅保存和加载模型参数(state_dict)，这是推荐方式，形式为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), PATH) <span class="comment"># 保存，推荐的文件后缀名是pt或pth</span></span><br><span class="line">model = TheModelClass(*args, **kwargs) <span class="comment"># 加载</span></span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure></p>
<p>例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">Y = net(X)</span><br><span class="line">PATH = <span class="string">&#x27;./net.pt&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), PATH) <span class="comment"># 存储模型参数</span></span><br><span class="line"></span><br><span class="line">net2 = MLP() <span class="comment"># net2和net一样都是MLP()类，所以模型参数相同</span></span><br><span class="line">net2.load_state_dict(torch.load(PATH))</span><br><span class="line">Y2 = net2(X)</span><br><span class="line">Y2 == Y <span class="comment"># 两者计算结果相同</span></span><br></pre></td></tr></table></figure><br>（2）保存和加载整个模型，形式为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model, PATH) <span class="comment"># 保存</span></span><br><span class="line">model = torch.load(PATH) <span class="comment"># 加载</span></span><br></pre></td></tr></table></figure></p>
<h2 id="GPU计算"><a href="#GPU计算" class="headerlink" title="GPU计算"></a>GPU计算</h2><p>对复杂的神经网络和大规模的数据来说，使用CPU来计算可能不够高效。在本节中，将介绍如何使用单块NVIDIA GPU来计算。需要确保已经安装好了PyTorch GPU版本。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi <span class="comment"># 查看显卡信息</span></span><br></pre></td></tr></table></figure></p>
<h3 id="计算设备"><a href="#计算设备" class="headerlink" title="计算设备"></a>计算设备</h3><p>PyTorch可以指定用来存储和计算的设备，如使用内存的CPU或者使用显存的GPU。默认情况下，PyTorch会将数据创建在内存，然后利用CPU来计算。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.cuda.is_available() <span class="comment"># 查看GPU是否可用</span></span><br><span class="line">torch.cuda.device_count() <span class="comment"># 查看GPU数目</span></span><br><span class="line">torch.cuda.current_device() <span class="comment"># 查看当前GPU索引号，从0开始</span></span><br><span class="line">torch.cuda.get_device_name(<span class="number">0</span>) <span class="comment"># 根据索引号查看GPU名称</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Tensor的GPU计算"><a href="#Tensor的GPU计算" class="headerlink" title="Tensor的GPU计算"></a>Tensor的GPU计算</h3><p>默认情况下，Tensor会被存在内存上。因此，之前我们每次打印Tensor的时候看不到GPU相关标识。<br>使用.cuda()可以将CPU上的Tensor转换（复制）到GPU上。如果有多块GPU，我们用.cuda(i)来表示第 iii 块GPU及相应的显存（iii从0开始）且cuda(0)和cuda()等价。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">x = x.cuda(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.device) <span class="comment"># 可以通过Tensor的device属性来查看该Tensor所在的设备</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], device=device) <span class="comment"># 可以在创建时就指定设备</span></span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]).to(device) <span class="comment"># 第二种方法</span></span><br><span class="line">y = x**<span class="number">2</span> <span class="comment"># 如果对在GPU上的数据进行运算，那么结果还是存放在GPU上</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><br>需要注意的是，存储在不同位置中的数据是不可以直接进行计算的。即存放在CPU上的数据不可以直接与存放在GPU上的数据进行运算，位于不同GPU上的数据也是不能直接进行计算的。</p>
<h3 id="模型的GPU计算"><a href="#模型的GPU计算" class="headerlink" title="模型的GPU计算"></a>模型的GPU计算</h3><p>同Tensor类似，PyTorch模型也可以通过.cuda转换到GPU上。我们可以通过检查模型的参数的device属性来查看存放模型的设备。<br>同时，需要保证模型输入的Tensor和模型都在同一设备上，否则会报错。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Linear(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line">net.cuda() <span class="comment"># 将模型转换到CPU上</span></span><br><span class="line"><span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>).cuda()</span><br><span class="line">net(x)</span><br></pre></td></tr></table></figure></p>
<h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p>卷积神经网络中涉及到输入和输出图像的形状的转换，这里将后面模型构造时用到的一段通用测试代码摘出来，供以后参考：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">net = vgg(conv_arch, fc_features, fc_hidden_units)</span><br><span class="line"><span class="comment"># 构造一个高和宽均为224的单通道数据样本来观察每一层的输出形状</span></span><br><span class="line">X = torch.rand(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"><span class="comment"># named_children获取一级子模块及其名字(named_modules会返回所有子模块,包括子模块的子模块)</span></span><br><span class="line"><span class="keyword">for</span> name, blk <span class="keyword">in</span> net.named_children(): </span><br><span class="line">    X = blk(X)</span><br><span class="line">    <span class="built_in">print</span>(name, <span class="string">&#x27;output shape: &#x27;</span>, X.shape)</span><br></pre></td></tr></table></figure></p>
<h2 id="二维卷积层"><a href="#二维卷积层" class="headerlink" title="二维卷积层"></a>二维卷积层</h2><p>卷积神经网络（convolutional neural network）是含有卷积层（convolutional layer）的神经网络。<br>虽然卷积层得名于卷积（convolution）运算，但我们通常在卷积层中使用更加直观的互相关（cross-correlation）运算。<br>二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。即，可以通过数据来学习卷积核。<br>实际上，卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。<br>那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。<br>为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。<br>二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素x的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做X的感受野（receptive field）。<br>我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。<br>比如，输入层是一个3乘3的图像，记为X，经过一个2乘2的卷积核，得到的输出层是一个2乘2的图像，记为Y。那么Y中每个元素的感受野是X中的2乘2的范围大小，即这个元素仅与X中的这四个元素相关。此时考虑一个更深的卷积网络：将Y与另一个形状为2乘2的卷积核做互相关运算，输出单个元素z，那么，z在Y上的感受野包括Y的全部四个元素，则在输入X上的感受野包括其中全部的9个元素（X的这9个元素是由Y的四个元素所感受的）</p>
<h2 id="填充和步幅"><a href="#填充和步幅" class="headerlink" title="填充和步幅"></a>填充和步幅</h2><p>卷积层的输出形状由输入形状和卷积核窗口形状决定。卷积层的两个超参数，即填充和步幅，它们可以对给定形状的输入和卷积核改变输出形状。<br>填充（padding）是指在输入高和宽的两侧填充元素（通常是0元素）。<br>卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。我们将每次滑动的行数和列数称为步幅（stride）。</p>
<h2 id="多输入通道和多输出通道"><a href="#多输入通道和多输出通道" class="headerlink" title="多输入通道和多输出通道"></a>多输入通道和多输出通道</h2><p>（1）多输入通道<br>当输入数据含多个通道时，我们需要构造一个输入通道数与输入数据的通道数相同的卷积核，从而能够与含多通道的输入数据做互相关运算。<br>即，卷积核的通道数由输入数据的通道数所决定。<br>（2）多输出通道<br>当输入通道有多个时，因为我们对各个通道的结果做了累加，所以不论输入通道数是多少，输出通道数总是为1。<br>如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为c乘以h乘以w的卷积核，将它们在输出通道上进行连结。<br>即，输出数据的通道数由卷积核的个数所决定。<br>（3）1乘1卷积层<br>1乘1卷积层通常用来调整网络层之间的通道数（可以类比于全连接层的隐藏神经元个数），并控制模型复杂度。<br>因为使用了最小窗口，1乘1卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能。实际上，1乘1卷积的主要计算发生在通道维上。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。<br>假设将通道维当作特征维，将高和宽维度上的元素当成数据样本，那么1乘1卷积层的作用与全连接层等价。但它又相比于全连接层有一个优点：它仍然保留了输入图像的空间信息，即不是一个很长的向量，从而使空间信息能够自然传递到后面的层中去。</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化（pooling）层的提出是为了缓解卷积层对位置的过度敏感性。<br>不同于卷积层里计算输入和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也分别叫做最大池化或平均池化。<br>同卷积层一样，池化层也可以在输入的高和宽两侧的填充并调整窗口的移动步幅来改变输出形状。池化层填充和步幅与卷积层填充和步幅的工作机制一样。<br>默认情况下，PyTorch里的池化层的步幅和池化窗口形状相同。<br>当然，我们也可以指定非正方形的池化窗口，并分别指定高和宽上的填充和步幅。<br>在处理多通道输入数据时，池化层对每个输入通道分别池化，而不是像卷积层那样将各通道的输入按通道相加。这意味着池化层的输出通道数与输入通道数相等。</p>
<h2 id="卷积神经网络（LeNet）"><a href="#卷积神经网络（LeNet）" class="headerlink" title="卷积神经网络（LeNet）"></a>卷积神经网络（LeNet）</h2><p>在之前对Fashion-MNIST数据集分类时，使用的方法是对图像中的像素全部展开得到一个很长的向量，然后输入进全连接层中。<br>然而，这种分类方法有一定的局限性。<br>（1）图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。<br>（2）对于大尺寸的输入图像，使用全连接层容易造成模型过大。这带来过复杂的模型和过高的存储开销。<br>卷积层尝试解决这两个问题。一方面，卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性均可能被有效识别；另一方面，卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。</p>
<h3 id="定义模型-3"><a href="#定义模型-3" class="headerlink" title="定义模型"></a>定义模型</h3><p>LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="comment"># 卷积操作的维度变化公式为:</span></span><br><span class="line"><span class="comment"># Height_out = (Height_in - Height_kernal + 2*padding) / stride +1 </span></span><br><span class="line"><span class="comment"># LeNet当时的输入图片是单通道的32*32像素的灰度图</span></span><br><span class="line"><span class="comment"># 但现在的Fashion-MNIST是28*28</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>), <span class="comment"># (输入通道，输出通道，卷积核尺寸)，所以输出尺寸为(28-5)+1=24，通道为6</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># Sigmoid激活</span></span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>), <span class="comment"># (卷积核尺寸，步幅)，所以输出尺寸为(24-2)/2+1=12，通道仍然为6</span></span><br><span class="line">            nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>), <span class="comment"># 所以输出尺寸为(12-5)+1=8，通道为16</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># Sigmoid激活</span></span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>) <span class="comment"># 所以输出尺寸为(8-2)/2+1=4，通道仍然为16</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">120</span>), <span class="comment"># 输入为16*4*4，输出为120个神经元</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># Sigmoid激活</span></span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>), <span class="comment"># 又一个全连接层</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># Sigmoid激活</span></span><br><span class="line">            nn.Linear(<span class="number">84</span>, <span class="number">10</span>) <span class="comment"># 输出层，类别为10</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        feature = self.conv(img)</span><br><span class="line">        output = self.fc(feature.view(img.shape[<span class="number">0</span>], -<span class="number">1</span>)) <span class="comment"># view一下形状，第一维为batch_size，剩下的就是图像转换成的向量</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">net = LeNet()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure></p>
<h3 id="获取数据和训练模型"><a href="#获取数据和训练模型" class="headerlink" title="获取数据和训练模型"></a>获取数据和训练模型</h3><p>（1）还是使用之前的数据下载和加载方式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">mnist_train = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line">mnist_test = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">num_workers = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">train_iter = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers)</span><br><span class="line">test_iter = torch.utils.data.DataLoader(mnist_test, batch_size = batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br></pre></td></tr></table></figure><br>（2）修改分类准确度计算代码，使其支持GPU计算：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">data_iter, net, device=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        <span class="comment"># 如果没指定device，则使用net的device</span></span><br><span class="line">        device = <span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line"></span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">                net.<span class="built_in">eval</span>() <span class="comment"># 评估模式，这会关闭dropout</span></span><br><span class="line">                acc_sum += (net(X.to(device)).argmax(dim=<span class="number">1</span>)==y.to(device)).<span class="built_in">float</span>().<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">                net.train() <span class="comment"># 改回训练模式</span></span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> acc_sum / n</span><br></pre></td></tr></table></figure><br>（3）修改训练过程，使其支持GPU计算：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch5</span>(<span class="params">net, train_iter, test_iter, batch_size, optimizer, device, num_epochs</span>):</span></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;training on&#x27;</span>, device)</span><br><span class="line">    loss = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            train_l_sum += l.cpu().item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&#x27;</span> </span><br><span class="line">              % (epoch+<span class="number">1</span>, train_l_sum/n, train_acc_sum/n, test_acc, time.time()-start))</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">lr, num_epochs = <span class="number">0.001</span>, <span class="number">5</span></span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class="line">train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)</span><br></pre></td></tr></table></figure></p>
<h2 id="深度卷积神经网络（AlexNet）"><a href="#深度卷积神经网络（AlexNet）" class="headerlink" title="深度卷积神经网络（AlexNet）"></a>深度卷积神经网络（AlexNet）</h2><p>我们在上一节看到，神经网络可以直接基于图像的原始像素进行分类。这种称为端到端（end-to-end）的方法节省了很多中间步骤。然而，在很长一段时间里更流行的是研究者通过勤劳与智慧所设计并生成的手工特征。这类图像分类研究的主要流程是：<br>获取图像数据集；<br>使用已有的特征提取函数生成图像的特征；<br>使用机器学习模型对图像的特征分类。<br>当时认为的机器学习部分仅限最后这一步。如果那时候跟机器学习研究者交谈，他们会认为机器学习既重要又优美。优雅的定理证明了许多分类器的性质。机器学习领域生机勃勃、严谨而且极其有用。然而，如果跟计算机视觉研究者交谈，则是另外一幅景象。他们会告诉你图像识别里“不可告人”的现实是：计算机视觉流程中真正重要的是数据和特征。也就是说，使用较干净的数据集和较有效的特征甚至比机器学习模型的选择对图像分类结果的影响更大。</p>
<h3 id="学习特征表示"><a href="#学习特征表示" class="headerlink" title="学习特征表示"></a>学习特征表示</h3><p>既然特征如此重要，它该如何表示呢？<br>我们已经提到，在相当长的时间里，特征都是基于各式各样手工设计的函数从数据中提取的。事实上，不少研究者通过提出新的特征提取函数不断改进图像分类结果。这一度为计算机视觉的发展做出了重要贡献。</p>
<p>然而，另一些研究者则持异议。他们认为特征本身也应该由学习得来。他们还相信，为了表征足够复杂的输入，特征本身应该分级表示。持这一想法的研究者相信，多层神经网络可能可以学得数据的多级表征，并逐级表示越来越抽象的概念或模式。以图像分类为例，以物体边缘检测为例。在多层神经网络中，图像的第一级的表示可以是在特定的位置和⻆度是否出现边缘；而第二级的表示说不定能够将这些边缘组合出有趣的模式，如花纹；在第三级的表示中，也许上一级的花纹能进一步汇合成对应物体特定部位的模式。这样逐级表示下去，最终，模型能够较容易根据最后一级的表示完成分类任务。需要强调的是，输入的逐级表示由多层模型中的参数决定，而这些参数都是学出来的。</p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>2012年，AlexNet横空出世。AlexNet使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。它首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状。<br>AlexNet跟LeNet结构类似，但使用了更多的卷积层和更大的参数空间来拟合大规模数据集ImageNet。它是浅层神经网络和深度神经网络的分界线。<br>两者具体对比如下：<br>第一，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。<br>AlexNet第一层中的卷积窗口形状是11×11。因为ImageNet中绝大多数图像的高和宽均比MNIST图像的高和宽大10倍以上，ImageNet图像的物体占用更多的像素，所以需要更大的卷积窗口来捕获物体。第二层中的卷积窗口形状减小到5×5，之后全采用3×3。此外，第一、第二和第五个卷积层之后都使用了窗口形状为3×3、步幅为2的最大池化层。而且，AlexNet使用的卷积通道数也大于LeNet中的卷积通道数数十倍。<br>紧接着最后一个卷积层的是两个输出个数为4096的全连接层。这两个巨大的全连接层带来将近1 GB的模型参数。由于早期显存的限制，最早的AlexNet使用双数据流的设计使一个GPU只需要处理一半模型。幸运的是，显存在过去几年得到了长足的发展，因此通常我们不再需要这样的特别设计了。<br>第二，AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。一方面，ReLU激活函数的计算更简单，例如它并没有sigmoid激活函数中的求幂运算。另一方面，ReLU激活函数在不同的参数初始化方法下使模型更容易训练。这是由于当sigmoid激活函数输出极接近0或1时，这些区域的梯度几乎为0，从而造成反向传播无法继续更新部分模型参数；而ReLU激活函数在正区间的梯度恒为1。因此，若模型参数初始化不当，sigmoid函数可能在正区间得到几乎为0的梯度，从而令模型无法得到有效训练。<br>第三，AlexNet通过丢弃法来控制全连接层的模型复杂度。而LeNet并没有使用丢弃法。<br>第四，AlexNet引入了大量的图像增广，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。</p>
<p>虽然看上去AlexNet的实现比LeNet的实现也就多了几行代码而已，但这个观念上的转变和真正优秀实验结果的产生令学术界付出了很多年。<br>（1）定义模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># AlexNet所使用的数据集是ImageNet</span></span><br><span class="line"><span class="comment"># 这里使用的输入图像是单通道的尺寸为224*224</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            <span class="comment"># 使用较大的11 x 11窗口来捕获物体。同时使用步幅4来较大幅度减小输出高和宽</span></span><br><span class="line">            <span class="comment"># 这里使用的输出通道数比LeNet中的也要大很多</span></span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, <span class="number">11</span>, <span class="number">4</span>), <span class="comment"># (输入通道，输出通道，卷积核尺寸，步幅，填充)，所以输出尺寸为(224-11)/4+1=54 这里不能整除，所以向下取整</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>), <span class="comment"># 所以输出尺寸为(54-3)/2+1=26，通道数仍为96，池化层是默认向下取整，可以改变ceil_mode参数来改成向上取整</span></span><br><span class="line">            <span class="comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，这是因为(x-5+2*2)/1+1=x</span></span><br><span class="line">            <span class="comment"># 且增大输出通道数</span></span><br><span class="line">            nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>), <span class="comment"># 输出为(26-5+2*2)/1+1=26</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>), <span class="comment"># (26-3)/2+1 = 12</span></span><br><span class="line">            <span class="comment"># 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数</span></span><br><span class="line">            <span class="comment"># 前两个卷积层后不使用池化层来减小输入的高和宽</span></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># 输出为(12-3+2*1)/1+1=12</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># 12</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># 12</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>) <span class="comment"># (12-3)/2+1=5</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">256</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        feature = self.conv(img)</span><br><span class="line">        output = self.fc(feature.view(img.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">net = AlexNet()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure></p>
<p>（2）读取数据<br>虽然论文中AlexNet使用ImageNet数据集，但因为ImageNet数据集训练时间较长，我们仍用前面的Fashion-MNIST数据集来演示AlexNet。读取数据的时候我们额外做了一步将图像高和宽扩大到AlexNet使用的图像高和宽224。这个可以通过torchvision.transforms.Resize实例来实现。也就是说，我们在ToTensor实例前使用Resize实例，然后使用Compose实例来将这两个变换串联以方便调用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将读取数据的步骤封装成一个函数，方便调用</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span>(<span class="params">batch_size, resize=<span class="literal">None</span>, root=<span class="string">&#x27;.&#x27;</span></span>):</span></span><br><span class="line">    trans = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        trans.append(torchvision.transforms.Resize(size=resize))</span><br><span class="line"></span><br><span class="line">    trans.append(torchvision.transforms.ToTensor())</span><br><span class="line">    transform = torchvision.transforms.Compose(trans)</span><br><span class="line">    mnist_train = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    mnist_test = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br><span class="line">    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size = batch_size, shuffle=<span class="literal">False</span>, num_workers=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br></pre></td></tr></table></figure></p>
<p>（3）训练<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分类准确度测量函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">data_iter, net, device=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        <span class="comment"># 如果没指定device，则使用net的device</span></span><br><span class="line">        device = <span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line"></span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">                net.<span class="built_in">eval</span>() <span class="comment"># 评估模式，这会关闭dropout</span></span><br><span class="line">                acc_sum += (net(X.to(device)).argmax(dim=<span class="number">1</span>)==y.to(device)).<span class="built_in">float</span>().<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">                net.train() <span class="comment"># 改回训练模式</span></span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> acc_sum / n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将训练过程封装起来，方便调用</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch5</span>(<span class="params">net, train_iter, test_iter, batch_size, optimizer, device, num_epochs</span>):</span></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;training on&#x27;</span>, device)</span><br><span class="line">    loss = torch.nn.CrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            train_l_sum += l.cpu().item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&#x27;</span> </span><br><span class="line">              % (epoch+<span class="number">1</span>, train_l_sum/n, train_acc_sum/n, test_acc, time.time()-start))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">lr, num_epochs = <span class="number">0.001</span>, <span class="number">5</span></span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class="line">train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)</span><br><span class="line"><span class="comment"># 相对于LeNet，由于图片尺寸变大了而且模型变大了，所以需要更大的显存，也需要更长的训练时间了。</span></span><br></pre></td></tr></table></figure></p>
<h2 id="使用重复元素的网络（VGG）"><a href="#使用重复元素的网络（VGG）" class="headerlink" title="使用重复元素的网络（VGG）"></a>使用重复元素的网络（VGG）</h2><p>AlexNet在LeNet的基础上增加了3个卷积层。但AlexNet作者对它们的卷积窗口、输出通道数和构造顺序均做了大量的调整。虽然AlexNet指明了深度卷积神经网络可以取得出色的结果，但并没有提供简单的规则以指导后来的研究者如何设计新的网络。</p>
<p>接下来会介绍几种不同的深度网络设计思路。</p>
<p>本节介绍VGG，它的名字来源于论文作者所在的实验室Visual Geometry Group。VGG提出了可以通过重复使用简单的基础块来构建深度模型的思路。</p>
<h3 id="VGG块"><a href="#VGG块" class="headerlink" title="VGG块"></a>VGG块</h3><p>VGG块的组成规律是：连续使用数个相同的填充为1、窗口形状为3乘3的卷积层后接上一个步幅为2、窗口形状为2乘2的最大池化层。卷积层保持输入的高和宽不变（因为(h-3+2x1）+1=h），而池化层则对其减半（因为(h-2)/2+1=h/2）。<br>对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核优于采用大的卷积核，因为可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。例如，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg_block</span>(<span class="params">num_convs, in_channels, out_channels</span>):</span></span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        blk.append(nn.ReLU())</span><br><span class="line">    blk.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*blk)</span><br></pre></td></tr></table></figure></p>
<h3 id="VGG网络"><a href="#VGG网络" class="headerlink" title="VGG网络"></a>VGG网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这个自定义层是将(n, c, h, w)拉伸成(n, c*h*w)，即将图像转成向量</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlattenLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 整个vgg网络前面是若干个卷积块，后面是3个全连接层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span>(<span class="params">conv_arch, fc_features, fc_hidden_units=<span class="number">4096</span></span>):</span></span><br><span class="line">    net = nn.Sequential()</span><br><span class="line">    <span class="comment"># 整个网络的卷积层部分</span></span><br><span class="line">    <span class="comment"># conv_arch参数包含了上面的vgg块的三个参数：块的数目、输入通道、输出通道</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, (num_convs, in_channels, out_channels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(conv_arch):</span><br><span class="line">        net.add_module(<span class="string">&#x27;vgg_block_&#x27;</span> + <span class="built_in">str</span>(i+<span class="number">1</span>), vgg_block(num_convs, in_channels, out_channels))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整个网络的全连接层部分</span></span><br><span class="line">    net.add_module(<span class="string">&quot;fc&quot;</span>, nn.Sequential(</span><br><span class="line">        FlattenLayer(),</span><br><span class="line">        <span class="comment"># fc_features就是前面经过卷积操作后图像的尺寸c*h*w, fc_hidden_units是隐藏层的神经元个数</span></span><br><span class="line">        nn.Linear(fc_features, fc_hidden_units),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(fc_hidden_units, fc_hidden_units),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(fc_hidden_units, <span class="number">10</span>)</span><br><span class="line">    ))</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"><span class="comment"># 有5个卷积块，前2块是单卷积层，后3块是双卷积层，即连续做两次卷积</span></span><br><span class="line"><span class="comment"># 经过5个vgg_block，宽和高会减半5次，变成224/(2^5)=224/32=7</span></span><br><span class="line"><span class="comment"># 同时，通道数也在翻倍，起始是1个通道，之后不断翻倍，直到512个通道</span></span><br><span class="line"><span class="comment"># 因为这个网络使用了8个卷积层和3个全连接层，所以经常被称为VGG-11。 </span></span><br><span class="line">conv_arch = ((<span class="number">1</span>, <span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">64</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">128</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">256</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>, <span class="number">512</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 经过上面的卷积操作后，输出通道为512，图像尺寸为7，所以输入到下面的全连接层的向量就是512*7*7</span></span><br><span class="line">fc_features = <span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span></span><br><span class="line"><span class="comment"># 全连接层的隐藏层的神经元个数，这个可以任意设定</span></span><br><span class="line">fc_hidden_units = <span class="number">4096</span></span><br><span class="line"><span class="comment"># 构造网络</span></span><br><span class="line">net = vgg(conv_arch, fc_features, fc_hidden_units)</span><br></pre></td></tr></table></figure>
<p>模型加载和训练过程与上一节的AlexNet相同。</p>
<h2 id="网络中的网络（NiN）"><a href="#网络中的网络（NiN）" class="headerlink" title="网络中的网络（NiN）"></a>网络中的网络（NiN）</h2><p>前几节介绍的LeNet、AlexNet和VGG在设计上的共同之处是：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。其中，AlexNet和VGG对LeNet的改进主要在于如何对这两个模块加宽（增加通道数）和加深。<br>网络中的网络（NiN）则提出了另外一个思路，即重复使用由卷积层和代替全连接层的1乘1卷积层构成的NiN块来构建深层网络。<br>NiN去除了容易造成过拟合的全连接输出层，而是将其替换成输出通道数等于标签类别数的NiN块和全局平均池化层。<br>NiN的以上设计思想影响了后面一系列卷积神经网络的设计。</p>
<p>加粗！！：NiN因为使用了全局平均池化层，从而使得每个通道的宽和高都为1，这样就使得输出与输入图片的尺寸无关，极大地提高了模型的灵活性，而之前的LeNet、AlexNet和VGG必须要给定特定尺寸的图片才能运行，否则会与全连接层的输入不匹配。</p>
<h3 id="NiN块"><a href="#NiN块" class="headerlink" title="NiN块"></a>NiN块</h3><p>卷积层的输入和输出通常是四维数组（样本，通道，高，宽），而全连接层的输入和输出则通常是二维数组（样本，特征）。如果想在全连接层后再接上卷积层，则需要将全连接层的输出变换为四维。而1乘1卷积层可以看成全连接层，其中空间维度（高和宽）上的每个元素相当于样本，通道相当于特征。因此，NiN使用1乘1卷积层来替代全连接层，从而使空间信息能够自然传递到后面的层中去。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NiN块是NiN中的基础块。</span></span><br><span class="line"><span class="comment"># 它由一个卷积层加两个充当全连接层的1×11×1卷积层串联而成。</span></span><br><span class="line"><span class="comment"># 其中第一个卷积层的超参数可以自行设置，而第二和第三个卷积层的超参数一般是固定的。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nin_block</span>(<span class="params">in_channels, out_channels, kernel_size, stride, padding</span>):</span></span><br><span class="line">    blk = nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.ReLU()</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> blk</span><br></pre></td></tr></table></figure></p>
<h3 id="NiN网络"><a href="#NiN网络" class="headerlink" title="NiN网络"></a>NiN网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GlobalAvgPool2d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现</span></span><br><span class="line">    <span class="comment"># 这样就可以将输入的图像平均池化成一个1*1大小的元素</span></span><br><span class="line">    <span class="comment"># 再配合上下面的FlattenLayer，就起到了最后全连接输出的效果</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> F.avg_pool2d(x, kernel_size = x.size()[<span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个自定义层是将(n, c, h, w)拉伸成(n, c*h*w)，即将图像转成向量</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlattenLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    <span class="comment"># NiN是在AlexNet问世不久后提出的。它们的卷积层设定有类似之处。</span></span><br><span class="line">    <span class="comment"># NiN使用卷积窗口形状分别为11×1111×11、5×55×5和3×33×3的卷积层，相应的输出通道数也与AlexNet中的一致。</span></span><br><span class="line">    nin_block(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">0</span>), <span class="comment"># 输出为(224-11)/4+1=54</span></span><br><span class="line">    <span class="comment"># 每个NiN块后接一个步幅为2、窗口形状为3×33×3的最大池化层</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>), <span class="comment"># 输出为(54-3)/2+1=26 </span></span><br><span class="line">    nin_block(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>), <span class="comment"># 输出为(26-5+2*2)/1+1=26</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>), <span class="comment"># 输出为(26-3)/2+1=12</span></span><br><span class="line">    nin_block(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>), <span class="comment"># (12-3+2*1)/1+1 = 12</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>), <span class="comment"># (12-3)/2+1=5</span></span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    nin_block(<span class="number">384</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>), <span class="comment"># (5-3+2*1)/1+1=5</span></span><br><span class="line">    GlobalAvgPool2d(), <span class="comment"># (5-5)/1+1=1</span></span><br><span class="line">    FlattenLayer()</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>
<h2 id="含并行连结的网络（GoogLeNet）"><a href="#含并行连结的网络（GoogLeNet）" class="headerlink" title="含并行连结的网络（GoogLeNet）"></a>含并行连结的网络（GoogLeNet）</h2><p>在2014年的ImageNet图像识别挑战赛中，一个名叫GoogLeNet的网络结构大放异彩。它虽然在名字上向LeNet致敬，但在网络结构上已经很难看到LeNet的影子。GoogLeNet吸收了NiN中网络串联网络的思想，并在此基础上做了很大改进。</p>
<h3 id="Inception块"><a href="#Inception块" class="headerlink" title="Inception块"></a>Inception块</h3><p>GoogLeNet中的基础卷积块叫作Inception块，得名于同名电影《盗梦空间》（Inception）。其结构如图所示：<br><img src="https://user-images.githubusercontent.com/6218739/75971838-4e3c2700-5f0d-11ea-8d34-cbe8e187f07b.png" alt="image"></p>
<p>可以看出，Inception块里有4条并行的线路。前3条线路使用窗口大小分别是1乘1、3乘3和5乘5的卷积层来抽取不同空间尺寸下的信息，其中中间2个线路会对输入先做1乘1卷积来减少输入通道数，以降低模型复杂度。第四条线路则使用3乘3最大池化层，后接1乘1卷积层来改变通道数。4条线路都使用了合适的填充来使输入与输出的高和宽一致。最后我们将每条线路的输出在通道维上连结，并输入接下来的层中去。<br>其中Inception块的通道数分配之比是在ImageNet数据集上通过大量的实验得来的。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Inception块中可以自定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inception</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># c1 - c4为每条线路里的层的输出通道数</span></span><br><span class="line">    <span class="comment"># c2和c3的内部因为都有两个层，所以输出通道也要有两个，来分别设定</span></span><br><span class="line">    <span class="comment"># c4的最大池化层不需要通道设定，所以c4的通道也只有一个即可</span></span><br><span class="line">    <span class="comment"># 假设输入图像的尺寸为h，经过下面的计算可得，输出图像的尺寸仍为h</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, c1, c2, c3, c4</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 线路1，单1 x 1卷积层</span></span><br><span class="line">        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=<span class="number">1</span>) <span class="comment"># (h-1)+1=h</span></span><br><span class="line">        <span class="comment"># 线路2，1 x 1卷积层后接3 x 3卷积层</span></span><br><span class="line">        self.p2_1 = nn.Conv2d(in_c, c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>) <span class="comment"># (h-1)+1=h</span></span><br><span class="line">        self.p2_2 = nn.Conv2d(c2[<span class="number">0</span>], c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) <span class="comment"># (h-3+2*1)+1=h</span></span><br><span class="line">        <span class="comment"># 线路3，1 x 1卷积层后接5 x 5卷积层</span></span><br><span class="line">        self.p3_1 = nn.Conv2d(in_c, c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>) <span class="comment"># (h-1)+1=h</span></span><br><span class="line">        self.p3_2 = nn.Conv2d(c3[<span class="number">0</span>], c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>) <span class="comment"># (h-5+2*2)+1=h</span></span><br><span class="line">        <span class="comment"># 线路4，3 x 3最大池化层后接1 x 1卷积层</span></span><br><span class="line">        self.p4_1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>) <span class="comment"># (h-3+2*1)/1+1=h</span></span><br><span class="line">        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=<span class="number">1</span>) <span class="comment"># (h-1)+1=h</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        p1 = F.relu(self.p1_1(x))</span><br><span class="line">        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x)))) <span class="comment"># 注意这里输入的也是x</span></span><br><span class="line">        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x)))) <span class="comment"># 注意这里输入的也是x</span></span><br><span class="line">        p4 = F.relu(self.p4_2(self.p4_1(x)))</span><br><span class="line">        <span class="keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="number">1</span>) <span class="comment"># 在通道维上进行连结</span></span><br></pre></td></tr></table></figure></p>
<h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GoogLeNet跟VGG一样，在主体卷积部分中使用5个模块（block），每个模块之间使用步幅为2的3×3最大池化层来减小输出高宽。</span></span><br><span class="line"><span class="comment"># 图片尺寸就以文中给出的96为例</span></span><br><span class="line"><span class="comment"># 第一模块使用一个64通道的7×77×7卷积层，输入通道为1，输出通道为64</span></span><br><span class="line">b1 = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>), <span class="comment"># (96-7+2*3)/2+1=48</span></span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>) <span class="comment"># (48-3+2*1)/2+1=24</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 第二模块使用2个卷积层和1个池化层，输入通道为64，输出通道为192</span></span><br><span class="line">b2 = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>), <span class="comment"># (24-1)+1=24</span></span><br><span class="line">    nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), <span class="comment">#(24-3+2*1)+1=24</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>) <span class="comment"># (24-3+2*1)/2+1=12</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 第三模块串联2个完整的Inception块</span></span><br><span class="line">b3 = nn.Sequential(</span><br><span class="line">    <span class="comment"># 第1个Inception块的输入通道为192，输出通道为64+128+32+32=256</span></span><br><span class="line">    Inception(<span class="number">192</span>, <span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>), <span class="comment"># 12</span></span><br><span class="line">    <span class="comment"># 第1个Inception块的输入通道为256，输出通道为128+192+96+64=480</span></span><br><span class="line">    Inception(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>), <span class="comment"># 12</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>) <span class="comment"># (12-3+2*1)/2+1=6</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 第四模块串联5个Inception块</span></span><br><span class="line">b4 = nn.Sequential(</span><br><span class="line">    <span class="comment"># 第1个Inception块的输入通道为480， 输出通道为192+208+48+64=512</span></span><br><span class="line">    Inception(<span class="number">480</span>, <span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>), <span class="comment"># 6</span></span><br><span class="line">    <span class="comment"># 输入512， 输出160+224+64+64=512</span></span><br><span class="line">    Inception(<span class="number">512</span>, <span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>), <span class="comment"># 6</span></span><br><span class="line">    <span class="comment"># 输入512， 输出128+256+64+64=512</span></span><br><span class="line">    Inception(<span class="number">512</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>), <span class="comment"># 6</span></span><br><span class="line">    <span class="comment"># 输入512， 输出112+288+64+64=528</span></span><br><span class="line">    Inception(<span class="number">512</span>, <span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>), <span class="comment"># 6</span></span><br><span class="line">    <span class="comment"># 输入528， 输出256+320+128+128=832</span></span><br><span class="line">    Inception(<span class="number">528</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>), <span class="comment"># 6</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>) <span class="comment"># (6-3+2*1)/2+1=3 </span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 第五模块串联2个Inception块</span></span><br><span class="line">b5 = nn.Sequential(</span><br><span class="line">    <span class="comment"># 输入832， 输出256+320+128+128=832</span></span><br><span class="line">    Inception(<span class="number">832</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>), <span class="comment"># 3</span></span><br><span class="line">    <span class="comment"># 输入832， 输出384+384+128+128=1024</span></span><br><span class="line">    Inception(<span class="number">832</span>, <span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>), <span class="comment"># 3</span></span><br><span class="line">    <span class="comment"># 这一步非常重要，使用全局平均池化层来将每个通道的高和宽变成1，这样就与输入图像的尺寸无关</span></span><br><span class="line">    GlobalAvgPool2d() <span class="comment"># 1</span></span><br><span class="line">)</span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    b1, b2, b3, b4, b5,</span><br><span class="line">    FlattenLayer(), <span class="comment"># (N, 1024, 1, 1)转化成向量(N, 1024)</span></span><br><span class="line">    nn.Linear(<span class="number">1024</span>, <span class="number">10</span>) <span class="comment"># 全连接层输出类别，这里的1024是之前的通道数，与图像尺寸无关</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>加载数据时，这里的尺寸改成了96，也可以继续用之前的224，GoogLeNet因为使用了全局平均池化，所以对输入图片尺寸不敏感：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">96</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h2><p>在之前的例子里，我们对输入数据做了标准化处理：处理后的任意一个特征在数据集中所有样本上的均值为0、标准差为1。标准化处理输入数据使各个特征的分布相近：这往往更容易训练出有效的模型。<br>通常来说，数据标准化预处理对于浅层模型就足够有效了。随着模型训练的进行，当每层中参数更新时，靠近输出层的输出较难出现剧烈变化。但对深层神经网络来说，即使输入数据已做标准化，训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化。这种计算数值的不稳定性通常令我们难以训练出有效的深度模型。<br>批量归一化的提出正是为了应对深度模型训练的挑战。在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使整个神经网络在各层的中间输出的数值更稳定。<br>批量归一化和下一节将要介绍的残差网络为训练和设计深度模型提供了两类重要思路。<br>对全连接层和卷积层做批量归一化的方法稍有不同。<br>（1）对全连接层做批量归一化：将批量归一化层置于全连接层中的仿射变换和激活函数之间，批量归一化层引入了两个可以学习的模型参数，拉伸（scale）参数$\gamma$和偏移（shift）参数$\beta$。<br>（2）对卷积层做批量归一化：对卷积层来说，批量归一化发生在卷积计算之后、应用激活函数之前。如果卷积计算输出多个通道，我们需要对这些通道的输出分别做批量归一化，且每个通道都拥有独立的拉伸和偏移参数，并均为标量。<br>（3）预测时的批量归一化：使用批量归一化训练时，我们可以将批量大小设得大一点，从而使批量内样本的均值和方差的计算都较为准确。将训练好的模型用于预测时，我们希望模型对于任意输入都有确定的输出。因此，单个样本的输出不应取决于批量归一化所需要的随机小批量中的均值和方差。一种常用的方法是通过移动平均估算整个训练数据集的样本均值和方差，并在预测时使用它们得到确定的输出。可见，和丢弃层一样，批量归一化层在训练模式和预测模式下的计算结果也是不一样的。</p>
<p>Pytorch中nn模块定义的BatchNorm1d和BatchNorm2d类使用起来非常简单，二者分别用于全连接层和卷积层，都需要指定输入的num_features参数值，对于全连接层来说该值应为输出个数，对于卷积层来说则为输出通道数。</p>
<h2 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h2><p>让我们先思考一个问题：对神经网络模型添加新的层，充分训练后的模型是否只可能更有效地降低训练误差？理论上，原模型解的空间只是新模型解的空间的子空间。也就是说，如果我们能将新添加的层训练成恒等映射f(x)=x，新模型和原模型将同样有效。由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差。然而在实践中，添加过多的层后训练误差往往不降反升。即使利用批量归一化带来的数值稳定性使训练深层模型更加容易，该问题仍然存在。针对这一问题，何恺明等人提出了残差网络（ResNet）。它在2015年的ImageNet图像识别挑战赛夺魁，并深刻影响了后来的深度神经网络的设计。<br>残差块通过跨层的数据通道从而能够训练出有效的深度神经网络。</p>
<h3 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h3><p>在残差块中，输入可通过跨层的数据线路更快地向前传播。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 残差块可以设定输出通道数、是否使用额外的1×11×1卷积层来修改通道数以及卷积层的步幅，即可以改变输出大小。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Residual</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, use_1x1conv=<span class="literal">False</span>, stride=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># ResNet沿用了VGG全3×33×3卷积层的设计。</span></span><br><span class="line">        <span class="comment"># 残差块里首先有2个有相同输出通道数的3×33×3卷积层。</span></span><br><span class="line">        <span class="comment"># 每个卷积层后接一个批量归一化层和ReLU激活函数。</span></span><br><span class="line">        <span class="comment"># 然后将输入跳过这两个卷积运算后直接加在最后的ReLU激活函数前。</span></span><br><span class="line">        <span class="comment"># 这样的设计要求两个卷积层的输出与输入形状一样，从而可以相加。如果想改变通道数，就需要引入一个额外的1×1卷积层来将输入变换成需要的形状后再做相加运算。</span></span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=stride)</span><br><span class="line">        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=stride)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        <span class="keyword">return</span> F.relu(Y + X)</span><br></pre></td></tr></table></figure></p>
<h3 id="ResNet模型"><a href="#ResNet模型" class="headerlink" title="ResNet模型"></a>ResNet模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ResNet的前两层跟GoogLeNet中的一样：在输出通道数为64、步幅为2的7×7卷积层后接步幅为2的3×3的最大池化层。</span></span><br><span class="line"><span class="comment"># 不同之处在于ResNet每个卷积层后增加的批量归一化层。</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"><span class="comment"># GoogLeNet在后面接了4个由Inception块组成的模块。ResNet则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet_block</span>(<span class="params">in_channels, out_channels, num_residuals, first_block=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> first_block:</span><br><span class="line">        <span class="comment"># 第一个模块的通道数同输入通道数一致</span></span><br><span class="line">        <span class="keyword">assert</span> in_channels == out_channels</span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_residuals):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> first_block:</span><br><span class="line">            <span class="comment"># 后面的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。</span></span><br><span class="line">            blk.append(Residual(in_channels, out_channels, use_1x1conv=<span class="literal">True</span>, stride=<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 在第一个模块中，由于之前已经使用了步幅为2的最大池化层，所以无须减小高和宽。</span></span><br><span class="line">            blk.append(Residual(out_channels, out_channels))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*blk)</span><br><span class="line"><span class="comment"># 为ResNet加入所有残差块。这里每个模块使用两个残差块。</span></span><br><span class="line">net.add_module(<span class="string">&#x27;resnet_block1&#x27;</span>, resnet_block(<span class="number">64</span>, <span class="number">64</span>, <span class="number">2</span>, first_block=<span class="literal">True</span>))</span><br><span class="line">net.add_module(<span class="string">&#x27;resnet_block2&#x27;</span>, resnet_block(<span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>))</span><br><span class="line">net.add_module(<span class="string">&#x27;resnet_block3&#x27;</span>, resnet_block(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line">net.add_module(<span class="string">&#x27;resnet_block4&#x27;</span>, resnet_block(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 最后，与GoogLeNet一样，加入全局平均池化层后接上全连接层输出。</span></span><br><span class="line">net.add_module(<span class="string">&#x27;global_avg_pool&#x27;</span>, GlobalAvgPool2d()) <span class="comment"># GlobalAvgPool2d的输出: (Batch, 512, 1, 1)</span></span><br><span class="line">net.add_module(<span class="string">&#x27;fc&#x27;</span>, nn.Sequential(FlattenLayer(), nn.Linear(<span class="number">512</span>, <span class="number">10</span>)))</span><br><span class="line"><span class="comment"># 这里每个模块里有4个卷积层（不计算1×11×1卷积层），加上最开始的卷积层和最后的全连接层，共计18层。这个模型通常也被称为ResNet-18。</span></span><br><span class="line"><span class="comment"># 通过配置不同的通道数和模块里的残差块数可以得到不同的ResNet模型，例如更深的含152层的ResNet-152。</span></span><br><span class="line"><span class="comment"># 虽然ResNet的主体架构跟GoogLeNet的类似，但ResNet结构更简单，修改也更方便。这些因素都导致了ResNet迅速被广泛使用。</span></span><br></pre></td></tr></table></figure>
<p>拿个测试数据跑一下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"><span class="keyword">for</span> name, layer <span class="keyword">in</span> net.named_children():</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(name, <span class="string">&#x27;output shape = &#x27;</span>, X.shape)</span><br></pre></td></tr></table></figure></p>
<p>最后，加载数据和训练模型都跟之前的一样。</p>
<h2 id="稠密连接网络（DenseNet）"><a href="#稠密连接网络（DenseNet）" class="headerlink" title="稠密连接网络（DenseNet）"></a>稠密连接网络（DenseNet）</h2><p>ResNet中的跨层连接设计引申出了数个后续工作，比如这里的稠密连接网络（DenseNet）。<br>假设将部分前后相邻的运算抽象为模块A和模块B。与ResNet的主要区别在于，DenseNet里模块B的输出不是像ResNet那样和模块A的输出相加，而是在通道维上连结。这样模块A的输出可以直接传入模块B后面的层。在这个设计里，模块A直接跟模块B后面的所有层连接在了一起。这也是它被称为“稠密连接”的原因。<br>DenseNet的主要构建模块是稠密块（dense block）和过渡层（transition layer）。前者定义了输入和输出是如何连结的，后者则用来控制通道数，使之不过大。</p>
<h3 id="稠密块"><a href="#稠密块" class="headerlink" title="稠密块"></a>稠密块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DenseNet使用了ResNet改良版的“批量归一化、激活和卷积”结构，首先在conv_block函数里实现这个结构。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_block</span>(<span class="params">in_channels, out_channels</span>):</span></span><br><span class="line">    blk = nn.Sequential(</span><br><span class="line">        nn.BatchNorm2d(in_channels),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line"><span class="comment"># 稠密块由多个conv_block组成，每块使用相同的输出通道数。</span></span><br><span class="line"><span class="comment"># 卷积块的通道数控制了输出通道数相对于输入通道数的增长，因此也被称为增长率（growth rate）</span></span><br><span class="line"><span class="comment"># 比如，定义一个有2个输出通道数为10的卷积块。使用通道数为3的输入时，我们会得到通道数为3+2×10=23的输出，增长率就是10</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DenseBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_convs, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        net = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">            in_c = in_channels + i* out_channels</span><br><span class="line">            net.append(conv_block(in_c, out_channels))</span><br><span class="line"></span><br><span class="line">        self.net = nn.ModuleList(net)</span><br><span class="line">        self.out_channels = in_channels + num_convs * out_channels <span class="comment"># 计算输出通道数</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> self.net:</span><br><span class="line">            Y = blk(X)</span><br><span class="line">            X = torch.cat((X, Y), dim=<span class="number">1</span>) <span class="comment"># 在通道维上将输入和输出连结</span></span><br><span class="line">        <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>
<h3 id="过渡层"><a href="#过渡层" class="headerlink" title="过渡层"></a>过渡层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于每个稠密块都会带来通道数的增加，使用过多则会带来过于复杂的模型。</span></span><br><span class="line"><span class="comment"># 过渡层用来控制模型复杂度。它通过1×11×1卷积层来减小通道数，并使用步幅为2的平均池化层减半高和宽，从而进一步降低模型复杂度。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transition_block</span>(<span class="params">in_channels, out_channels</span>):</span></span><br><span class="line">    blk = nn.Sequential(</span><br><span class="line">        nn.BatchNorm2d(in_channels),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> blk</span><br></pre></td></tr></table></figure>
<h3 id="DenseNet模型"><a href="#DenseNet模型" class="headerlink" title="DenseNet模型"></a>DenseNet模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DenseNet首先使用同ResNet一样的单卷积层和最大池化层。</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 类似于ResNet接下来使用的4个残差块，DenseNet使用的是4个稠密块。</span></span><br><span class="line"><span class="comment"># 同ResNet一样，可以设置每个稠密块使用多少个卷积层。这里我们设成4，从而与上一节的ResNet-18保持一致。</span></span><br><span class="line"><span class="comment"># 稠密块里的卷积层通道数（即增长率）设为32，所以每个稠密块将增加128个通道。</span></span><br><span class="line">num_channels, growth_rate = <span class="number">64</span>, <span class="number">32</span> <span class="comment"># num_channels为当前的通道数</span></span><br><span class="line">num_convs_in_dense_blocks = [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>] <span class="comment"># length为4，表明有4个稠密块，每个元素都是4，表明每个稠密块有4个卷积层</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, num_convs <span class="keyword">in</span> <span class="built_in">enumerate</span>(num_convs_in_dense_blocks):</span><br><span class="line">    DB = DenseBlock(num_convs, num_channels, growth_rate)</span><br><span class="line">    net.add_module(<span class="string">&#x27;DenseBlock_%d&#x27;</span> % i, DB)</span><br><span class="line">    <span class="comment"># 上一个稠密块的输出通道，这里用的是类.属性的用法</span></span><br><span class="line">    num_channels = DB.out_channels</span><br><span class="line">    <span class="comment"># 在稠密块之间加入通道数减半的过渡层</span></span><br><span class="line">    <span class="keyword">if</span> i != <span class="built_in">len</span>(num_convs_in_dense_blocks) - <span class="number">1</span>:</span><br><span class="line">        net.add_module(<span class="string">&#x27;transition_block_%d&#x27;</span> % i, transition_block(num_channels, num_channels // <span class="number">2</span>))</span><br><span class="line">        num_channels = num_channels // <span class="number">2</span></span><br><span class="line">net.add_module(<span class="string">&#x27;BN&#x27;</span>, nn.BatchNorm2d(num_channels))</span><br><span class="line">net.add_module(<span class="string">&#x27;relu&#x27;</span>, nn.ReLU())</span><br><span class="line"><span class="comment"># 与ResNet一样，最后加入全局平均池化层后接上全连接层输出。</span></span><br><span class="line">net.add_module(<span class="string">&#x27;global_avg_pool&#x27;</span>, GlobalAvgPool2d()) <span class="comment"># GlobalAvgPool2d的输出: (Batch, num_channels, 1, 1)</span></span><br><span class="line">net.add_module(<span class="string">&#x27;fc&#x27;</span>, nn.Sequential(FlattenLayer(), nn.Linear(num_channels, <span class="number">10</span>)))</span><br></pre></td></tr></table></figure>
<p>最后，加载数据和训练模型都跟之前的一样。</p>
<h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><p>本章先略过</p>
<h1 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h1><h2 id="优化与深度学习"><a href="#优化与深度学习" class="headerlink" title="优化与深度学习"></a>优化与深度学习</h2><p>虽然优化为深度学习提供了最小化损失函数的方法，但本质上，优化与深度学习的目标是有区别的。<br>由于优化算法的目标函数通常是一个基于训练数据集的损失函数，优化的目标在于降低训练误差。 而深度学习的目标在于降低泛化误差。为了降低泛化误差，除了使用优化算法降低训练误差以外，还需要注意应对过拟合。<br>在一个深度学习问题中，我们通常会预先定义一个损失函数。有了损失函数以后，我们就可以使用优化算法试图将其最小化。在优化中，这样的损失函数通常被称作优化问题的目标函数（objective function）。依据惯例，优化算法通常只考虑最小化目标函数。其实，任何最大化问题都可以很容易地转化为最小化问题，只需令目标函数的相反数为新的目标函数即可。<br>优化在深度学习中有很多挑战，比如局部最小值和鞍点。<br>（1）深度学习模型的目标函数可能有若干局部最优值。当一个优化问题的数值解在局部最优解附近时，由于目标函数有关解的梯度接近或变成零，最终迭代求得的数值解可能只令目标函数局部最小化而非全局最小化。<br>（2）梯度接近或变成零可能是由于当前解在局部最优解附近造成的。事实上，另一种可能性是当前解在鞍点（saddle point）附近。比如在鞍点位置，目标函数在x轴方向上是局部最小值，但在y轴方向上是局部最大值。<br>假设一个函数的输入为k维向量，输出为标量，那么它的海森矩阵（Hessian matrix）有k个特征值。该函数在梯度为0的位置上可能是局部最小值、局部最大值或者鞍点。<br>当函数的海森矩阵在梯度为零的位置上的特征值全为正时，该函数得到局部最小值。<br>当函数的海森矩阵在梯度为零的位置上的特征值全为负时，该函数得到局部最大值。<br>当函数的海森矩阵在梯度为零的位置上的特征值有正有负时，该函数得到鞍点。<br>随机矩阵理论告诉我们，对于一个大的高斯随机矩阵来说，任一特征值是正或者是负的概率都是0.5。那么，以上第一种情况的概率为 0.5的k次方。由于深度学习模型参数通常都是高维的（k很大），目标函数的鞍点通常比局部最小值更常见。</p>
<h2 id="梯度下降和随机梯度下降"><a href="#梯度下降和随机梯度下降" class="headerlink" title="梯度下降和随机梯度下降"></a>梯度下降和随机梯度下降</h2><p>下图中的公式清晰地解释了为什么梯度下降能降低目标函数的数值：<br><img src="https://user-images.githubusercontent.com/6218739/76134337-5bb1f800-6058-11ea-908d-a03ebaa1a44f.png" alt="image"><br>在深度学习里，目标函数通常是训练数据集中有关各个样本的损失函数的平均。当训练数据样本数很大时，梯度下降每次迭代的计算开销很高。<br>随机梯度下降（stochastic gradient descent，SGD）减少了每次迭代的计算开销。</p>
<h2 id="小批量随机梯度下降"><a href="#小批量随机梯度下降" class="headerlink" title="小批量随机梯度下降"></a>小批量随机梯度下降</h2><p>在每一次迭代中，梯度下降使用整个训练数据集来计算梯度，因此它有时也被称为批量梯度下降（batch gradient descent）。而随机梯度下降在每次迭代中只随机采样一个样本来计算梯度。我们还可以在每轮迭代中随机均匀采样多个样本来组成一个小批量，然后使用这个小批量来计算梯度。<br>在实际中，（小批量）随机梯度下降的学习率可以在迭代过程中自我衰减。<br>当批量大小为1时，小批量随机梯度下降算法即为随机梯度下降；当批量大小等于训练数据样本数时，该算法即为梯度下降。当批量较小时，每次迭代中使用的样本少，这会导致并行处理和内存使用效率变低。这使得在计算同样数目样本的情况下比使用更大批量时所花时间更多。当批量较大时，每个小批量梯度里可能含有更多的冗余信息。为了得到较好的解，批量较大时比批量较小时需要计算的样本数目可能更多，例如增大迭代周期数。</p>
<h2 id="动量法"><a href="#动量法" class="headerlink" title="动量法"></a>动量法</h2><p>目标函数有关自变量的梯度代表了目标函数在自变量当前位置下降最快的方向。因此，梯度下降也叫作最陡下降（steepest descent）。在每次迭代中，梯度下降根据自变量当前位置，沿着当前位置的梯度更新自变量。然而，如果自变量的迭代方向仅仅取决于自变量当前位置，这可能会带来一些问题。举个例子：同一位置上，假设目标函数在竖直方向比在水平方向的斜率的绝对值更大。因此，给定学习率，梯度下降迭代自变量时会使自变量在竖直方向比在水平方向移动幅度更大。那么，我们需要一个较小的学习率从而避免自变量在竖直方向上越过目标函数最优解。然而，这会造成自变量在水平方向上朝最优解移动变慢。<br>动量法的提出是为了解决梯度下降的上述问题。<br>（1）动量法使用了指数加权移动平均的思想。它将过去时间步的梯度做了加权平均，且权重按时间步指数衰减。<br>（2）动量法使得相邻时间步的自变量更新在方向上更加一致。<br>在PyTorch中，只需要通过参数momentum来指定动量超参数即可使用动量法。</p>
<h2 id="AdaGrad算法"><a href="#AdaGrad算法" class="headerlink" title="AdaGrad算法"></a>AdaGrad算法</h2><p>在之前介绍过的优化算法中，目标函数自变量的每一个元素在相同时间步都使用同一个学习率来自我迭代。<br>动量法依赖指数加权移动平均使得自变量的更新方向更加一致，从而降低发散的可能。而AdaGrad算法根据自变量在每个维度的梯度值的大小来调整各个维度上的学习率，从而避免统一的学习率难以适应所有维度的问题。<br>AdaGrad算法在迭代过程中不断调整学习率，并让目标函数自变量中每个元素都分别拥有自己的学习率。<br>使用AdaGrad算法时，自变量中每个元素的学习率在迭代过程中一直在降低（或不变）。<br>通过名称为Adagrad的优化器方法，我们便可使用PyTorch提供的AdaGrad算法来训练模型。</p>
<h2 id="RMSProp算法"><a href="#RMSProp算法" class="headerlink" title="RMSProp算法"></a>RMSProp算法</h2><p>RMSProp算法和AdaGrad算法的不同在于，RMSProp算法使用了小批量随机梯度按元素平方的指数加权移动平均来调整学习率。<br>通过名称为RMSprop的优化器方法，我们便可使用PyTorch提供的RMSProp算法来训练模型。注意，超参数$\gamma$通过alpha指定。</p>
<h2 id="AdaDelta算法"><a href="#AdaDelta算法" class="headerlink" title="AdaDelta算法"></a>AdaDelta算法</h2><p>除了RMSProp算法以外，另一个常用优化算法AdaDelta算法也针对AdaGrad算法在迭代后期可能较难找到有用解的问题做了改进。有意思的是，AdaDelta算法没有学习率这一超参数。AdaDelta算法没有学习率超参数，它通过使用有关自变量更新量平方的指数加权移动平均的项来替代RMSProp算法中的学习率。<br>通过名称为Adadelta的优化器方法，我们便可使用PyTorch提供的AdaDelta算法。它的超参数可以通过rho来指定。</p>
<h2 id="Adam算法"><a href="#Adam算法" class="headerlink" title="Adam算法"></a>Adam算法</h2><p>Adam算法在RMSProp算法基础上对小批量随机梯度也做了指数加权移动平均。所以Adam算法可以看做是RMSProp算法与动量法的结合。<br>Adam算法使用了偏差修正。<br>通过名称为“Adam”的优化器实例，我们便可使用PyTorch提供的Adam算法。</p>
<h1 id="计算性能"><a href="#计算性能" class="headerlink" title="计算性能"></a>计算性能</h1><h2 id="命令式编程和符号式编程"><a href="#命令式编程和符号式编程" class="headerlink" title="命令式编程和符号式编程"></a>命令式编程和符号式编程</h2><p>（1）命令式编程更方便。当我们在Python里使用命令式编程时，大部分代码编写起来都很直观。同时，命令式编程更容易调试。这是因为我们可以很方便地获取并打印所有的中间变量值，或者使用Python的调试工具。<br>（2）符号式编程更高效并更容易移植。一方面，在编译的时候系统容易做更多优化（因为在编译时系统能够完整地获取整个程序）；另一方面，符号式编程可以将程序变成一个与Python无关的格式，从而可以使程序在非Python环境下运行，以避开Python解释器的性能问题。<br>截止目前（2020年3月），PyTorch仅采用了命令式编程方式。</p>
<h2 id="异步计算"><a href="#异步计算" class="headerlink" title="异步计算"></a>异步计算</h2><p>以下一段是唐树森同学对PyTorch官网上的翻译。<br>默认情况下，PyTorch中的 GPU 操作是异步的。当调用一个使用 GPU 的函数时，这些操作会在特定的设备上排队但不一定会在稍后立即执行。这就使我们可以并行更多的计算，包括 CPU 或其他 GPU 上的操作。 一般情况下，异步计算的效果对调用者是不可见的，因为（1）每个设备按照它们排队的顺序执行操作，（2）在 CPU 和 GPU 之间或两个 GPU 之间复制数据时，PyTorch会自动执行必要的同步操作。因此，计算将按每个操作同步执行的方式进行。 可以通过设置环境变量CUDA_LAUNCH_BLOCKING = 1来强制进行同步计算。当 GPU 产生error时，这可能非常有用。（异步执行时，只有在实际执行操作之后才会报告此类错误，因此堆栈跟踪不会显示请求的位置。）</p>
<h2 id="自动并行计算"><a href="#自动并行计算" class="headerlink" title="自动并行计算"></a>自动并行计算</h2><p>PyTorch能有效地实现在不同设备上（比如两块GPU）自动并行计算。</p>
<h2 id="多GPU计算"><a href="#多GPU计算" class="headerlink" title="多GPU计算"></a>多GPU计算</h2><p>因为目前手头只有一块GPU，所以本节没法实战，故略过。<br>需要注意单主机多GPU计算与分布式计算的区别。</p>
<h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><h2 id="图像增广"><a href="#图像增广" class="headerlink" title="图像增广"></a>图像增广</h2><p>这个地方有几点提前注意：<br>（1）下面介绍的都是torchvision自带的函数，关于图像增广可以借助更专业的第三方库（比如可以将标注一块增广），比如：<br><a target="_blank" rel="noopener" href="https://github.com/aleju/imgaug">Image augmentation for machine learning experiments</a><br>（2）为了在预测时得到确定的结果，我们通常只将图像增广应用在训练样本上，而不在预测时使用含随机操作的图像增广。此外，在实际PyTorch应用时，注意使用ToTensor将小批量图像转成PyTorch需要的格式，即形状为(批量大小, 通道数, 高, 宽)、值域在0到1之间且类型为32位浮点数。</p>
<p>图像增广（image augmentation）技术通过对训练图像做一系列随机改变，来产生相似但又不同的训练样本，从而扩大训练数据集的规模。图像增广的另一种解释是，随机改变训练样本可以降低模型对某些属性的依赖，从而提高模型的泛化能力。例如，我们可以对图像进行不同方式的裁剪，使感兴趣的物体出现在不同位置，从而减轻模型对物体出现位置的依赖性。我们也可以调整亮度、色彩等因素来降低模型对色彩的敏感度。可以说，在当年AlexNet的成功中，图像增广技术功不可没。</p>
<p>这部分涉及PIL、skimage、OpenCV、PyTorch Tensor，这四个有类似的地方，也有很多小区别，比如：<br>（1）PIL、skimage、OpenCV的图像通道都是h乘w乘c，即高乘宽乘通道，而PyTorch的ToTensor自己会转化为c乘h乘w，同时转为float后除以255（这里一定注意，如果ToTensor接收的是numpy的array，一定保证它是uint8格式，否则可能仅是通道顺序变化，而数值没有除以255）<br>（2）PIL的数据类型是Image对象，skimage和OpenCV都是numpy。</p>
<p>torchvision.transforms模块有大量现成的转换方法，不过需要注意的是有的方法输入的是PIL图像，如Resize；有的方法输入的是tensor，如Normalize；而还有的是用于二者转换，如ToTensor将PIL图像转换成tensor。一定要注意这点，使用时看清文档。</p>
<p>具体可以参考如下文章：<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/52344534">OpenCV，PIL，Skimage你pick谁</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/dd08418c306f">opencv-PIL-matplotlib-Skimage-Pytorch图片读取区别与联系</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27382990">pytorch图像基本操作</a></p>
<h3 id="常用的图像增广方法"><a href="#常用的图像增广方法" class="headerlink" title="常用的图像增广方法"></a>常用的图像增广方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里使用PIL读取图像</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;drive/My Drive/cat1.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 翻转</span></span><br><span class="line"><span class="comment"># 左右翻转图像通常不改变物体的类别。它是最早也是最广泛使用的一种图像增广方法。</span></span><br><span class="line">horizon_flip = transforms.RandomHorizontalFlip()</span><br><span class="line"><span class="comment"># 上下翻转不如左右翻转通用。但是至少对于样例图像，上下翻转不会造成识别障碍。</span></span><br><span class="line">vertical_flip = transforms.RandomVerticalFlip()</span><br><span class="line"><span class="comment"># 裁剪</span></span><br><span class="line"><span class="comment"># 可以通过对图像随机裁剪来让物体以不同的比例出现在图像的不同位置</span></span><br><span class="line"><span class="comment"># 这同样能够降低模型对目标位置的敏感性。</span></span><br><span class="line"><span class="comment"># 每次随机裁剪出一块面积为原面积10%∼100%的区域，且该区域的宽和高之比随机取自0.5∼2，</span></span><br><span class="line"><span class="comment"># 然后再将该区域的宽和高分别缩放到200像素。</span></span><br><span class="line">shape_aug = transforms.RandomResizedCrop(<span class="number">200</span>, scale=(<span class="number">0.1</span>, <span class="number">1</span>), ratio=(<span class="number">0.5</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 变化颜色</span></span><br><span class="line"><span class="comment"># 可以从4个方面改变图像的颜色：亮度（brightness）、对比度（contrast）、饱和度（saturation）和色调（hue）。</span></span><br><span class="line"><span class="comment"># 将图像的亮度随机变化为原图亮度的50%（1−0.5）∼150%（1+0.5）</span></span><br><span class="line">brightness_change = transforms.ColorJitter(brightness=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 随机变化图像的色调</span></span><br><span class="line">hue_change = transforms.ColorJitter(hue=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 随机变化图像的对比度</span></span><br><span class="line">contrast_change = transforms.ColorJitter(contrast=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 综合设置颜色变化</span></span><br><span class="line">color_aug = transforms.ColorJitter(brightness=<span class="number">0.5</span>, contrast=<span class="number">0.5</span>, saturation=<span class="number">0.5</span>, hue=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 叠加多个图像增广方法</span></span><br><span class="line"><span class="comment"># 实际应用中我们会将多个图像增广方法叠加使用。</span></span><br><span class="line"><span class="comment"># 我们可以通过Compose实例将上面定义的多个图像增广方法叠加起来，再应用到每张图像之上。</span></span><br><span class="line">compose = transforms.Compose([</span><br><span class="line">                              transforms.RandomHorizontalFlip(),</span><br><span class="line">                              color_aug,</span><br><span class="line">                              shape_aug</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 大部分图像增广方法都有一定的随机性。</span></span><br><span class="line"><span class="comment"># 为了方便观察图像增广的效果，需要多次运行转换函数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    img_trans = horizon_flip(img)</span><br><span class="line">    img_trans = vertical_flip(img)</span><br><span class="line">    img_trans = shape_aug(img)</span><br><span class="line">    img_trans = brightness_change(img)</span><br><span class="line">    img_trans = hue_change(img)</span><br><span class="line">    img_trans = contrast_change(img)</span><br><span class="line">    img_trans = color_aug(img)</span><br><span class="line">    img_trans = compose(img)</span><br><span class="line">    <span class="comment"># 存储时使用skimage，借此看看skimage与PIL的转换</span></span><br><span class="line">    io.imsave(np.<span class="built_in">str</span>(i)+<span class="string">&#x27;.jpg&#x27;</span>, np.array(img_trans))</span><br></pre></td></tr></table></figure>
<h2 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h2><p>迁移学习是解决小数据集的一个有效方法。<br>本节介绍迁移学习中的一种常用技术：微调（fine tuning）。微调由以下4步构成。<br>在源数据集（如ImageNet数据集）上预训练一个神经网络模型，即源模型。<br>创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。我们还假设源模型的输出层跟源数据集的标签紧密相关，因此在目标模型中不予采用。<br>为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。<br>在目标数据集上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。<br>当目标数据集远小于源数据集时，微调有助于提升模型的泛化能力。</p>
<p>注: 在使用预训练模型时，一定要和预训练时作同样的预处理。 如果你使用的是torchvision的models，那就要求: All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. 如果你使用的是pretrained-models.pytorch仓库，请务必阅读其README，其中说明了如何预处理。</p>
<p>接下来我们来实践一个具体的例子：热狗识别。我们将基于一个小数据集对在ImageNet数据集上训练好的ResNet模型进行微调。该小数据集含有数千张包含热狗和不包含热狗的图像。我们将使用微调得到的模型来识别一张图像中是否包含热狗。<br>导入必要的包：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> ImageFolder</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="获取数据集-1"><a href="#获取数据集-1" class="headerlink" title="获取数据集"></a>获取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载数据集</span></span><br><span class="line">!wget https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/hotdog.<span class="built_in">zip</span></span><br><span class="line"><span class="comment"># 解压，得到两个文件夹hotdog/train和hotdog/test。</span></span><br><span class="line"><span class="comment"># 这两个文件夹下面均有hotdog和not-hotdog两个类别文件夹，每个类别文件夹里面是图像文件。</span></span><br><span class="line">!unzip hotdog.<span class="built_in">zip</span></span><br><span class="line"><span class="comment"># 查看一下数据</span></span><br><span class="line"><span class="comment"># 关于ImageFolder的用法可以参考下面的链接：</span></span><br><span class="line"><span class="comment"># https://discuss.pytorch.org/t/questions-about-imagefolder/774/3</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/TH_NUM/article/details/80877435</span></span><br><span class="line"><span class="built_in">print</span>(train_imgs.classes) <span class="comment"># ImageFolder假设所有的文件按文件夹保存好，每个文件夹下面存贮同一类别的图片，文件夹的名字为分类的名字。</span></span><br><span class="line"><span class="built_in">print</span>(train_imgs.class_to_idx) <span class="comment"># 字符串类别所对应的数值类别</span></span><br><span class="line">train_imgs[<span class="number">0</span>][<span class="number">0</span>] <span class="comment"># 前面的是正类图像，即热狗</span></span><br><span class="line">train_imgs[-<span class="number">1</span>][<span class="number">0</span>] <span class="comment"># 后面的是负类图像，即非热狗</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定RGB三个通道的均值和方差来将图像通道归一化 (每个数值减去该通道所有数值的平均值，再除以该通道所有数值的标准差作为输出)</span></span><br><span class="line"><span class="comment"># 这个地方一定与预训练模型所做的处理保持一致！！</span></span><br><span class="line">normalize = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line"><span class="comment"># 训练集所做的预处理</span></span><br><span class="line">train_augs = transforms.Compose([</span><br><span class="line">                                 <span class="comment"># 先从图像中裁剪出随机大小和随机高宽比的一块随机区域，然后将该区域缩放为高和宽均为224像素的输入</span></span><br><span class="line">                                 transforms.RandomResizedCrop(size=<span class="number">224</span>),</span><br><span class="line">                                 <span class="comment"># 左右翻转</span></span><br><span class="line">                                 transforms.RandomHorizontalFlip(),</span><br><span class="line">                                 <span class="comment"># 转为PyTorch所需的形状为(批量大小, 通道数, 高, 宽)、值域在0到1之间且类型为32位浮点数的数据</span></span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 <span class="comment"># 归一化</span></span><br><span class="line">                                 normalize</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 测试集所做的预处理</span></span><br><span class="line">test_augs = transforms.Compose([</span><br><span class="line">                                <span class="comment"># 将图像的高和宽均缩放为256像素</span></span><br><span class="line">                                transforms.Resize(size=<span class="number">256</span>),</span><br><span class="line">                                <span class="comment"># 然后从中裁剪出高和宽均为224像素的中心区域作为输入</span></span><br><span class="line">                                transforms.CenterCrop(size=<span class="number">224</span>),</span><br><span class="line">                                transforms.ToTensor(),</span><br><span class="line">                                normalize</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h3 id="定义和初始化模型-1"><a href="#定义和初始化模型-1" class="headerlink" title="定义和初始化模型"></a>定义和初始化模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用在ImageNet数据集上预训练的ResNet-18作为源模型。</span></span><br><span class="line"><span class="comment"># 这里指定pretrained=True来自动下载并加载预训练的模型参数。在第一次使用时需要联网下载模型参数。</span></span><br><span class="line"><span class="comment"># 不管你是使用的torchvision的models还是pretrained-models.pytorch仓库，默认都会将预训练好的模型参数下载到你的home目录下.torch文件夹。</span></span><br><span class="line"><span class="comment"># 你可以通过修改环境变量$TORCH_MODEL_ZOO来更改下载目录。</span></span><br><span class="line"><span class="comment"># 另一个比较常用的方法是，在其源码中找到下载地址直接浏览器输入地址下载，下载好后将其放到环境变量$TORCH_MODEL_ZOO所指文件夹即可，这样比较快。</span></span><br><span class="line">pretrained_net = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面打印源模型的成员变量fc。</span></span><br><span class="line"><span class="comment"># 作为一个全连接层，它将ResNet最终的全局平均池化层输出变换成ImageNet数据集上1000类的输出。</span></span><br><span class="line"><span class="comment"># 如果你使用的是其他模型，那可能没有成员变量fc（比如models中的VGG预训练模型），</span></span><br><span class="line"><span class="comment"># 所以正确做法是查看对应模型源码中其定义部分，这样既不会出错也能加深我们对模型的理解。</span></span><br><span class="line"><span class="built_in">print</span>(pretrained_net.fc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里应该将最后的fc成修改我们需要的输出类别数:</span></span><br><span class="line">pretrained_net.fc = nn.Linear(<span class="number">512</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(pretrained_net.fc)</span><br><span class="line"><span class="comment"># 此时fc层中的参数已经被初始化了，但是其他层依然保存着预训练得到的参数。</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(pretrained_net.fc.parameters()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于是在很大的ImageNet数据集上预训练的，所以非fc层的参数已经足够好，因此一般只需使用较小的学习率来微调这些参数</span></span><br><span class="line"><span class="comment"># 而fc中的随机初始化参数一般需要更大的学习率从头训练。</span></span><br><span class="line"><span class="comment"># PyTorch可以方便的对模型的不同部分设置不同的学习参数</span></span><br><span class="line"><span class="comment"># 将fc层的参数的id取出</span></span><br><span class="line">output_params = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">id</span>, pretrained_net.fc.parameters()))</span><br><span class="line"><span class="comment"># 从整个net的所有参数中剔除fc的参数，保留非fc中的参数放入feature_params中</span></span><br><span class="line">feature_params = <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: <span class="built_in">id</span>(p) <span class="keyword">not</span> <span class="keyword">in</span> output_params, pretrained_net.parameters())</span><br><span class="line">lr = <span class="number">0.01</span> <span class="comment"># 默认的学习率设为0.01</span></span><br><span class="line">optimizer = optim.SGD([</span><br><span class="line">                       &#123;<span class="string">&#x27;params&#x27;</span>: feature_params&#125;, <span class="comment"># 非fc层的参数使用默认的学习率，即外层的学习率</span></span><br><span class="line">                       &#123;<span class="string">&#x27;params&#x27;</span>: pretrained_net.fc.parameters(), <span class="string">&#x27;lr&#x27;</span>: lr*<span class="number">10</span>&#125; <span class="comment"># fc层参数的学习率设为已训练过的部分的10倍</span></span><br><span class="line">                       ],</span><br><span class="line">                      lr=lr,</span><br><span class="line">                      weight_decay=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<h3 id="微调模型"><a href="#微调模型" class="headerlink" title="微调模型"></a>微调模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先定义一个统一的训练过程函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">data_iter, net, device=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        <span class="comment"># 如果没指定device，则使用net的device</span></span><br><span class="line">        device = <span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">                net.<span class="built_in">eval</span>() <span class="comment"># 评估模式，这会关闭dropout</span></span><br><span class="line">                acc_sum += (net(X.to(device)).argmax(dim=<span class="number">1</span>)==y.to(device)).<span class="built_in">float</span>().<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">                net.train() <span class="comment"># 改回训练模式</span></span><br><span class="line"></span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> acc_sum / n</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">train_iter, test_iter, net, loss, optimizer, device, num_epochs</span>):</span></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;training on &quot;</span>, device)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            train_l_sum += l.cpu().item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&#x27;</span> </span><br><span class="line">              % (epoch+<span class="number">1</span>, train_l_sum/n, train_acc_sum/n, test_acc, time.time()-start))</span><br><span class="line"><span class="comment"># 再定义一个使用微调的训练函数train_fine_tuning以便多次调用</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fine_tuning</span>(<span class="params">net, optimizer, batch_size=<span class="number">128</span>, num_epochs=<span class="number">5</span></span>):</span></span><br><span class="line">    train_iter = DataLoader(ImageFolder(<span class="string">&#x27;hotdog/train&#x27;</span>, transform=train_augs), batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    test_iter = DataLoader(ImageFolder(<span class="string">&#x27;hotdog/test&#x27;</span>, transform=test_augs), batch_size)</span><br><span class="line">    loss = torch.nn.CrossEntropyLoss()</span><br><span class="line">    train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据前面的设置，我们将以10倍的学习率从头训练目标模型的输出层参数</span></span><br><span class="line">train_fine_tuning(pretrained_net, optimizer)</span><br></pre></td></tr></table></figure>
<h2 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h2><p>很多时候图像里有多个我们感兴趣的目标，我们不仅想知道它们的类别，还想得到它们在图像中的具体位置。在计算机视觉里，我们将这类任务称为目标检测（object detection）或物体检测。<br>在目标检测里，我们通常使用边界框（bounding box）来描述目标位置。边界框是一个矩形框，可以由矩形左上角的x和y轴坐标与右下角的x和y轴坐标确定。<br>目标检测相关知识暂时略过，包括下面的锚框、目标检测数据集、SSD、区域卷积神经网络R-CNN系列（R-CNN、Fast R-CNN、Faster R-CNN、Mask R-CNN）。<br>值得一提的是，Mask R-CNN在Faster R-CNN的基础上做了修改。Mask R-CNN将兴趣区域池化层替换成了兴趣区域对齐层，即通过双线性插值（bilinear interpolation）来保留特征图上的空间信息，从而更适于像素级预测。兴趣区域对齐层的输出包含了所有兴趣区域的形状相同的特征图。它们既用来预测兴趣区域的类别和边界框，又通过额外的全卷积网络预测目标的像素级位置。</p>
<h2 id="语义分割和数据集"><a href="#语义分割和数据集" class="headerlink" title="语义分割和数据集"></a>语义分割和数据集</h2><p>在目标检测问题中，我们一直使用方形边界框来标注和预测图像中的目标。而语义分割（semantic segmentation）问题，它关注如何将图像分割成属于不同语义类别的区域。值得一提的是，这些语义区域的标注和预测都是像素级的。与目标检测相比，语义分割标注的像素级的边框显然更加精细。</p>
<h3 id="图像分割和实例分割"><a href="#图像分割和实例分割" class="headerlink" title="图像分割和实例分割"></a>图像分割和实例分割</h3><p>计算机视觉领域还有2个与语义分割相似的重要问题，即图像分割（image segmentation）和实例分割（instance segmentation）。在这里将它们与语义分割简单区分一下。<br>（1）图像分割将图像分割成若干组成区域。这类问题的方法通常利用图像中像素之间的相关性。它在训练时不需要有关图像像素的标签信息，在预测时也无法保证分割出的区域具有我们希望得到的语义。比如，图像分割后不知道分割出来的东西是什么，并不知道哪个是狗，哪个是猫。<br>（2）实例分割又叫同时检测并分割（simultaneous detection and segmentation）。它研究如何识别图像中各个目标实例的像素级区域。与语义分割有所不同，实例分割不仅需要区分语义，还要区分不同的目标实例。如果图像中有两只狗，实例分割需要区分像素属于这两只狗中的哪一只。</p>
<h3 id="Pascal-VOC2012语义分割数据集"><a href="#Pascal-VOC2012语义分割数据集" class="headerlink" title="Pascal VOC2012语义分割数据集"></a>Pascal VOC2012语义分割数据集</h3><p>语义分割的一个重要数据集叫作Pascal VOC2012。<br>（1）下载并读取数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载数据集</span></span><br><span class="line">!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-<span class="number">2012.</span>tar</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_voc_images</span>(<span class="params">root=<span class="string">&quot;drive/My Drive/VOCdevkit/VOC2012&quot;</span>, is_train=<span class="literal">True</span>, max_num=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># ImageSets/Segmentation路径包含了指定训练和测试样本的文本文件</span></span><br><span class="line">    txt_fname = <span class="string">&#x27;%s/ImageSets/Segmentation/%s&#x27;</span> % (root, <span class="string">&#x27;train.txt&#x27;</span> <span class="keyword">if</span> is_train <span class="keyword">else</span> <span class="string">&#x27;val.txt&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_fname, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        images = f.read().split()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> max_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        images = images[:<span class="built_in">min</span>(max_num, <span class="built_in">len</span>(images))]</span><br><span class="line">    features, labels = [<span class="literal">None</span>]*<span class="built_in">len</span>(images), [<span class="literal">None</span>]*<span class="built_in">len</span>(images)</span><br><span class="line">    <span class="keyword">for</span> i, fname <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">        <span class="comment"># JPEGImages和SegmentationClass路径下分别包含了样本的输入图像和标签</span></span><br><span class="line">        features[i] = Image.<span class="built_in">open</span>(<span class="string">&#x27;%s/JPEGImages/%s.jpg&#x27;</span> % (root, fname)).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        <span class="comment"># 这里的标签也是图像格式，其尺寸和它所标注的输入图像的尺寸相同。标签中颜色相同的像素属于同一个语义类别。</span></span><br><span class="line">        labels[i] = Image.<span class="built_in">open</span>(<span class="string">&#x27;%s/SegmentationClass/%s.png&#x27;</span> % (root, fname)).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> features, labels</span><br><span class="line">voc_dir = <span class="string">&#x27;drive/My Drive/VOCdevkit/VOC2012&#x27;</span></span><br><span class="line">train_features, train_labels = read_voc_images(voc_dir, max_num=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在标签图像中，白色和黑色分别代表边框和背景，而其他不同的颜色则对应不同的类别。</span></span><br><span class="line"><span class="comment"># 接下来，我们列出标签中每个RGB颜色的值及其标注的类别。</span></span><br><span class="line">VOC_COLORMAP = [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">128</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">128</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">128</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">0</span>, <span class="number">128</span>, <span class="number">128</span>], [<span class="number">128</span>, <span class="number">128</span>, <span class="number">128</span>],</span><br><span class="line">                [<span class="number">64</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">192</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">64</span>, <span class="number">128</span>, <span class="number">0</span>], [<span class="number">192</span>, <span class="number">128</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">64</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">192</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">64</span>, <span class="number">128</span>, <span class="number">128</span>], [<span class="number">192</span>, <span class="number">128</span>, <span class="number">128</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">64</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">64</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">192</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">192</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">64</span>, <span class="number">128</span>]]</span><br><span class="line"></span><br><span class="line">VOC_CLASSES = [<span class="string">&#x27;background&#x27;</span>, <span class="string">&#x27;aeroplane&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;diningtable&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;motorbike&#x27;</span>, <span class="string">&#x27;person&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;potted plant&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;sofa&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;tv/monitor&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个256*256*256长度的tensor</span></span><br><span class="line">colormap2label = torch.zeros(<span class="number">256</span>**<span class="number">3</span>, dtype=torch.uint8)</span><br><span class="line"><span class="keyword">for</span> i, colormap <span class="keyword">in</span> <span class="built_in">enumerate</span>(VOC_COLORMAP):</span><br><span class="line">    <span class="comment"># 将颜色索引与类别索引一一对应起来</span></span><br><span class="line">    <span class="comment"># 注意colormap2label是一个一维向量，所以不同通道的颜色值传入后要乘以256</span></span><br><span class="line">    <span class="comment"># 具体的数值大小无意义，只要是不同类别能分辨开即可，同时与下面的</span></span><br><span class="line">    <span class="comment"># (colormap[:, :, 0]*256+colormap[:, :, 1])*256+colormap[:,:,2]要对应起来</span></span><br><span class="line">    colormap2label[(colormap[<span class="number">0</span>]*<span class="number">256</span>+colormap[<span class="number">1</span>])*<span class="number">256</span>+colormap[<span class="number">2</span>]] = i</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">voc_label_indices</span>(<span class="params">colormap, colormap2label</span>):</span></span><br><span class="line">    <span class="comment"># 将PIL Image转成numpy，然后数据类型改为int32位，colormap仍然是h*w*c的样式</span></span><br><span class="line">    colormap = np.array(colormap.convert(<span class="string">&#x27;RGB&#x27;</span>)).astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将不同的通道乘以256转化成索引值</span></span><br><span class="line">    <span class="comment"># 这样，idx的shape就是h*w</span></span><br><span class="line">    idx = ((colormap[:, :, <span class="number">0</span>]*<span class="number">256</span>+colormap[:, :, <span class="number">1</span>])*<span class="number">256</span>+colormap[:,:,<span class="number">2</span>])</span><br><span class="line">    <span class="comment"># 找到该索引矩阵所对应的标签类别</span></span><br><span class="line">    <span class="comment"># 因为idx是索引矩阵，其大小与图像大小相同，那么返回的也正是每个像素所对应的类别，即与图像同样大小的类别矩阵</span></span><br><span class="line">    <span class="keyword">return</span> colormap2label[idx]</span><br></pre></td></tr></table></figure><br>（2）预处理数据<br>在之前的章节中，我们通过缩放图像使其符合模型的输入形状。然而在语义分割里，这样做需要将预测的像素类别重新映射回原始尺寸的输入图像。这样的映射难以做到精确，尤其在不同语义的分割区域。为了避免这个问题，我们将图像裁剪成固定尺寸而不是缩放。具体来说，我们使用图像增广里的随机裁剪，并对输入图像和标签裁剪相同区域。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">voc_rand_crop</span>(<span class="params">feature, label, height, width</span>):</span></span><br><span class="line">    i, j, h, w = torchvision.transforms.RandomCrop.get_params(feature, output_size=(height, width))</span><br><span class="line">    feature = torchvision.transforms.functional.crop(feature, i, j, h, w)</span><br><span class="line">    label = torchvision.transforms.functional.crop(label, i, j, h, w)</span><br><span class="line">    <span class="keyword">return</span> feature, label</span><br><span class="line"></span><br><span class="line"><span class="comment"># 比如随机裁剪200*300大小的区域</span></span><br><span class="line">img = voc_rand_crop(train_features[<span class="number">0</span>], train_labels[<span class="number">0</span>], <span class="number">200</span>, <span class="number">300</span>)</span><br></pre></td></tr></table></figure><br>（3）自定义语义分割数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VOCSegDataset</span>(<span class="params">torch.utils.data.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, is_train, crop_size, voc_dir, colormap2label, max_num=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># 对输入图像的RGB三个通道的值分别做标准化</span></span><br><span class="line">        self.rgb_mean = np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">        self.rgb_std = np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">        self.tsf = torchvision.transforms.Compose([</span><br><span class="line">                                                   torchvision.transforms.ToTensor(),</span><br><span class="line">                                                   torchvision.transforms.Normalize(</span><br><span class="line">                                                       mean=self.rgb_mean,</span><br><span class="line">                                                       std=self.rgb_std)</span><br><span class="line">        ])</span><br><span class="line">        self.crop_size = crop_size</span><br><span class="line">        features, labels = read_voc_images(</span><br><span class="line">            root = voc_dir,</span><br><span class="line">            is_train = is_train,</span><br><span class="line">            max_num = max_num</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 由于数据集中有些图像的尺寸可能小于随机裁剪所指定的输出尺寸，这些样本需要通过自定义的filter函数所移除。</span></span><br><span class="line">        self.features = self.<span class="built_in">filter</span>(features)</span><br><span class="line">        self.labels = self.<span class="built_in">filter</span>(labels)</span><br><span class="line">        self.colormap2label = colormap2label</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;read &#x27;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(self.features)) + <span class="string">&#x27; valid samples&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这个地方需要特别注意，PIL.size返回的是(width, height)，即宽在前，高在后，而我们输入的参数是高在前</span></span><br><span class="line">    <span class="comment"># https://liam.page/2015/04/22/pil-tutorial-basic-usage/</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">filter</span>(<span class="params">self, imgs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [img <span class="keyword">for</span> img <span class="keyword">in</span> imgs <span class="keyword">if</span> (</span><br><span class="line">            img.size[<span class="number">1</span>] &gt;= self.crop_size[<span class="number">0</span>] <span class="keyword">and</span> </span><br><span class="line">            img.size[<span class="number">0</span>] &gt;= self.crop_size[<span class="number">1</span>]</span><br><span class="line">        )]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过实现__getitem__函数，我们可以任意访问数据集中索引为idx的输入图像及其每个像素的类别索引</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        feature, label = voc_rand_crop(self.features[idx], self.labels[idx], *self.crop_size)</span><br><span class="line">        <span class="keyword">return</span> (self.tsf(feature), <span class="comment"># feature是float32的tensor</span></span><br><span class="line">                voc_label_indices(label, self.colormap2label) <span class="comment"># label是uint8的tensor</span></span><br><span class="line">                )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.features)</span><br><span class="line"></span><br><span class="line">crop_size = (<span class="number">320</span>, <span class="number">480</span>)</span><br><span class="line">max_num = <span class="number">100</span></span><br><span class="line">voc_train = VOCSegDataset(<span class="literal">True</span>, crop_size, voc_dir, colormap2label, max_num)</span><br><span class="line">voc_test = VOCSegDataset(<span class="literal">False</span>, crop_size, voc_dir, colormap2label, max_num)</span><br><span class="line"><span class="comment"># 设批量大小为64，分别定义训练集和测试集的迭代器。</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">num_workers = <span class="number">4</span></span><br><span class="line">train_iter = torch.utils.data.DataLoader(voc_train, batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                              drop_last=<span class="literal">True</span>, num_workers=num_workers)</span><br><span class="line"></span><br><span class="line">test_iter = torch.utils.data.DataLoader(voc_test, batch_size, drop_last=<span class="literal">True</span>,</span><br><span class="line">                             num_workers=num_workers)</span><br></pre></td></tr></table></figure></p>
<h2 id="全卷积网络"><a href="#全卷积网络" class="headerlink" title="全卷积网络"></a>全卷积网络</h2><p>全卷积网络（fully convolutional network，FCN）采用卷积神经网络实现了从图像像素到像素类别的变换。与之前介绍的卷积神经网络有所不同，全卷积网络通过转置卷积（transposed convolution）层将中间层特征图的高和宽变换回输入图像的尺寸，从而令预测结果与输入图像在空间维（高和宽）上一一对应：给定空间维上的位置，通道维的输出即该位置对应像素的类别预测。<br>全卷积网络先使用卷积神经网络抽取图像特征，然后通过 1乘1 卷积层将通道数变换为类别个数，最后通过转置卷积层将特征图的高和宽变换为输入图像的尺寸，从而输出每个像素的类别。<br>在全卷积网络中，可以将转置卷积层初始化为双线性插值的上采样。</p>
<h1 id="自然语言处理"><a href="#自然语言处理" class="headerlink" title="自然语言处理"></a>自然语言处理</h1><p>暂时略过。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechat_reward.png" alt="Xin-Bo Qi(亓欣波) WeChat Pay">
        <p>WeChat Pay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/29/kaggle-nuclei/" rel="prev" title="Kaggle细胞赛：基于PyTorch/UNet算法的细胞核识别">
      <i class="fa fa-chevron-left"></i> Kaggle细胞赛：基于PyTorch/UNet算法的细胞核识别
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/03/09/dive-into-dl-video/" rel="next" title="《动手学深度学习》视频课程学习笔记">
      《动手学深度学习》视频课程学习笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">深度学习简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86"><span class="nav-number">2.</span> <span class="nav-text">预备知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C"><span class="nav-number">2.1.</span> <span class="nav-text">数据操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA"><span class="nav-number">2.1.1.</span> <span class="nav-text">创建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C"><span class="nav-number">2.1.2.</span> <span class="nav-text">操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6"><span class="nav-number">2.1.3.</span> <span class="nav-text">广播机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%90%E7%AE%97%E7%9A%84%E5%86%85%E5%AD%98%E5%BC%80%E9%94%80"><span class="nav-number">2.1.4.</span> <span class="nav-text">运算的内存开销</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor%E5%92%8CNumpy%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2"><span class="nav-number">2.1.5.</span> <span class="nav-text">Tensor和Numpy相互转换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor-on-GPU"><span class="nav-number">2.1.6.</span> <span class="nav-text">Tensor on GPU</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%B1%82%E6%A2%AF%E5%BA%A6"><span class="nav-number">2.2.</span> <span class="nav-text">自动求梯度</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A6%82%E5%BF%B5"><span class="nav-number">2.2.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor"><span class="nav-number">2.2.2.</span> <span class="nav-text">Tensor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6"><span class="nav-number">2.2.3.</span> <span class="nav-text">梯度</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80"><span class="nav-number">3.</span> <span class="nav-text">深度学习基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">3.1.</span> <span class="nav-text">线性回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.2.</span> <span class="nav-text">线性回归的从零开始实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">3.2.1.</span> <span class="nav-text">生成数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="nav-number">3.2.2.</span> <span class="nav-text">读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"><span class="nav-number">3.2.3.</span> <span class="nav-text">初始化模型参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.4.</span> <span class="nav-text">定义模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.5.</span> <span class="nav-text">定义损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-number">3.2.6.</span> <span class="nav-text">定义优化算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.7.</span> <span class="nav-text">训练模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.3.</span> <span class="nav-text">线性回归的简洁实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E9%9B%86-1"><span class="nav-number">3.3.1.</span> <span class="nav-text">生成数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE-1"><span class="nav-number">3.3.2.</span> <span class="nav-text">读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B-1"><span class="nav-number">3.3.3.</span> <span class="nav-text">定义模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0-1"><span class="nav-number">3.3.4.</span> <span class="nav-text">初始化模型参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-1"><span class="nav-number">3.3.5.</span> <span class="nav-text">定义损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-1"><span class="nav-number">3.3.6.</span> <span class="nav-text">定义优化算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B-1"><span class="nav-number">3.3.7.</span> <span class="nav-text">训练模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#softmax%E5%9B%9E%E5%BD%92"><span class="nav-number">3.4.</span> <span class="nav-text">softmax回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86Fashion-MNIST"><span class="nav-number">3.5.</span> <span class="nav-text">图像分类数据集Fashion-MNIST</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">3.5.1.</span> <span class="nav-text">获取数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E5%B0%8F%E6%89%B9%E9%87%8F"><span class="nav-number">3.5.2.</span> <span class="nav-text">读取小批量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.6.</span> <span class="nav-text">softmax回归的从零开始实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E5%92%8C%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="nav-number">3.6.1.</span> <span class="nav-text">获取和读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0-2"><span class="nav-number">3.6.2.</span> <span class="nav-text">初始化模型参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0softmax%E8%BF%90%E7%AE%97"><span class="nav-number">3.6.3.</span> <span class="nav-text">实现softmax运算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B-2"><span class="nav-number">3.6.4.</span> <span class="nav-text">定义模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-2"><span class="nav-number">3.6.5.</span> <span class="nav-text">定义损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%88%86%E7%B1%BB%E5%87%86%E7%A1%AE%E7%8E%87"><span class="nav-number">3.6.6.</span> <span class="nav-text">计算分类准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B-2"><span class="nav-number">3.6.7.</span> <span class="nav-text">训练模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B"><span class="nav-number">3.6.8.</span> <span class="nav-text">预测</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.7.</span> <span class="nav-text">softmax回归的简洁实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E5%92%8C%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE-1"><span class="nav-number">3.7.1.</span> <span class="nav-text">获取和读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.7.2.</span> <span class="nav-text">定义和初始化模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#softmax%E5%92%8C%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.7.3.</span> <span class="nav-text">softmax和交叉熵损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-2"><span class="nav-number">3.7.4.</span> <span class="nav-text">定义优化算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B-3"><span class="nav-number">3.7.5.</span> <span class="nav-text">训练模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-number">3.8.</span> <span class="nav-text">多层感知机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F"><span class="nav-number">3.9.</span> <span class="nav-text">权重衰减</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%A2%E5%BC%83%E6%B3%95"><span class="nav-number">3.10.</span> <span class="nav-text">丢弃法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E3%80%81%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="nav-number">3.11.</span> <span class="nav-text">正向传播、反向传播和计算图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E5%80%BC%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-number">3.12.</span> <span class="nav-text">数值稳定性和模型初始化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97"><span class="nav-number">4.</span> <span class="nav-text">深度学习计算</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%84%E9%80%A0"><span class="nav-number">4.1.</span> <span class="nav-text">模型构造</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%A7%E6%89%BFModule%E7%B1%BB%E6%9D%A5%E6%9E%84%E9%80%A0%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.1.1.</span> <span class="nav-text">继承Module类来构造模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Module%E7%9A%84%E5%AD%90%E7%B1%BB"><span class="nav-number">4.1.2.</span> <span class="nav-text">Module的子类</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E7%9A%84%E8%AE%BF%E9%97%AE%E3%80%81%E5%88%9D%E5%A7%8B%E5%8C%96%E5%92%8C%E5%85%B1%E4%BA%AB"><span class="nav-number">4.2.</span> <span class="nav-text">模型参数的访问、初始化和共享</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"><span class="nav-number">4.2.1.</span> <span class="nav-text">访问模型参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0-3"><span class="nav-number">4.2.2.</span> <span class="nav-text">初始化模型参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95"><span class="nav-number">4.2.3.</span> <span class="nav-text">自定义初始化方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"><span class="nav-number">4.2.4.</span> <span class="nav-text">共享模型参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82"><span class="nav-number">4.3.</span> <span class="nav-text">自定义层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8D%E5%90%AB%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82"><span class="nav-number">4.3.1.</span> <span class="nav-text">不含模型参数的自定义层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%AB%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82"><span class="nav-number">4.3.2.</span> <span class="nav-text">含模型参数的自定义层</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E5%92%8C%E5%AD%98%E5%82%A8"><span class="nav-number">4.4.</span> <span class="nav-text">读取和存储</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%BB%E5%86%99Tensor"><span class="nav-number">4.4.1.</span> <span class="nav-text">读写Tensor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%BB%E5%86%99%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.4.2.</span> <span class="nav-text">读写模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GPU%E8%AE%A1%E7%AE%97"><span class="nav-number">4.5.</span> <span class="nav-text">GPU计算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87"><span class="nav-number">4.5.1.</span> <span class="nav-text">计算设备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor%E7%9A%84GPU%E8%AE%A1%E7%AE%97"><span class="nav-number">4.5.2.</span> <span class="nav-text">Tensor的GPU计算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84GPU%E8%AE%A1%E7%AE%97"><span class="nav-number">4.5.3.</span> <span class="nav-text">模型的GPU计算</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">5.</span> <span class="nav-text">卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">5.1.</span> <span class="nav-text">二维卷积层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A1%AB%E5%85%85%E5%92%8C%E6%AD%A5%E5%B9%85"><span class="nav-number">5.2.</span> <span class="nav-text">填充和步幅</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E9%80%9A%E9%81%93%E5%92%8C%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93"><span class="nav-number">5.3.</span> <span class="nav-text">多输入通道和多输出通道</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="nav-number">5.4.</span> <span class="nav-text">池化层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88LeNet%EF%BC%89"><span class="nav-number">5.5.</span> <span class="nav-text">卷积神经网络（LeNet）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B-3"><span class="nav-number">5.5.1.</span> <span class="nav-text">定义模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E5%92%8C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.5.2.</span> <span class="nav-text">获取数据和训练模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88AlexNet%EF%BC%89"><span class="nav-number">5.6.</span> <span class="nav-text">深度卷积神经网络（AlexNet）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E7%89%B9%E5%BE%81%E8%A1%A8%E7%A4%BA"><span class="nav-number">5.6.1.</span> <span class="nav-text">学习特征表示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AlexNet"><span class="nav-number">5.6.2.</span> <span class="nav-text">AlexNet</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A0%E7%9A%84%E7%BD%91%E7%BB%9C%EF%BC%88VGG%EF%BC%89"><span class="nav-number">5.7.</span> <span class="nav-text">使用重复元素的网络（VGG）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#VGG%E5%9D%97"><span class="nav-number">5.7.1.</span> <span class="nav-text">VGG块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#VGG%E7%BD%91%E7%BB%9C"><span class="nav-number">5.7.2.</span> <span class="nav-text">VGG网络</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%EF%BC%88NiN%EF%BC%89"><span class="nav-number">5.8.</span> <span class="nav-text">网络中的网络（NiN）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#NiN%E5%9D%97"><span class="nav-number">5.8.1.</span> <span class="nav-text">NiN块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NiN%E7%BD%91%E7%BB%9C"><span class="nav-number">5.8.2.</span> <span class="nav-text">NiN网络</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9C%EF%BC%88GoogLeNet%EF%BC%89"><span class="nav-number">5.9.</span> <span class="nav-text">含并行连结的网络（GoogLeNet）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Inception%E5%9D%97"><span class="nav-number">5.9.1.</span> <span class="nav-text">Inception块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GoogLeNet"><span class="nav-number">5.9.2.</span> <span class="nav-text">GoogLeNet</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96"><span class="nav-number">5.10.</span> <span class="nav-text">批量归一化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C"><span class="nav-number">5.11.</span> <span class="nav-text">残差网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E5%9D%97"><span class="nav-number">5.11.1.</span> <span class="nav-text">残差块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ResNet%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.11.2.</span> <span class="nav-text">ResNet模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A8%A0%E5%AF%86%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C%EF%BC%88DenseNet%EF%BC%89"><span class="nav-number">5.12.</span> <span class="nav-text">稠密连接网络（DenseNet）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A8%A0%E5%AF%86%E5%9D%97"><span class="nav-number">5.12.1.</span> <span class="nav-text">稠密块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%87%E6%B8%A1%E5%B1%82"><span class="nav-number">5.12.2.</span> <span class="nav-text">过渡层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DenseNet%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.12.3.</span> <span class="nav-text">DenseNet模型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">6.</span> <span class="nav-text">循环神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-number">7.</span> <span class="nav-text">优化算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="nav-number">7.1.</span> <span class="nav-text">优化与深度学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">7.2.</span> <span class="nav-text">梯度下降和随机梯度下降</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%8F%E6%89%B9%E9%87%8F%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">7.3.</span> <span class="nav-text">小批量随机梯度下降</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A8%E9%87%8F%E6%B3%95"><span class="nav-number">7.4.</span> <span class="nav-text">动量法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AdaGrad%E7%AE%97%E6%B3%95"><span class="nav-number">7.5.</span> <span class="nav-text">AdaGrad算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RMSProp%E7%AE%97%E6%B3%95"><span class="nav-number">7.6.</span> <span class="nav-text">RMSProp算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AdaDelta%E7%AE%97%E6%B3%95"><span class="nav-number">7.7.</span> <span class="nav-text">AdaDelta算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adam%E7%AE%97%E6%B3%95"><span class="nav-number">7.8.</span> <span class="nav-text">Adam算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD"><span class="nav-number">8.</span> <span class="nav-text">计算性能</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%92%8C%E7%AC%A6%E5%8F%B7%E5%BC%8F%E7%BC%96%E7%A8%8B"><span class="nav-number">8.1.</span> <span class="nav-text">命令式编程和符号式编程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E8%AE%A1%E7%AE%97"><span class="nav-number">8.2.</span> <span class="nav-text">异步计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97"><span class="nav-number">8.3.</span> <span class="nav-text">自动并行计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9AGPU%E8%AE%A1%E7%AE%97"><span class="nav-number">8.4.</span> <span class="nav-text">多GPU计算</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="nav-number">9.</span> <span class="nav-text">计算机视觉</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF"><span class="nav-number">9.1.</span> <span class="nav-text">图像增广</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF%E6%96%B9%E6%B3%95"><span class="nav-number">9.1.1.</span> <span class="nav-text">常用的图像增广方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BE%AE%E8%B0%83"><span class="nav-number">9.2.</span> <span class="nav-text">微调</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86-1"><span class="nav-number">9.2.1.</span> <span class="nav-text">获取数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B-1"><span class="nav-number">9.2.2.</span> <span class="nav-text">定义和初始化模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">9.2.3.</span> <span class="nav-text">微调模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-number">9.3.</span> <span class="nav-text">目标检测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">9.4.</span> <span class="nav-text">语义分割和数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E5%92%8C%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2"><span class="nav-number">9.4.1.</span> <span class="nav-text">图像分割和实例分割</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pascal-VOC2012%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">9.4.2.</span> <span class="nav-text">Pascal VOC2012语义分割数据集</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="nav-number">9.5.</span> <span class="nav-text">全卷积网络</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"><span class="nav-number">10.</span> <span class="nav-text">自然语言处理</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xin-Bo Qi(亓欣波)"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Xin-Bo Qi(亓欣波)</p>
  <div class="site-description" itemprop="description">Digitize everything to realize Digitalization!</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">144</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">49</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/qixinbo" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:qixinbo@gmail.com" title="E-Mail → mailto:qixinbo@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/qixinbo" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fas fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.tsinghua.edu.cn/" title="https:&#x2F;&#x2F;www.tsinghua.edu.cn" rel="noopener" target="_blank">THU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.imr.cas.cn/" title="http:&#x2F;&#x2F;www.imr.cas.cn" rel="noopener" target="_blank">IMR</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.sdu.edu.cn/" title="http:&#x2F;&#x2F;www.sdu.edu.cn" rel="noopener" target="_blank">SDU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://liam0205.me/" title="http:&#x2F;&#x2F;liam0205.me&#x2F;" rel="noopener" target="_blank">黄晨成</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xin-Bo Qi(亓欣波)</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://qixinbo.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://qixinbo.github.io/2020/03/08/dive-into-dl/";
    this.page.identifier = "2020/03/08/dive-into-dl/";
    this.page.title = "《动手学深度学习》PyTorch版学习笔记";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://qixinbo.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
