<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"qixinbo.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="概览 赛事描述 Kaggle上正在进行一项名为“HuBMAP: Hacking the Kidney”的竞赛，链接见这里，总奖金是6万美金，该竞赛的目的是为了检测人体组织中的functional tissue units (FTUs)。FTU的定义是：three-dimensional block of cells centered around a capillary, such that ea">
<meta property="og:type" content="article">
<meta property="og:title" content="Kaggle肾小球图像分割比赛全解析">
<meta property="og:url" content="http://qixinbo.github.io/2021/02/14/kaggle-hubmap/index.html">
<meta property="og:site_name" content="数字旗手">
<meta property="og:description" content="概览 赛事描述 Kaggle上正在进行一项名为“HuBMAP: Hacking the Kidney”的竞赛，链接见这里，总奖金是6万美金，该竞赛的目的是为了检测人体组织中的functional tissue units (FTUs)。FTU的定义是：three-dimensional block of cells centered around a capillary, such that ea">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://user-images.githubusercontent.com/6218739/100980887-e7719a00-3580-11eb-9dcd-2921740efa80.png">
<meta property="article:published_time" content="2021-02-13T16:00:00.000Z">
<meta property="article:modified_time" content="2021-03-26T07:45:46.819Z">
<meta property="article:author" content="Xin-Bo Qi(亓欣波)">
<meta property="article:tag" content="kaggle">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://user-images.githubusercontent.com/6218739/100980887-e7719a00-3580-11eb-9dcd-2921740efa80.png">

<link rel="canonical" href="http://qixinbo.github.io/2021/02/14/kaggle-hubmap/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Kaggle肾小球图像分割比赛全解析 | 数字旗手</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="数字旗手" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">数字旗手</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">电气化、自动化、数字化、智能化、智慧化</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-scholar">

    <a href="/scholar/" rel="section"><i class="fa fa-chart-bar fa-fw"></i>scholar</a>

  </li>
        <li class="menu-item menu-item-sources">

    <a href="/sources/" rel="section"><i class="fa fa-rss fa-fw"></i>sources</a>

  </li>
        <li class="menu-item menu-item-gallery">

    <a href="/gallery/" rel="section"><i class="fa fa-file-image fa-fw"></i>gallery</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404.html" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://qixinbo.github.io/2021/02/14/kaggle-hubmap/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Xin-Bo Qi(亓欣波)">
      <meta itemprop="description" content="Digitize everything to realize Digitalization!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数字旗手">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kaggle肾小球图像分割比赛全解析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-02-14 00:00:00" itemprop="dateCreated datePublished" datetime="2021-02-14T00:00:00+08:00">2021-02-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-26 15:45:46" itemprop="dateModified" datetime="2021-03-26T15:45:46+08:00">2021-03-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2021/02/14/kaggle-hubmap/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2021/02/14/kaggle-hubmap/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h1><h2 id="赛事描述"><a href="#赛事描述" class="headerlink" title="赛事描述"></a>赛事描述</h2><p>Kaggle上正在进行一项名为“HuBMAP: Hacking the Kidney”的竞赛，链接见<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/hubmap-kidney-segmentation">这里</a>，总奖金是6万美金，该竞赛的目的是为了检测人体组织中的functional tissue units (FTUs)。FTU的定义是：three-dimensional block of cells centered around a capillary, such that each cell in this block is within diffusion distance from any other cell in the same block，感觉类似于细胞的概念，正中是细胞核，周围是细胞质。</p>
<h2 id="算法评估标准"><a href="#算法评估标准" class="headerlink" title="算法评估标准"></a>算法评估标准</h2><p>该竞赛使用Dice系数来评估算法的优劣。关于Dice系数，可以见如下博客解析：<br><a target="_blank" rel="noopener" href="https://www.aiuai.cn/aifarm1159.html">医学图像分割之 Dice Loss</a></p>
<p>竞赛所提交的文件使用游程编码方式（RLE，run-length encoding）来减小文件体积。<br>关于掩膜mask与rle编码与解码的代码，可以参见网友Paulo Pinto的notebook：<br><a target="_blank" rel="noopener" href="https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode">RLE functions - Run Lenght Encode &amp; Decode</a></p>
<h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><h2 id="数据集概览"><a href="#数据集概览" class="headerlink" title="数据集概览"></a>数据集概览</h2><p>该赛事中的数据一共有20张肾的图像，每一张都对其中的肾小球FTU进行了标注，有8张用于训练集，5张用于公榜测试集，剩下7张用于私榜测试集。<br>每一张图像都是非常大的TIFF格式，500MB-5GB大小。</p>
<p>训练集中的标注有两种形式：游程编码和未编码的JSON格式。<br>可以使用外部数据和/或预训练的机器学习模型，不过这些数据和模型必须在CC BY 4.0下授权。<br>下载数据集（这是在google colab上运行，colab上的机器性能较好；如果直接使用kaggle上的notebook，则数据集直接内置）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!kaggle competitions download -c hubmap-kidney-segmentation</span><br></pre></td></tr></table></figure><br>然后进行数据的探索性分析，该过程参考了以下notebook：<br><a target="_blank" rel="noopener" href="https://www.kaggle.com/ihelon/hubmap-exploratory-data-analysis">HuBMAP - Exploratory Data Analysis</a></p>
<h2 id="导入必要的包"><a href="#导入必要的包" class="headerlink" title="导入必要的包"></a>导入必要的包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pathlib, sys, os, random, time</span><br><span class="line"><span class="keyword">import</span> numba, cv2, gc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> albumentations <span class="keyword">as</span> A</span><br><span class="line"><span class="keyword">import</span> rasterio</span><br><span class="line"><span class="keyword">from</span> rasterio.windows <span class="keyword">import</span> Window</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> D</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> T</span><br></pre></td></tr></table></figure>
<h2 id="配置路径及超参数"><a href="#配置路径及超参数" class="headerlink" title="配置路径及超参数"></a>配置路径及超参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BASE_PATH = <span class="string">&quot;../input/hubmap-kidney-segmentation/&quot;</span></span><br><span class="line">TRAIN_PATH = os.path.join(BASE_PATH, <span class="string">&quot;train/&quot;</span>)</span><br><span class="line">TEST_PATH = os.path.join(BASE_PATH, <span class="string">&quot;test/&quot;</span>)</span><br><span class="line"></span><br><span class="line">EPOCHES = <span class="number">5</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">DEVICE = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="文件分析"><a href="#文件分析" class="headerlink" title="文件分析"></a>文件分析</h2><p>（1）训练集文件分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_train = pd.read_csv(os.path.join(BASE_PATH, <span class="string">&quot;train.csv&quot;</span>))</span><br><span class="line">df_train</span><br></pre></td></tr></table></figure></p>
<p>得到：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">           <span class="built_in">id</span>                        encoding</span><br><span class="line"><span class="number">0</span>        2f6ecfcdf        <span class="number">296084587</span> <span class="number">4</span> <span class="number">296115835</span> <span class="number">6</span> <span class="number">296115859</span> <span class="number">14</span> <span class="number">296147109.</span>..</span><br><span class="line"><span class="number">1</span>        aaa6a05cc        <span class="number">30989109</span> <span class="number">59</span> <span class="number">31007591</span> <span class="number">64</span> <span class="number">31026074</span> <span class="number">68</span> <span class="number">31044556</span> <span class="number">7.</span>..</span><br><span class="line"><span class="number">2</span>        cb2d976f4        <span class="number">78144363</span> <span class="number">5</span> <span class="number">78179297</span> <span class="number">15</span> <span class="number">78214231</span> <span class="number">25</span> <span class="number">78249165</span> <span class="number">35.</span>..</span><br><span class="line"><span class="number">3</span>        0486052bb        <span class="number">101676003</span> <span class="number">6</span> <span class="number">101701785</span> <span class="number">8</span> <span class="number">101727568</span> <span class="number">9</span> <span class="number">101753351</span> ...</span><br><span class="line"><span class="number">4</span>        e79de561c        <span class="number">7464094</span> <span class="number">14</span> <span class="number">7480273</span> <span class="number">41</span> <span class="number">7496453</span> <span class="number">67</span> <span class="number">7512632</span> <span class="number">82</span> <span class="number">75.</span>..</span><br><span class="line"><span class="number">5</span>        095bf7a1f        <span class="number">113430380</span> <span class="number">22</span> <span class="number">113468538</span> <span class="number">67</span> <span class="number">113506697</span> <span class="number">111</span> <span class="number">113544.</span>..</span><br><span class="line"><span class="number">6</span>        54f2eec69        <span class="number">124601765</span> <span class="number">36</span> <span class="number">124632133</span> <span class="number">109</span> <span class="number">124662536</span> <span class="number">147</span> <span class="number">12469.</span>..</span><br><span class="line"><span class="number">7</span>        1e2425f28        <span class="number">49453112</span> <span class="number">7</span> <span class="number">49479881</span> <span class="number">22</span> <span class="number">49506657</span> <span class="number">31</span> <span class="number">49533433</span> <span class="number">40.</span>..</span><br></pre></td></tr></table></figure><br>train.csv文件中包含了图像的id及其游程编码。可以看出图像的名称就是id名。<br>（2）提交文件分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_sub = pd.read_csv(os.path.join(BASE_PATH, <span class="string">&quot;sample_submission.csv&quot;</span>))</span><br><span class="line">df_sub</span><br></pre></td></tr></table></figure><br>得到：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   <span class="built_in">id</span>                          predicted</span><br><span class="line"><span class="number">0</span>        b9a3865fc        NaN</span><br><span class="line"><span class="number">1</span>        b2dc8411c        NaN</span><br><span class="line"><span class="number">2</span>        26dc41664        NaN</span><br><span class="line"><span class="number">3</span>        c68fe75ea        NaN</span><br><span class="line"><span class="number">4</span>        afa5e8098        NaN</span><br></pre></td></tr></table></figure><br>提交文件就是对公共测试集上的图像的预测，可以看出id就是公共测试集中的图像名称，predicted一栏需要后面填入。<br>（3）数据集大小分析：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;number of train images: &quot;, df_train.shape[0])</span><br><span class="line">print(&quot;number of test images: &quot;, df_sub.shape[0])</span><br></pre></td></tr></table></figure><br>分别是8和5。<br>（4）元数据分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_meta = pd.read_csv(os.path.join(BASE_PATH, <span class="string">&quot;HuBMAP-20-dataset_information.csv&quot;</span>))</span><br><span class="line">df_meta.sample(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><br>该文件中包含了数据集中的每一张图像额外的信息，比如它的主人的身体信息、性别、种族等。<br>同时指明训练集中除了肾小球的标注文件，比如1e2425f28.json，还有其他解剖组织的标注文件，比如1e2425f28-anatomical-structure.json。<br>该文件是为了辅助理解该赛题背后的医学知识，有可能对特征功能有用，但目前看没法直接使用。</p>
<h2 id="工具函数"><a href="#工具函数" class="headerlink" title="工具函数"></a>工具函数</h2><p>以下是关于游程编码和解码、读取图像、可视化的工具代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图像分块</span></span><br><span class="line"><span class="comment"># min_overlap这个参数指的是有可能出现的最小的overlap，而不是保证这个overlap一定会出现</span></span><br><span class="line"><span class="comment"># 即自适应产生的overlap肯定会大于该min_overlap</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_grid</span>(<span class="params">shape, window=<span class="number">256</span>, min_overlap=<span class="number">32</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Return Array of size (N,4), where N - number of tiles,</span></span><br><span class="line"><span class="string">        2nd axis represente slices: x1,x2,y1,y2</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x, y = shape</span><br><span class="line">    nx = x // (window - min_overlap) + <span class="number">1</span></span><br><span class="line">    x1 = np.linspace(<span class="number">0</span>, x, num=nx, endpoint=<span class="literal">False</span>, dtype=np.int64)</span><br><span class="line">    x1[-<span class="number">1</span>] = x - window</span><br><span class="line">    x2 = (x1 + window).clip(<span class="number">0</span>, x)</span><br><span class="line">    ny = y // (window - min_overlap) + <span class="number">1</span></span><br><span class="line">    y1 = np.linspace(<span class="number">0</span>, y, num=ny, endpoint=<span class="literal">False</span>, dtype=np.int64)</span><br><span class="line">    y1[-<span class="number">1</span>] = y - window</span><br><span class="line">    y2 = (y1 + window).clip(<span class="number">0</span>, y)</span><br><span class="line">    slices = np.zeros((nx,ny, <span class="number">4</span>), dtype=np.int64)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nx):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(ny):</span><br><span class="line">            slices[i,j] = x1[i], x2[i], y1[j], y2[j]   </span><br><span class="line">    <span class="keyword">return</span> slices.reshape(nx*ny,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 固定随机数，以保证可复现性</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_seeds</span>(<span class="params">seed=<span class="number">42</span></span>):</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 游程编码转为图像掩膜</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rle2mask</span>(<span class="params">mask_rle, shape</span>):</span></span><br><span class="line">    <span class="comment"># shape的形状是(width, height), width是通常理解的图像宽度</span></span><br><span class="line">    <span class="comment"># 原始的rle编码是str类型，里面的元素成对出现，即start起始像素及length长度</span></span><br><span class="line">    s = mask_rle.split()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将s中的start和length分别提取出来，因为它们在原始列表中是成对出现，所以这里对这两种数据都是每隔两个元素提取一次</span></span><br><span class="line">    <span class="comment"># 然后再通过python的列表生成式语法另存成numpy数组</span></span><br><span class="line">    <span class="comment"># https://www.liaoxuefeng.com/wiki/1016959663602400/1017317609699776</span></span><br><span class="line">    starts, lengths = [np.asarray(x, dtype=<span class="built_in">int</span>) <span class="keyword">for</span> x <span class="keyword">in</span> (s[<span class="number">0</span>:][::<span class="number">2</span>], s[<span class="number">1</span>:][::<span class="number">2</span>])]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 原始csv文件中的游程编码是从绝对位置开始，因此转化为numpy数组时需要减1</span></span><br><span class="line">    starts -= <span class="number">1</span></span><br><span class="line">    ends = starts + lengths</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据原始图像大小建立一个空白图像</span></span><br><span class="line">    img = np.zeros(shape[<span class="number">0</span>]*shape[<span class="number">1</span>], dtype=np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据起始像素和结束像素，在该空白图像上创建掩膜</span></span><br><span class="line">    <span class="comment"># 1为mask，0为背景</span></span><br><span class="line">    <span class="keyword">for</span> lo, hi <span class="keyword">in</span> <span class="built_in">zip</span>(starts, ends):</span><br><span class="line">        img[lo: hi] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将img按输入shape变换形状，这里就体现了shape中元素顺序的关键</span></span><br><span class="line">    <span class="comment"># 因为RLE编码是先从上到下，然后再从左到右进行的，所以分割时是先满足高度要求，即先按一列一列地来分组</span></span><br><span class="line">    <span class="comment"># 因为输入的shape是宽度在前，高度在后，正好reshape就按这个shape来变换形状</span></span><br><span class="line">    <span class="comment"># 比如原图如果宽为5，高为2，那么就reshape((5, 2))，即分成5组，每组2个元素</span></span><br><span class="line">    <span class="comment"># 然后因为图像存成numpy数组时是行数乘以列数，即转置一下即可</span></span><br><span class="line">    <span class="keyword">return</span> img.reshape(shape).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像掩膜转为游程编码</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/qq_35985044/article/details/104332577</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask2rle</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="comment"># 将掩膜按从上到下、从左到右的顺序压平</span></span><br><span class="line">    pixels = img.T.flatten()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前后各加一个0作为缓冲区</span></span><br><span class="line">    pixels = np.concatenate([[<span class="number">0</span>], pixels, [<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 以下记录的是掩膜值开始发生变化的位置，使用的方法是将数组错移一位，并与原数组比较</span></span><br><span class="line">    <span class="comment"># 这样每一段重复的序列在前后位置都有一个变化的位置记录，前后位置是成对出现的</span></span><br><span class="line">    <span class="comment"># +1是为了做位置调整</span></span><br><span class="line">    runs = np.where(pixels[<span class="number">1</span>:] != pixels[:-<span class="number">1</span>])[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这一步比较抽象，首先记住runs记录了像素值发生变化的位置</span></span><br><span class="line">    <span class="comment"># runs[1::2]是从第二个位置开始，每隔两个元素提取一次，即该表达式提取的是“成对出现的前后位置”中的“后”这一位置</span></span><br><span class="line">    <span class="comment"># runs[::2]则是从第一个位置开始，每隔两个元素提取一次，即该表达式提取的是“成对出现的前后位置”中的“前”这一位置</span></span><br><span class="line">    <span class="comment"># 然后两者相减，并在原来“后”这一位置存储差值，即每个重复序列的长度</span></span><br><span class="line">    runs[<span class="number">1</span>::<span class="number">2</span>] -= runs[::<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将上述元素逐个取出，并且使用空格符连接成字符串</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> runs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用numba加速</span></span><br><span class="line"><span class="comment"># 可以参考如下nb里的讨论部分</span></span><br><span class="line"><span class="comment"># https://www.kaggle.com/leighplt/pytorch-fcn-resnet50/comments</span></span><br><span class="line"><span class="meta">@numba.njit()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask2rle_numba_1d</span>(<span class="params">pixels</span>):</span></span><br><span class="line">    size = <span class="built_in">len</span>(pixels)</span><br><span class="line">    points = []</span><br><span class="line">    <span class="keyword">if</span> pixels[<span class="number">0</span>] == <span class="number">1</span>: points.append(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, size):</span><br><span class="line">        <span class="keyword">if</span> pixels[i] != pixels[i-<span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(points) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                points.append(i+<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                points.append(i+<span class="number">1</span> - points[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pixels[-<span class="number">1</span>] == <span class="number">1</span>: points.append(size-points[-<span class="number">1</span>]+<span class="number">1</span>)   </span><br><span class="line">    <span class="keyword">return</span> points</span><br><span class="line"></span><br><span class="line"><span class="comment"># 该函数必须得与上面的分开，因为最后的join函数不支持numba</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask2rle_numba</span>(<span class="params">image</span>):</span></span><br><span class="line">    pixels = image.T.flatten()</span><br><span class="line">    points = mask2rle_numba_1d(pixels)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> points)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取训练集图像</span></span><br><span class="line"><span class="comment"># 对于大型tif图像，推荐使用rasterio来读取，读取速度会提升很多倍</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_image</span>(<span class="params">image_id, scale=<span class="literal">None</span>, verbose=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="comment"># python3.6引入的f-string，用于格式化字符串</span></span><br><span class="line">    <span class="comment"># https://blog.csdn.net/sunxb10/article/details/81036693</span></span><br><span class="line">    image = tifffile.imread(os.path.join(TRAIN_PATH, <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.tiff&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集中有几张图像是(1, 1, 3, X, Y)这样的格式，需要将其转为正确的(X, Y, 3)格式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(image.shape) == <span class="number">5</span>:</span><br><span class="line">        image = image.sequeeze().transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这个地方用到了pandas对象的布尔数组索引</span></span><br><span class="line">    <span class="comment"># https://www.pypandas.cn/docs/user_guide/indexing.html#%E7%B4%A2%E5%BC%95%E7%9A%84%E4%B8%8D%E5%90%8C%E9%80%89%E6%8B%A9</span></span><br><span class="line">    <span class="comment"># 特别需要注意的是第二个参数的顺序，这里是图像的宽度在前，高度在后</span></span><br><span class="line">    mask = rle2mask(df_train[df_train[<span class="string">&quot;id&quot;</span>] == image_id][<span class="string">&#x27;encoding&#x27;</span>].values[<span class="number">0</span>], (image.shape[<span class="number">1</span>], image.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开启详细显示信息模式</span></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Mask shape: <span class="subst">&#123;mask.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 缩放</span></span><br><span class="line">    <span class="keyword">if</span> scale:</span><br><span class="line">        <span class="comment"># 注意opencv的resize函数要求的参数是先宽后高，注意顺序</span></span><br><span class="line">        new_size = (image.shape[<span class="number">1</span>] // scale, image.shape[<span class="number">0</span>] // scale)</span><br><span class="line">        image = cv2.resize(image, new_size)</span><br><span class="line">        mask = cv2.resize(mask, new_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Mask shape: <span class="subst">&#123;mask.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image, mask</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取测试集图像</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_test_image</span>(<span class="params">image_id, scale=<span class="literal">None</span>, verbose=<span class="number">1</span></span>):</span></span><br><span class="line">    image = tifffile.imread(os.path.join(TEST_PATH, <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.tiff&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(image.shape) == <span class="number">5</span>:</span><br><span class="line">        image = image.sequeeze().tranpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> scale:</span><br><span class="line">        new_size = (image.shape[<span class="number">1</span>] // scale, image.shape[<span class="number">0</span>] // scale)</span><br><span class="line">        image = cv2.resize(image, new_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化图像及其掩膜</span></span><br><span class="line"><span class="comment"># 主要是应用了matplotlib库，其用法可参考如下链接</span></span><br><span class="line"><span class="comment"># https://lijin-thu.github.io/06.%20matplotlib/06.01%20pyplot%20tutorial.html</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_image_and_mask</span>(<span class="params">image, mask, image_id</span>):</span></span><br><span class="line">    <span class="comment"># 产生一幅图，指定其大小</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一行三列的子图</span></span><br><span class="line">    <span class="comment"># 这里是第一个子图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.title(<span class="string">f&quot;Image <span class="subst">&#123;image_id&#125;</span>&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二个子图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.imshow(mask, cmap=<span class="string">&quot;hot&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.title(<span class="string">f&quot;Image <span class="subst">&#123;image_id&#125;</span> + mask&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第三个子图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.imshow(mask, cmap=<span class="string">&quot;hot&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">f&quot;Mask&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化图像及其掩膜的一部分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_slice_image_and_mask</span>(<span class="params">image, mask, start_h, end_h, start_w, end_w</span>):</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line">    sub_image = image[start_h : end_h, start_w : end_w, :]</span><br><span class="line">    sub_mask = mask[start_h : end_h, start_w : end_w]</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(sub_image)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">    plt.imshow(sub_image)</span><br><span class="line">    plt.imshow(sub_mask, cmap=<span class="string">&quot;hot&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.imshow(sub_mask, cmap=<span class="string">&quot;hot&quot;</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p>
<p>依据这些工具函数，可以很方便地进行数据集的读取和调用。<br>以训练集中的某张图像为例，观察其部分原图及其标注：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">image_id = <span class="string">&quot;0486052bb&quot;</span></span><br><span class="line">image, mask = read_image(image_id, <span class="number">2</span>)</span><br><span class="line">plot_image_and_mask(image, mask, image_id)</span><br><span class="line"></span><br><span class="line">plot_slice_image_and_mask(image, mask, <span class="number">5000</span>, <span class="number">7500</span>, <span class="number">2500</span>, <span class="number">5000</span>)</span><br><span class="line">plot_slice_image_and_mask(image, mask, <span class="number">5250</span>, <span class="number">5720</span>, <span class="number">3500</span>, <span class="number">4000</span>)</span><br></pre></td></tr></table></figure><br>结果如下图：<br><img src="https://user-images.githubusercontent.com/6218739/100980887-e7719a00-3580-11eb-9dcd-2921740efa80.png" alt="vis"></p>
<h2 id="无网络连接安装依赖"><a href="#无网络连接安装依赖" class="headerlink" title="无网络连接安装依赖"></a>无网络连接安装依赖</h2><p>因为这个比赛的notebook不允许使用Internet，因此，如果调用了kaggle默认环境所没有的模块和包时，需要事先自己在线下准备好。<br>具体做法可以参考<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/113195">该教程</a>：<br>（1）首先打开notebook的网络，然后使用pip下载所依赖的包的whl文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip download [package_name]</span><br></pre></td></tr></table></figure><br>记住此时download的顺序以及版本号（这点一定要注意），后面要按该顺序的逆序进行安装。<br>（2）将这些whl文件上传到kaggle的dataset中；<br>这一步又涉及怎样将这些文件先下载下来，此时可以参考<a target="_blank" rel="noopener" href="https://www.kaggle.com/getting-started/168312">该教程</a>：<br>一种是直接在右侧的output侧栏中点击下载；<br>一种是通过命令下载：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%cd /kaggle/working</span><br><span class="line">from IPython.display import FileLink -&gt; FileLink(r&#x27;*name of file*&#x27;)</span><br></pre></td></tr></table></figure><br>注意，在kaggle上上传非whl的安装包时，比如上传的时.tar.gz格式的源码包，kaggle会自动将其解压成文件夹。<br>因此，需要将此种文件后缀名需要更改为.xyz，然后上传。<br>上传时如果发现其他dataset仓库已经有相同的软件包，可以直接用那里的，也可以选择include duplicates上传自己的。<br>（3）在该notebook中引用上面的dataset，然后按逆序安装这些whl。<br>对于非whl的文件，注意将其copy到本地路径后，再修改为.tar.gz后缀名，然后正常pip install即可。</p>
<h1 id="正确提交一次和跑一遍模型"><a href="#正确提交一次和跑一遍模型" class="headerlink" title="正确提交一次和跑一遍模型"></a>正确提交一次和跑一遍模型</h1><h2 id="正确提交一次"><a href="#正确提交一次" class="headerlink" title="正确提交一次"></a>正确提交一次</h2><p>这里首先通过正确提交一次，保证提交文件是正确的，否则可能花了很多时间搭建算法和训练，最后却卡在提交上，没法及时提交。<br>因为Kaggle的submission目前看像是一个玄学，大家都在尝试怎样提交成功，比如下面的讨论：<br><a target="_blank" rel="noopener" href="https://www.kaggle.com/c/tensorflow2-question-answering/discussion/116409">Scoring error on submission - even with sample_submission.csv</a><br><a target="_blank" rel="noopener" href="https://www.kaggle.com/c/tensorflow2-question-answering/discussion/123466">Scoring error again</a><br>原因就是如第一个帖子中Julia所说，kaggle官方为了确保测试集不会被大家hack或产生leak，将测试集藏得很深。<br>想要提交成功，要假设测试集就在那里，且文件的ID千万不能硬编码，要做到“自适应”，同时里面的内容一开始可以全部设为0，但也注意有些竞赛对于数值也有要求，比如下面的帖子中，因为最后的score要计算Spearman系数，所以每一个array中至少要有两个不同的值：<br><a target="_blank" rel="noopener" href="https://www.kaggle.com/c/google-quest-challenge/discussion/126777">Unable to fix submission scoring error</a><br>针对于此例，一个很小的提交如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">DATA_PATH = <span class="string">&#x27;../input/hubmap-kidney-segmentation&#x27;</span></span><br><span class="line">identity = rasterio.Affine(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">p = pathlib.Path(DATA_PATH)</span><br><span class="line">subm = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(p.glob(<span class="string">&#x27;test/*.tiff&#x27;</span>)):</span><br><span class="line">    dataset = rasterio.<span class="built_in">open</span>(filename.as_posix(), transform = identity)</span><br><span class="line">    preds = np.zeros(dataset.shape, dtype=np.uint8)</span><br><span class="line">    subm[i] = &#123;<span class="string">&#x27;id&#x27;</span>:filename.stem, <span class="string">&#x27;predicted&#x27;</span>: mask2rle_numba(preds)&#125;</span><br><span class="line">    <span class="keyword">del</span> preds</span><br><span class="line">    gc.collect();</span><br><span class="line"></span><br><span class="line">submission = pd.DataFrame.from_dict(subm, orient=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line">submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="跑一遍模型"><a href="#跑一遍模型" class="headerlink" title="跑一遍模型"></a>跑一遍模型</h2><p>这里实际是用随机权重的模型在测试集上跑一遍，保证整个流程是通路的，然后再进行模型的训练，即“以终为始”。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span>():</span></span><br><span class="line">    model = torchvision.models.segmentation.fcn_resnet50(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原来的用于多类分割的模型最后一层改为目前的两类分割</span></span><br><span class="line">    model.classifier[<span class="number">4</span>] = nn.Conv2d(<span class="number">512</span>, <span class="number">1</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这一步也非常重要，因为不能有网络连接，如果不事先下载好这些权重文件，notebook运行过程中会联网下载，导致提交不成功</span></span><br><span class="line">!mkdir -p /root/.cache/torch/hub/checkpoints/</span><br><span class="line">!cp ../<span class="built_in">input</span>/pytorch-pretrained-models/resnet50-19c8e357.pth /root/.cache/torch/hub/checkpoints/</span><br><span class="line">!cp ../<span class="built_in">input</span>/pretrain-coco-weights-pytorch/fcn_resnet50_coco-1167a1af.pth /root/.cache/torch/hub/checkpoints/</span><br><span class="line"></span><br><span class="line">model = get_model()</span><br><span class="line">model.to(DEVICE);</span><br><span class="line"></span><br><span class="line">identity = rasterio.Affine(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个变换一定要与训练集的变换相同</span></span><br><span class="line">trfm = T.Compose([</span><br><span class="line">    T.ToPILImage(),</span><br><span class="line">    T.Resize(NEW_SIZE),</span><br><span class="line">    T.ToTensor(),</span><br><span class="line">    T.Normalize([<span class="number">0.625</span>, <span class="number">0.448</span>, <span class="number">0.688</span>],</span><br><span class="line">                [<span class="number">0.131</span>, <span class="number">0.177</span>, <span class="number">0.101</span>]),</span><br><span class="line">])</span><br><span class="line"> </span><br><span class="line">p = pathlib.Path(DATA_PATH)</span><br><span class="line"></span><br><span class="line">subm = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 真正使用过程中，在训练模型后，在这里要加载训练好的模型</span></span><br><span class="line"><span class="comment"># model.load_state_dict(torch.load(&quot;../input/models/HuBMAP_model_best.pth&quot;))</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历测试集中的文件</span></span><br><span class="line"><span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(p.glob(<span class="string">&#x27;test/*.tiff&#x27;</span>)):</span><br><span class="line">    <span class="comment"># 使用rasterio来打开tiff文件，实测速度会很快</span></span><br><span class="line">    <span class="comment"># transform参数是用来进行仿射变换，这里不涉及坐标系变换，可以不用</span></span><br><span class="line">    <span class="comment"># 常用用法可见：</span></span><br><span class="line">    <span class="comment"># https://theonegis.github.io/geos/%E4%BD%BF%E7%94%A8Rasterio%E8%AF%BB%E5%8F%96%E6%A0%85%E6%A0%BC%E6%95%B0%E6%8D%AE/index.html</span></span><br><span class="line">    dataset = rasterio.<span class="built_in">open</span>(filename.as_posix(), transform = identity)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 因为原始图像很大，为防止爆内存，将其分块处理</span></span><br><span class="line">    slices = make_grid(dataset.shape, window=WINDOW, min_overlap=MIN_OVERLAP)</span><br><span class="line">    <span class="comment"># 创建一个存储预测结果的缓存</span></span><br><span class="line">    preds = np.zeros(dataset.shape, dtype=np.uint8)</span><br><span class="line">    <span class="comment"># 对分块图像进行遍历</span></span><br><span class="line">    <span class="keyword">for</span> (x1,x2,y1,y2) <span class="keyword">in</span> slices:</span><br><span class="line">        <span class="comment"># read方法将rasterio的数据集格式转为numpy.ndarray</span></span><br><span class="line">        image = dataset.read([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], window=Window.from_slices((x1,x2),(y1,y2)))</span><br><span class="line">        <span class="comment"># 改变一下维度次序</span></span><br><span class="line">        image = np.moveaxis(image, <span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 与训练集采用同样的tranform变换</span></span><br><span class="line">        image = trfm(image)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="comment"># 将image放入DEVICE中，cpu或gpu</span></span><br><span class="line">            image = image.to(DEVICE)[<span class="literal">None</span>]</span><br><span class="line">            <span class="comment"># 模型对图像进行预测</span></span><br><span class="line">            <span class="comment"># 这个地方需要注意的是model的返回值</span></span><br><span class="line">            <span class="comment"># torchvision模型库中的classification和segmentation、detection的模型返回值不同</span></span><br><span class="line">            <span class="comment"># 比如，用于classification的模型，比如AlexNet，其model(X)返回的就是预测值y的tensor</span></span><br><span class="line">            <span class="comment"># 而segmentation的模型，比如fcn_resnet50，它的返回值是一个有序字典，其中的key有out和aux</span></span><br><span class="line">            <span class="comment"># 所以下面的代码需要使用out这个key来获得预测值tensor</span></span><br><span class="line">            <span class="comment"># 可以参考：</span></span><br><span class="line">            <span class="comment"># https://pytorch.org/docs/stable/torchvision/models.html</span></span><br><span class="line">            <span class="comment"># https://github.com/pytorch/vision/blob/d0063f3d83beac01e85f3027c4de6499a8985469/torchvision/models/segmentation/fcn.py#L9</span></span><br><span class="line">            <span class="comment"># https://colab.research.google.com/github/spmallick/learnopencv/blob/master/PyTorch-Segmentation-torchvision/intro-seg.ipynb#scrollTo=ZsIngeXleQ1H</span></span><br><span class="line">            score = model(image)[<span class="string">&#x27;out&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 这个得分有可能是负的，为了一致性，将其使用sigmoid激活，转为0到1</span></span><br><span class="line">            score_sigmoid = score.sigmoid().cpu().numpy()</span><br><span class="line">            score_sigmoid = cv2.resize(score_sigmoid, (WINDOW, WINDOW))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 以0.5作为阈值，输出mask</span></span><br><span class="line">            preds[x1:x2,y1:y2] = (score_sigmoid &gt; <span class="number">0.5</span>).astype(np.uint8)</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># 将预测值转为RLE编码</span></span><br><span class="line">    subm[i] = &#123;<span class="string">&#x27;id&#x27;</span>:filename.stem, <span class="string">&#x27;predicted&#x27;</span>: mask2rle_numba(preds)&#125;</span><br><span class="line">    <span class="comment"># 删除临时变量</span></span><br><span class="line">    <span class="keyword">del</span> preds</span><br><span class="line">    <span class="comment"># 回收内存，防止内部爆掉，这一步非常重要</span></span><br><span class="line">    gc.collect();</span><br><span class="line"></span><br><span class="line">submission = pd.DataFrame.from_dict(subm, orient=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line">submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h1 id="制作数据集"><a href="#制作数据集" class="headerlink" title="制作数据集"></a>制作数据集</h1><p>因为原始图像太大了，单张甚至达到5G大小，极易爆内存，因此需要将其切分成小图像，才能进行可行的训练。</p>
<h2 id="在线制作数据集"><a href="#在线制作数据集" class="headerlink" title="在线制作数据集"></a>在线制作数据集</h2><p>这一节之所以称为“在线制作”，是因为数据集的加载和切分都是在程序运行时才开始进行，与之对应的，下面一节采用的是事先将原来的数据集切分好，等到用的时候直接读入即可。<br>这一节的在线制作是直接制作了适用于PyTorch的数据集格式，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line">identity = rasterio.Affine(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义数据集的制作可以参考如下链接：</span></span><br><span class="line"><span class="comment"># https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HubDataset</span>(<span class="params">D.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root_dir, transform,</span></span></span><br><span class="line"><span class="function"><span class="params">                 window=<span class="number">256</span>, overlap=<span class="number">32</span>, threshold = <span class="number">100</span></span>):</span></span><br><span class="line">        <span class="comment"># 加载路径使用pathlib，后续推荐使用它来替代os.path</span></span><br><span class="line">        <span class="comment"># 具体使用方法可以参考：</span></span><br><span class="line">        <span class="comment"># https://docs.python.org/zh-cn/3/library/pathlib.html</span></span><br><span class="line">        self.path = pathlib.Path(root_dir)</span><br><span class="line">        self.overlap = overlap</span><br><span class="line">        self.window = window</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.csv = pd.read_csv((self.path / <span class="string">&#x27;train.csv&#x27;</span>).as_posix(),</span><br><span class="line">                               index_col=[<span class="number">0</span>])</span><br><span class="line">        self.threshold = threshold</span><br><span class="line">        self.x, self.y = [], []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 运行下面的分块函数</span></span><br><span class="line">        self.build_slices()</span><br><span class="line">        self.<span class="built_in">len</span> = <span class="built_in">len</span>(self.x)</span><br><span class="line">        self.as_tensor = T.Compose([</span><br><span class="line">            <span class="comment"># ToTensor函数接受PIL Image或numpy.ndarray，将其先由HWC转置为CHW格式，再转为float后每个像素除以255，</span></span><br><span class="line">            <span class="comment"># 从而将数据范围变换到[0, 1]之间</span></span><br><span class="line">            <span class="comment"># https://www.cnblogs.com/ocean1100/p/9494640.html</span></span><br><span class="line">            T.ToTensor(),</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 标准化的操作是减去均值并除以标准差，即将数据变换为均值为0、标准差为1的标准正态分布</span></span><br><span class="line">            <span class="comment"># 之所以标准化，常用的解释是：（1）突出特征；（2）方便反向传播的计算，具体讨论可以参考：</span></span><br><span class="line">            <span class="comment"># http://www.soolco.com/post/62169_1_1.html</span></span><br><span class="line">            T.Normalize([<span class="number">0.625</span>, <span class="number">0.448</span>, <span class="number">0.688</span>],</span><br><span class="line">                        [<span class="number">0.131</span>, <span class="number">0.177</span>, <span class="number">0.101</span>]),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分块</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_slices</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.masks = []</span><br><span class="line">        self.files = []</span><br><span class="line">        self.slices = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.csv.index.values):</span><br><span class="line">            filepath = (self.path /<span class="string">&#x27;train&#x27;</span>/(filename+<span class="string">&#x27;.tiff&#x27;</span>)).as_posix()</span><br><span class="line">            self.files.append(filepath)</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Transform&#x27;</span>, filename)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> rasterio.<span class="built_in">open</span>(filepath, transform = identity) <span class="keyword">as</span> dataset:</span><br><span class="line">                self.masks.append(rle_decode(self.csv.loc[filename, <span class="string">&#x27;encoding&#x27;</span>], dataset.shape))</span><br><span class="line">                slices = make_grid(dataset.shape, window=self.window, min_overlap=self.overlap)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 排除掉一些没有目标对象的分块</span></span><br><span class="line">                <span class="keyword">for</span> slc <span class="keyword">in</span> tqdm(slices):</span><br><span class="line">                    x1,x2,y1,y2 = slc</span><br><span class="line">                    <span class="keyword">if</span> self.masks[-<span class="number">1</span>][x1:x2,y1:y2].<span class="built_in">sum</span>() &gt; self.threshold <span class="keyword">or</span> np.random.randint(<span class="number">100</span>) &gt; <span class="number">120</span>:</span><br><span class="line">                        self.slices.append([i,x1,x2,y1,y2])</span><br><span class="line"></span><br><span class="line">                        image = dataset.read([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">                            window=Window.from_slices((x1,x2),(y1,y2)))</span><br><span class="line"></span><br><span class="line">                         <span class="comment"># if image.std().mean() &lt; 10:</span></span><br><span class="line">                         <span class="comment">#     continue</span></span><br><span class="line"></span><br><span class="line">                         <span class="comment"># print(image.std().mean(), self.masks[-1][x1:x2,y1:y2].sum())</span></span><br><span class="line"></span><br><span class="line">                        image = np.moveaxis(image, <span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">                        self.x.append(image)</span><br><span class="line">                        self.y.append(self.masks[-<span class="number">1</span>][x1:x2,y1:y2])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get data operation</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        image, mask = self.x[index], self.y[index]</span><br><span class="line">        augments = self.transform(image=image, mask=mask)</span><br><span class="line">        <span class="keyword">return</span> self.as_tensor(augments[<span class="string">&#x27;image&#x27;</span>]), augments[<span class="string">&#x27;mask&#x27;</span>][<span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Total number of samples in the dataset</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line">WINDOW=<span class="number">1024</span></span><br><span class="line">MIN_OVERLAP=<span class="number">32</span></span><br><span class="line">NEW_SIZE=<span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># albumentations是一个基于OpenCV的数据增强库，拥有非常简单且强大的可以用于多种任务（分割、检测）的接口，易于定制且添加其他框架非常方便。</span></span><br><span class="line"><span class="comment"># 它可以对数据集进行逐像素的转换，如模糊、下采样、高斯噪声、高斯模糊、动态模糊、RGB转换、随机雾化等；</span></span><br><span class="line"><span class="comment"># 也可以进行空间转换（同时也会对目标标签进行转换），如裁剪、翻转、随机裁剪等</span></span><br><span class="line"><span class="comment"># 数据增强的方式是这样的：</span></span><br><span class="line"><span class="comment"># 比如在一个epoch之内，我是把所有的图片都过一遍，对于每张图片我都是进行一个transform的操作，比如transform内部有0.5的概率进行左右flip，</span></span><br><span class="line"><span class="comment"># 那么这张图片左右flip的概率就是0.5，可能这一个epoch不flip，下一个epoch就会flip.</span></span><br><span class="line"><span class="comment"># 换句话说，现有的数据增强是带有随机性的，比如是否随机镜像翻转，随机crop的时候选择哪块区域，加多强的噪声等，每次增强的结果可能都不一样，</span></span><br><span class="line"><span class="comment"># 这样模型相当于看到了很多份不同的图像。如果没有概率性的操作，即p=1， 做一次增强之后便不再变化，则和不做增强是等价的，即模型在整个训练过程中只能看到一份相同的不断重复的数据。</span></span><br><span class="line"><span class="comment"># 可以详见</span></span><br><span class="line"><span class="comment"># https://discuss.gluon.ai/t/topic/1666</span></span><br><span class="line">trfm = A.Compose([</span><br><span class="line">    A.Resize(NEW_SIZE,NEW_SIZE),</span><br><span class="line">    A.HorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">    A.VerticalFlip(p=<span class="number">0.5</span>),</span><br><span class="line"></span><br><span class="line">    A.OneOf([</span><br><span class="line">        A.RandomContrast(),</span><br><span class="line">        A.RandomGamma(),</span><br><span class="line">        A.RandomBrightness(),</span><br><span class="line">        A.ColorJitter(brightness=<span class="number">0.07</span>, contrast=<span class="number">0.07</span>,</span><br><span class="line">                   saturation=<span class="number">0.1</span>, hue=<span class="number">0.1</span>, always_apply=<span class="literal">False</span>, p=<span class="number">0.3</span>),</span><br><span class="line">        ], p=<span class="number">0.3</span>),</span><br><span class="line"></span><br><span class="line">    A.OneOf([</span><br><span class="line">        A.ElasticTransform(alpha=<span class="number">120</span>, sigma=<span class="number">120</span> * <span class="number">0.05</span>, alpha_affine=<span class="number">120</span> * <span class="number">0.03</span>),</span><br><span class="line">        A.GridDistortion(),</span><br><span class="line">        A.OpticalDistortion(distort_limit=<span class="number">2</span>, shift_limit=<span class="number">0.5</span>),</span><br><span class="line">        ], p=<span class="number">0.0</span>),</span><br><span class="line">    A.ShiftScaleRotate(),</span><br><span class="line">])</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型库里的模型时，有的模型所需要的输入图像的尺寸是固定的，比如必须是64*64等，所以在图像增强后要保证图像的尺寸满足该要求。</span></span><br><span class="line"><span class="comment"># 可以采取以下方法来满足任意图像尺寸的输入：</span></span><br><span class="line"><span class="comment">#（1）传统办法：预处理，也就是边缘补0，或者切割，或者重采样、resize来得到相同大小的输入图片作为input。</span></span><br><span class="line"><span class="comment">#（2）模型方法：使用Kaiming He大佬的SPP-Net可以输入任意大小的图片，原文arxiv地址：https://arxiv.org/abs/1406.4729</span></span><br><span class="line"><span class="comment">#（3）优雅方法：加一层torch.nn.AdaptiveMaxPool2d。</span></span><br><span class="line"><span class="comment"># 具体讨论可以见</span></span><br><span class="line"><span class="comment"># https://www.zhihu.com/question/45873400</span></span><br><span class="line"></span><br><span class="line">ds = HubDataset(DATA_PATH, window=WINDOW, overlap=MIN_OVERLAP, transform=trfm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分验证集和训练集</span></span><br><span class="line">valid_idx, train_idx = [], []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ds)):</span><br><span class="line">    <span class="comment"># 挑出第8张图片的所有切片作为验证集</span></span><br><span class="line">    <span class="keyword">if</span> ds.slices[i][<span class="number">0</span>] == <span class="number">7</span>:</span><br><span class="line">        valid_idx.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        train_idx.append(i)</span><br><span class="line"></span><br><span class="line">train_ds = D.Subset(ds, train_idx)</span><br><span class="line">valid_ds = D.Subset(ds, valid_idx)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define training and validation data loaders</span></span><br><span class="line">loader = D.DataLoader(</span><br><span class="line">    train_ds, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">vloader = D.DataLoader(</span><br><span class="line">    valid_ds, batch_size=BATCH_SIZE, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="离线制作数据集"><a href="#离线制作数据集" class="headerlink" title="离线制作数据集"></a>离线制作数据集</h2><p>如上所述，上述制作数据集的方式是离线进行的，该数据集准备过程参考了如下notebook：<br><a target="_blank" rel="noopener" href="https://www.kaggle.com/iafoss/256x256-images">256x256 images</a><br>具体切分方式与上面在线制作时不同，但表达的意思相同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对迭代器进行tqdm封装，传入total参数来指明预计迭代次数</span></span><br><span class="line"><span class="comment"># https://ptorch.com/news/170.html</span></span><br><span class="line"><span class="comment"># 如果想选择dataframe某一行作为测试，可以参考dataframe各种索引方法</span></span><br><span class="line"><span class="comment"># https://www.jianshu.com/p/32bfb327bf07</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, rles <span class="keyword">in</span> tqdm(df_mask.iterrows(), total=<span class="built_in">len</span>(df_mask)):</span><br><span class="line">    <span class="built_in">print</span>(index)</span><br><span class="line">    img, mask = read_image(index)</span><br><span class="line">    shape = img.shape</span><br><span class="line">    tile_before_compress = compress * tile_size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算填充量，使得可以整除</span></span><br><span class="line">    pad0 = tile_before_compress - shape[<span class="number">0</span>] % tile_before_compress</span><br><span class="line">    pad1 = tile_before_compress - shape[<span class="number">1</span>] % tile_before_compress</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用0填充</span></span><br><span class="line">    <span class="comment"># https://numpy.org/doc/stable/reference/generated/numpy.pad.html</span></span><br><span class="line">    <span class="comment"># 对于img，x和y两个维度都填充，第三维度则不填充，所以第三维度设为(0, 0)</span></span><br><span class="line">    img = np.pad(img, ((pad0 // <span class="number">2</span>, pad0 - pad0 // <span class="number">2</span>), (pad1 // <span class="number">2</span>, pad1 - pad1 // <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>)), constant_values=<span class="number">0</span>)</span><br><span class="line">    mask = np.pad(mask, ((pad0 // <span class="number">2</span>, pad0 - pad0 // <span class="number">2</span>), (pad1 // <span class="number">2</span>, pad1 - pad1 // <span class="number">2</span>)), constant_values=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 压缩图像</span></span><br><span class="line">    img = cv2.resize(img, (img.shape[<span class="number">1</span>]//compress, img.shape[<span class="number">0</span>]//compress), interpolation = cv2.INTER_AREA)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将图像分块成tile大小</span></span><br><span class="line">    img = img.reshape(img.shape[<span class="number">0</span>] // tile_size, tile_size, img.shape[<span class="number">1</span>] // tile_size, tile_size, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将图像的通道调整顺序，横纵个数放在前面，然后让两者相乘，得到分块总个数</span></span><br><span class="line">    img = img.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>).reshape(-<span class="number">1</span>, tile_size, tile_size, <span class="number">3</span>)</span><br><span class="line">    mask = cv2.resize(mask, (mask.shape[<span class="number">1</span>]//compress, mask.shape[<span class="number">0</span>]//compress), interpolation = cv2.INTER_AREA)</span><br><span class="line">    mask = mask.reshape(mask.shape[<span class="number">0</span>] // tile_size, tile_size, mask.shape[<span class="number">1</span>] // tile_size, tile_size)</span><br><span class="line">    mask = mask.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).reshape(-<span class="number">1</span>, tile_size, tile_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用zip函数将img和mask中的元素打包在一块，统一调用</span></span><br><span class="line">    <span class="comment"># https://www.runoob.com/python3/python3-func-zip.html</span></span><br><span class="line">    <span class="keyword">for</span> i, (im, m) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(img, mask)):</span><br><span class="line">        x_tot.append((im / <span class="number">255.0</span>).reshape(-<span class="number">1</span>, <span class="number">3</span>).mean(<span class="number">0</span>))</span><br><span class="line">        x2_tot.append((im / <span class="number">255.0</span>).reshape(-<span class="number">1</span>, <span class="number">3</span>).mean(<span class="number">0</span>))</span><br><span class="line">        cv2.imwrite(OUT_IMG + <span class="string">f&#x27;<span class="subst">&#123;index&#125;</span>_<span class="subst">&#123;i&#125;</span>.png&#x27;</span>, cv2.cvtColor(im, cv2.COLOR_RGB2BGR))</span><br><span class="line">        cv2.imwrite(OUT_MASK + <span class="string">f&#x27;<span class="subst">&#123;index&#125;</span>_<span class="subst">&#123;i&#125;</span>.png&#x27;</span>, m)</span><br><span class="line"></span><br><span class="line">img_avr = np.array(x_tot).mean(<span class="number">0</span>)</span><br><span class="line">img_std = np.sqrt(np.array(x2_tot).mean(<span class="number">0</span>) - img_avr**<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mean: &quot;</span>, img_avr, <span class="string">&quot;, std:&quot;</span>, img_std)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>首先通过上面的get_model()加载模型，然后再定义一系列的必要步骤，包括优化器、损失评价等，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义Soft Dice Loss</span></span><br><span class="line"><span class="comment"># 网友总结了用于图像分割的常用的损失函数的PyTorch实现，见：</span></span><br><span class="line"><span class="comment"># https://github.com/JunMa11/SegLoss</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftDiceLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, smooth=<span class="number">1.</span>, dims=(<span class="params">-<span class="number">2</span>,-<span class="number">1</span></span>)</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SoftDiceLoss, self).__init__()</span><br><span class="line">        self.smooth = smooth</span><br><span class="line">        self.dims = dims</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        tp = (x * y).<span class="built_in">sum</span>(self.dims)</span><br><span class="line">        fp = (x * (<span class="number">1</span> - y)).<span class="built_in">sum</span>(self.dims)</span><br><span class="line">        fn = ((<span class="number">1</span> - x) * y).<span class="built_in">sum</span>(self.dims)</span><br><span class="line">        dc = (<span class="number">2</span> * tp + self.smooth) / (<span class="number">2</span> * tp + fp + fn + self.smooth)</span><br><span class="line">        dc = dc.mean()</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> - dc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数1</span></span><br><span class="line">bce_fn = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数2</span></span><br><span class="line">dice_fn = SoftDiceLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终损失是两种损失函数的加权平均</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_fn</span>(<span class="params">y_pred, y_true</span>):</span></span><br><span class="line">    bce = bce_fn(y_pred, y_true)</span><br><span class="line">    dice = dice_fn(y_pred.sigmoid(), y_true)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.8</span>*bce+ <span class="number">0.2</span>*dice</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在验证集上运行模型</span></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validation</span>(<span class="params">model, loader, loss_fn</span>):</span></span><br><span class="line">    losses = []</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> image, target <span class="keyword">in</span> loader:</span><br><span class="line">        image, target = image.to(DEVICE), target.<span class="built_in">float</span>().to(DEVICE)</span><br><span class="line">        output = model(image)[<span class="string">&#x27;out&#x27;</span>]</span><br><span class="line">        loss = loss_fn(output, target)</span><br><span class="line">        losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(losses).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">### 为了让中间输出结果好看，专门定制了一个显示效果</span></span><br><span class="line">header = <span class="string">r&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Train | Valid</span></span><br><span class="line"><span class="string">Epoch |  Loss |  Loss | Time, m</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#          Epoch         metrics            time</span></span><br><span class="line">raw_line = <span class="string">&#x27;&#123;:6d&#125;&#x27;</span> + <span class="string">&#x27;\u2502&#123;:7.3f&#125;&#x27;</span>*<span class="number">2</span> + <span class="string">&#x27;\u2502&#123;:6.2f&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line">best_loss = <span class="number">10</span></span><br><span class="line">EPOCHES = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始迭代训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, EPOCHES+<span class="number">1</span>):</span><br><span class="line">    losses = []</span><br><span class="line">    <span class="comment"># 计时开始</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这里显式地设置model是train模式，以使dropout和batchnorm等网络层中的参数不固定</span></span><br><span class="line">    <span class="comment"># 它仅仅是一个flag，与之类似的：model.eval()是设定eval模式，即这些网络层中的参数固定，以保证测试结果的可重复性</span></span><br><span class="line">    <span class="comment"># https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch</span></span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始在训练集数据中迭代</span></span><br><span class="line">    <span class="keyword">for</span> image, target <span class="keyword">in</span> loader:</span><br><span class="line">        image, target = image.to(DEVICE), target.<span class="built_in">float</span>().to(DEVICE)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(image)[<span class="string">&#x27;out&#x27;</span>]</span><br><span class="line">        loss = loss_fn(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在验证集上运行模型</span></span><br><span class="line">    vloss = validation(model, vloader, loss_fn)</span><br><span class="line">    <span class="built_in">print</span>(raw_line.<span class="built_in">format</span>(epoch, np.array(losses).mean(), vloss,</span><br><span class="line">                              (time.time()-start_time)/<span class="number">60</span>**<span class="number">1</span>))</span><br><span class="line">    losses = []</span><br><span class="line">    <span class="comment"># 及时地将最佳模型存储下来</span></span><br><span class="line">    <span class="keyword">if</span> vloss &lt; best_loss:</span><br><span class="line">        best_loss = vloss</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&#x27;model_best.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练结束后删除这些存储数据地变量，并回收内存</span></span><br><span class="line"><span class="keyword">del</span> loader, vloader, train_ds, valid_ds, ds</span><br><span class="line">gc.collect();</span><br></pre></td></tr></table></figure></p>
<p>训练完后的模型就开始接下来在上面的测试集上进行推导，并提交结果文件（注意在kaggle上提交时，可以把前面的训练过程去掉，直接提交训练好的模型）。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechat_reward.png" alt="Xin-Bo Qi(亓欣波) WeChat Pay">
        <p>WeChat Pay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/kaggle/" rel="tag"># kaggle</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/12/26/algorithm/" rel="prev" title="数据结构与算法笔记">
      <i class="fa fa-chevron-left"></i> 数据结构与算法笔记
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/03/25/hexo-migration/" rel="next" title="hexo博客在不同电脑间迁移记录">
      hexo博客在不同电脑间迁移记录 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A6%82%E8%A7%88"><span class="nav-number">1.</span> <span class="nav-text">概览</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B5%9B%E4%BA%8B%E6%8F%8F%E8%BF%B0"><span class="nav-number">1.1.</span> <span class="nav-text">赛事描述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E6%A0%87%E5%87%86"><span class="nav-number">1.2.</span> <span class="nav-text">算法评估标准</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="nav-number">2.</span> <span class="nav-text">数据分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A6%82%E8%A7%88"><span class="nav-number">2.1.</span> <span class="nav-text">数据集概览</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%8C%85"><span class="nav-number">2.2.</span> <span class="nav-text">导入必要的包</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E8%B7%AF%E5%BE%84%E5%8F%8A%E8%B6%85%E5%8F%82%E6%95%B0"><span class="nav-number">2.3.</span> <span class="nav-text">配置路径及超参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90"><span class="nav-number">2.4.</span> <span class="nav-text">文件分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B7%A5%E5%85%B7%E5%87%BD%E6%95%B0"><span class="nav-number">2.5.</span> <span class="nav-text">工具函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96"><span class="nav-number">2.6.</span> <span class="nav-text">无网络连接安装依赖</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%AD%A3%E7%A1%AE%E6%8F%90%E4%BA%A4%E4%B8%80%E6%AC%A1%E5%92%8C%E8%B7%91%E4%B8%80%E9%81%8D%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">正确提交一次和跑一遍模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A3%E7%A1%AE%E6%8F%90%E4%BA%A4%E4%B8%80%E6%AC%A1"><span class="nav-number">3.1.</span> <span class="nav-text">正确提交一次</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B7%91%E4%B8%80%E9%81%8D%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.</span> <span class="nav-text">跑一遍模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%B6%E4%BD%9C%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">4.</span> <span class="nav-text">制作数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8%E7%BA%BF%E5%88%B6%E4%BD%9C%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">4.1.</span> <span class="nav-text">在线制作数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A6%BB%E7%BA%BF%E5%88%B6%E4%BD%9C%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">4.2.</span> <span class="nav-text">离线制作数据集</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.</span> <span class="nav-text">训练模型</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xin-Bo Qi(亓欣波)"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Xin-Bo Qi(亓欣波)</p>
  <div class="site-description" itemprop="description">Digitize everything to realize Digitalization!</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">156</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/qixinbo" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:qixinbo@gmail.com" title="E-Mail → mailto:qixinbo@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/qixinbo" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fas fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.tsinghua.edu.cn/" title="https:&#x2F;&#x2F;www.tsinghua.edu.cn" rel="noopener" target="_blank">THU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.imr.cas.cn/" title="http:&#x2F;&#x2F;www.imr.cas.cn" rel="noopener" target="_blank">IMR</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.sdu.edu.cn/" title="http:&#x2F;&#x2F;www.sdu.edu.cn" rel="noopener" target="_blank">SDU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://liam0205.me/" title="http:&#x2F;&#x2F;liam0205.me&#x2F;" rel="noopener" target="_blank">黄晨成</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xin-Bo Qi(亓欣波)</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://qixinbo.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://qixinbo.github.io/2021/02/14/kaggle-hubmap/";
    this.page.identifier = "2021/02/14/kaggle-hubmap/";
    this.page.title = "Kaggle肾小球图像分割比赛全解析";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://qixinbo.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
