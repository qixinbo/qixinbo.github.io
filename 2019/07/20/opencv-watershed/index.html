<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"qixinbo.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="在学习OpenCV的分水岭算法时，找到Xuhui Zhao小朋友的一篇总结文章，把分水岭算法所需要的预处理和背景知识都讲解得非常透彻细致，特向他申请了转载权限，致谢～ 原文链接在这里。  &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;  二值图像距离变换 图像距离变换是二值化图像处理与操">
<meta property="og:type" content="article">
<meta property="og:title" content="OpenCV分水岭Watershed算法的前因后果[转载]">
<meta property="og:url" content="http://qixinbo.github.io/2019/07/20/opencv-watershed/index.html">
<meta property="og:site_name" content="数字旗手">
<meta property="og:description" content="在学习OpenCV的分水岭算法时，找到Xuhui Zhao小朋友的一篇总结文章，把分水岭算法所需要的预处理和背景知识都讲解得非常透彻细致，特向他申请了转载权限，致谢～ 原文链接在这里。  &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;  二值图像距离变换 图像距离变换是二值化图像处理与操">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmgly1g56azq3bb4j30jc08it8u.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006Xmmmggy1g56b5o0velj30f708c745.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006Xmmmggy1g56b684ge0j30bx0be74a.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006Xmmmggy1g56b79f6eyj30cj04i741.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmggy1g56b83pqutj30i208yq3j.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmggy1g56bac479ij30hs0dcjse.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmggy1g56bbuuap3g30hp0cx1l1.gif">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmggy1g56bbg7cn0j3074074t8q.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmggy1g56bbg7e3fj30cf09b3zt.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmgly1g56bi4ohn6j30gj0aoq32.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006Xmmmggy1g56bjk190cj30fs0abjrp.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmggy1g56blvi5q8j30fk0act99.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmgly1g56bnimc4dj30i205gt8m.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006Xmmmggy1g56bp2brdmj30i205gmx3.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmggy1g56brxk8ltj30i609yt8p.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006Xmmmggy1g56btfiun6j30i20gdtd1.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006Xmmmggy1g56bu1k7jaj30i20gdgqd.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmggy1g56bvl2r4bj30hp0amweh.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmggy1g56bweiqxvj30i209ogmk.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006Xmmmggy1g56bxmda6fj307008owen.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmggy1g56byzx4jtj30eb09imx0.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmggy1g56bzysfhnj30ek09i3yc.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmggy1g56c1cvv98j309z0bg0sr.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006Xmmmggy1g56c1cspgoj307709iq2p.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmggy1g56c2yivrzj307709i3ya.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmggy1g56c3yp50ej30el09iglf.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006Xmmmggy1g56c4vxubbj307709igle.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmgly1g56c5vxim1j309x0b93yc.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006Xmmmggy1g56c6iz8v9j307709i741.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006Xmmmgly1g56c7nvj4pj30a30bddfp.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006Xmmmggy1g56c7nre97j307709i75c.jpg">
<meta property="article:published_time" content="2019-07-19T16:00:00.000Z">
<meta property="article:modified_time" content="2021-03-26T07:49:37.595Z">
<meta property="article:author" content="Xin-Bo Qi(亓欣波)">
<meta property="article:tag" content="OpenCV">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ws1.sinaimg.cn/large/006Xmmmgly1g56azq3bb4j30jc08it8u.jpg">

<link rel="canonical" href="http://qixinbo.github.io/2019/07/20/opencv-watershed/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>OpenCV分水岭Watershed算法的前因后果[转载] | 数字旗手</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="数字旗手" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">数字旗手</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">电气化、自动化、数字化、智能化、智慧化</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-scholar">

    <a href="/scholar/" rel="section"><i class="fa fa-chart-bar fa-fw"></i>scholar</a>

  </li>
        <li class="menu-item menu-item-sources">

    <a href="/sources/" rel="section"><i class="fa fa-rss fa-fw"></i>sources</a>

  </li>
        <li class="menu-item menu-item-gallery">

    <a href="/gallery/" rel="section"><i class="fa fa-file-image fa-fw"></i>gallery</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404.html" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://qixinbo.github.io/2019/07/20/opencv-watershed/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Xin-Bo Qi(亓欣波)">
      <meta itemprop="description" content="Digitize everything to realize Digitalization!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数字旗手">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          OpenCV分水岭Watershed算法的前因后果[转载]
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2019-07-20T00:00:00+08:00">2019-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-26 15:49:37" itemprop="dateModified" datetime="2021-03-26T15:49:37+08:00">2021-03-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/algorithm/" itemprop="url" rel="index"><span itemprop="name">algorithm</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2019/07/20/opencv-watershed/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/07/20/opencv-watershed/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>在学习OpenCV的分水岭算法时，找到Xuhui Zhao小朋友的一篇总结文章，把分水岭算法所需要的预处理和背景知识都讲解得非常透彻细致，特向他申请了转载权限，致谢～<br>原文链接在<a target="_blank" rel="noopener" href="https://zhaoxuhui.top/blog/2017/06/23/%E5%9F%BA%E4%BA%8EPython%E7%9A%84OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%8615.html#%E5%9B%9B%E5%88%86%E6%B0%B4%E5%B2%AD%E7%AE%97%E6%B3%95%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2">这里</a>。</p>
<p>===============================================================================</p>
<h1 id="二值图像距离变换"><a href="#二值图像距离变换" class="headerlink" title="二值图像距离变换"></a>二值图像距离变换</h1><p>图像距离变换是二值化图像处理与操作中的常用手段， 其主要思想是通过标识空间点(目标点与背景点)距离，将二值化图像转换为灰度图像。 可用于骨架提取、图像窄化等等。它的结果是得到一张与输入影像类似的灰度图像， 但是灰度值只出现在前景区域，并且离物体边缘越远的像素灰度值越大。</p>
<h2 id="主要过程"><a href="#主要过程" class="headerlink" title="主要过程"></a>主要过程</h2><ol>
<li>将图像中的目标像素点分类，分为内部点、外部点和孤立点。 以中心像素的四邻域为例，如果中心像素为目标像素(值为1)且四邻域都为目标像素(值为1)， 则该点为内部点。如果该中心像素为目标像素，四邻域为背景像素(值为0)，则该中心点为孤立点，如下图所示。<br><img src="https://ws1.sinaimg.cn/large/006Xmmmgly1g56azq3bb4j30jc08it8u.jpg" alt=""><br>除了内部点和孤立点之外的目标区域点为边界点。</li>
<li>统计图像中所有的内部点和非内部点，分别用S1、S2表示。</li>
<li>对于S1中的每个内部点P(x,y)，使用距离计算公式dist()计算其与S2中所有点的最小距离。每一个点对应一个最小距离， 这些最小距离构成集合S3。</li>
<li>计算S3中的最大值Max、最小值Min。</li>
<li>对于S1中的所有内部点，其对应灰度按下式计算：<script type="math/tex; mode=display">
G(x,y)=\frac{\left | S_{3}(x,y) - Min\right |}{\left | Max-Min \right |}\cdot 255</script>S3(x,y)表示(x,y)对应的像素与S2中所有点的最短距离。</li>
<li>对于孤立点灰度值保持不变。</li>
</ol>
<h2 id="距离变换算法"><a href="#距离变换算法" class="headerlink" title="距离变换算法"></a>距离变换算法</h2><p>在上面步骤中，提到了计算距离的函数dist()，这便是不同算法体现之处。按照变换类型可以分为欧式距离变换和非欧式距离变换两种。 非欧式距离变换包括棋盘距离变换、城市街区距离变换、倒角距离变换等。主要算法公式如下：<br>(1)欧氏距离</p>
<script type="math/tex; mode=display">
dist((x_{1},y_{1}),(x_{2},y_{2}))=\sqrt{(x_{1}-x_{2})^{2}+(y_{1}-y_{2})^{2}}</script><p>(2)曼哈顿距离</p>
<script type="math/tex; mode=display">
dist((x_{1},y_{1}),(x_{2},y_{2}))=\left | x_{1}-x_{2} \right |+\left | y_{1}-y_{2} \right |</script><p>(3)切比雪夫距离</p>
<script type="math/tex; mode=display">
dist((x_{1},y_{1}),(x_{2},y_{2}))=max(\left | x_{1}-x_{2} \right |,\left | y_{1}-y_{2} \right |)</script><h2 id="OpenCV实现"><a href="#OpenCV实现" class="headerlink" title="OpenCV实现"></a>OpenCV实现</h2><p>在OpenCV中有方便的cv2.distanceTransform()用于实现距离变换。代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以灰度模式读取图像</span></span><br><span class="line">img = cv2.imread(<span class="string">&quot;E:\\dist.png&quot;</span>, <span class="number">0</span>)</span><br><span class="line"><span class="comment"># 设置阈值进行二值化</span></span><br><span class="line"><span class="comment"># 注意这里二值化的同时对图像进行了反色，因为背景比前景颜色要浅，</span></span><br><span class="line"><span class="comment"># 直接二值化的结果是背景是白色的，前景是黑色的，这显然不是我们想要的结果</span></span><br><span class="line"><span class="comment"># 同时注意这样两个操作相加的这种写法</span></span><br><span class="line">ret, binary = cv2.threshold(img, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_OTSU + cv2.THRESH_BINARY_INV)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用距离变换函数</span></span><br><span class="line"><span class="comment"># 第一个参数是二值化图像</span></span><br><span class="line"><span class="comment"># 第二个参数是类型distanceType</span></span><br><span class="line"><span class="comment"># 第三个参数是maskSize</span></span><br><span class="line"><span class="comment"># 返回的结果是一张灰度图像，但注意这个图像直接采用OpenCV的imshow显示是有问题的</span></span><br><span class="line"><span class="comment"># 所以采用Matplotlib的imshow显示或者对其进行归一化再用OpenCV显示</span></span><br><span class="line">dist = cv2.distanceTransform(binary, cv2.DIST_L2, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将灰度、二值化图像合并到一个窗口中显示</span></span><br><span class="line">result = np.hstack((img, binary))</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&quot;result&quot;</span>, result)</span><br><span class="line">plt.imshow(dist, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><br>效果如下：<br><img src="https://ws3.sinaimg.cn/large/006Xmmmggy1g56b5o0velj30f708c745.jpg" alt=""><br><img src="https://ws3.sinaimg.cn/large/006Xmmmggy1g56b684ge0j30bx0be74a.jpg" alt=""></p>
<p>可以看到，通过距离变换的图像越靠近物体中心的地方越亮。</p>
<h1 id="灰度三维模型"><a href="#灰度三维模型" class="headerlink" title="灰度三维模型"></a>灰度三维模型</h1><p>在介绍分水岭法之前，先介绍图像的另一种表达形式，灰度三维模型。简单来说就是把某个像素的灰度值当作高程， 图像的宽高为x、y轴，这样就可以做出一个三维模型。例如有一幅图像如下所示：<br><img src="https://ws4.sinaimg.cn/large/006Xmmmggy1g56b79f6eyj30cj04i741.jpg" alt=""><br>我们以灰度为高程，可以做出如下图形：<br><img src="https://ws2.sinaimg.cn/large/006Xmmmggy1g56b83pqutj30i208yq3j.jpg" alt=""><br>可以看到，图中蓝色越深的地方表示灰度值越低，越黄的地方表示灰度值越高。该图是采用Matlab绘制的。代码非常简单。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">function [] = Draw3DGray( path )</span><br><span class="line">%将RGB图像转换成对应的灰度图像并以各像素灰度数值画出3D模型</span><br><span class="line">%   例如输入文件路径为：E:\p1.png</span><br><span class="line">    I = imread(path);</span><br><span class="line">    GrayScaleImage = rgb2gray(I);</span><br><span class="line">    mesh(GrayScaleImage);</span><br><span class="line">end</span><br></pre></td></tr></table></figure><br>那么在Python下如何绘制呢，这是我们下面讨论的问题。</p>
<h2 id="绘制图像的灰度三维模型"><a href="#绘制图像的灰度三维模型" class="headerlink" title="绘制图像的灰度三维模型"></a>绘制图像的灰度三维模型</h2><p>代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&quot;E:\\color.png&quot;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">X = np.arange(<span class="number">0</span>, img.shape[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">Y = np.arange(<span class="number">0</span>, img.shape[<span class="number">1</span>], <span class="number">1</span>)</span><br><span class="line">X, Y = np.meshgrid(X, Y)</span><br><span class="line">Z = img[X, Y]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 具体函数方法可用 help(function) 查看</span></span><br><span class="line">ax.plot_surface(X, Y, Z, rstride=<span class="number">1</span>, cstride=<span class="number">1</span>, cmap=<span class="string">&#x27;rainbow&#x27;</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&quot;img&quot;</span>, img)</span><br><span class="line">plt.show()</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><br>在代码中用到了Matplotlib以及绘制三维图像的库。效果如下：<br><img src="https://ws2.sinaimg.cn/large/006Xmmmggy1g56bac479ij30hs0dcjse.jpg" alt=""><br>下面的动图更好地展示了三维灰度模型的效果。这里为了绘制更快，将行列的采样间隔设置为6，以减少绘制的点数。 仔细观察边缘会发现精度有一定损失。<br><img src="https://ws2.sinaimg.cn/large/006Xmmmggy1g56bbuuap3g30hp0cx1l1.gif" alt=""><br>下图是对一块真实地物进行绘制的效果。原图如下：<br><img src="https://ws2.sinaimg.cn/large/006Xmmmggy1g56bbg7cn0j3074074t8q.jpg" alt=""><br>三维灰度地形图如下：<br><img src="https://ws1.sinaimg.cn/large/006Xmmmggy1g56bbg7e3fj30cf09b3zt.jpg" alt=""></p>
<h1 id="图像梯度"><a href="#图像梯度" class="headerlink" title="图像梯度"></a>图像梯度</h1><p>图像梯度和数学上的梯度其实是类似的，可以用一阶导数或二阶偏导数求解。 沿梯度方向导数变化量达到最大值，也就是说，梯度的方向是函数在这点变化最快的方向。 反映的是图像灰度在某点的变化，梯度越大表示变化越明显。 但是图像以矩阵的形式存储的，不能像数学理论中对直线或者曲线求导一样， 对一幅图像的求导相当于对一个平面、曲面求导。对图像的操作， 采用模板对原图进行卷积运算，从而达到想要的效果。 而获取一幅图像的梯度就转化为：模板（Roberts、Prewitt、Sobel、Lapacian算子）对原图像进行卷积。</p>
<h2 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h2><p>(1)Roberts算子<br>在一维连续数集上求导，有如下公式：</p>
<script type="math/tex; mode=display">
{f}'(x)=\frac{f(x+ \Delta x)-f(x)}{\Delta x}</script><p>在二维连续数集上，在x、y方向有偏导数，公式如下：</p>
<script type="math/tex; mode=display">
\frac{\partial f(x,y)}{\partial x}=\frac{f(x+\Delta x,y)-f(x,y)}{\Delta x}</script><script type="math/tex; mode=display">
\frac{\partial f(x,y)}{\partial y}=\frac{f(x,y+\Delta y)-f(x,y)}{\Delta y}</script><p>在某点的梯度为一矢量，如下：</p>
<script type="math/tex; mode=display">
grad(f)=\left ( \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}\right )</script><p>其对应的梯度的大小为：</p>
<script type="math/tex; mode=display">
\left | grad(f) \right |=\sqrt{\left ( \frac{\partial f}{\partial x} \right )^{2}+ \left ( \frac{\partial f}{\partial y} \right )^{2}}</script><p>而在二维离散数集上，令$\Delta x =1$、$\Delta y =1$则可得到对应离散情况下的公式，也可以为2，只是表示一个单位的度量。 因此对于图像而言，其偏导数以及梯度公式如下：</p>
<script type="math/tex; mode=display">
g_{x}=\frac{\partial f(x,y)}{\partial x}=f(x+1,y)-f(x,y)</script><script type="math/tex; mode=display">
g_{y}=\frac{\partial f(x,y)}{\partial y}=f(x,y+1)-f(x,y)</script><script type="math/tex; mode=display">
\left | grad(f) \right |=\sqrt{g_{x}^{2}+ {g_{y}^{2}}}\approx \left | g_{x}^{2} \right |+\left | g_{y}^{2} \right |</script><p>因此，在x方向，由偏导公式可知，其实就是相邻两个像素的值相减。同理，y方向也是如此。因此可以得到如下算子。<br><img src="https://ws2.sinaimg.cn/large/006Xmmmgly1g56bi4ohn6j30gj0aoq32.jpg" alt=""><br>类似地，对于对角线方向梯度，公式和算子如下：</p>
<script type="math/tex; mode=display">
g_{x}=\frac{\partial f(x,y)}{\partial x}=f(x+1,y+1)-f(x,y)</script><script type="math/tex; mode=display">
g_{y}=\frac{\partial f(x,y)}{\partial x}=f(x+1,y)-f(x,y+1)</script><p><img src="https://ws4.sinaimg.cn/large/006Xmmmggy1g56bjk190cj30fs0abjrp.jpg" alt=""><br>上述算子为Robert算子。</p>
<p>(2)Prewitt算子<br>2×2模板在概念上很简单，但是对于计算边缘方向不是很有用。一般模板最小为3×3。 在3×3模板中，定义图像梯度如下：<br><img src="https://ws1.sinaimg.cn/large/006Xmmmggy1g56blvi5q8j30fk0act99.jpg" alt=""></p>
<script type="math/tex; mode=display">
g_{x}=\frac{\partial f}{\partial x}=(z_{7}+z_{8}+z_{9})-(z_{1}+z_{2}+z_{3})</script><script type="math/tex; mode=display">
g_{y}=\frac{\partial f}{\partial y}=(z_{3}+z_{6}+z_{9})-(z_{1}+z_{4}+z_{7})</script><script type="math/tex; mode=display">
g_{x}^{'}==(z_{2}+z_{3}+z_{6})-(z_{4}+z_{7}+z_{8})</script><script type="math/tex; mode=display">
g_{y}^{'}==(z_{6}+z_{8}+z_{9})-(z_{1}+z_{2}+z_{4})</script><p>以上公式对应的算子如下：<br><img src="https://ws1.sinaimg.cn/large/006Xmmmgly1g56bnimc4dj30i205gt8m.jpg" alt=""><br>这些算子称为Prewitt算子。</p>
<p>(3)Sobel算子<br>Sobel算子是在Prewitt算子的基础上改进的，在中心系数上使用一个权值2， 相比较Prewitt算子，Sobel模板能够较好的抑制（平滑）噪声。</p>
<script type="math/tex; mode=display">
g_{x}=\frac{\partial f}{\partial x}=(z_{7}+2z_{8}+z_{9})-(z_{1}+2z_{2}+z_{3})</script><script type="math/tex; mode=display">
g_{y}=\frac{\partial f}{\partial y}=(z_{3}+2z_{6}+z_{9})-(z_{1}+2z_{4}+z_{7})</script><p>对应算子如下：<br><img src="https://ws3.sinaimg.cn/large/006Xmmmggy1g56bp2brdmj30i205gmx3.jpg" alt=""></p>
<p>(4)Lapacian算子<br>上述所有算子都是通过求一阶导数来计算梯度的，通常用于边缘检测。 在图像处理过程中，除了检测线，有时候也需要检测特殊点，这就需要用二阶导数进行检测。 离散二阶导数计算公式如下：</p>
<script type="math/tex; mode=display">
\frac{\partial ^{2}f}{\partial x^{2}}=\frac{ {\partial}' f}{\partial x}
\\={(f(x+1)-f(x))}'
\\={f(x+1)}'-{f(x)}'
\\=(f(x+2)-f(x+1))-(f(x+1)-f(x))
\\=f(x+2)-2f(x+1)+f(x)</script><p>但我们想要的是x位置的偏导，因此x整体减一，得到：</p>
<script type="math/tex; mode=display">
\frac{\partial ^{2}f}{\partial x^{2}}=\frac{ {\partial}' f}{\partial x}
\\={(f(x+1)-f(x))}'
\\={f(x+1)}'-{f(x)}'
\\=(f(x+2)-f(x+1))-(f(x+1)-f(x))
\\=f(x+2)-2f(x+1)+f(x)</script><script type="math/tex; mode=display">
\frac{\partial ^{2}f}{\partial x^{2}}=f(x+1)-2f(x)+f(x-1)</script><p>同理可以得到y的二阶导数。求梯度时使用拉普拉斯模板，即可以得到拉普拉斯算子计算公式：</p>
<script type="math/tex; mode=display">
\bigtriangledown ^{2}f(x,y)=\frac{\partial ^{2}f}{\partial x^{2}}+\frac{\partial ^{2}f}{\partial y^{2}}
\\=[f(x+1,y)-2f(x,y)+f(x-1,y)]+[f(x,y+1)-2f(x,y)+f(x,y-1)]
\\=f(x+1,y)+f(x,y+1)+f(x,y-1)+f(x-1,y)-4f(x,y)</script><p>算子为：<br><img src="https://ws1.sinaimg.cn/large/006Xmmmggy1g56brxk8ltj30i609yt8p.jpg" alt=""><br>模板中心位置的数字是-8而不是-4，是因为要使模板中的这些系数之和为0。 这样不至于改变原图的明暗程度。如果模板的系数大于0，则使用该模板处理完后，所有像素的灰度值都变大了， 直观反映就是图像变亮了。 在用Lapacian算子图像进行卷积运算时，当响应的绝对值超过指定阈值时，那么该点就是被检测出来的孤立点。</p>
<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><p>如下代码计算x方向的Prewitt算子。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&quot;E:\\jack_fruit.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">grad_x = np.matrix(<span class="string">&#x27;-1,-1,-1;&#x27;</span></span><br><span class="line">                   <span class="string">&#x27;0,0,0;&#x27;</span></span><br><span class="line">                   <span class="string">&#x27;1,1,1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">grad_y = np.matrix(<span class="string">&#x27;-1,0,1;&#x27;</span></span><br><span class="line">                   <span class="string">&#x27;-1,0,1;&#x27;</span></span><br><span class="line">                   <span class="string">&#x27;-1,0,1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">dst_x = cv2.filter2D(gray, -<span class="number">1</span>, grad_x)</span><br><span class="line">dst_y = cv2.filter2D(gray, -<span class="number">1</span>, grad_y)</span><br><span class="line"></span><br><span class="line">dst = cv2.add(dst_x, dst_y)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&quot;fruit&quot;</span>, img)</span><br><span class="line">cv2.imshow(<span class="string">&quot;dst&quot;</span>, dst)</span><br><span class="line">cv2.imshow(<span class="string">&quot;dst_x&quot;</span>, dst_x)</span><br><span class="line">cv2.imshow(<span class="string">&quot;dst_y&quot;</span>, dst_y)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>效果如下：<br><img src="https://ws4.sinaimg.cn/large/006Xmmmggy1g56btfiun6j30i20gdtd1.jpg" alt=""><br><img src="https://ws4.sinaimg.cn/large/006Xmmmggy1g56bu1k7jaj30i20gdgqd.jpg" alt=""><br>得到了x、y以及总的梯度图像。</p>
<h1 id="分水岭算法图像分割"><a href="#分水岭算法图像分割" class="headerlink" title="分水岭算法图像分割"></a>分水岭算法图像分割</h1><h2 id="思路与原理"><a href="#思路与原理" class="headerlink" title="思路与原理"></a>思路与原理</h2><p>有了上面对图像灰度三维模型的直观感受，会更好理解分水岭算法的思想。 在分水岭算法中，一幅图像中灰度值高的区域被看作山峰，灰度值低的区域被看作山谷。 然后从山谷的最低点灌水，水会慢慢在不同的地方汇合，而这些汇合的地方就是需要对图像分割的地方。 分水岭算法的核心思想就是建立堤坝阻止不同盆地的水汇合。 在一般分水岭算法中，通常是把一副彩色图像灰度化，然后再求梯度图， 最后在梯度图的基础上进行分水岭算法，求得分段图像的边缘线。如下所示是一个“地形”的剖面示意图。<br><img src="https://ws1.sinaimg.cn/large/006Xmmmggy1g56bvl2r4bj30hp0amweh.jpg" alt=""><br>以绿色虚线为界，左边表示地物1，右边表示地物2。A为地物1在当前范围内的最小值点， E为地物2在当前范围内的最小值点，两个盆地的交汇点为D。在地物1中C为小范围内的极小值点。</p>
<p>首先在两个盆地的最小值点A、E开始向盆地中注水，水会缓慢上升。 在两个盆地的水汇集的时刻，在交接的边缘线上(D点所在位置，也即分水岭线)， 建一个堤坝(图中黑色线段)，来阻止两个盆地的水汇集成一片水域。 这样图像就被分成2个像素集，一个是注水盆地像素集，一个是分水岭线像素集。</p>
<p>但仔细观察就会发现问题，传统的基于图像梯度的分水岭算法由于存在太多极小区域而产生许多小的集水盆地， 带来的结果就是图像过分割。 如图C点所在的极小值区域会形成一个小盆地，从而让地物1被分成两部分， 当C盆地的水和A盆地的水要汇合时，会在B点建立个水坝(图中灰色虚线)， 这显然不是我们想要的结果。 所以必须对分割相似的结果进行合并。 举个例子如一个桌面的图片，由于光照、纹理等因素，桌面会有很多明暗变化，反映在梯度图上就是一个个圈， 此时利用分水岭算法就会出现很多小盆地，从而分割出很多小区域。但这显而易见是不符合常识的。 因为桌面是一个整体，应该属于同一类，而不是因为纹理而分成不同的部分。</p>
<p>因此需要对分水岭算法进行改进。在OpenCV中采用的是基于标记的分水岭算法。 水淹过程从预先定义好的标记图像（像素）开始， 这样可以减少很多极小值点盆地产生的影响。 较好的克服了过度分割的不足。 本质上讲，基于标记点的改进算法是利用先验知识来帮助分割的一种方法。 对比如下图所示。<br><img src="https://ws1.sinaimg.cn/large/006Xmmmggy1g56bweiqxvj30i209ogmk.jpg" alt=""></p>
<h2 id="OpenCV实现-1"><a href="#OpenCV实现-1" class="headerlink" title="OpenCV实现"></a>OpenCV实现</h2><p>在OpenCV中实现分水岭算法可以使用cv2.watershed()函数实现，主要有以下步骤：</p>
<ol>
<li>输入图像，对图像进行二值化</li>
<li>对二值化后的图像进行噪声去除</li>
<li>通过腐蚀、膨胀运算对图像进行前景、背景标注</li>
<li>运用分水岭算法对图像进行分割<br>从调用API的角度而言，在整个过程中并没有对原始影像求梯度，而是直接进行二值化， 进行像素标记。然后将标记图像与原图一起传入函数。 具体求梯度的操作封装在了函数中，用户无需关心。</li>
</ol>
<p>具体实例如下，下面是待分割的影像。影像中有很多彼此连接的硬币， 我们需要将这些硬币彼此分开。<br><img src="https://ws4.sinaimg.cn/large/006Xmmmggy1g56bxmda6fj307008owen.jpg" alt=""><br>(1) 读取图像进行二值化操作<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">&quot;E:\\coins.jpg&quot;</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh = cv2.threshold(gray, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_OTSU + cv2.THRESH_BINARY_INV)</span><br></pre></td></tr></table></figure><br>需要注意的是，由于这里前景比背景颜色深，所以需要在二值化后反色操作一下。 下图是反色前与反色后的效果，我们希望得到的是右边的效果(前景比背景亮)。<br><img src="https://ws2.sinaimg.cn/large/006Xmmmggy1g56byzx4jtj30eb09imx0.jpg" alt=""></p>
<p>(2)对二值化图像进行噪声去除<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>), np.uint8)</span><br><span class="line"><span class="built_in">open</span> = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><br>仔细观察二值化后的图像，会发现有一些噪声点。如果这些噪声点不去除，则在后续步骤中会被标记成前景或背景， 从而影响分割。由前面形态学知识可知，对于白噪声，如黑色背景中的小白点，可以使用开运算(先腐蚀后膨胀)去除，效果很好。 同理，对于硬币中的黑色小洞(白色背景中的小黑点)，可以使用闭运算(先膨胀后腐蚀)。 在这里主要是白噪声，硬币内部并没有空洞，因此只需要进行开运算即可。完成后效果如下。<br><img src="https://ws2.sinaimg.cn/large/006Xmmmggy1g56bzysfhnj30ek09i3yc.jpg" alt=""></p>
<p>(3)图像标记<br>在完成了前期工作后，就可以对图像进行标记了。简单说来，对图像进行标记主要是将图像标记成三个部分： 前景(物体)、背景以及未知区域。 我们现在知道靠近对象中心的区域肯定是前景，而远离对象中心的区域肯定是背景，不能确定的区域即是图像边界。 对于前景区域，可以在第二步得到的图像上进行多次腐蚀运算， 这样就可以得到肯定是前景的区域。同样，对该图像进行多次膨胀运算，可以得到比前景大的范围， 除去这些范围的部分肯定是背景。至于在两者之间的就是未知区域，也就是需要运用分水岭算法， 从而给出分水岭边界的地方。</p>
<p>a.前景标记<br>提取肯定是硬币的区域(前景)，可以使用腐蚀操作。腐蚀操作可以去除边缘像素，剩下就可以肯定是硬币了。 当硬币之间没有接触时，这种操作是有效的。但是由于硬币之间是相互接触的， 我们就有了另外一个更好的选择：距离变换再加上合适的阈值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">distance_transform = cv2.distanceTransform(<span class="built_in">open</span>, <span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">ret, sure_fg = cv2.threshold(distance_transform, <span class="number">0.7</span> * distance_transform.<span class="built_in">max</span>(), <span class="number">255</span>, cv2.THRESH_BINARY)</span><br></pre></td></tr></table></figure><br>效果如下：<br><img src="https://ws1.sinaimg.cn/large/006Xmmmggy1g56c1cvv98j309z0bg0sr.jpg" alt=""><br><img src="https://ws3.sinaimg.cn/large/006Xmmmggy1g56c1cspgoj307709iq2p.jpg" alt=""></p>
<p>图中白色的部分我们可以肯定是硬币，也就是前景。</p>
<p>b.背景标记<br>背景标记相对简单。在开运算结果的基础上，对其进行多次膨胀。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sure_bg = cv2.dilate(<span class="built_in">open</span>, kernel, iterations=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><br>结果如下：<br><img src="https://ws1.sinaimg.cn/large/006Xmmmggy1g56c2yivrzj307709i3ya.jpg" alt=""><br>图中黑色部分肯定是背景。</p>
<p>c.未知区域<br>背景、前景对比图如下：<br><img src="https://ws2.sinaimg.cn/large/006Xmmmggy1g56c3yp50ej30el09iglf.jpg" alt=""><br>所以可以用背景减去前景，就可以得到边界所在的范围，形成一个白色环。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sure_fg = np.uint8(sure_fg)</span><br><span class="line">unknown = cv2.subtract(sure_bg, sure_fg)</span><br></pre></td></tr></table></figure><br>需要注意的是，距离变换后获得的图像数据类型是float32，因此需要转成uint8才能和sure_bg做运算。 效果如下：<br><img src="https://ws4.sinaimg.cn/large/006Xmmmggy1g56c4vxubbj307709igle.jpg" alt=""></p>
<p>(4)创建标签<br>在知道了哪些肯定是前景区域后，就可以给它们创建标签了(一个与原图像大小相同，数据类型为int32的数组)。 对我们已经确定分类的区域（无论是前景还是背景）使用不同的正整数标记，对不确定的区域使用0标记。 我们可以使用函数cv2.connectedComponents()来完成。 它会把将背景标记为0，其它对象使用从1开始的正整数标记。 但我们知道如果背景标记为0，那分水岭算法就会把它当成未知区域了。 因此我们还需要对返回的结果进行一些修改，如统一加1或其它数字。 但这里不能减。因为OpenCV会把边界标记成负数。因此这里都使用正数。 在把背景和前景标记完后，最后是将未知区域标记为0。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ret, markers1 = cv2.connectedComponents(sure_fg)</span><br><span class="line">markers = markers1 + <span class="number">1</span></span><br><span class="line">markers[unknown == <span class="number">255</span>] = <span class="number">0</span></span><br></pre></td></tr></table></figure><br>标记完成后，利用Matplotlib中Jet ColorMap显示效果如下：<br><img src="https://ws2.sinaimg.cn/large/006Xmmmgly1g56c5vxim1j309x0b93yc.jpg" alt=""><br>深蓝色区域为未知区域。肯定是硬币的区域使用不同的颜色标记。其余区域就是用浅蓝色标记的背景了。 这里不能使用OpenCV的cv2.imshow()显示，否则效果如下：<br><img src="https://ws1.sinaimg.cn/large/006Xmmmggy1g56c6iz8v9j307709i741.jpg" alt=""></p>
<p>原因是，由于每个像素的标记值都很小，而且彼此差异不大，所以在OpenCV中显示一片黑，灰度虽然和0有差别，但人眼几乎无法分辨。 所以不是理想的效果。如果要使用OpenCV显示，则需要先对标记影像进行拉伸，拉伸到0-255范围。</p>
<p>(5)实施分水岭算法<br>之前的工作都是为这一步做准备。这一步最核心，也最简单，代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">markers3 = cv2.watershed(img, markers)</span><br><span class="line">img[markers3 == -<span class="number">1</span>] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>]</span><br></pre></td></tr></table></figure><br>分割效果如下：<br><img src="https://ws2.sinaimg.cn/large/006Xmmmgly1g56c7nvj4pj30a30bddfp.jpg" alt=""><br><img src="https://ws3.sinaimg.cn/large/006Xmmmggy1g56c7nre97j307709i75c.jpg" alt=""></p>
<p>可以看到有些硬币边缘分割很好，有些不够好。</p>
<h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开影像</span></span><br><span class="line">img = cv2.imread(<span class="string">&quot;E:\\coins.jpg&quot;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 阈值+反色操作</span></span><br><span class="line"><span class="comment"># 注意将两个操作放在一起的用法</span></span><br><span class="line">ret, thresh = cv2.threshold(gray, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_OTSU + cv2.THRESH_BINARY_INV)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行开运算操作，去除噪声</span></span><br><span class="line">kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>), np.uint8)</span><br><span class="line"><span class="built_in">open</span> = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 膨胀操作获取背景</span></span><br><span class="line">sure_bg = cv2.dilate(<span class="built_in">open</span>, kernel, iterations=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 距离变换+阈值获取前景</span></span><br><span class="line"><span class="comment"># 距离变换第一个参数是输入图像</span></span><br><span class="line"><span class="comment"># 第二个参数是距离类型</span></span><br><span class="line"><span class="comment"># 第三个参数是范围大小</span></span><br><span class="line">distance_transform = cv2.distanceTransform(<span class="built_in">open</span>, cv2.DIST_L2, <span class="number">5</span>)</span><br><span class="line"><span class="comment"># 注意获取某幅图像最大值max()的用法</span></span><br><span class="line">ret, sure_fg = cv2.threshold(distance_transform, <span class="number">0.7</span> * distance_transform.<span class="built_in">max</span>(), <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 背景、前景相减，得到未知区域</span></span><br><span class="line">sure_fg = np.uint8(sure_fg)</span><br><span class="line">unknown = cv2.subtract(sure_bg, sure_fg)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标记图像</span></span><br><span class="line">ret, markers1 = cv2.connectedComponents(sure_fg)</span><br><span class="line">markers = markers1 + <span class="number">1</span></span><br><span class="line"><span class="comment"># 注意这种简便用法</span></span><br><span class="line"><span class="comment"># markers和unknown是规模相等的两个矩阵</span></span><br><span class="line"><span class="comment"># 如果unknown某个元素为255，则在markers对应位置上的元素赋为0</span></span><br><span class="line">markers[unknown == <span class="number">255</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用分水岭算法</span></span><br><span class="line">markers3 = cv2.watershed(img, markers)</span><br><span class="line"><span class="comment"># 注意OpenCV读取的图像顺序是BGR</span></span><br><span class="line"><span class="comment"># OpenCV中将分水岭边界标记为-1</span></span><br><span class="line">img[markers3 == -<span class="number">1</span>] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示结果</span></span><br><span class="line">plt.imshow(markers3, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;result&quot;</span>, img)</span><br><span class="line">plt.show()</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechat_reward.png" alt="Xin-Bo Qi(亓欣波) WeChat Pay">
        <p>WeChat Pay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/OpenCV/" rel="tag"># OpenCV</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/05/08/aliyun/" rel="prev" title="阿里云服务器：购买、连接和部署">
      <i class="fa fa-chevron-left"></i> 阿里云服务器：购买、连接和部署
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/07/20/cmd-proxy/" rel="next" title="命令行终端设置代理上网（pac文件）">
      命令行终端设置代理上网（pac文件） <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C%E5%80%BC%E5%9B%BE%E5%83%8F%E8%B7%9D%E7%A6%BB%E5%8F%98%E6%8D%A2"><span class="nav-number">1.</span> <span class="nav-text">二值图像距离变换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E8%BF%87%E7%A8%8B"><span class="nav-number">1.1.</span> <span class="nav-text">主要过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B7%9D%E7%A6%BB%E5%8F%98%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="nav-number">1.2.</span> <span class="nav-text">距离变换算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.3.</span> <span class="nav-text">OpenCV实现</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%81%B0%E5%BA%A6%E4%B8%89%E7%BB%B4%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">灰度三维模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%98%E5%88%B6%E5%9B%BE%E5%83%8F%E7%9A%84%E7%81%B0%E5%BA%A6%E4%B8%89%E7%BB%B4%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.1.</span> <span class="nav-text">绘制图像的灰度三维模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E6%A2%AF%E5%BA%A6"><span class="nav-number">3.</span> <span class="nav-text">图像梯度</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B"><span class="nav-number">3.1.</span> <span class="nav-text">推导过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B"><span class="nav-number">3.2.</span> <span class="nav-text">代码示例</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E6%B0%B4%E5%B2%AD%E7%AE%97%E6%B3%95%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2"><span class="nav-number">4.</span> <span class="nav-text">分水岭算法图像分割</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%8E%9F%E7%90%86"><span class="nav-number">4.1.</span> <span class="nav-text">思路与原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV%E5%AE%9E%E7%8E%B0-1"><span class="nav-number">4.2.</span> <span class="nav-text">OpenCV实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="nav-number">4.3.</span> <span class="nav-text">完整代码</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xin-Bo Qi(亓欣波)"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Xin-Bo Qi(亓欣波)</p>
  <div class="site-description" itemprop="description">Digitize everything to realize Digitalization!</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">131</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">45</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/qixinbo" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:qixinbo@gmail.com" title="E-Mail → mailto:qixinbo@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/qixinbo" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;qixinbo" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fas fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.tsinghua.edu.cn/" title="https:&#x2F;&#x2F;www.tsinghua.edu.cn" rel="noopener" target="_blank">THU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.imr.cas.cn/" title="http:&#x2F;&#x2F;www.imr.cas.cn" rel="noopener" target="_blank">IMR</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.sdu.edu.cn/" title="http:&#x2F;&#x2F;www.sdu.edu.cn" rel="noopener" target="_blank">SDU</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://liam0205.me/" title="http:&#x2F;&#x2F;liam0205.me&#x2F;" rel="noopener" target="_blank">黄晨成</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xin-Bo Qi(亓欣波)</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://qixinbo.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://qixinbo.github.io/2019/07/20/opencv-watershed/";
    this.page.identifier = "2019/07/20/opencv-watershed/";
    this.page.title = "OpenCV分水岭Watershed算法的前因后果[转载]";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://qixinbo.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
