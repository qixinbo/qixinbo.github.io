<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>亓欣波</title>
  
  <subtitle>Hi, I am Xin-Bo Qi (亓欣波)</subtitle>
  <link href="http://qixinbo.github.io/atom.xml" rel="self"/>
  
  <link href="http://qixinbo.github.io/"/>
  <updated>2021-03-26T03:27:27.823Z</updated>
  <id>http://qixinbo.github.io/</id>
  
  <author>
    <name>Xin-Bo Qi(亓欣波)</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ImagePy解析： 25 -- 智能画笔</title>
    <link href="http://qixinbo.github.io/2021/03/26/ImagePy_25/"/>
    <id>http://qixinbo.github.io/2021/03/26/ImagePy_25/</id>
    <published>2021-03-25T16:00:00.000Z</published>
    <updated>2021-03-26T03:27:27.823Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本文介绍ImagePy中的智能画笔工具，它能够很方便地对图像进行像素级标注，尤其是在复杂图像上进行多种类别的标注时，用好这个智能画笔，能使效率飞升。<br>先来一连串的功能介绍镇楼：<br>（1）鼠标左键<br>左键：具有联想功能的局部标注<br>Ctrl+左键单击：吸取颜色<br>Ctrl+左键：普通画笔<br>Shift+左键：落笔选定保护色，在矩形框内闭合且非保护色区域被填充<br>Alt+左键：落笔选定保护色，在矩形框内对该色进行描边<br>Ctrl+Alt+左键：落笔选定保护色，对任意的非保护色的区域进行标注</p><p>（2）鼠标右键<br>右键：全局填充<br>Shift+右键：落笔所在的保护色的内部闭合区域被填充<br>Ctrl+右键：落笔所在的保护色的外边缘被描边<br>Alt+右键：落笔所在的保护色的内边缘被描边<br>Ctrl+Alt+右键：落笔选定保护色，外部非保护色区域被填充</p><p>（3）鼠标中键/滚轮<br>中键/滚轮：缩放，按住则拖动画布<br>Shift+滚轮：调节联想功能的粘性系数<br>Ctrl+滚轮：调节画笔的宽度<br>Ctrl+Alt+滚轮：调节矩形框大小</p><p>那么主角就是下面这个工具了：<br><img src="https://user-images.githubusercontent.com/6218739/111566949-1e3e8980-87d9-11eb-94d0-04e023349d42.png" alt="aipen"><br>对应源码在<a href="https://github.com/Image-Py/imagepy/blob/master/imagepy/tools/Draw/aibrush_tol.py">这里</a>。</p><h1 id="控制参数"><a href="#控制参数" class="headerlink" title="控制参数"></a>控制参数</h1><p>智能画笔工具有如此强大的功能，自然有相应的参数可以供调节：<br><img src="https://user-images.githubusercontent.com/6218739/111739860-b5314180-88be-11eb-89d0-dfc741c7de40.png" alt="para-view"><br>（1）win：矩形框窗口尺寸，控制局部标注区域的大小<br>（2）color：矩形框窗口颜色<br>（3）stickiness：粘性系数<br>（4）radius：画笔宽度<br>（5）tolerance：填充的容忍度<br>（6）connect：邻域</p><h1 id="功能解析"><a href="#功能解析" class="headerlink" title="功能解析"></a>功能解析</h1><h2 id="鼠标左键"><a href="#鼠标左键" class="headerlink" title="鼠标左键"></a>鼠标左键</h2><h3 id="吸取颜色"><a href="#吸取颜色" class="headerlink" title="吸取颜色"></a>吸取颜色</h3><p>Ctrl+左键单击来吸取颜色的代码如下：<br>（代码逻辑就是左键按下时记录下鼠标位置，鼠标弹起时判断是否是左键+Ctrl，同时鼠标未移动，符合条件后就将当前图像中的颜色数值传递给颜色管理器中的前景色）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    self.oldp = self.pickp = (y, x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    <span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> (y,x)==self.pickp <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">        x = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(x,<span class="number">0</span>), ips.img.shape[<span class="number">1</span>])))</span><br><span class="line">        y = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(y,<span class="number">0</span>), ips.img.shape[<span class="number">0</span>])))</span><br><span class="line">        self.app.manager(<span class="string">&#x27;color&#x27;</span>).add(<span class="string">&#x27;front&#x27;</span>, ips.img[y, x])</span><br></pre></td></tr></table></figure><h3 id="获取局部区域"><a href="#获取局部区域" class="headerlink" title="获取局部区域"></a>获取局部区域</h3><p>鼠标左键相关的动作是与局部标注相关联的，因此在介绍鼠标左键功能实现时非常重要的一点就是先介绍这个局部区域是怎样获得的。<br>奥秘就在如下代码中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    <span class="comment"># 获取当前鼠标位置</span></span><br><span class="line">    x = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(x,<span class="number">0</span>), img.shape[<span class="number">1</span>])))</span><br><span class="line">    y = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(y,<span class="number">0</span>), img.shape[<span class="number">0</span>])))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 获取当前位置与上一个位置之间的连续坐标，注意这里的加号是作用在tuple上，即连接两个元组，而不是数值相加</span></span><br><span class="line">    rs, cs = line(*[<span class="built_in">int</span>(<span class="built_in">round</span>(i)) <span class="keyword">for</span> i <span class="keyword">in</span> self.oldp + (y, x)])</span><br><span class="line">    <span class="comment"># 确保这些坐标都在图像内部</span></span><br><span class="line">    np.clip(rs, <span class="number">0</span>, img.shape[<span class="number">0</span>]-<span class="number">1</span>, out=rs)</span><br><span class="line">    np.clip(cs, <span class="number">0</span>, img.shape[<span class="number">1</span>]-<span class="number">1</span>, out=cs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">        start = time()</span><br><span class="line">        w = self.para[<span class="string">&#x27;win&#x27;</span>]</span><br><span class="line">        <span class="comment"># 以上述坐标为中心，获取其上下左右间距为w的矩形窗口，同时还保证这个窗口也在图像内部</span></span><br><span class="line">     <span class="comment"># 这样一来，如果在图像中抠出该窗口，那么窗口中心就是w</span></span><br><span class="line">        sr = (<span class="built_in">max</span>(<span class="number">0</span>,r-w), <span class="built_in">min</span>(img.shape[<span class="number">0</span>], r+w))</span><br><span class="line">        sc = (<span class="built_in">max</span>(<span class="number">0</span>,c-w), <span class="built_in">min</span>(img.shape[<span class="number">1</span>], c+w))</span><br><span class="line">        <span class="comment"># 如果上述坐标本身数值就小于窗口大小，那么窗口中心就得是实际的这个坐标</span></span><br><span class="line">        r, c = <span class="built_in">min</span>(r, w), <span class="built_in">min</span>(c, w)</span><br><span class="line">        <span class="comment"># 从原图中抠出该窗口</span></span><br><span class="line">        backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">           <span class="comment"># 从背景图中同步抠出该窗口</span></span><br><span class="line">            backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br></pre></td></tr></table></figure><h3 id="局部区域和画笔展示"><a href="#局部区域和画笔展示" class="headerlink" title="局部区域和画笔展示"></a>局部区域和画笔展示</h3><p>在执行鼠标左键操作时，会涉及局部区域和画笔在界面上的展示。<br>局部区域是用矩形框显示，画笔是用一个小的圆形显示，以及会有一个文本显示矩形框尺寸和粘度大小。源码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">     <span class="keyword">if</span> self.status == <span class="literal">None</span> <span class="keyword">and</span> ips.mark != <span class="literal">None</span>:</span><br><span class="line">         ips.mark = <span class="literal">None</span></span><br><span class="line">         ips.update()</span><br><span class="line">     <span class="keyword">if</span> <span class="keyword">not</span> self.status <span class="keyword">in</span> [<span class="string">&#x27;local_pen&#x27;</span>,<span class="string">&#x27;local_brush&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;local_sketch&#x27;</span>,<span class="string">&#x27;local_in&#x27;</span>,<span class="string">&#x27;local_out&#x27;</span>,<span class="string">&#x27;move&#x27;</span>]:  <span class="keyword">return</span></span><br><span class="line">     img, color = ips.img, self.app.manager(<span class="string">&#x27;color&#x27;</span>).get(<span class="string">&#x27;front&#x27;</span>)</span><br><span class="line">     x = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(x,<span class="number">0</span>), img.shape[<span class="number">1</span>])))</span><br><span class="line">     y = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(y,<span class="number">0</span>), img.shape[<span class="number">0</span>])))</span><br><span class="line"></span><br><span class="line">   <span class="comment"># 绘制的形状传给ips的mark属性，在ips.update时就会将其绘制出来</span></span><br><span class="line">     ips.mark = self.make_mark(x, y)</span><br><span class="line">     self.oldp = (y, x)</span><br><span class="line">     ips.update()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 具体绘制的函数</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">make_mark</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">     wins = self.para[<span class="string">&#x27;win&#x27;</span>]</span><br><span class="line">     rect = &#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;rectangle&#x27;</span>, <span class="string">&#x27;body&#x27;</span>:(x-wins, y-wins, wins*<span class="number">2</span>, wins*<span class="number">2</span>), <span class="string">&#x27;color&#x27;</span>:self.para[<span class="string">&#x27;color&#x27;</span>]&#125;</span><br><span class="line">     <span class="comment"># 只需将矩形框、文本、圆形的属性用非常简单的语句描述出来即可</span></span><br><span class="line">     mark = &#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;layer&#x27;</span>, <span class="string">&#x27;body&#x27;</span>:[rect]&#125;</span><br><span class="line">     r = <span class="number">2</span> <span class="keyword">if</span> self.status==<span class="string">&#x27;local_brush&#x27;</span> <span class="keyword">else</span> self.para[<span class="string">&#x27;r&#x27;</span>]/<span class="number">2</span></span><br><span class="line">     mark[<span class="string">&#x27;body&#x27;</span>].append(&#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;circle&#x27;</span>, <span class="string">&#x27;body&#x27;</span>:(x, y, r), <span class="string">&#x27;color&#x27;</span>:self.para[<span class="string">&#x27;color&#x27;</span>]&#125;)</span><br><span class="line">     mark[<span class="string">&#x27;body&#x27;</span>].append(&#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;body&#x27;</span>:(x-wins, y-wins, </span><br><span class="line">         <span class="string">&#x27;S:%s W:%s&#x27;</span>%(self.para[<span class="string">&#x27;ms&#x27;</span>], self.para[<span class="string">&#x27;win&#x27;</span>])), <span class="string">&#x27;pt&#x27;</span>:<span class="literal">False</span>, <span class="string">&#x27;color&#x27;</span>:self.para[<span class="string">&#x27;color&#x27;</span>]&#125;)</span><br><span class="line">     <span class="keyword">return</span> mark2shp(mark)</span><br></pre></td></tr></table></figure><h3 id="普通画笔功能"><a href="#普通画笔功能" class="headerlink" title="普通画笔功能"></a>普通画笔功能</h3><p>Ctrl键和鼠标左键实现普通画笔功能：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">1</span> <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;local_pen&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status == <span class="string">&#x27;local_pen&#x27;</span>:</span><br><span class="line">                local_pen(imgclip, r, c, self.para[<span class="string">&#x27;r&#x27;</span>], color)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_pen</span>(<span class="params">img, r, c, R, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 以r和c为中心，R/2为半径进行画圆，获取该圆内的坐标</span></span><br><span class="line">    rs, cs = circle(r, c, R/<span class="number">2</span>+<span class="number">1e-6</span>, shape=img.shape)</span><br><span class="line">    img[rs, cs] = color</span><br></pre></td></tr></table></figure><h3 id="有联想功能的画笔"><a href="#有联想功能的画笔" class="headerlink" title="有联想功能的画笔"></a>有联想功能的画笔</h3><p>左键点击后拖动就会对区域进行有联想功能的填充，使用的算法是Felzenszwalb算法，原理是使用像素之间的颜色距离来衡量两者的相似性，具体原理可以参照<a href="https://blog.csdn.net/ttransposition/article/details/38024557">该博客</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">1</span>:</span><br><span class="line">            self.status = <span class="string">&#x27;local_brush&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status == <span class="string">&#x27;local_brush&#x27;</span>:</span><br><span class="line">                <span class="keyword">if</span> (imgclip[r,c] - color).<span class="built_in">sum</span>()==<span class="number">0</span>: <span class="keyword">continue</span></span><br><span class="line">                local_brush(imgclip, backclip, r, c, color, <span class="number">0</span>, self.para[<span class="string">&#x27;ms&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_brush</span>(<span class="params">img, back, r, c, color, sigma, msize</span>):</span></span><br><span class="line">    <span class="comment"># 使用felzenszwalb算法对该局部区域进行分割</span></span><br><span class="line">    lab = felzenszwalb(back, <span class="number">1</span>, sigma, msize)</span><br><span class="line">    <span class="comment"># 对分割后的区域进行泛洪填充，将区域分为True和False，True的地方即标注颜色</span></span><br><span class="line">    msk = flood(lab, (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    img[msk] = color</span><br></pre></td></tr></table></figure><h3 id="落笔选定保护色，在矩形框内闭合且非保护色区域被填充"><a href="#落笔选定保护色，在矩形框内闭合且非保护色区域被填充" class="headerlink" title="落笔选定保护色，在矩形框内闭合且非保护色区域被填充"></a>落笔选定保护色，在矩形框内闭合且非保护色区域被填充</h3><p>Shift+左键用来实现上述功能。<br>这里要注意有三个关键点：保护色、矩形框内闭合区域、非保护色区域。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="comment"># 设定保护色</span></span><br><span class="line">        self.pickcolor = ips.img[y, x]</span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">1</span> <span class="keyword">and</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;local_in&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        img, color = ips.img, self.app.manager(<span class="string">&#x27;color&#x27;</span>).get(<span class="string">&#x27;front&#x27;</span>)</span><br><span class="line">        color = (np.mean(color), color)[img.ndim==<span class="number">3</span>]</span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status == <span class="string">&#x27;local_in&#x27;</span>:</span><br><span class="line">                local_in_fill(imgclip, r, c, self.para[<span class="string">&#x27;r&#x27;</span>], self.pickcolor, color)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_in_fill</span>(<span class="params">img, r, c, R, color, bcolor</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 判断当前颜色是否是保护色，返回True和False矩阵</span></span><br><span class="line">    msk = (img == color).<span class="built_in">min</span>(axis=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 将上面判断保护色后的结果进行“填充孔洞”，如果不是保护色区域的孔洞，则不会填充</span></span><br><span class="line">    filled = binary_fill_holes(msk)</span><br><span class="line">    <span class="comment"># 将填充孔洞后的结果与原掩膜进行“异或”操作，两者相异的地方结果为1</span></span><br><span class="line">   <span class="comment"># 这样就把孔洞内非保护色的区域给提取了出来，</span></span><br><span class="line">   <span class="comment"># 因此，即使非保护色，如果不属于保护色内的孔洞，也不会被提取出来</span></span><br><span class="line">    filled ^= msk</span><br><span class="line">    <span class="comment"># 获得当前画笔描绘的区域</span></span><br><span class="line">    rs, cs = circle(r, c, R/<span class="number">2</span>+<span class="number">1e-6</span>, shape=img.shape)</span><br><span class="line">    <span class="comment"># 将原掩膜全部置为0</span></span><br><span class="line">    msk[:] = <span class="number">0</span></span><br><span class="line">   <span class="comment"># 将当前画笔描绘的区域置为1</span></span><br><span class="line">    msk[rs, cs] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 将孔洞内非保护色区域与现在的掩膜进行“与”操作，两者都为1，结果才为1</span></span><br><span class="line">    msk &amp;= filled</span><br><span class="line">    <span class="comment"># 将最终的掩膜处的图像置为当前的前景色</span></span><br><span class="line">    img[msk] = bcolor</span><br></pre></td></tr></table></figure><h3 id="落笔选定保护色，在矩形框内对该色进行描边"><a href="#落笔选定保护色，在矩形框内对该色进行描边" class="headerlink" title="落笔选定保护色，在矩形框内对该色进行描边"></a>落笔选定保护色，在矩形框内对该色进行描边</h3><p>Alt+左键用来实现上述功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="comment"># 设定保护色</span></span><br><span class="line">        self.pickcolor = ips.img[y, x]</span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">1</span> <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;local_sketch&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        img, color = ips.img, self.app.manager(<span class="string">&#x27;color&#x27;</span>).get(<span class="string">&#x27;front&#x27;</span>)</span><br><span class="line">        color = (np.mean(color), color)[img.ndim==<span class="number">3</span>]</span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status == <span class="string">&#x27;local_sketch&#x27;</span>:</span><br><span class="line">                local_sketch(imgclip, r, c, self.para[<span class="string">&#x27;r&#x27;</span>], self.pickcolor, color)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_sketch</span>(<span class="params">img, r, c, R, color, bcolor</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 判断当前颜色是否是保护色，返回True和False矩阵</span></span><br><span class="line">    msk = (img == color).<span class="built_in">min</span>(axis=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 对该掩膜进行膨胀操作</span></span><br><span class="line">    dilation = binary_dilation(msk, np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">    <span class="comment"># 对膨胀后的掩膜与原掩膜进行“异或”操作，这样就提取出了保护色的边界</span></span><br><span class="line">    dilation ^= msk</span><br><span class="line">    rs, cs = circle(r, c, R/<span class="number">2</span>+<span class="number">1e-6</span>, shape=img.shape)</span><br><span class="line">    msk[:] = <span class="number">0</span></span><br><span class="line">    msk[rs, cs] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 取出既是边界，同时又是画笔所描绘的地方</span></span><br><span class="line">    msk &amp;= dilation</span><br><span class="line">    <span class="comment"># 将这个地方赋以前景色</span></span><br><span class="line">    img[msk] = bcolor</span><br></pre></td></tr></table></figure><h3 id="落笔选定保护色，对任意的非保护色的区域进行标注"><a href="#落笔选定保护色，对任意的非保护色的区域进行标注" class="headerlink" title="落笔选定保护色，对任意的非保护色的区域进行标注"></a>落笔选定保护色，对任意的非保护色的区域进行标注</h3><p>Ctrl+Alt+左键实现如上功能：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="comment"># 设定保护色</span></span><br><span class="line">        self.pickcolor = ips.img[y, x]</span><br><span class="line">        <span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;local_out&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        img, color = ips.img, self.app.manager(<span class="string">&#x27;color&#x27;</span>).get(<span class="string">&#x27;front&#x27;</span>)</span><br><span class="line">        color = (np.mean(color), color)[img.ndim==<span class="number">3</span>]</span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status==<span class="string">&#x27;local_out&#x27;</span>:</span><br><span class="line">                local_out_fill(imgclip, r, c, self.para[<span class="string">&#x27;r&#x27;</span>], self.pickcolor, color)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_out_fill</span>(<span class="params">img, r, c, R, color, bcolor</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 判断当前颜色是否不是保护色（注意这里选择“非保护色”），返回True和False矩阵</span></span><br><span class="line">    msk = (img != color).<span class="built_in">max</span>(axis=<span class="number">2</span>)</span><br><span class="line">    rs, cs = circle(r, c, R/<span class="number">2</span>+<span class="number">1e-6</span>, shape=img.shape)</span><br><span class="line">    buf = np.zeros_like(msk)</span><br><span class="line">    buf[rs, cs] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 挑选出既是非保护色，然后又是鼠标描绘的地方</span></span><br><span class="line">    msk &amp;= buf</span><br><span class="line">    img[msk] = bcolor</span><br></pre></td></tr></table></figure><h2 id="鼠标右键"><a href="#鼠标右键" class="headerlink" title="鼠标右键"></a>鼠标右键</h2><p>鼠标右键的操作都是与全局标注相关的。</p><h3 id="全局填充"><a href="#全局填充" class="headerlink" title="全局填充"></a>全局填充</h3><p>右键单击就实现了全局填充的功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span>:</span><br><span class="line">            <span class="keyword">if</span> (ips.img[y, x] - color).<span class="built_in">sum</span>()==<span class="number">0</span>: <span class="keyword">return</span></span><br><span class="line">            conn = &#123;<span class="string">&#x27;4-connect&#x27;</span>:<span class="number">1</span>, <span class="string">&#x27;8-connect&#x27;</span>:<span class="number">2</span>&#125;</span><br><span class="line">            conn = conn[self.para[<span class="string">&#x27;con&#x27;</span>]]</span><br><span class="line">            tor = self.para[<span class="string">&#x27;tor&#x27;</span>]</span><br><span class="line">            fill_normal(ips.img, y, x, color, conn, tor)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fill_normal</span>(<span class="params">img, r, c, color, con, tor</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    msk = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="comment"># 将多通道的图像拆分成每一个通道来泛洪填充</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        <span class="comment"># 以鼠标点击的像素为中心，以tolerance为容差，以及设定邻域范围，然后在单一通道上进行填充</span></span><br><span class="line">      <span class="comment"># 虽然是每一通道分别处理，但是所有通道都是与msk进行“与”操作</span></span><br><span class="line">      <span class="comment"># 所以msk最终是满足所有通道的填充结果</span></span><br><span class="line">        msk &amp;= flood(img[:,:,i], (r, c), connectivity=con, tolerance=tor)</span><br><span class="line">    img[msk] = color</span><br></pre></td></tr></table></figure><h3 id="落笔所在保护色的内部闭合区域被填充"><a href="#落笔所在保护色的内部闭合区域被填充" class="headerlink" title="落笔所在保护色的内部闭合区域被填充"></a>落笔所在保护色的内部闭合区域被填充</h3><p>Shift+右键完成上述功能：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span> <span class="keyword">and</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;global_in_fill&#x27;</span></span><br><span class="line">            global_in_fill(ips.img, y, x, color)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">global_in_fill</span>(<span class="params">img, r, c, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    msk = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="comment"># 以鼠标所在的颜色为种子点，进行泛洪填充</span></span><br><span class="line">   <span class="comment"># 但与上面的填充不同的是，这里不设定tolerance，即严格地与该保护色相等地地方才填充</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        msk &amp;= flood(img[:,:,i], (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 填充的地方如果有孔洞，那么就填充起来</span></span><br><span class="line">    filled = binary_fill_holes(msk)</span><br><span class="line">    <span class="comment"># 填充孔洞后的图像与原先泛洪后的图像进行“异或”操作，就得到了孔洞区域</span></span><br><span class="line">    filled ^= msk</span><br><span class="line">    <span class="comment"># 将孔洞区域赋值为前景色</span></span><br><span class="line">    img[filled] = color</span><br></pre></td></tr></table></figure><h3 id="落笔所在的保护色的外边缘被描边"><a href="#落笔所在的保护色的外边缘被描边" class="headerlink" title="落笔所在的保护色的外边缘被描边"></a>落笔所在的保护色的外边缘被描边</h3><p>Ctrl+右键完成上述功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span> <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;global_out_line&#x27;</span></span><br><span class="line">            global_out_line(ips.img, y, x, color)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">global_out_line</span>(<span class="params">img, r, c, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    msk = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="comment"># 同样的严格按照鼠标所在的颜色进行泛洪填充</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        msk &amp;= flood(img[:,:,i], (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 对内部孔洞进行填充</span></span><br><span class="line">    msk = binary_fill_holes(msk)</span><br><span class="line">    <span class="comment"># 膨胀一下</span></span><br><span class="line">    dilation = binary_dilation(msk, np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">    <span class="comment"># 膨胀的图像与未膨胀的图像进行异或，得到外边缘</span></span><br><span class="line">    dilation ^= msk</span><br><span class="line">    img[dilation] = color</span><br></pre></td></tr></table></figure><h3 id="落笔所在保护色的内边缘被描边"><a href="#落笔所在保护色的内边缘被描边" class="headerlink" title="落笔所在保护色的内边缘被描边"></a>落笔所在保护色的内边缘被描边</h3><p>Alt+右键完成上述功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span> <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;global_in_line&#x27;</span></span><br><span class="line">            global_in_line(ips.img, y, x, color)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">global_in_line</span>(<span class="params">img, r, c, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    msk = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="comment"># 同样的严格按照鼠标所在的颜色进行泛洪填充</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        msk &amp;= flood(img[:,:,i], (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 对内部孔洞进行填充</span></span><br><span class="line">    inarea = binary_fill_holes(msk)</span><br><span class="line">    <span class="comment"># 填充孔洞后的图像与未填充孔洞的图像进行异或，得到孔洞区域</span></span><br><span class="line">    inarea ^= msk</span><br><span class="line">    <span class="comment"># 对孔洞区域腐蚀一下，然后与原孔洞进行异或，从而得到这个孔洞的外边缘，也就是保护色填充区域的内边缘。</span></span><br><span class="line">    inarea ^= binary_erosion(inarea, np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">    img[inarea] = color</span><br></pre></td></tr></table></figure><h3 id="落笔选定保护色，外部非保护色区域被填充"><a href="#落笔选定保护色，外部非保护色区域被填充" class="headerlink" title="落笔选定保护色，外部非保护色区域被填充"></a>落笔选定保护色，外部非保护色区域被填充</h3><p>Ctrl+Alt+右键完成该功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span> <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;global_out_fill&#x27;</span></span><br><span class="line">            global_out_fill(ips.img, y, x, color)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">global_out_fill</span>(<span class="params">img, r, c, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 同样的严格按照鼠标所在的颜色进行泛洪填充，注意如果与保护色不连续的地方，也是不会被填充的，因为水流不过去</span></span><br><span class="line">    ori = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        ori &amp;= flood(img[:,:,i], (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 对内部孔洞进行填充</span></span><br><span class="line">    filled = binary_fill_holes(ori)</span><br><span class="line">    <span class="comment"># 膨胀一下</span></span><br><span class="line">    dilation = binary_dilation(ori)</span><br><span class="line">    <span class="comment"># 获得泛洪填充区域的外边缘</span></span><br><span class="line">    dilation ^= filled</span><br><span class="line">    <span class="comment"># 获得这些外边缘像素的坐标序列</span></span><br><span class="line">    rs, cs = np.where(dilation)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(rs)==<span class="number">0</span>: <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 挑选图像中与鼠标所在的保护色相等的地方，返回1和0的掩膜矩阵</span></span><br><span class="line">    msk = ((img == img[r,c]).<span class="built_in">min</span>(axis=<span class="number">2</span>)).astype(np.uint8)</span><br><span class="line">    <span class="comment"># 对该掩膜进行泛洪填充，种子点就是外边缘像素中的一个（注意这里只是用了这个外边缘像素的位置，填充时参考的数值是掩膜中的0）</span></span><br><span class="line">   <span class="comment"># 这里用的是flood_fill，原理与flood相同，只是flood返回的是掩膜，而flood_fill则是对原矩阵进行直接数值填充</span></span><br><span class="line">   <span class="comment"># 这里填充的新值设为2</span></span><br><span class="line">   <span class="comment"># 这里还有一个隐藏功能，就是保护色的内部孔洞区域仍然是0，所以这些内部孔洞在后面也不会被填充为前景色。</span></span><br><span class="line">    flood_fill(msk, (rs[<span class="number">0</span>], cs[<span class="number">0</span>]), <span class="number">2</span>, connectivity=<span class="number">2</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 将值为2的地方设为前景色</span></span><br><span class="line">    img[msk==<span class="number">2</span>] = color</span><br></pre></td></tr></table></figure><h2 id="鼠标中键"><a href="#鼠标中键" class="headerlink" title="鼠标中键"></a>鼠标中键</h2><p>鼠标中键的功能非常容易理解，比如滚动滚轮进行缩放、按住滚轮来拖动画布等都是常规的画布操作。<br>而与Shift、Ctrl和Alt等的组合用法，其实就是对上面参数（win、stickiness和radius）的调节。<br>鼠标中键相关操作的源码对应实现分别为：</p><h3 id="拖动画布"><a href="#拖动画布" class="headerlink" title="拖动画布"></a>拖动画布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    <span class="keyword">if</span> btn==<span class="number">2</span>: </span><br><span class="line">        self.oldp = key[<span class="string">&#x27;canvas&#x27;</span>].to_panel_coor(x,y)</span><br><span class="line">        self.status = <span class="string">&#x27;move&#x27;</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    x = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(x,<span class="number">0</span>), img.shape[<span class="number">1</span>])))</span><br><span class="line">    y = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(y,<span class="number">0</span>), img.shape[<span class="number">0</span>])))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> self.status == <span class="string">&#x27;move&#x27;</span>:</span><br><span class="line">        x,y = key[<span class="string">&#x27;canvas&#x27;</span>].to_panel_coor(x,y)</span><br><span class="line">        key[<span class="string">&#x27;canvas&#x27;</span>].move(x-self.oldp[<span class="number">0</span>], y-self.oldp[<span class="number">1</span>])</span><br><span class="line">        self.oldp = x, y</span><br><span class="line">        ips.update()</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure><h3 id="通过滚轮调节参数"><a href="#通过滚轮调节参数" class="headerlink" title="通过滚轮调节参数"></a>通过滚轮调节参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, ips, x, y, d, **key</span>):</span></span><br><span class="line">    <span class="keyword">if</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> d&gt;<span class="number">0</span>: self.para[<span class="string">&#x27;ms&#x27;</span>] = <span class="built_in">min</span>(<span class="number">50</span>, self.para[<span class="string">&#x27;ms&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> d&lt;<span class="number">0</span>: self.para[<span class="string">&#x27;ms&#x27;</span>] = <span class="built_in">max</span>(<span class="number">10</span>, self.para[<span class="string">&#x27;ms&#x27;</span>]-<span class="number">1</span>)</span><br><span class="line">        ips.mark = self.make_mark(x, y)</span><br><span class="line">    <span class="keyword">elif</span> key[<span class="string">&#x27;ctrl&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> d&gt;<span class="number">0</span>: self.para[<span class="string">&#x27;win&#x27;</span>] = <span class="built_in">min</span>(<span class="number">64</span>, self.para[<span class="string">&#x27;win&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> d&lt;<span class="number">0</span>: self.para[<span class="string">&#x27;win&#x27;</span>] = <span class="built_in">max</span>(<span class="number">28</span>, self.para[<span class="string">&#x27;win&#x27;</span>]-<span class="number">1</span>)</span><br><span class="line">        ips.mark = self.make_mark(x, y)</span><br><span class="line">    <span class="keyword">elif</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> d&gt;<span class="number">0</span>: self.para[<span class="string">&#x27;r&#x27;</span>] = <span class="built_in">min</span>(<span class="number">30</span>, self.para[<span class="string">&#x27;r&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> d&lt;<span class="number">0</span>: self.para[<span class="string">&#x27;r&#x27;</span>] = <span class="built_in">max</span>(<span class="number">2</span>, self.para[<span class="string">&#x27;r&#x27;</span>]-<span class="number">1</span>)</span><br><span class="line">        ips.mark = self.make_mark(x, y)</span><br></pre></td></tr></table></figure><h3 id="缩放画布"><a href="#缩放画布" class="headerlink" title="缩放画布"></a>缩放画布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> self.status == <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> d&gt;<span class="number">0</span>:key[<span class="string">&#x27;canvas&#x27;</span>].zoomout(x, y, <span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> d&lt;<span class="number">0</span>:key[<span class="string">&#x27;canvas&#x27;</span>].zoomin(x, y, <span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">ips.update()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">简介
本文介绍ImagePy中的智能画笔工具，它能够很方便地对图像进行像素级标注，尤其是在复杂图像上进行多种类别的标注时，用好这个智能画笔，能使效率飞升。
先来一连串的功能介绍镇楼：
（1）鼠标左键
左键：具有联想功能的局部标注
Ctrl+左键单击：吸取颜色
Ctrl+左键：普通画笔
Shift+左键：落笔选定保护色，在矩形框内闭合且非保护色区域被填充
Alt+左键：落笔选定保护色，在矩形框内对该色进行描边
Ctrl+Alt+左键：落笔选定保护色，对任意的非保护色的区域进行标注

（2）鼠标右键
右键：全局填充
Shift+右键：落笔所在的保护色的内部闭合区域被填充
Ctrl+右键：落笔所在的</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>hexo博客在不同电脑间迁移记录</title>
    <link href="http://qixinbo.github.io/2021/03/25/hexo-migration/"/>
    <id>http://qixinbo.github.io/2021/03/25/hexo-migration/</id>
    <published>2021-03-24T16:00:00.000Z</published>
    <updated>2021-03-26T03:28:18.145Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>该博客是基于hexo搭建的，部署在github pages里，用netlify加速。之前一直用自己的笔记本写博客，现在需要换用另一台电脑，因此需要在新电脑上将环境重新搭建一遍，顺便对hexo及其next主题进行升级。</p><h1 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h1><p>下载地址见<a href="https://nodejs.org/en/download/">这里</a>。<br>然后正常安装。<br>安装完成后，输入node -v和npm -v，如果出现版本号，那么就安装成功了。</p><h1 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h1><p>下载地址见<a href="https://git-scm.com/download/win">这里</a>。<br>然后正常安装，只不过最后一步添加路径时选择Use Git from the Windows Command Prompt，这样我们就可以直接在命令提示符里打开git了。<br>安装完成后在命令提示符中输入git –version验证是否安装成功。</p><h1 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h1><p>新建一个文件夹，如Blog，然后安装hexo：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i hexo-cli -g</span><br></pre></td></tr></table></figure><p>安装完成后输入hexo -v验证是否安装成功。<br>还要安装用于hexo的git部署插件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><h1 id="初始化博客"><a href="#初始化博客" class="headerlink" title="初始化博客"></a>初始化博客</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><h1 id="安装next主题"><a href="#安装next主题" class="headerlink" title="安装next主题"></a>安装next主题</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/theme-<span class="built_in">next</span>/hexo-theme-<span class="built_in">next</span> themes/<span class="built_in">next</span></span><br></pre></td></tr></table></figure><h1 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h1><p>离开该目录，然后将备份在github上的博客仓库下载下来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/qixinbo/blogBackup.git</span><br></pre></td></tr></table></figure><p>复制该blogBackup文件下的以下文件及文件夹到Blog文件夹下，并覆盖原始文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_config.yml文件</span><br><span class="line">theme/<span class="built_in">next</span>下的_config.yml文件</span><br><span class="line">source文件夹</span><br><span class="line">.git文件夹</span><br><span class="line">将<span class="built_in">next</span>/source/images下的wechat_reward复制到相应位置</span><br></pre></td></tr></table></figure><p>注意，由于next主题时有大版本更新，原有的配置可能不适用于新版本，此时直接覆盖可能会出错，解决方法只有对照两个配置文件，然后手工更改配置。</p><h1 id="重新备份"><a href="#重新备份" class="headerlink" title="重新备份"></a>重新备份</h1><p>在Blog文件夹下重新git备份（因为.git文件夹已经自带了配置信息，这里无需再次配置）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">&quot;migration&quot;</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure><h1 id="重新部署"><a href="#重新部署" class="headerlink" title="重新部署"></a>重新部署</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d -g</span><br></pre></td></tr></table></figure><p>如果出现实际效果与本地不符，可以尝试清理缓存：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure><h1 id="其他可能问题"><a href="#其他可能问题" class="headerlink" title="其他可能问题"></a>其他可能问题</h1><h2 id="添加rss"><a href="#添加rss" class="headerlink" title="添加rss"></a>添加rss</h2><p>首先安装必要插件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-feed --save</span><br></pre></td></tr></table></figure><p>然后在next主题配置文件中添加：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#订阅RSS</span></span><br><span class="line">feed:</span><br><span class="line">  <span class="built_in">type</span>: atom</span><br><span class="line">  path: atom.xml</span><br><span class="line">  limit: false</span><br></pre></td></tr></table></figure><p>并且增加RSS字段：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">follow_me:</span><br><span class="line">  RSS: /atom.xml || fa fa-rss</span><br></pre></td></tr></table></figure><h2 id="首页自动生成摘要"><a href="#首页自动生成摘要" class="headerlink" title="首页自动生成摘要"></a>首页自动生成摘要</h2><p>首先安装必要插件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-auto-excerpt</span><br></pre></td></tr></table></figure><p>然后在next的主题配置文件中添加：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">auto_excerpt:</span><br><span class="line">  enable: true</span><br><span class="line">  length: <span class="number">150</span></span><br></pre></td></tr></table></figure><h2 id="修改dns服务器"><a href="#修改dns服务器" class="headerlink" title="修改dns服务器"></a>修改dns服务器</h2><p>将hexo博客部署在netlify上，可以充分利用netlify的cdn加速。这里需要将dns解析服务器由原来的dnspod改为netlify。<br>首先需要在netlify上对域名开启netlify的dns服务，这一步在网页上可以很方便的操作。<br>然后在godaddy（这是域名服务商）上设置nameservers：<br>原来是dnspod家的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">F1G1NS1.DNSPOD.NET</span><br><span class="line">F1G1NS2.DNSPOD.NET</span><br></pre></td></tr></table></figure><p>现在改为netlify家的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dns1.p04.nsone.net</span><br><span class="line">dns2.p04.nsone.net</span><br><span class="line">dns3.p04.nsone.net</span><br><span class="line">dns4.p04.nsone.net</span><br></pre></td></tr></table></figure><p>改完后无论是境内还是境外，速度飞起~~</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://zhuanlan.zhihu.com/p/35668237">超详细Hexo+Github博客搭建小白教程</a><br><a href="https://zhuanlan.zhihu.com/p/26625249">GitHub+Hexo 搭建个人网站详细教程</a><br><a href="https://hasaik.com/posts/19c94341.html">为Hexo添加RSS订阅</a><br><a href="https://suyin-blog.club/2020/2M3YWE7/">给 Hexo 中的 Next 主题添加 RSS 功能</a><br><a href="https://ninesix.cc/post/hexo-yilia-auto-excerpt.html">hexo博文摘要生成方案</a></p>]]></content>
    
    
    <summary type="html">简介
该博客是基于hexo搭建的，部署在github pages里，用netlify加速。之前一直用自己的笔记本写博客，现在需要换用另一台电脑，因此需要在新电脑上将环境重新搭建一遍，顺便对hexo及其next主题进行升级。

安装Node.js
下载地址见这里。
然后正常安装。
安装完成后，输入node -v和npm -v，如果出现版本号，那么就安装成功了。

安装git
下载地址见这里。
然后正常安装，只不过最后一步添加路径时选择Use Git from the Windows Command Prompt，这样我们就可以直接在命令提示符里打开git了。
安装完成后在命令提示符中输入git </summary>
    
    
    
    <category term="programming" scheme="http://qixinbo.github.io/categories/programming/"/>
    
    
    <category term="blog" scheme="http://qixinbo.github.io/tags/blog/"/>
    
  </entry>
  
  <entry>
    <title>Cellpose后处理加速算法解析</title>
    <link href="http://qixinbo.github.io/2021/03/03/cellpose-3/"/>
    <id>http://qixinbo.github.io/2021/03/03/cellpose-3/</id>
    <published>2021-03-02T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.500Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本文的目的是介绍霄龙新开发的用于cellpose后处理加速的算法。<br>前面已写了两篇文章介绍了cellpose，它是一个非常强大的用于胞状物体分割的算法，具体见：<br><a href="https://qixinbo.info/2020/10/24/cellpose-1/">胞状物体通用分割算法Cellpose解析：使用篇</a><br><a href="https://qixinbo.info/2020/10/24/cellpose-2/">胞状物体通用分割算法Cellpose解析：开发篇</a><br>总体而言，cellpose由两部分组成：第一部分是Unet网络，建立了原图与其流场图flow之间的关系；第二部分是将上一步流场图复原为掩膜mask，即转换为最终的分割结果。<br>第一部分主要是神经网络的训练和推理，可以跑在CPU或GPU上（当然GPU会更快）；第二部分只能由CPU计算。两者的计算用时见cellpose作者的实测结果：<br><img src="https://user-images.githubusercontent.com/6218739/109473155-eb448800-7aad-11eb-8690-27873f9018f9.png" alt="timing"><br>DNN代表第一部分的神经网络推理部分，实际使用时可以只用1个网络1net，也可用4个网络4net，然后取平均；Postprocessing代表第二部分的后处理部分，即通过流场复原掩膜部分。<br>可以看出，对于1024乘1024的图像，如果在GPU上只运算1个网络，即1net，第一部分仅用时0.31s，而第二部分却用了6.1s，是第一部分的20倍时长；即使选择CPU，然后运算4个网络4net，第一部分也只用了9.1s，第二部分基本不变，仍为6.1s。<br>所以，对于cellpose的整体运算，第二部分的由流场复原掩膜的计算成为了速度瓶颈。<br>然后，毫无意外地，“优化狂魔”霄龙对第二部分下手了，由此有了这个cellpose2msk算法:)。<br>上链接！！——<a href="https://github.com/Image-Py/cellpose2msk">链接</a></p><h1 id="测试用例"><a href="#测试用例" class="headerlink" title="测试用例"></a>测试用例</h1><p>为了研究一下该算法到底干了啥，构建一个15乘15像素大小的示例图像如下：<br><img src="https://user-images.githubusercontent.com/6218739/109582208-b2052a00-7b38-11eb-8c85-66dd5f5e23ee.png" alt="raw"><br>（不能直接下载使用，因为这里是为了显示方便，不再是原来的分辨率）<br>该图的像素矩阵为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> <span class="number">255</span> <span class="number">255</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br><span class="line">[  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><p>图中有两个白色区域，算法最终目的是找到这两个区域的边界。</p><h1 id="生成流场图"><a href="#生成流场图" class="headerlink" title="生成流场图"></a>生成流场图</h1><p>如前所述，第一部分的流场仍然是由cellpose计算所得，这是因为cellpose预训练模型的泛化能力很强：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> cellpose</span><br><span class="line"><span class="keyword">from</span> cellpose <span class="keyword">import</span> models, utils</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&quot;1.png&quot;</span>, <span class="number">0</span>)</span><br><span class="line">use_GPU = models.use_gpu()</span><br><span class="line">model = models.Cellpose(gpu=use_GPU, model_type=<span class="string">&#x27;cyto&#x27;</span>)</span><br><span class="line">channels = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">_, flow, style, diam = model.<span class="built_in">eval</span>(</span><br><span class="line">    img, diameter=<span class="number">30</span>, rescale=<span class="literal">None</span>, channels=channels)</span><br></pre></td></tr></table></figure><p>这里仍然是调用了cellpose的models模块的eval方法。<br>注意，该eval方法其实是对神经网络计算的一个封装，并不是最原始的纯粹的神经网络计算部分，它默认是将上面的两部分计算都执行的，因此，这里如果单纯的这样调用eval方法，速度仍然会很慢。（最纯粹的神经网络计算是由_run_nets方法执行的，但是它不是一个友好的API，直接调用它的话需要做很多预处理，比如判断通道数、2D或3D，很麻烦。）</p><p>好在CellposeModel这个类的eval方法提供了compute_masks这个参数开关，将它置为False的话，就只计算flow，而不计算mask。具体来说，就简单地在<a href="https://github.com/MouseLand/cellpose/blob/master/cellpose/models.py#L357">这一行</a>改写就行。</p><p>这一部分我们只需要flow流场，同时该变量flow是一个复合变量，包含了将流场转为彩色图的值、原始向量场、判断是物体的概率等，这里只需要它的原始向量场，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>它的形状是2乘15乘15，2表示向量场有X和Y两个分量，其中第一个分量是Y方向，第二个分量是X方向上。<br>后面在使用向量场时，会将它的维度调换一下顺序，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow[<span class="number">1</span>].transpose(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>即变为15乘15乘2的矩阵。</p><h1 id="后处理加速算法解析"><a href="#后处理加速算法解析" class="headerlink" title="后处理加速算法解析"></a>后处理加速算法解析</h1><p>下面就是该加速算法的核心：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">water, core, msk = flow2msk(flow[<span class="number">1</span>].transpose(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>), <span class="literal">None</span>, <span class="number">0.1</span>, <span class="number">5</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>即调用flow2msk函数，其全貌为（注意，以下代码只适用于二维图像，此时可以去源码里看看，应该目前的代码是二维和三维通用了）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flow2msk</span>(<span class="params">flow, prob, grad=<span class="number">1.0</span>, area=<span class="number">150</span>, volume=<span class="number">500</span></span>):</span></span><br><span class="line">    l = np.linalg.norm(flow, axis=-<span class="number">1</span>)</span><br><span class="line">    flow /= l[:,:,<span class="literal">None</span>]; flow[l&lt;grad] = <span class="number">0</span></span><br><span class="line">    flow[[<span class="number">0</span>,-<span class="number">1</span>],:,<span class="number">0</span>], flow[:,[<span class="number">0</span>,-<span class="number">1</span>],<span class="number">1</span>] = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    sn = np.sign(flow); sn *= <span class="number">0.5</span>; flow += sn;</span><br><span class="line">    dn = flow.astype(np.int32).reshape(-<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">    strides = np.cumprod(flow.shape[::-<span class="number">1</span>])//<span class="number">2</span></span><br><span class="line">    dn = (dn * strides[-<span class="number">2</span>::-<span class="number">1</span>]).<span class="built_in">sum</span>(axis=-<span class="number">1</span>)</span><br><span class="line">    rst = np.arange(flow.size//<span class="number">2</span>) + dn</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): rst = rst[rst]</span><br><span class="line">    hist = np.bincount(rst, minlength=<span class="built_in">len</span>(rst))</span><br><span class="line">    hist.shape = rst.shape = flow.shape[:<span class="number">2</span>]</span><br><span class="line">    lab, n = ndimg.label(hist, np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">    areas = np.bincount(lab.ravel())</span><br><span class="line">    weight = ndimg.<span class="built_in">sum</span>(hist, lab, np.arange(n+<span class="number">1</span>))</span><br><span class="line">    msk = (areas&lt;area) &amp; (weight&gt;volume)</span><br><span class="line">    lut = np.zeros(n+<span class="number">1</span>, np.int32)</span><br><span class="line">    lut[msk] = np.arange(<span class="number">1</span>, msk.<span class="built_in">sum</span>()+<span class="number">1</span>)</span><br><span class="line">    mask = lut[lab].ravel()[rst]</span><br><span class="line">    <span class="keyword">return</span> hist, lut[lab], mask</span><br></pre></td></tr></table></figure><p>下面将对该函数逐行理解，其中涉及的算法示意图均来自霄龙分享的笔记，比心~~<br>（注意，为了方便讲清脉络，下文叙述与源码略有不同，增加了一些冗余代码）</p><h2 id="计算流动方向和距离"><a href="#计算流动方向和距离" class="headerlink" title="计算流动方向和距离"></a>计算流动方向和距离</h2><p>首先对原像素点进行位置编号：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mark = np.arange(flow.size//<span class="number">2</span>) <span class="comment"># 这里除以2是因为flow最后通道有两个向量场</span></span><br></pre></td></tr></table></figure><p>示意图如下：<br><img src="https://user-images.githubusercontent.com/6218739/109622997-af75f500-7b77-11eb-80cf-2cef16b86aaf.png" alt="number"></p><p>然后计算流场这个向量场的绝对强度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l = np.linalg.norm(flow, axis=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>其中axis指定为-1，即按最后一个axis来计算2范数，因为flow已经将x和y分量放在了最后一维，所以，上面就是计算了如下公式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqrt(x^<span class="number">2</span>+y^<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>附赠一个理解numpy的axis的博文：<br><a href="https://www.sharpsightlabs.com/blog/numpy-axes-explained/">NUMPY AXES EXPLAINED</a></p><p>对原flow场的x和y分量根据上面的绝对强度进行归一化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow /= l[:,:,<span class="literal">None</span>]</span><br></pre></td></tr></table></figure><p>加上None是为了增加一个维度，与原flow进行统一。<br>经过上面的归一化操作，现在的flow的x和y分量满足：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x^<span class="number">2</span>+y^<span class="number">2</span>=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>接下来根据绝对强度对flow场进行梯度阈值分割，这里的梯度阈值是人为设定的，即grad参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow[l&lt;grad] = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>即判断某像素点上的绝对流场强度，如果强度小于梯度阈值，则直接将该处的流场置为0，即不流动。<br>（关于该阈值的设置在最后会说明）</p><p>进一步地，该算法是模拟水流过程，为了防止水流到区域外面，将第一行和最后一行的Y分量设为0，将第一列和最后一列的X分量设为0：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow[[<span class="number">0</span>,-<span class="number">1</span>],:,<span class="number">0</span>], flow[:,[<span class="number">0</span>,-<span class="number">1</span>],<span class="number">1</span>] = <span class="number">0</span>, <span class="number">0</span></span><br></pre></td></tr></table></figure><p>然后挑选出强度特别大的流场所在位置，判断这里的像素点流动的方向：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dn = flow.<span class="built_in">round</span>().astype(np.int32).reshape(-<span class="number">1</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>不过追求速度极致的龙哥嫌numpy的round速度太慢，用以下运算来替代了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sn = np.sign(flow); sn *= <span class="number">0.5</span>; flow += sn;</span><br><span class="line">dn = flow.astype(np.int32).reshape(-<span class="number">1</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>这个dn的数值有很大讲究，首先其数值为-1、0、1三种，然后它的形状为(225, 2)，225是像素点总个数，2表示两个向量场方向，第一个方向是Y方向，即跨行移动，第二个方向是X方向，即跨列移动，所以如果dn中的某元素为[1, -1]，表示向下移动一行，然后再向左移动一列；0则表示不移动。<br>根据dn可以知道某处的水是怎样流动的，示意图如下：<br><img src="https://user-images.githubusercontent.com/6218739/109625035-cd445980-7b79-11eb-9c0a-30ecb52ba007.png" alt="flow"></p><p>具体实操上，还需要更复杂的操作，才能实现示意图中的运算。因为后续会将二维数组压平成一维（这里都压平成一维，是为了适用于任意维度），所以跨行和跨列的移动在内存中的距离是不一样的，比如5乘4的二维矩阵，跨列移动，内存差1，跨行移动则内存差4。<br>所以首先要根据原始矩阵大小获得其某个像素的邻居像素的标识：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strides = np.cumprod(flow.shape[::-<span class="number">1</span>])//<span class="number">2</span></span><br></pre></td></tr></table></figure><p>这里获得邻居标识的过程在find_max和watershed等算法中都用到过，只是这里需要注意因为flow最后一维是2，所以最后除了一个2。<br>（该方法可以用于任意维度的矩阵的邻居标识的获取）<br>这里因为是15乘15的矩阵，所以strides的数值为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[  <span class="number">1</span>  <span class="number">15</span> <span class="number">225</span>]</span><br></pre></td></tr></table></figure><p>再将dn的移动方向转换为实际的移动距离：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dn = (dn * strides[-<span class="number">2</span>::-<span class="number">1</span>]).<span class="built_in">sum</span>(axis=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>对以上代码要分为两步看，首先：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(dn * strides[-<span class="number">2</span>::-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>这是将两个方向上的原来的移动距离转换为真正的移动距离，比如[1, -1]变为了[15, -1]，然后：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(dn * strides[-<span class="number">2</span>::-<span class="number">1</span>]).<span class="built_in">sum</span>(axis=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>这是对两个方向上的移动进行组合，比如上一步的[15, -1]，就变成了14，所以原来的表示向下移动一行，然后再向左移动一列的[1, -1]数组就变成了一维的移动14距离即可。</p><p>有了表征真实移动距离的dn，就可以准确知道水下一刻到达的位置：<br><img src="https://user-images.githubusercontent.com/6218739/109745683-34601d80-7c0f-11eb-96bd-cd273f4cefed.png" alt="dn"><br>该例中，dn的数值为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">dn =  [  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>  <span class="number">15</span></span><br><span class="line">  <span class="number">15</span>  <span class="number">15</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>  <span class="number">15</span>  <span class="number">15</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>  <span class="number">16</span>  <span class="number">15</span>  <span class="number">15</span>  <span class="number">15</span>  <span class="number">15</span></span><br><span class="line">   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>  <span class="number">15</span>  <span class="number">15</span>  <span class="number">15</span>  <span class="number">15</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">1</span>  <span class="number">16</span>  <span class="number">15</span>  <span class="number">15</span>  <span class="number">14</span>  <span class="number">14</span>   <span class="number">0</span>   <span class="number">0</span></span><br><span class="line">  <span class="number">16</span>  <span class="number">16</span>  <span class="number">15</span>  <span class="number">15</span>  <span class="number">15</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">1</span>   <span class="number">1</span>  <span class="number">16</span>  <span class="number">14</span>  -<span class="number">1</span>  -<span class="number">1</span>   <span class="number">0</span>   <span class="number">0</span>  <span class="number">16</span>  <span class="number">16</span>  <span class="number">15</span></span><br><span class="line">  <span class="number">14</span>  <span class="number">15</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">1</span> -<span class="number">14</span> -<span class="number">14</span> -<span class="number">16</span>  -<span class="number">1</span>  -<span class="number">1</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">1</span>  <span class="number">16</span>  <span class="number">15</span>  <span class="number">14</span>  <span class="number">14</span>   <span class="number">0</span></span><br><span class="line">   <span class="number">0</span> -<span class="number">14</span> -<span class="number">14</span> -<span class="number">15</span> -<span class="number">15</span> -<span class="number">16</span> -<span class="number">16</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">1</span>   <span class="number">1</span>  <span class="number">15</span>  <span class="number">14</span>  <span class="number">14</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span></span><br><span class="line">-<span class="number">15</span> -<span class="number">15</span> -<span class="number">15</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span>  -<span class="number">1</span>  -<span class="number">1</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span></span><br><span class="line">  <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">1</span>   <span class="number">1</span> -<span class="number">14</span>  -<span class="number">1</span>  -<span class="number">1</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span></span><br><span class="line">   <span class="number">1</span>   <span class="number">1</span> -<span class="number">14</span> -<span class="number">16</span>  -<span class="number">1</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> -<span class="number">14</span> -<span class="number">14</span> -<span class="number">15</span></span><br><span class="line">-<span class="number">16</span>  -<span class="number">1</span> -<span class="number">15</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> -<span class="number">14</span> -<span class="number">14</span> -<span class="number">15</span> -<span class="number">15</span> -<span class="number">16</span> -<span class="number">15</span></span><br><span class="line">   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> -<span class="number">14</span> -<span class="number">15</span> -<span class="number">15</span> -<span class="number">16</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span></span><br><span class="line">   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span> -<span class="number">15</span> -<span class="number">15</span> -<span class="number">15</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span></span><br><span class="line">   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>第一次的编号转移如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rst = np.arange(flow.size//<span class="number">2</span>) + dn</span><br></pre></td></tr></table></figure><p>转移结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rst =  [  <span class="number">0</span>   <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>  <span class="number">13</span>  <span class="number">14</span>  <span class="number">15</span>  <span class="number">16</span>  <span class="number">32</span></span><br><span class="line">  <span class="number">33</span>  <span class="number">34</span>  <span class="number">20</span>  <span class="number">21</span>  <span class="number">22</span>  <span class="number">23</span>  <span class="number">24</span>  <span class="number">40</span>  <span class="number">41</span>  <span class="number">27</span>  <span class="number">28</span>  <span class="number">29</span>  <span class="number">30</span>  <span class="number">47</span>  <span class="number">47</span>  <span class="number">48</span>  <span class="number">49</span>  <span class="number">50</span></span><br><span class="line">  <span class="number">36</span>  <span class="number">37</span>  <span class="number">38</span>  <span class="number">54</span>  <span class="number">55</span>  <span class="number">56</span>  <span class="number">57</span>  <span class="number">43</span>  <span class="number">44</span>  <span class="number">45</span>  <span class="number">47</span>  <span class="number">63</span>  <span class="number">63</span>  <span class="number">64</span>  <span class="number">64</span>  <span class="number">65</span>  <span class="number">52</span>  <span class="number">53</span></span><br><span class="line">  <span class="number">70</span>  <span class="number">71</span>  <span class="number">71</span>  <span class="number">72</span>  <span class="number">73</span>  <span class="number">59</span>  <span class="number">60</span>  <span class="number">62</span>  <span class="number">63</span>  <span class="number">79</span>  <span class="number">78</span>  <span class="number">64</span>  <span class="number">65</span>  <span class="number">67</span>  <span class="number">68</span>  <span class="number">85</span>  <span class="number">86</span>  <span class="number">86</span></span><br><span class="line">  <span class="number">86</span>  <span class="number">88</span>  <span class="number">74</span>  <span class="number">75</span>  <span class="number">77</span>  <span class="number">63</span>  <span class="number">64</span>  <span class="number">63</span>  <span class="number">79</span>  <span class="number">80</span>  <span class="number">82</span>  <span class="number">83</span>  <span class="number">85</span> <span class="number">101</span> <span class="number">101</span> <span class="number">101</span> <span class="number">102</span>  <span class="number">89</span></span><br><span class="line">  <span class="number">90</span>  <span class="number">77</span>  <span class="number">78</span>  <span class="number">78</span>  <span class="number">79</span>  <span class="number">79</span>  <span class="number">80</span>  <span class="number">97</span>  <span class="number">98</span> <span class="number">100</span> <span class="number">101</span> <span class="number">116</span> <span class="number">116</span> <span class="number">117</span> <span class="number">104</span> <span class="number">105</span> <span class="number">106</span> <span class="number">107</span></span><br><span class="line">  <span class="number">93</span>  <span class="number">94</span>  <span class="number">95</span> <span class="number">111</span> <span class="number">112</span> <span class="number">113</span> <span class="number">115</span> <span class="number">116</span> <span class="number">117</span> <span class="number">116</span> <span class="number">117</span> <span class="number">119</span> <span class="number">120</span> <span class="number">121</span> <span class="number">122</span> <span class="number">123</span> <span class="number">124</span> <span class="number">125</span></span><br><span class="line"><span class="number">126</span> <span class="number">127</span> <span class="number">128</span> <span class="number">130</span> <span class="number">131</span> <span class="number">117</span> <span class="number">131</span> <span class="number">132</span> <span class="number">134</span> <span class="number">135</span> <span class="number">136</span> <span class="number">137</span> <span class="number">138</span> <span class="number">139</span> <span class="number">140</span> <span class="number">141</span> <span class="number">142</span> <span class="number">143</span></span><br><span class="line"><span class="number">145</span> <span class="number">146</span> <span class="number">132</span> <span class="number">131</span> <span class="number">147</span> <span class="number">149</span> <span class="number">150</span> <span class="number">151</span> <span class="number">152</span> <span class="number">153</span> <span class="number">154</span> <span class="number">155</span> <span class="number">156</span> <span class="number">157</span> <span class="number">158</span> <span class="number">145</span> <span class="number">146</span> <span class="number">146</span></span><br><span class="line"><span class="number">146</span> <span class="number">162</span> <span class="number">149</span> <span class="number">165</span> <span class="number">166</span> <span class="number">167</span> <span class="number">168</span> <span class="number">169</span> <span class="number">170</span> <span class="number">171</span> <span class="number">172</span> <span class="number">173</span> <span class="number">160</span> <span class="number">161</span> <span class="number">161</span> <span class="number">162</span> <span class="number">162</span> <span class="number">164</span></span><br><span class="line"><span class="number">180</span> <span class="number">181</span> <span class="number">182</span> <span class="number">183</span> <span class="number">184</span> <span class="number">185</span> <span class="number">186</span> <span class="number">187</span> <span class="number">188</span> <span class="number">189</span> <span class="number">176</span> <span class="number">176</span> <span class="number">177</span> <span class="number">177</span> <span class="number">194</span> <span class="number">195</span> <span class="number">196</span> <span class="number">197</span></span><br><span class="line"><span class="number">198</span> <span class="number">199</span> <span class="number">200</span> <span class="number">201</span> <span class="number">202</span> <span class="number">203</span> <span class="number">204</span> <span class="number">205</span> <span class="number">191</span> <span class="number">192</span> <span class="number">193</span> <span class="number">209</span> <span class="number">210</span> <span class="number">211</span> <span class="number">212</span> <span class="number">213</span> <span class="number">214</span> <span class="number">215</span></span><br><span class="line"><span class="number">216</span> <span class="number">217</span> <span class="number">218</span> <span class="number">219</span> <span class="number">220</span> <span class="number">221</span> <span class="number">222</span> <span class="number">223</span> <span class="number">224</span>]</span><br></pre></td></tr></table></figure><h2 id="位置更新"><a href="#位置更新" class="headerlink" title="位置更新"></a>位置更新</h2><p>在上一节的最后，得到了图中各像素的原始编号及下一步要转移到的编号，这就建立了位置a到位置b的映射。<br>下一步就是要不断迭代，逐步将所有的位置上的编号进行更新。<br>注意，这里的位置a就是最开始的位置编号，里面的数值是np.range()的顺序编号，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure><p>而位置b这个变量则有两层意思，举一例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure><p>首先是里面的数值，如上所述，是更新后的位置编号，即a中的0要更新到1上，1要更新到2上，2更新到3，3更新到4，4更新到5，5就指向自己，不更新；<br>然后是其本身的索引index，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b[<span class="number">0</span>], b[<span class="number">1</span>], b[<span class="number">2</span>], b[<span class="number">3</span>], b[<span class="number">4</span>], b[<span class="number">5</span>]</span><br></pre></td></tr></table></figure><p>里面的0到5就暗含了a中的编号，即b中的位置所对应的本来位置。b对本身的索引就代表了一次更新，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b[b] =</span><br><span class="line">array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure><p>所以，这种不断对自身的索引就是位置更新的机制。<br>从另外一个角度理解，可以把网格上的编号理解为有向图中的节点（多谢霄龙的指点），比如上面的0号节点指向1号节点，4号指向5号，5号指向自身。这个位置更新的过程就是沿着有向图不断行走的过程。<br>这里有两种更新方式：一种是单步推演，一种是连锁推演。<br>单步推演的示意图如下：<br><img src="https://user-images.githubusercontent.com/6218739/109754873-cd973000-7c1f-11eb-85c6-9e15eef5f535.png" alt="onestep"><br>即某个位置上的位置更新每次都仅执行一次。<br>连锁推演的示意图如下：<br><img src="https://user-images.githubusercontent.com/6218739/109755154-675edd00-7c20-11eb-8dea-2849cbfa908a.png" alt="multistep"><br>即某个位置上的位置更新每次可跨越执行。<br>这两种的原理可通过下面的代码很清楚地理解：<br><img src="https://user-images.githubusercontent.com/6218739/109755277-ae4cd280-7c20-11eb-9391-1fd87ce2768d.png" alt="update"><br>即前一个是以b为被索引对象，而后一个是以不断更新的位置作为被索引对象。可以看出，对于单次推演，本例中需要4次才能稳定；而连锁推演，需要3次即可。<br>单步推演有线性复杂度，而连锁推演，系统具有对数复杂度。理论可知连锁推演10次，可以将半径扩张到1024，通常这已经足够识别常见的任意物体。<br>因此，采用连续推演的代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rst = np.arange(flow.size//<span class="number">2</span>) + dn</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    rst = rst[rst]</span><br></pre></td></tr></table></figure><p>最终更新的位置编号为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rst =  [  <span class="number">0</span>   <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>  <span class="number">13</span>  <span class="number">14</span>  <span class="number">15</span>  <span class="number">16</span>  <span class="number">79</span></span><br><span class="line">  <span class="number">79</span>  <span class="number">78</span>  <span class="number">20</span>  <span class="number">21</span>  <span class="number">22</span>  <span class="number">23</span>  <span class="number">24</span> <span class="number">116</span> <span class="number">116</span>  <span class="number">27</span>  <span class="number">28</span>  <span class="number">29</span>  <span class="number">30</span>  <span class="number">63</span>  <span class="number">63</span>  <span class="number">63</span>  <span class="number">64</span>  <span class="number">64</span></span><br><span class="line">  <span class="number">36</span>  <span class="number">37</span>  <span class="number">38</span> <span class="number">117</span> <span class="number">117</span> <span class="number">117</span> <span class="number">117</span>  <span class="number">43</span>  <span class="number">44</span>  <span class="number">45</span>  <span class="number">63</span>  <span class="number">79</span>  <span class="number">79</span>  <span class="number">78</span>  <span class="number">78</span>  <span class="number">64</span>  <span class="number">52</span>  <span class="number">53</span></span><br><span class="line"><span class="number">116</span> <span class="number">116</span> <span class="number">116</span> <span class="number">116</span> <span class="number">116</span>  <span class="number">59</span>  <span class="number">60</span>  <span class="number">63</span>  <span class="number">79</span>  <span class="number">63</span>  <span class="number">64</span>  <span class="number">78</span>  <span class="number">64</span>  <span class="number">67</span>  <span class="number">68</span> <span class="number">117</span> <span class="number">117</span> <span class="number">117</span></span><br><span class="line"><span class="number">117</span> <span class="number">117</span>  <span class="number">74</span>  <span class="number">75</span>  <span class="number">63</span>  <span class="number">79</span>  <span class="number">78</span>  <span class="number">79</span>  <span class="number">63</span>  <span class="number">79</span>  <span class="number">82</span>  <span class="number">83</span> <span class="number">117</span> <span class="number">116</span> <span class="number">116</span> <span class="number">116</span> <span class="number">116</span>  <span class="number">89</span></span><br><span class="line">  <span class="number">90</span>  <span class="number">63</span>  <span class="number">64</span>  <span class="number">64</span>  <span class="number">63</span>  <span class="number">63</span>  <span class="number">79</span>  <span class="number">97</span>  <span class="number">98</span> <span class="number">117</span> <span class="number">116</span> <span class="number">117</span> <span class="number">117</span> <span class="number">116</span> <span class="number">104</span> <span class="number">105</span> <span class="number">106</span> <span class="number">107</span></span><br><span class="line">  <span class="number">78</span>  <span class="number">79</span>  <span class="number">79</span> <span class="number">111</span> <span class="number">112</span> <span class="number">113</span> <span class="number">116</span> <span class="number">117</span> <span class="number">116</span> <span class="number">117</span> <span class="number">116</span> <span class="number">119</span> <span class="number">120</span> <span class="number">121</span> <span class="number">122</span> <span class="number">123</span> <span class="number">124</span> <span class="number">125</span></span><br><span class="line"><span class="number">126</span> <span class="number">127</span> <span class="number">128</span> <span class="number">116</span> <span class="number">117</span> <span class="number">116</span> <span class="number">117</span> <span class="number">116</span> <span class="number">134</span> <span class="number">135</span> <span class="number">136</span> <span class="number">137</span> <span class="number">138</span> <span class="number">139</span> <span class="number">140</span> <span class="number">141</span> <span class="number">142</span> <span class="number">143</span></span><br><span class="line"><span class="number">116</span> <span class="number">117</span> <span class="number">116</span> <span class="number">117</span> <span class="number">116</span> <span class="number">149</span> <span class="number">150</span> <span class="number">151</span> <span class="number">152</span> <span class="number">153</span> <span class="number">154</span> <span class="number">155</span> <span class="number">156</span> <span class="number">157</span> <span class="number">158</span> <span class="number">116</span> <span class="number">117</span> <span class="number">117</span></span><br><span class="line"><span class="number">117</span> <span class="number">116</span> <span class="number">149</span> <span class="number">165</span> <span class="number">166</span> <span class="number">167</span> <span class="number">168</span> <span class="number">169</span> <span class="number">170</span> <span class="number">171</span> <span class="number">172</span> <span class="number">173</span> <span class="number">116</span> <span class="number">116</span> <span class="number">116</span> <span class="number">116</span> <span class="number">116</span> <span class="number">149</span></span><br><span class="line"><span class="number">180</span> <span class="number">181</span> <span class="number">182</span> <span class="number">183</span> <span class="number">184</span> <span class="number">185</span> <span class="number">186</span> <span class="number">187</span> <span class="number">188</span> <span class="number">189</span> <span class="number">117</span> <span class="number">117</span> <span class="number">117</span> <span class="number">117</span> <span class="number">194</span> <span class="number">195</span> <span class="number">196</span> <span class="number">197</span></span><br><span class="line"><span class="number">198</span> <span class="number">199</span> <span class="number">200</span> <span class="number">201</span> <span class="number">202</span> <span class="number">203</span> <span class="number">204</span> <span class="number">205</span> <span class="number">116</span> <span class="number">116</span> <span class="number">116</span> <span class="number">209</span> <span class="number">210</span> <span class="number">211</span> <span class="number">212</span> <span class="number">213</span> <span class="number">214</span> <span class="number">215</span></span><br><span class="line"><span class="number">216</span> <span class="number">217</span> <span class="number">218</span> <span class="number">219</span> <span class="number">220</span> <span class="number">221</span> <span class="number">222</span> <span class="number">223</span> <span class="number">224</span>]</span><br></pre></td></tr></table></figure><h2 id="获得稳定集水区"><a href="#获得稳定集水区" class="headerlink" title="获得稳定集水区"></a>获得稳定集水区</h2><p>经过若干次推演，其实我们是模拟每个网格从最初的位置移动到了新的位置，此时只要对新的位置进行频率统计，就可以得到集水图。<br>还是一步步看代码怎么实现的。<br>首先对上面的最新位置编号进行统计，看每个编号出现的次数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hist = np.bincount(rst, minlength=<span class="built_in">len</span>(rst))</span><br><span class="line">hist.shape = rst.shape = flow.shape[:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>次数统计结果（已经转成了原图像的形状）为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">11</span>  <span class="number">7</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">6</span> <span class="number">11</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">32</span> <span class="number">26</span>  <span class="number">0</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">3</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>]</span><br><span class="line">[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>]]</span><br></pre></td></tr></table></figure><p>这个矩阵的数值就代表了集水区，比如0就是水都流走了，是贫水区，1的地方表示水原地没动，数值大于1的地方表示水都汇集在了此处，数值越大表示集水量越大。</p><p>下面的工作就是获得这些集水区的区域标记。<br>首先进行连通域标记：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lab, n = ndimg.label(hist, np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br></pre></td></tr></table></figure><p>标记结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">lab =</span><br><span class="line">[[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">3</span> <span class="number">3</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]]</span><br></pre></td></tr></table></figure><p>再统计一下这些区域的面积大小，即每个集水区的面积大小：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">areas = np.bincount(lab.ravel())</span><br></pre></td></tr></table></figure><p>结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">areas =  [ <span class="number">89</span> <span class="number">130</span>   <span class="number">4</span>   <span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>统计这些区域的权重，即每个集水区中集水量的大小，即容积：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weight = ndimg.<span class="built_in">sum</span>(hist, lab, np.arange(n+<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weight =  [  <span class="number">0.</span> <span class="number">132.</span>  <span class="number">35.</span>  <span class="number">58.</span>]</span><br></pre></td></tr></table></figure><p>因此，集水区的面积和集水量就是衡量这个集水区的两个有效标准。<br>（1）对于集水区的面积，集水区应该面积较小，理想情况下汇集在一点，即周围的水都往一点流，如果本来区域是狭长的，那么就没法汇集于一点，但总归面积不能太大；<br>（2）对于集水区的容积，即集水量，集水量应该比较大，这意味着集水前该集水点所覆盖的面积比较大。</p><p>算法中提供了面积和容积（集水量）这两个阈值的调控接口，即函数的area和volume参数。<br>根据面积阈值和体积阈值设定掩膜，这里设置的阈值分别是5和10：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">msk = (areas&lt;area) &amp; (weight&gt;volume)</span><br></pre></td></tr></table></figure><p>结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(areas&lt;area) =  [<span class="literal">False</span> <span class="literal">False</span>  <span class="literal">True</span>  <span class="literal">True</span>]</span><br><span class="line">(weight&gt;volume) =  [<span class="literal">False</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>]</span><br><span class="line"></span><br><span class="line">msk = [<span class="literal">False</span> <span class="literal">False</span>  <span class="literal">True</span>  <span class="literal">True</span>]</span><br></pre></td></tr></table></figure><p>即，对于面积而言，前两个集水区面积太大了，不满足条件；对于容积而言，后三个都满足容积要求，第一个集水区则不满足。<br>综上，前两个掩膜为False，后两个为True。</p><p>根据上面的掩膜创建一个查找表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lut = np.zeros(n+<span class="number">1</span>, np.int32)</span><br><span class="line">lut[msk] = np.arange(<span class="number">1</span>, msk.<span class="built_in">sum</span>()+<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>其值为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>有了这个查找表，再将集水区的连通域标记作为索引，就可以得到集水区的区域标记，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lut[lab]</span><br></pre></td></tr></table></figure><p>结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><h2 id="获得集水前区域标记"><a href="#获得集水前区域标记" class="headerlink" title="获得集水前区域标记"></a>获得集水前区域标记</h2><p>上面得到了集水区的区域标记，这些标记标明了水最终汇集到的地方，也就是原始网格更新后的位置。<br>因此，通过集水区的区域标记，再结合之前的位置更新，就可以得到集水前的区域标记（注意是集水“前”）。<br>代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mask = lut[lab].ravel()[rst]</span><br></pre></td></tr></table></figure><p>最终结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><h1 id="参数调节"><a href="#参数调节" class="headerlink" title="参数调节"></a>参数调节</h1><p>这一节讲一下该加速算法里的三个参数（梯度阈值、面积阈值、容积阈值）的调节原则（所涉图像均为霄龙测试结果）。</p><h2 id="梯度阈值"><a href="#梯度阈值" class="headerlink" title="梯度阈值"></a>梯度阈值</h2><p>梯度阈值决定集水区的稳定状态，如果阈值设定过小，有可能产生细长区域的过分割，增加阈值会让稳定集水区面积增加，不会打碎较弱的漩涡，而设置过大，有可能会让较弱的流场与背景联通，进而无法被检测到。<br><img src="https://user-images.githubusercontent.com/6218739/109767652-d5ac9b00-7c32-11eb-9b86-142233eb47f3.png" alt="grad1"><br><img src="https://user-images.githubusercontent.com/6218739/109767709-ebba5b80-7c32-11eb-84ff-d74d4b8067f3.png" alt="grad2"><br><img src="https://user-images.githubusercontent.com/6218739/109767749-f96fe100-7c32-11eb-8509-7180cc6e059b.png" alt="grad3"><br>梯度阈值0.8时，中间狭长区域汇集成两个核，被分成两份；<br>梯度阈值1.0时，中间下场区域联通成一个核，是一个整体；<br>梯度阈值1.3时，左侧有两个区域与边界联通，进而后续被面积阈值过滤掉了。</p><h2 id="面积阈值"><a href="#面积阈值" class="headerlink" title="面积阈值"></a>面积阈值</h2><p>对于集水区的面积，集水区应该面积较小，理想情况下汇集在一点，即周围的水都往一点流，如果本来区域是狭长的，那么就没法汇集于一点，但总归面积不能太大。<br>因此，稳定集水区面积不得大于给定的阈值。<br><img src="https://user-images.githubusercontent.com/6218739/109767862-215f4480-7c33-11eb-8359-3d9ef9706f9a.png" alt="area1"><br><img src="https://user-images.githubusercontent.com/6218739/109767921-31772400-7c33-11eb-99e0-3b5ca3c81aa1.png" alt="area2"></p><h2 id="容积阈值"><a href="#容积阈值" class="headerlink" title="容积阈值"></a>容积阈值</h2><p>对于集水区的容积，即集水量，集水量应该比较大，这意味着集水前该集水点所覆盖的面积比较大。<br>因此，稳定集水区所对应的集水前的面积应该大于容积阈值。<br><img src="https://user-images.githubusercontent.com/6218739/109767862-215f4480-7c33-11eb-8359-3d9ef9706f9a.png" alt="area1"><br><img src="https://user-images.githubusercontent.com/6218739/109768719-3c7e8400-7c34-11eb-9af5-8bc965efb6d2.png" alt="vol2"></p>]]></content>
    
    
    <summary type="html">简介
本文的目的是介绍霄龙新开发的用于cellpose后处理加速的算法。
前面已写了两篇文章介绍了cellpose，它是一个非常强大的用于胞状物体分割的算法，具体见：
胞状物体通用分割算法Cellpose解析：使用篇
胞状物体通用分割算法Cellpose解析：开发篇
总体而言，cellpose由两部分组成：第一部分是Unet网络，建立了原图与其流场图flow之间的关系；第二部分是将上一步流场图复原为掩膜mask，即转换为最终的分割结果。
第一部分主要是神经网络的训练和推理，可以跑在CPU或GPU上（当然GPU会更快）；第二部分只能由CPU计算。两者的计算用时见cellpose作者的实测结果：
</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="cellpose" scheme="http://qixinbo.github.io/tags/cellpose/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle肾小球图像分割比赛全解析</title>
    <link href="http://qixinbo.github.io/2021/02/14/kaggle-hubmap/"/>
    <id>http://qixinbo.github.io/2021/02/14/kaggle-hubmap/</id>
    <published>2021-02-13T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.701Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h1><h2 id="赛事描述"><a href="#赛事描述" class="headerlink" title="赛事描述"></a>赛事描述</h2><p>Kaggle上正在进行一项名为“HuBMAP: Hacking the Kidney”的竞赛，链接见<a href="https://www.kaggle.com/c/hubmap-kidney-segmentation">这里</a>，总奖金是6万美金，该竞赛的目的是为了检测人体组织中的functional tissue units (FTUs)。FTU的定义是：three-dimensional block of cells centered around a capillary, such that each cell in this block is within diffusion distance from any other cell in the same block，感觉类似于细胞的概念，正中是细胞核，周围是细胞质。</p><h2 id="算法评估标准"><a href="#算法评估标准" class="headerlink" title="算法评估标准"></a>算法评估标准</h2><p>该竞赛使用Dice系数来评估算法的优劣。关于Dice系数，可以见如下博客解析：<br><a href="https://www.aiuai.cn/aifarm1159.html">医学图像分割之 Dice Loss</a></p><p>竞赛所提交的文件使用游程编码方式（RLE，run-length encoding）来减小文件体积。<br>关于掩膜mask与rle编码与解码的代码，可以参见网友Paulo Pinto的notebook：<br><a href="https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode">RLE functions - Run Lenght Encode &amp; Decode</a></p><h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><h2 id="数据集概览"><a href="#数据集概览" class="headerlink" title="数据集概览"></a>数据集概览</h2><p>该赛事中的数据一共有20张肾的图像，每一张都对其中的肾小球FTU进行了标注，有8张用于训练集，5张用于公榜测试集，剩下7张用于私榜测试集。<br>每一张图像都是非常大的TIFF格式，500MB-5GB大小。</p><p>训练集中的标注有两种形式：游程编码和未编码的JSON格式。<br>可以使用外部数据和/或预训练的机器学习模型，不过这些数据和模型必须在CC BY 4.0下授权。<br>下载数据集（这是在google colab上运行，colab上的机器性能较好；如果直接使用kaggle上的notebook，则数据集直接内置）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!kaggle competitions download -c hubmap-kidney-segmentation</span><br></pre></td></tr></table></figure><p>然后进行数据的探索性分析，该过程参考了以下notebook：<br><a href="https://www.kaggle.com/ihelon/hubmap-exploratory-data-analysis">HuBMAP - Exploratory Data Analysis</a></p><h2 id="导入必要的包"><a href="#导入必要的包" class="headerlink" title="导入必要的包"></a>导入必要的包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pathlib, sys, os, random, time</span><br><span class="line"><span class="keyword">import</span> numba, cv2, gc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> albumentations <span class="keyword">as</span> A</span><br><span class="line"><span class="keyword">import</span> rasterio</span><br><span class="line"><span class="keyword">from</span> rasterio.windows <span class="keyword">import</span> Window</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> D</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> T</span><br></pre></td></tr></table></figure><h2 id="配置路径及超参数"><a href="#配置路径及超参数" class="headerlink" title="配置路径及超参数"></a>配置路径及超参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BASE_PATH = <span class="string">&quot;../input/hubmap-kidney-segmentation/&quot;</span></span><br><span class="line">TRAIN_PATH = os.path.join(BASE_PATH, <span class="string">&quot;train/&quot;</span>)</span><br><span class="line">TEST_PATH = os.path.join(BASE_PATH, <span class="string">&quot;test/&quot;</span>)</span><br><span class="line"></span><br><span class="line">EPOCHES = <span class="number">5</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">DEVICE = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="文件分析"><a href="#文件分析" class="headerlink" title="文件分析"></a>文件分析</h2><p>（1）训练集文件分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_train = pd.read_csv(os.path.join(BASE_PATH, <span class="string">&quot;train.csv&quot;</span>))</span><br><span class="line">df_train</span><br></pre></td></tr></table></figure><p>得到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">           <span class="built_in">id</span>                        encoding</span><br><span class="line"><span class="number">0</span>        2f6ecfcdf        <span class="number">296084587</span> <span class="number">4</span> <span class="number">296115835</span> <span class="number">6</span> <span class="number">296115859</span> <span class="number">14</span> <span class="number">296147109.</span>..</span><br><span class="line"><span class="number">1</span>        aaa6a05cc        <span class="number">30989109</span> <span class="number">59</span> <span class="number">31007591</span> <span class="number">64</span> <span class="number">31026074</span> <span class="number">68</span> <span class="number">31044556</span> <span class="number">7.</span>..</span><br><span class="line"><span class="number">2</span>        cb2d976f4        <span class="number">78144363</span> <span class="number">5</span> <span class="number">78179297</span> <span class="number">15</span> <span class="number">78214231</span> <span class="number">25</span> <span class="number">78249165</span> <span class="number">35.</span>..</span><br><span class="line"><span class="number">3</span>        0486052bb        <span class="number">101676003</span> <span class="number">6</span> <span class="number">101701785</span> <span class="number">8</span> <span class="number">101727568</span> <span class="number">9</span> <span class="number">101753351</span> ...</span><br><span class="line"><span class="number">4</span>        e79de561c        <span class="number">7464094</span> <span class="number">14</span> <span class="number">7480273</span> <span class="number">41</span> <span class="number">7496453</span> <span class="number">67</span> <span class="number">7512632</span> <span class="number">82</span> <span class="number">75.</span>..</span><br><span class="line"><span class="number">5</span>        095bf7a1f        <span class="number">113430380</span> <span class="number">22</span> <span class="number">113468538</span> <span class="number">67</span> <span class="number">113506697</span> <span class="number">111</span> <span class="number">113544.</span>..</span><br><span class="line"><span class="number">6</span>        54f2eec69        <span class="number">124601765</span> <span class="number">36</span> <span class="number">124632133</span> <span class="number">109</span> <span class="number">124662536</span> <span class="number">147</span> <span class="number">12469.</span>..</span><br><span class="line"><span class="number">7</span>        1e2425f28        <span class="number">49453112</span> <span class="number">7</span> <span class="number">49479881</span> <span class="number">22</span> <span class="number">49506657</span> <span class="number">31</span> <span class="number">49533433</span> <span class="number">40.</span>..</span><br></pre></td></tr></table></figure><p>train.csv文件中包含了图像的id及其游程编码。可以看出图像的名称就是id名。<br>（2）提交文件分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_sub = pd.read_csv(os.path.join(BASE_PATH, <span class="string">&quot;sample_submission.csv&quot;</span>))</span><br><span class="line">df_sub</span><br></pre></td></tr></table></figure><p>得到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   <span class="built_in">id</span>                          predicted</span><br><span class="line"><span class="number">0</span>        b9a3865fc        NaN</span><br><span class="line"><span class="number">1</span>        b2dc8411c        NaN</span><br><span class="line"><span class="number">2</span>        26dc41664        NaN</span><br><span class="line"><span class="number">3</span>        c68fe75ea        NaN</span><br><span class="line"><span class="number">4</span>        afa5e8098        NaN</span><br></pre></td></tr></table></figure><p>提交文件就是对公共测试集上的图像的预测，可以看出id就是公共测试集中的图像名称，predicted一栏需要后面填入。<br>（3）数据集大小分析：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;number of train images: &quot;, df_train.shape[0])</span><br><span class="line">print(&quot;number of test images: &quot;, df_sub.shape[0])</span><br></pre></td></tr></table></figure><p>分别是8和5。<br>（4）元数据分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_meta = pd.read_csv(os.path.join(BASE_PATH, <span class="string">&quot;HuBMAP-20-dataset_information.csv&quot;</span>))</span><br><span class="line">df_meta.sample(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>该文件中包含了数据集中的每一张图像额外的信息，比如它的主人的身体信息、性别、种族等。<br>同时指明训练集中除了肾小球的标注文件，比如1e2425f28.json，还有其他解剖组织的标注文件，比如1e2425f28-anatomical-structure.json。<br>该文件是为了辅助理解该赛题背后的医学知识，有可能对特征功能有用，但目前看没法直接使用。</p><h2 id="工具函数"><a href="#工具函数" class="headerlink" title="工具函数"></a>工具函数</h2><p>以下是关于游程编码和解码、读取图像、可视化的工具代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图像分块</span></span><br><span class="line"><span class="comment"># min_overlap这个参数指的是有可能出现的最小的overlap，而不是保证这个overlap一定会出现</span></span><br><span class="line"><span class="comment"># 即自适应产生的overlap肯定会大于该min_overlap</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_grid</span>(<span class="params">shape, window=<span class="number">256</span>, min_overlap=<span class="number">32</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Return Array of size (N,4), where N - number of tiles,</span></span><br><span class="line"><span class="string">        2nd axis represente slices: x1,x2,y1,y2</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x, y = shape</span><br><span class="line">    nx = x // (window - min_overlap) + <span class="number">1</span></span><br><span class="line">    x1 = np.linspace(<span class="number">0</span>, x, num=nx, endpoint=<span class="literal">False</span>, dtype=np.int64)</span><br><span class="line">    x1[-<span class="number">1</span>] = x - window</span><br><span class="line">    x2 = (x1 + window).clip(<span class="number">0</span>, x)</span><br><span class="line">    ny = y // (window - min_overlap) + <span class="number">1</span></span><br><span class="line">    y1 = np.linspace(<span class="number">0</span>, y, num=ny, endpoint=<span class="literal">False</span>, dtype=np.int64)</span><br><span class="line">    y1[-<span class="number">1</span>] = y - window</span><br><span class="line">    y2 = (y1 + window).clip(<span class="number">0</span>, y)</span><br><span class="line">    slices = np.zeros((nx,ny, <span class="number">4</span>), dtype=np.int64)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nx):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(ny):</span><br><span class="line">            slices[i,j] = x1[i], x2[i], y1[j], y2[j]   </span><br><span class="line">    <span class="keyword">return</span> slices.reshape(nx*ny,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 固定随机数，以保证可复现性</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_seeds</span>(<span class="params">seed=<span class="number">42</span></span>):</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 游程编码转为图像掩膜</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rle2mask</span>(<span class="params">mask_rle, shape</span>):</span></span><br><span class="line">    <span class="comment"># shape的形状是(width, height), width是通常理解的图像宽度</span></span><br><span class="line">    <span class="comment"># 原始的rle编码是str类型，里面的元素成对出现，即start起始像素及length长度</span></span><br><span class="line">    s = mask_rle.split()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将s中的start和length分别提取出来，因为它们在原始列表中是成对出现，所以这里对这两种数据都是每隔两个元素提取一次</span></span><br><span class="line">    <span class="comment"># 然后再通过python的列表生成式语法另存成numpy数组</span></span><br><span class="line">    <span class="comment"># https://www.liaoxuefeng.com/wiki/1016959663602400/1017317609699776</span></span><br><span class="line">    starts, lengths = [np.asarray(x, dtype=<span class="built_in">int</span>) <span class="keyword">for</span> x <span class="keyword">in</span> (s[<span class="number">0</span>:][::<span class="number">2</span>], s[<span class="number">1</span>:][::<span class="number">2</span>])]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 原始csv文件中的游程编码是从绝对位置开始，因此转化为numpy数组时需要减1</span></span><br><span class="line">    starts -= <span class="number">1</span></span><br><span class="line">    ends = starts + lengths</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据原始图像大小建立一个空白图像</span></span><br><span class="line">    img = np.zeros(shape[<span class="number">0</span>]*shape[<span class="number">1</span>], dtype=np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据起始像素和结束像素，在该空白图像上创建掩膜</span></span><br><span class="line">    <span class="comment"># 1为mask，0为背景</span></span><br><span class="line">    <span class="keyword">for</span> lo, hi <span class="keyword">in</span> <span class="built_in">zip</span>(starts, ends):</span><br><span class="line">        img[lo: hi] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将img按输入shape变换形状，这里就体现了shape中元素顺序的关键</span></span><br><span class="line">    <span class="comment"># 因为RLE编码是先从上到下，然后再从左到右进行的，所以分割时是先满足高度要求，即先按一列一列地来分组</span></span><br><span class="line">    <span class="comment"># 因为输入的shape是宽度在前，高度在后，正好reshape就按这个shape来变换形状</span></span><br><span class="line">    <span class="comment"># 比如原图如果宽为5，高为2，那么就reshape((5, 2))，即分成5组，每组2个元素</span></span><br><span class="line">    <span class="comment"># 然后因为图像存成numpy数组时是行数乘以列数，即转置一下即可</span></span><br><span class="line">    <span class="keyword">return</span> img.reshape(shape).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像掩膜转为游程编码</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/qq_35985044/article/details/104332577</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask2rle</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="comment"># 将掩膜按从上到下、从左到右的顺序压平</span></span><br><span class="line">    pixels = img.T.flatten()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前后各加一个0作为缓冲区</span></span><br><span class="line">    pixels = np.concatenate([[<span class="number">0</span>], pixels, [<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 以下记录的是掩膜值开始发生变化的位置，使用的方法是将数组错移一位，并与原数组比较</span></span><br><span class="line">    <span class="comment"># 这样每一段重复的序列在前后位置都有一个变化的位置记录，前后位置是成对出现的</span></span><br><span class="line">    <span class="comment"># +1是为了做位置调整</span></span><br><span class="line">    runs = np.where(pixels[<span class="number">1</span>:] != pixels[:-<span class="number">1</span>])[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这一步比较抽象，首先记住runs记录了像素值发生变化的位置</span></span><br><span class="line">    <span class="comment"># runs[1::2]是从第二个位置开始，每隔两个元素提取一次，即该表达式提取的是“成对出现的前后位置”中的“后”这一位置</span></span><br><span class="line">    <span class="comment"># runs[::2]则是从第一个位置开始，每隔两个元素提取一次，即该表达式提取的是“成对出现的前后位置”中的“前”这一位置</span></span><br><span class="line">    <span class="comment"># 然后两者相减，并在原来“后”这一位置存储差值，即每个重复序列的长度</span></span><br><span class="line">    runs[<span class="number">1</span>::<span class="number">2</span>] -= runs[::<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将上述元素逐个取出，并且使用空格符连接成字符串</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> runs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用numba加速</span></span><br><span class="line"><span class="comment"># 可以参考如下nb里的讨论部分</span></span><br><span class="line"><span class="comment"># https://www.kaggle.com/leighplt/pytorch-fcn-resnet50/comments</span></span><br><span class="line"><span class="meta">@numba.njit()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask2rle_numba_1d</span>(<span class="params">pixels</span>):</span></span><br><span class="line">    size = <span class="built_in">len</span>(pixels)</span><br><span class="line">    points = []</span><br><span class="line">    <span class="keyword">if</span> pixels[<span class="number">0</span>] == <span class="number">1</span>: points.append(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, size):</span><br><span class="line">        <span class="keyword">if</span> pixels[i] != pixels[i-<span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(points) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                points.append(i+<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                points.append(i+<span class="number">1</span> - points[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pixels[-<span class="number">1</span>] == <span class="number">1</span>: points.append(size-points[-<span class="number">1</span>]+<span class="number">1</span>)   </span><br><span class="line">    <span class="keyword">return</span> points</span><br><span class="line"></span><br><span class="line"><span class="comment"># 该函数必须得与上面的分开，因为最后的join函数不支持numba</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask2rle_numba</span>(<span class="params">image</span>):</span></span><br><span class="line">    pixels = image.T.flatten()</span><br><span class="line">    points = mask2rle_numba_1d(pixels)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> points)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取训练集图像</span></span><br><span class="line"><span class="comment"># 对于大型tif图像，推荐使用rasterio来读取，读取速度会提升很多倍</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_image</span>(<span class="params">image_id, scale=<span class="literal">None</span>, verbose=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="comment"># python3.6引入的f-string，用于格式化字符串</span></span><br><span class="line">    <span class="comment"># https://blog.csdn.net/sunxb10/article/details/81036693</span></span><br><span class="line">    image = tifffile.imread(os.path.join(TRAIN_PATH, <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.tiff&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集中有几张图像是(1, 1, 3, X, Y)这样的格式，需要将其转为正确的(X, Y, 3)格式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(image.shape) == <span class="number">5</span>:</span><br><span class="line">        image = image.sequeeze().transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这个地方用到了pandas对象的布尔数组索引</span></span><br><span class="line">    <span class="comment"># https://www.pypandas.cn/docs/user_guide/indexing.html#%E7%B4%A2%E5%BC%95%E7%9A%84%E4%B8%8D%E5%90%8C%E9%80%89%E6%8B%A9</span></span><br><span class="line">    <span class="comment"># 特别需要注意的是第二个参数的顺序，这里是图像的宽度在前，高度在后</span></span><br><span class="line">    mask = rle2mask(df_train[df_train[<span class="string">&quot;id&quot;</span>] == image_id][<span class="string">&#x27;encoding&#x27;</span>].values[<span class="number">0</span>], (image.shape[<span class="number">1</span>], image.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开启详细显示信息模式</span></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Mask shape: <span class="subst">&#123;mask.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 缩放</span></span><br><span class="line">    <span class="keyword">if</span> scale:</span><br><span class="line">        <span class="comment"># 注意opencv的resize函数要求的参数是先宽后高，注意顺序</span></span><br><span class="line">        new_size = (image.shape[<span class="number">1</span>] // scale, image.shape[<span class="number">0</span>] // scale)</span><br><span class="line">        image = cv2.resize(image, new_size)</span><br><span class="line">        mask = cv2.resize(mask, new_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Mask shape: <span class="subst">&#123;mask.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image, mask</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取测试集图像</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_test_image</span>(<span class="params">image_id, scale=<span class="literal">None</span>, verbose=<span class="number">1</span></span>):</span></span><br><span class="line">    image = tifffile.imread(os.path.join(TEST_PATH, <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.tiff&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(image.shape) == <span class="number">5</span>:</span><br><span class="line">        image = image.sequeeze().tranpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> scale:</span><br><span class="line">        new_size = (image.shape[<span class="number">1</span>] // scale, image.shape[<span class="number">0</span>] // scale)</span><br><span class="line">        image = cv2.resize(image, new_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化图像及其掩膜</span></span><br><span class="line"><span class="comment"># 主要是应用了matplotlib库，其用法可参考如下链接</span></span><br><span class="line"><span class="comment"># https://lijin-thu.github.io/06.%20matplotlib/06.01%20pyplot%20tutorial.html</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_image_and_mask</span>(<span class="params">image, mask, image_id</span>):</span></span><br><span class="line">    <span class="comment"># 产生一幅图，指定其大小</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一行三列的子图</span></span><br><span class="line">    <span class="comment"># 这里是第一个子图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.title(<span class="string">f&quot;Image <span class="subst">&#123;image_id&#125;</span>&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二个子图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.imshow(mask, cmap=<span class="string">&quot;hot&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.title(<span class="string">f&quot;Image <span class="subst">&#123;image_id&#125;</span> + mask&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第三个子图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.imshow(mask, cmap=<span class="string">&quot;hot&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">f&quot;Mask&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化图像及其掩膜的一部分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_slice_image_and_mask</span>(<span class="params">image, mask, start_h, end_h, start_w, end_w</span>):</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line">    sub_image = image[start_h : end_h, start_w : end_w, :]</span><br><span class="line">    sub_mask = mask[start_h : end_h, start_w : end_w]</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(sub_image)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">    plt.imshow(sub_image)</span><br><span class="line">    plt.imshow(sub_mask, cmap=<span class="string">&quot;hot&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.imshow(sub_mask, cmap=<span class="string">&quot;hot&quot;</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>依据这些工具函数，可以很方便地进行数据集的读取和调用。<br>以训练集中的某张图像为例，观察其部分原图及其标注：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">image_id = <span class="string">&quot;0486052bb&quot;</span></span><br><span class="line">image, mask = read_image(image_id, <span class="number">2</span>)</span><br><span class="line">plot_image_and_mask(image, mask, image_id)</span><br><span class="line"></span><br><span class="line">plot_slice_image_and_mask(image, mask, <span class="number">5000</span>, <span class="number">7500</span>, <span class="number">2500</span>, <span class="number">5000</span>)</span><br><span class="line">plot_slice_image_and_mask(image, mask, <span class="number">5250</span>, <span class="number">5720</span>, <span class="number">3500</span>, <span class="number">4000</span>)</span><br></pre></td></tr></table></figure><p>结果如下图：<br><img src="https://user-images.githubusercontent.com/6218739/100980887-e7719a00-3580-11eb-9dcd-2921740efa80.png" alt="vis"></p><h2 id="无网络连接安装依赖"><a href="#无网络连接安装依赖" class="headerlink" title="无网络连接安装依赖"></a>无网络连接安装依赖</h2><p>因为这个比赛的notebook不允许使用Internet，因此，如果调用了kaggle默认环境所没有的模块和包时，需要事先自己在线下准备好。<br>具体做法可以参考<a href="https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/113195">该教程</a>：<br>（1）首先打开notebook的网络，然后使用pip下载所依赖的包的whl文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip download [package_name]</span><br></pre></td></tr></table></figure><p>记住此时download的顺序以及版本号（这点一定要注意），后面要按该顺序的逆序进行安装。<br>（2）将这些whl文件上传到kaggle的dataset中；<br>这一步又涉及怎样将这些文件先下载下来，此时可以参考<a href="https://www.kaggle.com/getting-started/168312">该教程</a>：<br>一种是直接在右侧的output侧栏中点击下载；<br>一种是通过命令下载：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%cd /kaggle/working</span><br><span class="line">from IPython.display import FileLink -&gt; FileLink(r&#x27;*name of file*&#x27;)</span><br></pre></td></tr></table></figure><p>注意，在kaggle上上传非whl的安装包时，比如上传的时.tar.gz格式的源码包，kaggle会自动将其解压成文件夹。<br>因此，需要将此种文件后缀名需要更改为.xyz，然后上传。<br>上传时如果发现其他dataset仓库已经有相同的软件包，可以直接用那里的，也可以选择include duplicates上传自己的。<br>（3）在该notebook中引用上面的dataset，然后按逆序安装这些whl。<br>对于非whl的文件，注意将其copy到本地路径后，再修改为.tar.gz后缀名，然后正常pip install即可。</p><h1 id="正确提交一次和跑一遍模型"><a href="#正确提交一次和跑一遍模型" class="headerlink" title="正确提交一次和跑一遍模型"></a>正确提交一次和跑一遍模型</h1><h2 id="正确提交一次"><a href="#正确提交一次" class="headerlink" title="正确提交一次"></a>正确提交一次</h2><p>这里首先通过正确提交一次，保证提交文件是正确的，否则可能花了很多时间搭建算法和训练，最后却卡在提交上，没法及时提交。<br>因为Kaggle的submission目前看像是一个玄学，大家都在尝试怎样提交成功，比如下面的讨论：<br><a href="https://www.kaggle.com/c/tensorflow2-question-answering/discussion/116409">Scoring error on submission - even with sample_submission.csv</a><br><a href="https://www.kaggle.com/c/tensorflow2-question-answering/discussion/123466">Scoring error again</a><br>原因就是如第一个帖子中Julia所说，kaggle官方为了确保测试集不会被大家hack或产生leak，将测试集藏得很深。<br>想要提交成功，要假设测试集就在那里，且文件的ID千万不能硬编码，要做到“自适应”，同时里面的内容一开始可以全部设为0，但也注意有些竞赛对于数值也有要求，比如下面的帖子中，因为最后的score要计算Spearman系数，所以每一个array中至少要有两个不同的值：<br><a href="https://www.kaggle.com/c/google-quest-challenge/discussion/126777">Unable to fix submission scoring error</a><br>针对于此例，一个很小的提交如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">DATA_PATH = <span class="string">&#x27;../input/hubmap-kidney-segmentation&#x27;</span></span><br><span class="line">identity = rasterio.Affine(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">p = pathlib.Path(DATA_PATH)</span><br><span class="line">subm = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(p.glob(<span class="string">&#x27;test/*.tiff&#x27;</span>)):</span><br><span class="line">    dataset = rasterio.<span class="built_in">open</span>(filename.as_posix(), transform = identity)</span><br><span class="line">    preds = np.zeros(dataset.shape, dtype=np.uint8)</span><br><span class="line">    subm[i] = &#123;<span class="string">&#x27;id&#x27;</span>:filename.stem, <span class="string">&#x27;predicted&#x27;</span>: mask2rle_numba(preds)&#125;</span><br><span class="line">    <span class="keyword">del</span> preds</span><br><span class="line">    gc.collect();</span><br><span class="line"></span><br><span class="line">submission = pd.DataFrame.from_dict(subm, orient=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line">submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h2 id="跑一遍模型"><a href="#跑一遍模型" class="headerlink" title="跑一遍模型"></a>跑一遍模型</h2><p>这里实际是用随机权重的模型在测试集上跑一遍，保证整个流程是通路的，然后再进行模型的训练，即“以终为始”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span>():</span></span><br><span class="line">    model = torchvision.models.segmentation.fcn_resnet50(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原来的用于多类分割的模型最后一层改为目前的两类分割</span></span><br><span class="line">    model.classifier[<span class="number">4</span>] = nn.Conv2d(<span class="number">512</span>, <span class="number">1</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这一步也非常重要，因为不能有网络连接，如果不事先下载好这些权重文件，notebook运行过程中会联网下载，导致提交不成功</span></span><br><span class="line">!mkdir -p /root/.cache/torch/hub/checkpoints/</span><br><span class="line">!cp ../<span class="built_in">input</span>/pytorch-pretrained-models/resnet50-19c8e357.pth /root/.cache/torch/hub/checkpoints/</span><br><span class="line">!cp ../<span class="built_in">input</span>/pretrain-coco-weights-pytorch/fcn_resnet50_coco-1167a1af.pth /root/.cache/torch/hub/checkpoints/</span><br><span class="line"></span><br><span class="line">model = get_model()</span><br><span class="line">model.to(DEVICE);</span><br><span class="line"></span><br><span class="line">identity = rasterio.Affine(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个变换一定要与训练集的变换相同</span></span><br><span class="line">trfm = T.Compose([</span><br><span class="line">    T.ToPILImage(),</span><br><span class="line">    T.Resize(NEW_SIZE),</span><br><span class="line">    T.ToTensor(),</span><br><span class="line">    T.Normalize([<span class="number">0.625</span>, <span class="number">0.448</span>, <span class="number">0.688</span>],</span><br><span class="line">                [<span class="number">0.131</span>, <span class="number">0.177</span>, <span class="number">0.101</span>]),</span><br><span class="line">])</span><br><span class="line"> </span><br><span class="line">p = pathlib.Path(DATA_PATH)</span><br><span class="line"></span><br><span class="line">subm = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 真正使用过程中，在训练模型后，在这里要加载训练好的模型</span></span><br><span class="line"><span class="comment"># model.load_state_dict(torch.load(&quot;../input/models/HuBMAP_model_best.pth&quot;))</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历测试集中的文件</span></span><br><span class="line"><span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(p.glob(<span class="string">&#x27;test/*.tiff&#x27;</span>)):</span><br><span class="line">    <span class="comment"># 使用rasterio来打开tiff文件，实测速度会很快</span></span><br><span class="line">    <span class="comment"># transform参数是用来进行仿射变换，这里不涉及坐标系变换，可以不用</span></span><br><span class="line">    <span class="comment"># 常用用法可见：</span></span><br><span class="line">    <span class="comment"># https://theonegis.github.io/geos/%E4%BD%BF%E7%94%A8Rasterio%E8%AF%BB%E5%8F%96%E6%A0%85%E6%A0%BC%E6%95%B0%E6%8D%AE/index.html</span></span><br><span class="line">    dataset = rasterio.<span class="built_in">open</span>(filename.as_posix(), transform = identity)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 因为原始图像很大，为防止爆内存，将其分块处理</span></span><br><span class="line">    slices = make_grid(dataset.shape, window=WINDOW, min_overlap=MIN_OVERLAP)</span><br><span class="line">    <span class="comment"># 创建一个存储预测结果的缓存</span></span><br><span class="line">    preds = np.zeros(dataset.shape, dtype=np.uint8)</span><br><span class="line">    <span class="comment"># 对分块图像进行遍历</span></span><br><span class="line">    <span class="keyword">for</span> (x1,x2,y1,y2) <span class="keyword">in</span> slices:</span><br><span class="line">        <span class="comment"># read方法将rasterio的数据集格式转为numpy.ndarray</span></span><br><span class="line">        image = dataset.read([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], window=Window.from_slices((x1,x2),(y1,y2)))</span><br><span class="line">        <span class="comment"># 改变一下维度次序</span></span><br><span class="line">        image = np.moveaxis(image, <span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 与训练集采用同样的tranform变换</span></span><br><span class="line">        image = trfm(image)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="comment"># 将image放入DEVICE中，cpu或gpu</span></span><br><span class="line">            image = image.to(DEVICE)[<span class="literal">None</span>]</span><br><span class="line">            <span class="comment"># 模型对图像进行预测</span></span><br><span class="line">            <span class="comment"># 这个地方需要注意的是model的返回值</span></span><br><span class="line">            <span class="comment"># torchvision模型库中的classification和segmentation、detection的模型返回值不同</span></span><br><span class="line">            <span class="comment"># 比如，用于classification的模型，比如AlexNet，其model(X)返回的就是预测值y的tensor</span></span><br><span class="line">            <span class="comment"># 而segmentation的模型，比如fcn_resnet50，它的返回值是一个有序字典，其中的key有out和aux</span></span><br><span class="line">            <span class="comment"># 所以下面的代码需要使用out这个key来获得预测值tensor</span></span><br><span class="line">            <span class="comment"># 可以参考：</span></span><br><span class="line">            <span class="comment"># https://pytorch.org/docs/stable/torchvision/models.html</span></span><br><span class="line">            <span class="comment"># https://github.com/pytorch/vision/blob/d0063f3d83beac01e85f3027c4de6499a8985469/torchvision/models/segmentation/fcn.py#L9</span></span><br><span class="line">            <span class="comment"># https://colab.research.google.com/github/spmallick/learnopencv/blob/master/PyTorch-Segmentation-torchvision/intro-seg.ipynb#scrollTo=ZsIngeXleQ1H</span></span><br><span class="line">            score = model(image)[<span class="string">&#x27;out&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 这个得分有可能是负的，为了一致性，将其使用sigmoid激活，转为0到1</span></span><br><span class="line">            score_sigmoid = score.sigmoid().cpu().numpy()</span><br><span class="line">            score_sigmoid = cv2.resize(score_sigmoid, (WINDOW, WINDOW))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 以0.5作为阈值，输出mask</span></span><br><span class="line">            preds[x1:x2,y1:y2] = (score_sigmoid &gt; <span class="number">0.5</span>).astype(np.uint8)</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># 将预测值转为RLE编码</span></span><br><span class="line">    subm[i] = &#123;<span class="string">&#x27;id&#x27;</span>:filename.stem, <span class="string">&#x27;predicted&#x27;</span>: mask2rle_numba(preds)&#125;</span><br><span class="line">    <span class="comment"># 删除临时变量</span></span><br><span class="line">    <span class="keyword">del</span> preds</span><br><span class="line">    <span class="comment"># 回收内存，防止内部爆掉，这一步非常重要</span></span><br><span class="line">    gc.collect();</span><br><span class="line"></span><br><span class="line">submission = pd.DataFrame.from_dict(subm, orient=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line">submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h1 id="制作数据集"><a href="#制作数据集" class="headerlink" title="制作数据集"></a>制作数据集</h1><p>因为原始图像太大了，单张甚至达到5G大小，极易爆内存，因此需要将其切分成小图像，才能进行可行的训练。</p><h2 id="在线制作数据集"><a href="#在线制作数据集" class="headerlink" title="在线制作数据集"></a>在线制作数据集</h2><p>这一节之所以称为“在线制作”，是因为数据集的加载和切分都是在程序运行时才开始进行，与之对应的，下面一节采用的是事先将原来的数据集切分好，等到用的时候直接读入即可。<br>这一节的在线制作是直接制作了适用于PyTorch的数据集格式，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line">identity = rasterio.Affine(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义数据集的制作可以参考如下链接：</span></span><br><span class="line"><span class="comment"># https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HubDataset</span>(<span class="params">D.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root_dir, transform,</span></span></span><br><span class="line"><span class="function"><span class="params">                 window=<span class="number">256</span>, overlap=<span class="number">32</span>, threshold = <span class="number">100</span></span>):</span></span><br><span class="line">        <span class="comment"># 加载路径使用pathlib，后续推荐使用它来替代os.path</span></span><br><span class="line">        <span class="comment"># 具体使用方法可以参考：</span></span><br><span class="line">        <span class="comment"># https://docs.python.org/zh-cn/3/library/pathlib.html</span></span><br><span class="line">        self.path = pathlib.Path(root_dir)</span><br><span class="line">        self.overlap = overlap</span><br><span class="line">        self.window = window</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.csv = pd.read_csv((self.path / <span class="string">&#x27;train.csv&#x27;</span>).as_posix(),</span><br><span class="line">                               index_col=[<span class="number">0</span>])</span><br><span class="line">        self.threshold = threshold</span><br><span class="line">        self.x, self.y = [], []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 运行下面的分块函数</span></span><br><span class="line">        self.build_slices()</span><br><span class="line">        self.<span class="built_in">len</span> = <span class="built_in">len</span>(self.x)</span><br><span class="line">        self.as_tensor = T.Compose([</span><br><span class="line">            <span class="comment"># ToTensor函数接受PIL Image或numpy.ndarray，将其先由HWC转置为CHW格式，再转为float后每个像素除以255，</span></span><br><span class="line">            <span class="comment"># 从而将数据范围变换到[0, 1]之间</span></span><br><span class="line">            <span class="comment"># https://www.cnblogs.com/ocean1100/p/9494640.html</span></span><br><span class="line">            T.ToTensor(),</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 标准化的操作是减去均值并除以标准差，即将数据变换为均值为0、标准差为1的标准正态分布</span></span><br><span class="line">            <span class="comment"># 之所以标准化，常用的解释是：（1）突出特征；（2）方便反向传播的计算，具体讨论可以参考：</span></span><br><span class="line">            <span class="comment"># http://www.soolco.com/post/62169_1_1.html</span></span><br><span class="line">            T.Normalize([<span class="number">0.625</span>, <span class="number">0.448</span>, <span class="number">0.688</span>],</span><br><span class="line">                        [<span class="number">0.131</span>, <span class="number">0.177</span>, <span class="number">0.101</span>]),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分块</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_slices</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.masks = []</span><br><span class="line">        self.files = []</span><br><span class="line">        self.slices = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.csv.index.values):</span><br><span class="line">            filepath = (self.path /<span class="string">&#x27;train&#x27;</span>/(filename+<span class="string">&#x27;.tiff&#x27;</span>)).as_posix()</span><br><span class="line">            self.files.append(filepath)</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Transform&#x27;</span>, filename)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> rasterio.<span class="built_in">open</span>(filepath, transform = identity) <span class="keyword">as</span> dataset:</span><br><span class="line">                self.masks.append(rle_decode(self.csv.loc[filename, <span class="string">&#x27;encoding&#x27;</span>], dataset.shape))</span><br><span class="line">                slices = make_grid(dataset.shape, window=self.window, min_overlap=self.overlap)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 排除掉一些没有目标对象的分块</span></span><br><span class="line">                <span class="keyword">for</span> slc <span class="keyword">in</span> tqdm(slices):</span><br><span class="line">                    x1,x2,y1,y2 = slc</span><br><span class="line">                    <span class="keyword">if</span> self.masks[-<span class="number">1</span>][x1:x2,y1:y2].<span class="built_in">sum</span>() &gt; self.threshold <span class="keyword">or</span> np.random.randint(<span class="number">100</span>) &gt; <span class="number">120</span>:</span><br><span class="line">                        self.slices.append([i,x1,x2,y1,y2])</span><br><span class="line"></span><br><span class="line">                        image = dataset.read([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">                            window=Window.from_slices((x1,x2),(y1,y2)))</span><br><span class="line"></span><br><span class="line">                         <span class="comment"># if image.std().mean() &lt; 10:</span></span><br><span class="line">                         <span class="comment">#     continue</span></span><br><span class="line"></span><br><span class="line">                         <span class="comment"># print(image.std().mean(), self.masks[-1][x1:x2,y1:y2].sum())</span></span><br><span class="line"></span><br><span class="line">                        image = np.moveaxis(image, <span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">                        self.x.append(image)</span><br><span class="line">                        self.y.append(self.masks[-<span class="number">1</span>][x1:x2,y1:y2])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get data operation</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        image, mask = self.x[index], self.y[index]</span><br><span class="line">        augments = self.transform(image=image, mask=mask)</span><br><span class="line">        <span class="keyword">return</span> self.as_tensor(augments[<span class="string">&#x27;image&#x27;</span>]), augments[<span class="string">&#x27;mask&#x27;</span>][<span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Total number of samples in the dataset</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line">WINDOW=<span class="number">1024</span></span><br><span class="line">MIN_OVERLAP=<span class="number">32</span></span><br><span class="line">NEW_SIZE=<span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># albumentations是一个基于OpenCV的数据增强库，拥有非常简单且强大的可以用于多种任务（分割、检测）的接口，易于定制且添加其他框架非常方便。</span></span><br><span class="line"><span class="comment"># 它可以对数据集进行逐像素的转换，如模糊、下采样、高斯噪声、高斯模糊、动态模糊、RGB转换、随机雾化等；</span></span><br><span class="line"><span class="comment"># 也可以进行空间转换（同时也会对目标标签进行转换），如裁剪、翻转、随机裁剪等</span></span><br><span class="line"><span class="comment"># 数据增强的方式是这样的：</span></span><br><span class="line"><span class="comment"># 比如在一个epoch之内，我是把所有的图片都过一遍，对于每张图片我都是进行一个transform的操作，比如transform内部有0.5的概率进行左右flip，</span></span><br><span class="line"><span class="comment"># 那么这张图片左右flip的概率就是0.5，可能这一个epoch不flip，下一个epoch就会flip.</span></span><br><span class="line"><span class="comment"># 换句话说，现有的数据增强是带有随机性的，比如是否随机镜像翻转，随机crop的时候选择哪块区域，加多强的噪声等，每次增强的结果可能都不一样，</span></span><br><span class="line"><span class="comment"># 这样模型相当于看到了很多份不同的图像。如果没有概率性的操作，即p=1， 做一次增强之后便不再变化，则和不做增强是等价的，即模型在整个训练过程中只能看到一份相同的不断重复的数据。</span></span><br><span class="line"><span class="comment"># 可以详见</span></span><br><span class="line"><span class="comment"># https://discuss.gluon.ai/t/topic/1666</span></span><br><span class="line">trfm = A.Compose([</span><br><span class="line">    A.Resize(NEW_SIZE,NEW_SIZE),</span><br><span class="line">    A.HorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">    A.VerticalFlip(p=<span class="number">0.5</span>),</span><br><span class="line"></span><br><span class="line">    A.OneOf([</span><br><span class="line">        A.RandomContrast(),</span><br><span class="line">        A.RandomGamma(),</span><br><span class="line">        A.RandomBrightness(),</span><br><span class="line">        A.ColorJitter(brightness=<span class="number">0.07</span>, contrast=<span class="number">0.07</span>,</span><br><span class="line">                   saturation=<span class="number">0.1</span>, hue=<span class="number">0.1</span>, always_apply=<span class="literal">False</span>, p=<span class="number">0.3</span>),</span><br><span class="line">        ], p=<span class="number">0.3</span>),</span><br><span class="line"></span><br><span class="line">    A.OneOf([</span><br><span class="line">        A.ElasticTransform(alpha=<span class="number">120</span>, sigma=<span class="number">120</span> * <span class="number">0.05</span>, alpha_affine=<span class="number">120</span> * <span class="number">0.03</span>),</span><br><span class="line">        A.GridDistortion(),</span><br><span class="line">        A.OpticalDistortion(distort_limit=<span class="number">2</span>, shift_limit=<span class="number">0.5</span>),</span><br><span class="line">        ], p=<span class="number">0.0</span>),</span><br><span class="line">    A.ShiftScaleRotate(),</span><br><span class="line">])</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型库里的模型时，有的模型所需要的输入图像的尺寸是固定的，比如必须是64*64等，所以在图像增强后要保证图像的尺寸满足该要求。</span></span><br><span class="line"><span class="comment"># 可以采取以下方法来满足任意图像尺寸的输入：</span></span><br><span class="line"><span class="comment">#（1）传统办法：预处理，也就是边缘补0，或者切割，或者重采样、resize来得到相同大小的输入图片作为input。</span></span><br><span class="line"><span class="comment">#（2）模型方法：使用Kaiming He大佬的SPP-Net可以输入任意大小的图片，原文arxiv地址：https://arxiv.org/abs/1406.4729</span></span><br><span class="line"><span class="comment">#（3）优雅方法：加一层torch.nn.AdaptiveMaxPool2d。</span></span><br><span class="line"><span class="comment"># 具体讨论可以见</span></span><br><span class="line"><span class="comment"># https://www.zhihu.com/question/45873400</span></span><br><span class="line"></span><br><span class="line">ds = HubDataset(DATA_PATH, window=WINDOW, overlap=MIN_OVERLAP, transform=trfm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分验证集和训练集</span></span><br><span class="line">valid_idx, train_idx = [], []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ds)):</span><br><span class="line">    <span class="comment"># 挑出第8张图片的所有切片作为验证集</span></span><br><span class="line">    <span class="keyword">if</span> ds.slices[i][<span class="number">0</span>] == <span class="number">7</span>:</span><br><span class="line">        valid_idx.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        train_idx.append(i)</span><br><span class="line"></span><br><span class="line">train_ds = D.Subset(ds, train_idx)</span><br><span class="line">valid_ds = D.Subset(ds, valid_idx)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define training and validation data loaders</span></span><br><span class="line">loader = D.DataLoader(</span><br><span class="line">    train_ds, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">vloader = D.DataLoader(</span><br><span class="line">    valid_ds, batch_size=BATCH_SIZE, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="离线制作数据集"><a href="#离线制作数据集" class="headerlink" title="离线制作数据集"></a>离线制作数据集</h2><p>如上所述，上述制作数据集的方式是离线进行的，该数据集准备过程参考了如下notebook：<br><a href="https://www.kaggle.com/iafoss/256x256-images">256x256 images</a><br>具体切分方式与上面在线制作时不同，但表达的意思相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对迭代器进行tqdm封装，传入total参数来指明预计迭代次数</span></span><br><span class="line"><span class="comment"># https://ptorch.com/news/170.html</span></span><br><span class="line"><span class="comment"># 如果想选择dataframe某一行作为测试，可以参考dataframe各种索引方法</span></span><br><span class="line"><span class="comment"># https://www.jianshu.com/p/32bfb327bf07</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, rles <span class="keyword">in</span> tqdm(df_mask.iterrows(), total=<span class="built_in">len</span>(df_mask)):</span><br><span class="line">    <span class="built_in">print</span>(index)</span><br><span class="line">    img, mask = read_image(index)</span><br><span class="line">    shape = img.shape</span><br><span class="line">    tile_before_compress = compress * tile_size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算填充量，使得可以整除</span></span><br><span class="line">    pad0 = tile_before_compress - shape[<span class="number">0</span>] % tile_before_compress</span><br><span class="line">    pad1 = tile_before_compress - shape[<span class="number">1</span>] % tile_before_compress</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用0填充</span></span><br><span class="line">    <span class="comment"># https://numpy.org/doc/stable/reference/generated/numpy.pad.html</span></span><br><span class="line">    <span class="comment"># 对于img，x和y两个维度都填充，第三维度则不填充，所以第三维度设为(0, 0)</span></span><br><span class="line">    img = np.pad(img, ((pad0 // <span class="number">2</span>, pad0 - pad0 // <span class="number">2</span>), (pad1 // <span class="number">2</span>, pad1 - pad1 // <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>)), constant_values=<span class="number">0</span>)</span><br><span class="line">    mask = np.pad(mask, ((pad0 // <span class="number">2</span>, pad0 - pad0 // <span class="number">2</span>), (pad1 // <span class="number">2</span>, pad1 - pad1 // <span class="number">2</span>)), constant_values=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 压缩图像</span></span><br><span class="line">    img = cv2.resize(img, (img.shape[<span class="number">1</span>]//compress, img.shape[<span class="number">0</span>]//compress), interpolation = cv2.INTER_AREA)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将图像分块成tile大小</span></span><br><span class="line">    img = img.reshape(img.shape[<span class="number">0</span>] // tile_size, tile_size, img.shape[<span class="number">1</span>] // tile_size, tile_size, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将图像的通道调整顺序，横纵个数放在前面，然后让两者相乘，得到分块总个数</span></span><br><span class="line">    img = img.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>).reshape(-<span class="number">1</span>, tile_size, tile_size, <span class="number">3</span>)</span><br><span class="line">    mask = cv2.resize(mask, (mask.shape[<span class="number">1</span>]//compress, mask.shape[<span class="number">0</span>]//compress), interpolation = cv2.INTER_AREA)</span><br><span class="line">    mask = mask.reshape(mask.shape[<span class="number">0</span>] // tile_size, tile_size, mask.shape[<span class="number">1</span>] // tile_size, tile_size)</span><br><span class="line">    mask = mask.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).reshape(-<span class="number">1</span>, tile_size, tile_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用zip函数将img和mask中的元素打包在一块，统一调用</span></span><br><span class="line">    <span class="comment"># https://www.runoob.com/python3/python3-func-zip.html</span></span><br><span class="line">    <span class="keyword">for</span> i, (im, m) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(img, mask)):</span><br><span class="line">        x_tot.append((im / <span class="number">255.0</span>).reshape(-<span class="number">1</span>, <span class="number">3</span>).mean(<span class="number">0</span>))</span><br><span class="line">        x2_tot.append((im / <span class="number">255.0</span>).reshape(-<span class="number">1</span>, <span class="number">3</span>).mean(<span class="number">0</span>))</span><br><span class="line">        cv2.imwrite(OUT_IMG + <span class="string">f&#x27;<span class="subst">&#123;index&#125;</span>_<span class="subst">&#123;i&#125;</span>.png&#x27;</span>, cv2.cvtColor(im, cv2.COLOR_RGB2BGR))</span><br><span class="line">        cv2.imwrite(OUT_MASK + <span class="string">f&#x27;<span class="subst">&#123;index&#125;</span>_<span class="subst">&#123;i&#125;</span>.png&#x27;</span>, m)</span><br><span class="line"></span><br><span class="line">img_avr = np.array(x_tot).mean(<span class="number">0</span>)</span><br><span class="line">img_std = np.sqrt(np.array(x2_tot).mean(<span class="number">0</span>) - img_avr**<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mean: &quot;</span>, img_avr, <span class="string">&quot;, std:&quot;</span>, img_std)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>首先通过上面的get_model()加载模型，然后再定义一系列的必要步骤，包括优化器、损失评价等，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义Soft Dice Loss</span></span><br><span class="line"><span class="comment"># 网友总结了用于图像分割的常用的损失函数的PyTorch实现，见：</span></span><br><span class="line"><span class="comment"># https://github.com/JunMa11/SegLoss</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftDiceLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, smooth=<span class="number">1.</span>, dims=(<span class="params">-<span class="number">2</span>,-<span class="number">1</span></span>)</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SoftDiceLoss, self).__init__()</span><br><span class="line">        self.smooth = smooth</span><br><span class="line">        self.dims = dims</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        tp = (x * y).<span class="built_in">sum</span>(self.dims)</span><br><span class="line">        fp = (x * (<span class="number">1</span> - y)).<span class="built_in">sum</span>(self.dims)</span><br><span class="line">        fn = ((<span class="number">1</span> - x) * y).<span class="built_in">sum</span>(self.dims)</span><br><span class="line">        dc = (<span class="number">2</span> * tp + self.smooth) / (<span class="number">2</span> * tp + fp + fn + self.smooth)</span><br><span class="line">        dc = dc.mean()</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> - dc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数1</span></span><br><span class="line">bce_fn = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数2</span></span><br><span class="line">dice_fn = SoftDiceLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终损失是两种损失函数的加权平均</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_fn</span>(<span class="params">y_pred, y_true</span>):</span></span><br><span class="line">    bce = bce_fn(y_pred, y_true)</span><br><span class="line">    dice = dice_fn(y_pred.sigmoid(), y_true)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.8</span>*bce+ <span class="number">0.2</span>*dice</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在验证集上运行模型</span></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validation</span>(<span class="params">model, loader, loss_fn</span>):</span></span><br><span class="line">    losses = []</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> image, target <span class="keyword">in</span> loader:</span><br><span class="line">        image, target = image.to(DEVICE), target.<span class="built_in">float</span>().to(DEVICE)</span><br><span class="line">        output = model(image)[<span class="string">&#x27;out&#x27;</span>]</span><br><span class="line">        loss = loss_fn(output, target)</span><br><span class="line">        losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(losses).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">### 为了让中间输出结果好看，专门定制了一个显示效果</span></span><br><span class="line">header = <span class="string">r&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Train | Valid</span></span><br><span class="line"><span class="string">Epoch |  Loss |  Loss | Time, m</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#          Epoch         metrics            time</span></span><br><span class="line">raw_line = <span class="string">&#x27;&#123;:6d&#125;&#x27;</span> + <span class="string">&#x27;\u2502&#123;:7.3f&#125;&#x27;</span>*<span class="number">2</span> + <span class="string">&#x27;\u2502&#123;:6.2f&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line">best_loss = <span class="number">10</span></span><br><span class="line">EPOCHES = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始迭代训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, EPOCHES+<span class="number">1</span>):</span><br><span class="line">    losses = []</span><br><span class="line">    <span class="comment"># 计时开始</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这里显式地设置model是train模式，以使dropout和batchnorm等网络层中的参数不固定</span></span><br><span class="line">    <span class="comment"># 它仅仅是一个flag，与之类似的：model.eval()是设定eval模式，即这些网络层中的参数固定，以保证测试结果的可重复性</span></span><br><span class="line">    <span class="comment"># https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch</span></span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始在训练集数据中迭代</span></span><br><span class="line">    <span class="keyword">for</span> image, target <span class="keyword">in</span> loader:</span><br><span class="line">        image, target = image.to(DEVICE), target.<span class="built_in">float</span>().to(DEVICE)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(image)[<span class="string">&#x27;out&#x27;</span>]</span><br><span class="line">        loss = loss_fn(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在验证集上运行模型</span></span><br><span class="line">    vloss = validation(model, vloader, loss_fn)</span><br><span class="line">    <span class="built_in">print</span>(raw_line.<span class="built_in">format</span>(epoch, np.array(losses).mean(), vloss,</span><br><span class="line">                              (time.time()-start_time)/<span class="number">60</span>**<span class="number">1</span>))</span><br><span class="line">    losses = []</span><br><span class="line">    <span class="comment"># 及时地将最佳模型存储下来</span></span><br><span class="line">    <span class="keyword">if</span> vloss &lt; best_loss:</span><br><span class="line">        best_loss = vloss</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&#x27;model_best.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练结束后删除这些存储数据地变量，并回收内存</span></span><br><span class="line"><span class="keyword">del</span> loader, vloader, train_ds, valid_ds, ds</span><br><span class="line">gc.collect();</span><br></pre></td></tr></table></figure><p>训练完后的模型就开始接下来在上面的测试集上进行推导，并提交结果文件（注意在kaggle上提交时，可以把前面的训练过程去掉，直接提交训练好的模型）。</p>]]></content>
    
    
    <summary type="html">概览
赛事描述
Kaggle上正在进行一项名为“HuBMAP: Hacking the Kidney”的竞赛，链接见这里，总奖金是6万美金，该竞赛的目的是为了检测人体组织中的functional tissue units (FTUs)。FTU的定义是：three-dimensional block of cells centered around a capillary, such that each cell in this block is within diffusion distance from any other cell in the same block，感觉类似于细胞的概念，</summary>
    
    
    
    <category term="programming" scheme="http://qixinbo.github.io/categories/programming/"/>
    
    
    <category term="kaggle" scheme="http://qixinbo.github.io/tags/kaggle/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法笔记</title>
    <link href="http://qixinbo.github.io/2020/12/26/algorithm/"/>
    <id>http://qixinbo.github.io/2020/12/26/algorithm/</id>
    <published>2020-12-25T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.469Z</updated>
    
    <content type="html"><![CDATA[<p>本文是对极客时间app上王争老师的&lt;数据结构与算法之美&gt;的课堂笔记。</p><h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><p>算法与数据结构是编程的内功。</p><p>从广义上讲，数据结构就是指一组数据的存储和逻辑结构。算法就是操作数据的一组方法。</p><p>数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。 因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。（比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。）</p><p><img src="https://user-images.githubusercontent.com/6218739/100428771-548fb600-30cf-11eb-99f1-a46d7204f313.png" alt="base"></p><p><img src="https://user-images.githubusercontent.com/6218739/100430003-29a66180-30d1-11eb-9cf3-1e09f6111ded.png" alt="algo"></p><p>数据结构与算法中最重要的概念——复杂度分析：数据结构和算法解决的是如何更省、更快地存储和处理数据的问题，因此，我们就需要一个考量效率和资源消耗的方法，这就是复杂度分析方法。所以，如果你只掌握了数据结构和算法的特点、用法，但是没有学会复杂度分析，那就相当于只知道操作口诀，而没掌握心法。只有把心法了然于胸，才能做到无招胜有招！</p><h1 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h1><h2 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h2><p>时间复杂度：大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。</p><p>实际分析时间复杂度时就是计算代码执行次数。</p><p>（1）加法法则：总复杂度等于量级最大的那段代码的复杂度（如果两段代码复杂度无法事先评估，则此时需要两者复杂度相加）；</p><p>（2）乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。</p><p>常见复杂度量级（按数量级递增）：常数阶O(1)（只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度都记作 O(1)）、对数阶O(logn)、线性阶O(n)、线性对数阶O(nlogn)、平方阶O(n^2)、立方阶O(n^3)、…、k次方阶O(n^k)、指数阶O(2^n)、阶乘阶O(n!)。</p><p>为了表示代码在不同情况下的不同时间复杂度，需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。</p><p>最好情况时间复杂度（best case time complexity）：在最理想的情况下，执行这段代码的时间复杂度。</p><p>最坏情况时间复杂度（worst case time complexity）：在最糟糕的情况下，执行这段代码的时间复杂度。</p><p>平均情况时间复杂度（average case time complexity）：最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，使用平均情况时间复杂度，计算方法是将各种情况按权值加和，得到平均值，所以又称为加权平均时间复杂度或者期望时间复杂度。</p><p>实际上，在大多数情况下，并不需要区分最好、最坏、平均情况时间复杂度三种情况。很多时候，使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，才会使用这三种复杂度表示法来区分。</p><h2 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h2><p>空间复杂度全称是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。</p><p>常见的空间复杂度就是 O(1)、O(n)、O(n^2)。</p><p>空间复杂度是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。</p><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><p>数组结构有线性表Linear List和非线性表Nonlinear List之分。</p><p>线性表是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。数组、链表、队列、栈等是线性表结构。</p><p>在非线性表中，数据之间并不是简单的前后关系，比如二叉树、堆、图等。</p><h2 id="数组Array"><a href="#数组Array" class="headerlink" title="数组Array"></a>数组Array</h2><p>数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。</p><p>这两个特性使得数组可以“随机访问”，即数组适合“查找”，但同时也会造成低效的“插入”和“删除”。</p><p>插入操作：假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。这个处理思想在快排中也会用到。</p><p>删除操作：跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。这就是 JVM 标记清除垃圾回收算法的核心思想。</p><p>针对数组类型，很多语言都提供了容器类，比如 Java 中的 ArrayList、C++ STL 中的 vector。容器可以将很多数组操作的细节封装起来，且支持动态扩容。但数组也有优点，其作为基本数据结构，在极端情况下有性能优势。</p><p>为什么数组从0开始编号：从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。如果从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。另外一个原因是历史原因，C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。</p><h2 id="链表Linked-List"><a href="#链表Linked-List" class="headerlink" title="链表Linked List"></a>链表Linked List</h2><p>链表不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。内存块称为“结点”。</p><p>三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表。</p><p>单链表：为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。把这个记录下个结点地址的指针叫作后继指针 next。其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。但因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。</p><p>利用哨兵简化难度：把有哨兵结点的链表叫带头链表。相反，没有哨兵结点的链表就叫作不带头链表。如果引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。如果没有哨兵结点，针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。（实际上，这种利用哨兵简化编程难度的技巧，在很多代码实现中都有用到，比如插入排序、归并排序、动态规划等。）</p><p>循环链表：循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。</p><p>双向链表：双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。</p><p>从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。原因如下：</p><p>在实际的软件开发中，从链表中删除一个数据无外乎这两种情况：</p><p>（1）删除结点中“值等于某个给定值”的结点；</p><p>（2）删除给定指针指向的结点。</p><p>对于第一种情况，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过指针操作将其删除。尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。</p><p>对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p-&gt;next=q，说明 p 是 q 的前驱结点。但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。</p><p>除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。</p><p>因此，在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。这就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。</p><h2 id="跳表Skip-List"><a href="#跳表Skip-List" class="headerlink" title="跳表Skip List"></a>跳表Skip List</h2><p>链表加多级索引的结构，就是跳表。比如每两个结点提取一个结点到上一级，我们把抽出来的那一级叫做索引或索引层。</p><p>在跳表中查询任意数据的时间复杂度是 O(logn)，这个查找的时间复杂度跟二分查找是一样的。换句话说，其实是基于单链表实现了二分查找，不过这种查询效率的提升，前提是建立了很多级索引，也就是用空间换时间的设计思路。</p><p>跳表的空间复杂度是 O(n)。实际上，在软件开发中，我们不必太在意索引占用的额外空间。在讲数据结构和算法时，我们习惯性地把要处理的数据看成整数，但是在实际的软件开发中，原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略了。</p><p>实际上，跳表这个动态数据结构，不仅支持查找操作，还支持动态的插入、删除操作，而且插入、删除操作的时间复杂度也是 O(logn)。</p><p>因此，跳表是一种各方面性能都比较优秀的动态数据结构，可以支持快速地插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树（Red-black tree）。不过，跳表也不能完全替代红黑树。因为红黑树比跳表的出现要早一些，很多编程语言中的 Map 类型都是通过红黑树来实现的。我们做业务开发的时候，直接拿来用就可以了，不用费劲自己去实现一个红黑树，但是跳表并没有一个现成的实现，所以在开发中，如果你想使用跳表，必须要自己实现。</p><h2 id="栈Stack"><a href="#栈Stack" class="headerlink" title="栈Stack"></a>栈Stack</h2><p>后进者先出，先进者后出，这就是典型的“栈”结构。</p><p>事实上，从功能上来说，数组或链表确实可以替代栈，但特定的数据结构是对特定场景的抽象，而且，数组或链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然也就更容易出错。当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构。</p><p>栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作顺序栈，用链表实现的栈，我们叫作链式栈。</p><p>不管是顺序栈还是链式栈，我们存储数据只需要一个大小为 n 的数组就够了。在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度是 O(1)（注意，这里存储数据需要一个大小为 n 的数组，并不是说空间复杂度就是 O(n)。因为，这 n 个空间是必须的，无法省掉。）。</p><p>不管是顺序栈还是链式栈，入栈、出栈只涉及栈顶个别数据的操作，所以时间复杂度都是 O(1)。</p><p>栈在函数调用中的应用：操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。</p><p>栈在表达式求值中的应用：比如一个只包含加减乘除四则运算的算术表达式，编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。</p><p><img src="https://user-images.githubusercontent.com/6218739/100187781-c88d5b00-2f23-11eb-9b58-89281033ad3e.png" alt="stack"></p><p>栈在括号匹配中的应用：我们用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如“(”跟“)”匹配，“[”跟“]”匹配，“{”跟“}”匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。</p><p>内存中的堆栈和数据结构堆栈不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构。内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。</p><p>代码区：存储方法体的二进制代码。高级调度（作业调度）、中级调度（内存调度）、低级调度（进程调度）控制代码区执行代码的切换。</p><p>静态数据区：存储全局变量、静态变量、常量，常量包括final修饰的常量和String常量。系统自动分配和回收。</p><p>栈区：存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。</p><p>堆区：new一个对象的引用或地址存储在栈区，指向该对象存储在堆区中的真实数据。</p><h2 id="队列Queue"><a href="#队列Queue" class="headerlink" title="队列Queue"></a>队列Queue</h2><p>先进者先出，这就是典型的“队列”。</p><p>我们知道，栈只支持两个基本操作：入栈 push()和出栈 pop()。队列跟栈非常相似，支持的操作也很有限，最基本的操作也是两个：入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。</p><p>作为一种非常基础的数据结构，队列的应用也非常广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。</p><p>跟栈一样，队列可以用数组来实现，也可以用链表来实现。用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。</p><p>对于栈来说，我们只需要一个栈顶指针就可以了。但是实现队列需要两个指针：一个是 head 指针，指向队头；一个是 tail 指针，指向队尾。</p><p>用数组来实现队列的时候，在 tail==n 时，会有数据搬移操作，这样入队操作性能就会受到影响。此时可以使用循环队列（循环队列，顾名思义，它长得像一个环。原本数组是有头有尾的，是一条直线。现在我们把首尾相连，扳成了一个环。）。</p><p>一些在业务中常用的队列应用：</p><p>（1）阻塞队列：其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。上述的定义就是一个“生产者 - 消费者模型”。这种基于阻塞队列实现的“生产者 - 消费者模型”，可以有效地协调生产和消费的速度。当“生产者”生产数据的速度过快，“消费者”来不及消费时，存储数据的队列很快就会满了。这个时候，生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续“生产”。而且不仅如此，基于阻塞队列，我们还可以通过协调“生产者”和“消费者”的个数，来提高数据的处理效率。比如可以多配置几个“消费者”，来应对一个“生产者”。</p><p>（2）并发队列：线程安全的队列我们叫作并发队列。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。</p><p>对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。</p><p>有一种特殊的队列，称为优先级队列：优先级队列，顾名思义，它首先应该是一个队列。队列最大的特性就是先进先出。不过，在优先级队列中，数据的出队顺序不是先进先出，而是按照优先级来，优先级最高的，最先出队。优先级队列这一概念可以由下面的“堆”这一数据结构来高效实现。</p><h2 id="散列表Hash-Table"><a href="#散列表Hash-Table" class="headerlink" title="散列表Hash Table"></a>散列表Hash Table</h2><p>散列表，又称哈希表、Hash表，用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。</p><p>散列表用的就是数组支持按照下标随机访问时，时间复杂度是 O(1) 的特性。我们通过散列函数（或称哈希函数、Hash函数）把元素的键值key映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。</p><p>散列函数：散列函数，顾名思义，它是一个函数。我们可以把它定义成 hash(key)，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。</p><p>散列函数设计的三点基本要求：</p><p>（1）散列函数计算得到的散列值是一个非负整数（因为数组下标是从 0 开始的）；</p><p>（2）如果 key1 = key2，那 hash(key1) == hash(key2)；</p><p>（3）如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。</p><p>第三点要求看起来合情合理，但是在真实的情况下，要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的。即便像业界著名的MD5、SHA、CRC等哈希算法，也无法完全避免这种散列冲突。而且，因为数组的存储空间有限，也会加大散列冲突的概率。所以我们几乎无法找到一个完美的无冲突的散列函数，即便能找到，付出的时间成本、计算成本也是很大的，所以针对散列冲突问题，我们需要通过其他途径来解决。</p><p>常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。</p><p>（1）开放寻址法：开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。一个比较简单的重新探测新的位置的方法是线性探测（Linear Probing）。当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。</p><p>当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。</p><p>（2）链表法：链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。当插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)。当查找、删除一个元素时，我们同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。那查找或删除操作的时间复杂度跟链表的长度 k 成正比，也就是 O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。</p><p>基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。</p><p>散列表这种数据结构虽然支持非常高效的数据插入、删除、查找操作，但是散列表中的数据都是通过散列函数打乱之后无规律存储的。也就说，它无法支持按照某种顺序快速地遍历数据。如果希望按照顺序遍历散列表中的数据，那我们需要将散列表中的数据拷贝到数组中，然后排序，再遍历。因为散列表是动态数据结构，不停地有数据的插入、删除，所以每当我们希望按顺序遍历散列表中的数据的时候，都需要先排序，那效率势必会很低。为了解决这个问题，我们将散列表和链表（或者跳表）结合在一起使用。</p><h2 id="位图Bitmap"><a href="#位图Bitmap" class="headerlink" title="位图Bitmap"></a>位图Bitmap</h2><p>位图是一种比较“特殊”的散列表。</p><p>位图是用一个 bit 位来标记某个元素对应的 value， 而 key 即是该元素。由于采用了 bit 为单位来存储数据，因此在存储空间方面，可以大大节省。</p><h2 id="布隆过滤器Bloom-Filter"><a href="#布隆过滤器Bloom-Filter" class="headerlink" title="布隆过滤器Bloom Filter"></a>布隆过滤器Bloom Filter</h2><p>布隆过滤器是对位图数据结构的一种改进。</p><p>布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。</p><h2 id="树Tree"><a href="#树Tree" class="headerlink" title="树Tree"></a>树Tree</h2><p>树中的几个概念：树中的每个元素叫做“节点”；用来连接相邻节点之间的关系，叫做“父子关系”。没有父节点的节点叫做根节点。把没有子节点的节点叫做叶子节点或者叶节点。</p><p>节点的高度：该节点到叶子节点的最长路径（边数）；</p><p>节点的深度：根节点到该节点所经历的边的个数；</p><p>节点的层数：节点的深度+1；</p><p>树的高度：根节点的高度。</p><h3 id="二叉树Binary-Tree"><a href="#二叉树Binary-Tree" class="headerlink" title="二叉树Binary Tree"></a>二叉树Binary Tree</h3><p>二叉树，顾名思义，每个节点最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。不过，二叉树并不要求每个节点都有两个子节点，有的节点只有左子节点，有的节点只有右子节点。</p><p>除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树叫做满二叉树。</p><p>叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做完全二叉树。（堆其实就是一种完全二叉树，最常用的存储方式就是数组。）</p><p>有两种方法可用于存储一棵二叉树，一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法。对于链式存储：每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针，大部分二叉树代码都是通过这种结构来实现的；对于基于数组的顺序存储法：把根节点存储在下标 i = 1 的位置，那左子节点存储在下标 2 * i = 2 的位置，右子节点存储在 2 * i + 1 = 3 的位置，因此如果节点 X 存储在数组中下标为 i 的位置，下标为 2 * i 的位置存储的就是左子节点，下标为 2 * i + 1 的位置存储的就是右子节点。反过来，下标为 i/2 的位置存储就是它的父节点。通过这种方式，我们只要知道根节点存储的位置（一般情况下，为了方便计算子节点，根节点会存储在下标为 1 的位置），这样就可以通过下标计算，把整棵树都串起来。</p><p>对于完全二叉树，仅仅“浪费”了一个下标为 0 的存储位置。如果是非完全二叉树，其实会浪费比较多的数组存储空间。所以，如果某棵二叉树是一棵完全二叉树，那用数组存储无疑是最节省内存的一种方式。因为数组的存储方式并不需要像链式存储法那样，要存储额外的左右子节点的指针。这也是为什么完全二叉树会单独拎出来的原因，也是为什么完全二叉树要求最后一层的子节点都靠左的原因。</p><p>二叉树的遍历，经典的方法有三种，前序遍历、中序遍历和后序遍历。其中，前、中、后序，表示的是节点与它的左右子树节点遍历打印的先后顺序。</p><p>（1）前序遍历是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。</p><p>（2）中序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。</p><p>（3）后序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。</p><p>实际上，二叉树的前、中、后序遍历就是一个递归的过程。比如，前序遍历，其实就是先打印根节点，然后再递归地打印左子树，最后递归地打印右子树。二叉树遍历的时间复杂度是 O(n)。</p><h4 id="二叉查找树Binary-Search-Tree"><a href="#二叉查找树Binary-Search-Tree" class="headerlink" title="二叉查找树Binary Search Tree"></a>二叉查找树Binary Search Tree</h4><p>二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树。顾名思义，二叉查找树是为了实现快速查找而生的。不过，它不仅仅支持快速查找一个数据，还支持快速插入、删除一个数据。</p><p>这些都依赖于二叉查找树的特殊结构。二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。</p><p>散列表的插入、删除、查找操作的时间复杂度可以做到常量级的 O(1)，非常高效。而二叉查找树在比较平衡的情况下，插入、删除、查找操作时间复杂度才是 O(logn)，相对散列表，好像并没有什么优势，那我们为什么还要用二叉查找树呢？有下面几个原因：</p><p>（1）第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。</p><p>（2）第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。</p><p>（3）第三，笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。</p><p>（4）第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。</p><p>（5）最后，为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。</p><p>综合这几点，平衡二叉查找树在某些方面还是优于散列表的，所以，这两者的存在并不冲突。我们在实际的开发过程中，需要结合具体的需求来选择使用哪一个。</p><h4 id="红黑树Red-Black-Tree"><a href="#红黑树Red-Black-Tree" class="headerlink" title="红黑树Red-Black Tree"></a>红黑树Red-Black Tree</h4><p>平衡二叉树的严格定义（注意是严格定义）：二叉树中任意一个节点的左右子树的高度相差不能大于 1。</p><p>平衡二叉查找树不仅满足上面平衡二叉树的定义，还满足二叉查找树的特点。</p><p>最先被发明的平衡二叉查找树是AVL 树，它严格符合平衡二叉查找树的定义，即任何节点的左右子树高度相差不超过 1，是一种高度平衡的二叉查找树。但是很多平衡二叉查找树其实并没有严格符合上面的定义（树中任意一个节点的左右子树的高度相差不能大于 1），比如红黑树，它从根节点到各个叶子节点的最长路径，有可能会比最短路径大一倍。</p><p>发明平衡二叉查找树这类数据结构的初衷是，解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的问题。所以，平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。</p><p>所以，如果我们现在设计一个新的平衡二叉查找树，只要树的高度不比 log2n 大很多（比如树的高度仍然是对数量级的），尽管它不符合我们前面讲的严格的平衡二叉查找树的定义，但我们仍然可以说，这是一个合格的平衡二叉查找树。</p><p>红黑树的英文是“Red-Black Tree”，简称 R-B Tree。它是一种不严格的平衡二叉查找树。红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求：</p><p>（1）根节点是黑色的；</p><p>（2）每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；</p><p>（3）任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；</p><p>（4）每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点。</p><p>它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。因为红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是用到动态插入、删除、查找数据的场景，都可以用到它。</p><h4 id="堆Heap"><a href="#堆Heap" class="headerlink" title="堆Heap"></a>堆Heap</h4><p>堆是一种特殊的树。只要满足这两点，它就是一个堆：</p><p>（1）堆是一个完全二叉树；</p><p>（2）堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。</p><p>对于每个节点的值都大于等于子树中每个节点值的堆，叫做“大顶堆”。对于每个节点的值都小于等于子树中每个节点值的堆，叫做“小顶堆”。</p><p>往堆中插入一个元素和删除堆顶元素的时间复杂度都是 O(logn)。</p><p>最直接、最高效的实现优先级队列的方法是使用堆。这是因为，堆和优先级队列非常相似。一个堆就可以看作一个优先级队列。很多时候，它们只是概念上的区分而已。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。</p><h3 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h3><p>B+树是一种数据结构，是一个N叉排序树，每个节点通常有多个孩子，一棵B+树包含根节点、内部节点和叶子节点。根节点可能是一个叶子节点， 也可能是一个包含两个或两个以上孩子节点的节点。</p><p>B+树通常用于数据库和操作系统的文件系统中。NTFS、ReiserFS、NSS、XFS、JFS、ReFS和BFS等文件系统都在使用B+树作为元数据索引。B+树的特点是能够保持数据稳定有序， 其插入与修改拥有较稳定的对数时间复杂度。B+树元素自底向上插入。</p><h2 id="图Graph"><a href="#图Graph" class="headerlink" title="图Graph"></a>图Graph</h2><p>图中的元素叫做顶点（vertex）。图中的一个顶点可以与任意其他顶点建立连接关系，这种建立的关系叫做边（edge）。跟顶点相连接的边的条数，叫做顶点的度（degree）。</p><p>边有方向的图叫做“有向图”。边没有方向的图叫做“无向图”。</p><p>在有向图中，把度分为入度（In-degree）和出度（Out-degree）。顶点的入度，表示有多少条边指向这个顶点；顶点的出度，表示有多少条边是以这个顶点为起点指向其他顶点。</p><p>有一种特别的图，称为带权图（weighted graph）。在带权图中，每条边都有一个权重（weight）。</p><p>在内存中存储图这种数据结构的方法有：</p><p>（1）邻接矩阵存储方法：图最直观的一种存储方法就是，邻接矩阵（Adjacency Matrix）。邻接矩阵的底层依赖一个二维数组。对于无向图来说，如果顶点 i 与顶点 j 之间有边，我们就将 A[i][j]和 A[j][i]标记为 1；对于有向图来说，如果顶点 i 到顶点 j 之间，有一条箭头从顶点 i 指向顶点 j 的边，那我们就将 A[i][j]标记为 1。同理，如果有一条箭头从顶点 j 指向顶点 i 的边，我们就将 A[j][i]标记为 1。对于带权图，数组中就存储相应的权重。</p><p>优点：首先，邻接矩阵的存储方式简单、直接，因为基于数组，所以在获取两个顶点的关系时，就非常高效。其次，用邻接矩阵存储图的另外一个好处是方便计算。这是因为，用邻接矩阵的方式存储图，可以将很多图的运算转换成矩阵之间的运算。</p><p>缺点：如果存储的是稀疏图（Sparse Matrix），即顶点很多，但每个顶点的边并不多，那邻接矩阵的存储方法就更加浪费空间了。</p><p>（2）邻接表存储方法：每个顶点对应一条链表，链表中存储的是与这个顶点相连接的其他顶点。尽管邻接表的存储方式比较节省存储空间，但链表不方便查找，所以查询效率没有邻接矩阵存储方式高。</p><p>可以将邻接表中的链表改成平衡二叉查找树。实际开发中，我们可以选择用红黑树。这样，我们就可以更加快速地查找两个顶点之间是否存在边了。当然，这里的二叉查找树可以换成其他动态数据结构，比如跳表、散列表等。除此之外，我们还可以将链表改成有序动态数组，可以通过二分查找的方法来快速定位两个顶点之间否是存在边。</p><h2 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a>Trie树</h2><p>Trie 树，也叫“字典树”。顾名思义，它是一个树形结构（多叉树）。它是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。</p><p>Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起。其中，根节点不包含任何信息。每个节点表示一个字符串中的字符，从根节点到红色节点的一条路径表示一个字符串（注意：红色节点并不都是叶子节点）。</p><p>字符串的匹配问题，笼统上讲，其实就是数据的查找问题。对于支持动态数据高效操作的数据结构，有散列表、红黑树、跳表等等。实际上，这些数据结构也可以实现在一组字符串中查找字符串的功能。而Trie 树实际上对要处理的字符串有极其严苛的要求：</p><p>（1）第一，字符串中包含的字符集不能太大。如果字符集太大，那存储空间可能就会浪费很多。即便可以优化，但也要付出牺牲查询、插入效率的代价。</p><p>（2）第二，要求字符串的前缀重合比较多，不然空间消耗会变大很多。</p><p>（3）第三，如果要用 Trie 树解决问题，那就要自己从零开始实现一个 Trie 树，还要保证没有 bug，这个在工程上是将简单问题复杂化，除非必须，一般不建议这样做。</p><p>（4）第四，通过指针串起来的数据块是不连续的，而 Trie 树中用到了指针，所以，对缓存并不友好，性能上会打个折扣。</p><p>综合这几点，针对在一组字符串中查找字符串的问题，在工程中更倾向于用散列表或者红黑树。因为这两种数据结构，都不需要自己去实现，直接利用编程语言中提供的现成类库就行了。实际上，Trie 树不适合精确匹配查找，这种问题更适合用散列表或者红黑树来解决。Trie 树比较适合的是查找前缀匹配的字符串，比如搜索引擎的关键词提示。</p><h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><h2 id="递归Recursion"><a href="#递归Recursion" class="headerlink" title="递归Recursion"></a>递归Recursion</h2><p>写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。</p><p>在实际的软件开发中，编写递归代码时，需要注意的问题有：</p><p>（1）递归代码要警惕堆栈溢出：在“栈”那一节讲过，函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。</p><p>（2）递归代码要警惕重复计算：比如想要计算 f(5)，需要先计算 f(4) 和 f(3)，而计算 f(4) 还需要计算 f(3)，因此，f(3) 就被计算了很多次，这就是重复计算问题。为了避免重复计算，我们可以通过一个数据结构（比如散列表）来保存已经求解过的 f(k)。当递归调用到 f(k) 时，先看下是否已经求解过了。如果是，则直接从散列表中取值返回，不需要重复计算，这样就能避免刚讲的问题了。</p><h2 id="哈希Hash"><a href="#哈希Hash" class="headerlink" title="哈希Hash"></a>哈希Hash</h2><p>将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。</p><p>一个优秀的哈希算法需要满足的几点要求：</p><p>（1）从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；</p><p>（2）对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；</p><p>（3）散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小（不可能完全不冲突，因为哈希算法产生的哈希值的长度是固定且有限的，而要哈希的数据是无穷的。）；</p><p>（4）哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。</p><p>之前的散列函数中也用到了哈希算法，不过散列函数对于散列算法冲突的要求要低很多。即便出现个别散列冲突，只要不是过于严重，我们都可以通过开放寻址法或者链表法解决。不仅如此，散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，也就是，一组数据是否能均匀地散列在各个槽中。除此之外，散列函数执行的快慢，也会影响散列表的性能，所以，散列函数用的散列算法一般都比较简单，比较追求效率。</p><h2 id="排序Sort"><a href="#排序Sort" class="headerlink" title="排序Sort"></a>排序Sort</h2><h3 id="冒泡排序Bubble-Sort"><a href="#冒泡排序Bubble-Sort" class="headerlink" title="冒泡排序Bubble Sort"></a>冒泡排序Bubble Sort</h3><p>冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。</p><p>冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为 O(1)，是一个原地排序算法。</p><p>在冒泡排序中，只有交换才可以改变两个元素的前后顺序。为了保证冒泡排序算法的稳定性，当有相邻的两个元素大小相等的时候，我们不做交换，相同大小的数据在排序前后不会改变顺序，所以冒泡排序是稳定的排序算法。</p><p>最好情况下，要排序的数据已经是有序的了，我们只需要进行一次冒泡操作，就可以结束了，所以最好情况时间复杂度是 O(n)。而最坏的情况是，要排序的数据刚好是倒序排列的，我们需要进行 n 次冒泡操作，所以最坏情况时间复杂度为 O(n2)。平均情况下的时间复杂度就是 O(n2)。</p><h3 id="插入排序Insertion-Sort"><a href="#插入排序Insertion-Sort" class="headerlink" title="插入排序Insertion Sort"></a>插入排序Insertion Sort</h3><p>首先，我们将数组中的数据分为两个区间，已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束。</p><p>从实现过程可以很明显地看出，插入排序算法的运行并不需要额外的存储空间，所以空间复杂度是 O(1)，也就是说，这是一个原地排序算法。</p><p>在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现元素的后面，这样就可以保持原有的前后顺序不变，所以插入排序是稳定的排序算法。</p><p>如果要排序的数据已经是有序的，我们并不需要搬移任何数据。如果我们从尾到头在有序数据组里面查找插入位置，每次只需要比较一个数据就能确定插入的位置。所以这种情况下，最好是时间复杂度为 O(n)。注意，这里是从尾到头遍历已经有序的数据。如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，所以最坏情况时间复杂度为 O(n2)。因为在数组中插入一个数据的平均时间复杂度是 O(n)，所以，对于插入排序来说，每次插入操作都相当于在数组中插入一个数据，循环执行 n 次插入操作，所以平均时间复杂度为 O(n2)。</p><p>虽然冒泡排序和插入排序在时间复杂度上是一样的，都是 O(n2)，但是如果我们希望把性能优化做到极致，那肯定首选插入排序。</p><h3 id="选择排序Selection-Sort"><a href="#选择排序Selection-Sort" class="headerlink" title="选择排序Selection Sort"></a>选择排序Selection Sort</h3><p>选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。</p><p>选择排序空间复杂度为 O(1)，是一种原地排序算法。选择排序的最好情况时间复杂度、最坏情况和平均情况时间复杂度都为 O(n2)。</p><p>选择排序是一种不稳定的排序算法。因为选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样破坏了稳定性。</p><h3 id="归并排序Merge-Sort"><a href="#归并排序Merge-Sort" class="headerlink" title="归并排序Merge Sort"></a>归并排序Merge Sort</h3><p>如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。</p><p>归并排序使用的就是分治思想。分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。</p><p>归并排序是一个稳定的排序算法。</p><p>归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)。</p><p>归并排序不是原地排序算法，空间复杂度是 O(n)。</p><h3 id="快速排序Quick-Sort"><a href="#快速排序Quick-Sort" class="headerlink" title="快速排序Quick Sort"></a>快速排序Quick Sort</h3><p>快排的思想是这样的：如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。根据分治、递归的处理思想，我们可以用递归排序下标从 p 到 q-1 之间的数据和下标从 q+1 到 r 之间的数据，直到区间缩小为 1，就说明所有的数据都有序了。</p><p>快速排序并不是一个稳定的排序算法。</p><p>快排和归并的区别：可以发现，归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法。我们前面讲过，归并之所以是非原地排序算法，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。</p><p>在大部分情况下的时间复杂度都可以做到 O(nlogn)，只有在极端情况下，才会退化到 O(n2)。</p><p>以下三种算法：桶排序、计数排序、基数排序，时间复杂度都是 O(n)。因为这些排序算法的时间复杂度是线性的，所以我们把这类排序算法叫作线性排序（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。</p><h3 id="桶排序Bucket-Sort"><a href="#桶排序Bucket-Sort" class="headerlink" title="桶排序Bucket Sort"></a>桶排序Bucket Sort</h3><p>桶排序，顾名思义，会用到“桶”，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。</p><p>桶排序对要排序数据的要求是非常苛刻的：首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。</p><p>桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。</p><h3 id="计数排序Counting-Sort"><a href="#计数排序Counting-Sort" class="headerlink" title="计数排序Counting Sort"></a>计数排序Counting Sort</h3><p>计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。</p><p>计数排序的名称来源于其利用另外一个数组来计数的实现方式。</p><p>计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。</p><h3 id="基数排序Radix-Sort"><a href="#基数排序Radix-Sort" class="headerlink" title="基数排序Radix Sort"></a>基数排序Radix Sort</h3><p>以对11位的手机号码排序为例：先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。</p><p>基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。</p><h3 id="堆排序Heap-Sort"><a href="#堆排序Heap-Sort" class="headerlink" title="堆排序Heap Sort"></a>堆排序Heap Sort</h3><p>借助于堆这种数据结构实现的排序算法，叫做堆排序。</p><p>整个堆排序的过程，都只需要极个别临时存储空间，所以堆排序是原地排序算法。堆排序包括建堆和排序两个操作，建堆过程的时间复杂度是 O(n)，排序过程的时间复杂度是 O(nlogn)，所以，堆排序整体的时间复杂度是 O(nlogn)。堆排序不是稳定的排序算法，因为在排序的过程，存在将堆的最后一个节点跟堆顶节点互换的操作，所以就有可能改变值相同数据的原始相对顺序。</p><h3 id="如何实现一个通用的、高性能的排序函数"><a href="#如何实现一个通用的、高性能的排序函数" class="headerlink" title="如何实现一个通用的、高性能的排序函数"></a>如何实现一个通用的、高性能的排序函数</h3><p>为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 O(nlogn) 的排序算法来实现排序函数。</p><p>时间复杂度是 O(nlogn) 的排序算法不止一个，比如归并排序、快速排序，以及后面的堆排序。虽然归并排序可以做到平均情况、最坏情况下的时间复杂度都是 O(nlogn)，但归并排序并不是原地排序算法，空间复杂度是 O(n)，所以它不太适合作为通用排序函数（Glibc中的qsort()函数在数据量小时会优先使用归并排序来排序输入数据，排序的数据量比较大的时候，qsort() 会改为用快速排序算法来排序，实际上，当要排序的区间中，元素的个数小于等于 4 时，qsort() 就退化为插入排序，不再继续用递归来做快速排序）。堆排序和快速排序都有比较多的应用，比如 Java 语言采用堆排序实现排序函数，C 语言使用快速排序实现排序函数。</p><p>快速排序有两个问题：</p><p>（1）最坏情况下快速排序的时间复杂度是 O(n^2)，这种 O(n^2) 时间复杂度出现的主要原因还是因为分区点选得不够合理。最理想的分区点是：被分区点分开的两个分区中，数据的数量差不多。比较常用、比较简单的分区算法有：一个是三数取中法：从区间的首、尾、中间，分别取出一个数，然后对比大小，取这 3 个数的中间值作为分区点。这样每间隔某个固定的长度，取数据出来比较，将中间值作为分区点的分区算法，肯定要比单纯取某一个数据更好。但是，如果要排序的数组比较大，那“三数取中”可能就不够了，可能要“五数取中”或者“十数取中”。另一个是随机法：随机法就是每次从要排序的区间中，随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好，但是从概率的角度来看，也不大可能会出现每次分区点都选得很差的情况，所以平均情况下，这样选的分区点是比较好的。时间复杂度退化为最糟糕的 O(n2) 的情况，出现的可能性不大。</p><p>（2）快速排序是用递归来实现的，而递归要警惕堆栈溢出。为了避免快速排序里，递归过深而堆栈过小，导致堆栈溢出，我们有两种解决办法：第一种是限制递归深度。一旦递归过深，超过了我们事先设定的阈值，就停止递归。第二种是通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。</p><h2 id="二分查找Binary-Search"><a href="#二分查找Binary-Search" class="headerlink" title="二分查找Binary Search"></a>二分查找Binary Search</h2><p>二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。</p><p>二分查找应用场景的局限性：</p><p>首先，二分查找依赖的是顺序表结构，简单点说就是数组，主要原因是二分查找算法需要按照下标随机访问元素；</p><p>其次，二分查找针对的是有序数据。如果数据没有序，我们需要先排序。如果我们针对的是一组静态的数据，没有频繁地插入、删除，我们可以进行一次排序，多次二分查找。这样排序的成本可被均摊，二分查找的边际成本就会比较低。但是，如果我们的数据集合有频繁的插入和删除操作，要想用二分查找，要么每次插入、删除操作之后保证数据仍然有序，要么在每次二分查找之前都先进行排序。针对这种动态数据集合，无论哪种方法，维护有序的成本都是很高的。</p><p>再次，数据量太小不适合二分查找。如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。</p><p>最后，数据量太大也不适合二分查找。二分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。</p><p>大部分情况下，用二分查找可以解决的问题，用散列表、二叉树这些支持快速查找的动态数据结构都可以解决。但是，不管是散列表还是二叉树，都会需要比较多的额外的内存空间。而二分查找底层依赖的是数组，除了数据本身之外，不需要额外存储其他信息，是最省内存空间的存储方式，所以如果内存受限，则可能只能应用二分查找。</p><h2 id="优先搜索First-Search"><a href="#优先搜索First-Search" class="headerlink" title="优先搜索First Search"></a>优先搜索First Search</h2><p>优先搜索算法是基于“图”这种数据结构的。这是因为，图这种数据结构的表达能力很强，大部分涉及搜索的场景都可以抽象成“图”。</p><p>图上的搜索算法，最直接的理解就是，在图中找出从一个顶点出发，到另一个顶点的路径。具体方法有很多，比如最简单、最“暴力”的深度优先、广度优先搜索，还有 A<em>、IDA</em> 等启发式搜索算法。</p><h3 id="广度优先搜索Breadth-First-Search"><a href="#广度优先搜索Breadth-First-Search" class="headerlink" title="广度优先搜索Breadth First Search"></a>广度优先搜索Breadth First Search</h3><p>广度优先搜索（Breadth-First-Search），简称 BFS。直观地讲，它其实就是一种“地毯式”层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索。</p><p>广度优先搜索需要借助队列来实现，遍历得到的路径就是，起始顶点到终止顶点的最短路径。</p><p>广度优先搜索的时间复杂度是 O(V+E)，其中，V 表示顶点的个数，E 表示边的个数，空间复杂度是 O(V)。</p><h3 id="深度优先搜索Depth-First-Search"><a href="#深度优先搜索Depth-First-Search" class="headerlink" title="深度优先搜索Depth First Search"></a>深度优先搜索Depth First Search</h3><p>深度优先搜索（Depth-First-Search），简称 DFS。最直观的例子就是“走迷宫”。</p><p>假设你站在迷宫的某个岔路口，然后想找到出口。你随意选择一个岔路口来走，走着走着发现走不通的时候，你就回退到上一个岔路口，重新选择一条路继续走，直到最终找到出口。这种走法就是一种深度优先搜索策略。</p><p>实际上，深度优先搜索用的是一种比较著名的回溯思想。这种思想解决问题的过程，非常适合用递归来实现。换种说法，深度优先搜索是借助栈来实现的。</p><p>图上的深度优先搜索算法的时间复杂度是 O(E)，E 表示边的个数，空间复杂度就是 O(V)，V表示顶点的个数 。</p><h2 id="字符串匹配String-Match"><a href="#字符串匹配String-Match" class="headerlink" title="字符串匹配String Match"></a>字符串匹配String Match</h2><p>主串和模式串：比如在字符串 A 中查找字符串 B，那字符串 A 就是主串，字符串 B 就是模式串。把主串的长度记作 n，模式串的长度记作 m。因为是在主串中查找模式串，所以 n&gt;m。</p><p>单模式串匹配算法，是在一个模式串和一个主串之间进行匹配，也就是说，在一个主串中查找一个模式串。包括下面的BF 算法、RK 算法、BM 算法、KMP 算法。</p><p>多模式串匹配算法，就是在多个模式串和一个主串之间做匹配，也就是说，在一个主串中查找多个模式串。包括下面的Trie树算法、AC自动机等。</p><h3 id="暴力匹配Brute-Force"><a href="#暴力匹配Brute-Force" class="headerlink" title="暴力匹配Brute Force"></a>暴力匹配Brute Force</h3><p>暴力匹配算法，简称为BF算法，也叫朴素匹配算法。从名字可以看出，这种算法的字符串匹配方式很“暴力”，当然也就会比较简单、好懂，但相应的性能也不高。</p><p>作为最简单、最暴力的字符串匹配算法，BF 算法的思想可以用一句话来概括，那就是，在主串中，检查起始位置分别是 0、1、2…n-m 且长度为 m 的 n-m+1 个子串，看有没有跟模式串匹配的。</p><p>尽管理论上，BF 算法的时间复杂度很高，是 O(n*m)，但在实际的开发中，它却是一个比较常用的字符串匹配算法。原因有两点：</p><p>（1）第一，实际的软件开发中，大部分情况下，模式串和主串的长度都不会太长。而且每次模式串与主串中的子串匹配的时候，当中途遇到不能匹配的字符的时候，就可以就停止了，不需要把 m 个字符都比对一下。所以，尽管理论上的最坏情况时间复杂度是 O(n*m)，但是，统计意义上，大部分情况下，算法执行效率要比这个高很多。</p><p>（2）第二，朴素字符串匹配算法思想简单，代码实现也非常简单。简单意味着不容易出错，如果有 bug 也容易暴露和修复。在工程中，在满足性能要求的前提下，简单是首选。这也是常说的KISS（Keep it Simple and Stupid）设计原则。</p><h3 id="RK算法"><a href="#RK算法" class="headerlink" title="RK算法"></a>RK算法</h3><p>RK 算法的全称叫 Rabin-Karp 算法，是由它的两位发明者 Rabin 和 Karp 的名字来命名的。它其实就是BF 算法的升级版。</p><p>在BF算法中，每次检查主串与子串是否匹配，需要依次比对每个字符，所以 BF 算法的时间复杂度就比较高，是 O(n*m)。RK算法则对朴素的字符串匹配算法稍加改造，引入哈希算法，时间复杂度立刻就会降低。</p><p>RK 算法的思路：通过哈希算法对主串中的 n-m+1 个子串分别求哈希值，然后逐个与模式串的哈希值比较大小。如果某个子串的哈希值与模式串相等，那就说明对应的子串和模式串匹配了（这里先不考虑哈希冲突的问题）。因为哈希值是一个数字，数字之间比较是否相等是非常快速的，所以模式串和子串比较的效率就提高了。</p><p>理想情况下，RK 算法的时间复杂度是 O(n)，跟 BF 算法相比，效率提高了很多。不过这样的效率取决于哈希算法的设计方法，如果存在冲突的情况下，时间复杂度可能会退化。极端情况下，哈希算法大量冲突，时间复杂度就退化为 O(n*m)。</p><h3 id="BM算法"><a href="#BM算法" class="headerlink" title="BM算法"></a>BM算法</h3><p>BM（Boyer-Moore）算法是一种非常高效的字符串匹配算法，有实验统计，它的性能是著名的KMP 算法的 3 到 4 倍。</p><p>BM 算法的核心思想：把模式串和主串的匹配过程，看作模式串在主串中不停地往后滑动。当遇到不匹配的字符时，BF 算法和 RK 算法的做法是，模式串往后滑动一位，然后从模式串的第一个字符开始重新匹配。而BM 算法是在模式串与主串匹配的过程中，当模式串和主串某个字符不匹配的时候，能够跳过一些肯定不会匹配的情况，将模式串往后多滑动几位。</p><h3 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a>KMP算法</h3><p>在所有的字符串匹配算法里，最知名的一种非 KMP 算法莫属。很多时候，提到字符串匹配，首先想到的就是 KMP 算法。</p><p>KMP 算法是根据三位作者（D.E.Knuth，J.H.Morris 和 V.R.Pratt）的名字来命名的，算法的全称是 Knuth Morris Pratt 算法，简称为 KMP 算法。</p><p>KMP 算法的核心思想，跟 BM 算法非常相近，都是根据规律在遇到坏字符的时候，把模式串往后多滑动几位。</p><h3 id="Trie树算法"><a href="#Trie树算法" class="headerlink" title="Trie树算法"></a>Trie树算法</h3><p>Trie 树是一种解决字符串快速匹配问题的数据结构。如果用来构建 Trie 树的这一组字符串中，前缀重复的情况不是很多，那 Trie 树这种数据结构总体上来讲是比较费内存的，是一种空间换时间的解决问题思路。尽管比较耗费内存，但是对内存不敏感或者内存消耗在接受范围内的情况下，在 Trie 树中做字符串匹配还是非常高效的，时间复杂度是 O(k)，k 表示要匹配的字符串的长度。但是，Trie 树的优势并不在于，用它来做动态集合数据的查找，因为，这个工作完全可以用更加合适的散列表或者红黑树来替代。Trie 树最有优势的是查找前缀匹配的字符串，比如搜索引擎中的关键词提示功能这个场景，就比较适合用它来解决，也是 Trie 树比较经典的应用场景。</p><h3 id="AC自动机"><a href="#AC自动机" class="headerlink" title="AC自动机"></a>AC自动机</h3><p>AC 自动机算法，全称是 Aho-Corasick 算法。</p><p>AC 自动机实际上就是在 Trie 树之上，加了类似 KMP 的 next 数组，只不过此处的 next 数组是构建在树上罢了。</p><h2 id="贪心算法Greedy-Algorithm"><a href="#贪心算法Greedy-Algorithm" class="headerlink" title="贪心算法Greedy Algorithm"></a>贪心算法Greedy Algorithm</h2><p>贪心算法有很多经典的应用，比如霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法。</p><p>贪心算法解决问题的步骤：</p><p>（1）第一步，当我们看到这类问题的时候，首先要联想到贪心算法：针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。</p><p>（2）第二步，我们尝试看下这个问题是否可以用贪心算法解决：每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。</p><p>（3）第三步，我们举几个例子看下贪心算法产生的结果是否是最优的。大部分情况下，举几个例子验证一下就可以了。严格地证明贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。而且，从实践的角度来说，大部分能用贪心算法解决的问题，贪心算法的正确性都是显而易见的，也不需要严格的数学推导证明。</p><p>实际上，用贪心算法解决问题的思路，并不总能给出最优解。主要原因是，前面的选择，会影响后面的选择。</p><p>贪心算法的最难的一块是如何将要解决的问题抽象成贪心算法模型，只要这一步搞定之后，贪心算法的编码一般都很简单。</p><h2 id="分治算法Divide-and-Conquer"><a href="#分治算法Divide-and-Conquer" class="headerlink" title="分治算法Divide and Conquer"></a>分治算法Divide and Conquer</h2><p>分治算法（divide and conquer）的核心思想其实就是四个字，分而治之 ，也就是将原问题划分成 n 个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。</p><p>这个定义看起来有点类似递归的定义。关于分治和递归的区别，分治算法是一种处理问题的思想，递归是一种编程技巧。实际上，分治算法一般都比较适合用递归来实现。分治算法的递归实现中，每一层递归都会涉及这样三个操作：</p><p>（1）分解：将原问题分解成一系列子问题；</p><p>（2）解决：递归地求解各个子问题，若子问题足够小，则直接求解；</p><p>（3）合并：将子问题的结果合并成原问题。</p><p>分治算法能解决的问题，一般需要满足下面这几个条件：</p><p>（1）原问题与分解成的小问题具有相同的模式；</p><p>（2）原问题分解成的子问题可以独立求解，子问题之间没有相关性，这一点跟动态规划有明显区别；</p><p>（3）具有分解终止条件，也就是说，当问题足够小时，可以直接求解；</p><p>（4）可以将子问题合并成原问题，而这个合并操作的复杂度不能太高，否则就起不到减小算法总体复杂度的效果了。</p><p>两种分治算法的典型的应用场景，一个是用来指导编码，降低问题求解的时间复杂度，另一个是解决海量数据处理问题。比如 MapReduce 本质上就是利用了分治思想。</p><h2 id="回溯算法Backtracking-Algorithm"><a href="#回溯算法Backtracking-Algorithm" class="headerlink" title="回溯算法Backtracking Algorithm"></a>回溯算法Backtracking Algorithm</h2><p>回溯的处理思想，有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。</p><p>回溯算法的思想非常简单，大部分情况下，都是用来解决广义的搜索问题，也就是，从一组可能的解中，选择出一个满足要求的解。回溯算法非常适合用递归来实现，在实现的过程中，剪枝操作是提高回溯效率的一种技巧。利用剪枝，我们并不需要穷举搜索所有的情况，从而提高搜索效率。</p><p>尽管回溯算法的原理非常简单，但是却可以解决很多问题，比如我们开头提到的深度优先搜索、八皇后、0-1 背包问题、图的着色、旅行商问题、数独、全排列、正则表达式匹配等等。</p><h2 id="动态规划Dynamic-Programming"><a href="#动态规划Dynamic-Programming" class="headerlink" title="动态规划Dynamic Programming"></a>动态规划Dynamic Programming</h2><p>动态规划所能解决的问题可以总结为“一个模型三个特征”：</p><p>（1）一个模型：它指的是动态规划适合解决的问题的模型，可定义为“多阶段决策最优解模型”。一般是用动态规划来解决最优问题。而解决问题的过程，需要经历多个决策阶段。每个决策阶段都对应着一组状态。然后寻找一组决策序列，经过这组决策序列，能够产生最终期望求解的最优值。</p><p>（2）三个特征：分别是最优子结构、无后效性和重复子问题。</p><p>（2.1）最优子结构：最优子结构指的是问题的最优解包含子问题的最优解。反过来说就是，可以通过子问题的最优解，推导出问题的最优解。如果把最优子结构对应到前面定义的动态规划问题模型上，也可以理解为，后面阶段的状态可以通过前面阶段的状态推导出来。</p><p>（2.2）无后效性：无后效性有两层含义，第一层含义是，在推导后面阶段的状态的时候，只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。第二层含义是，某阶段状态一旦确定，就不受之后阶段的决策影响。无后效性是一个非常“宽松”的要求。只要满足前面提到的动态规划问题模型，其实基本上都会满足无后效性。</p><p>（2.3）重复子问题：不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。</p><p>解决动态规划问题，一般有两种思路：状态转移表法和状态转移方程法。</p><p>（1）状态转移表法：</p><p>一般能用动态规划解决的问题，都可以使用回溯算法的暴力搜索解决。所以，当拿到问题的时候，可以先用简单的回溯算法解决，然后定义状态，每个状态表示一个节点，然后对应画出递归树。从递归树中，很容易可以看出来是否存在重复子问题，以及重复子问题是如何产生的。以此来寻找规律，看是否能用动态规划解决。找到重复子问题之后，接下来，有两种处理思路，第一种是直接用回溯加“备忘录”的方法，来避免重复子问题。从执行效率上来讲，这跟动态规划的解决思路没有差别。第二种是使用动态规划的解决方法，状态转移表法。</p><p>状态转移表法解题思路大致可以概括为：回溯算法实现 - 定义状态 - 画递归树 - 找重复子问题 - 画状态转移表 - 根据递推关系填表 - 将填表过程翻译成代码。</p><p>（2）状态转移方程法：</p><p>状态转移方程法有点类似递归的解题思路。需要分析某个问题如何通过子问题来递归求解，也就是所谓的最优子结构。根据最优子结构，写出递归公式，也就是所谓的状态转移方程。有了状态转移方程，代码实现就非常简单了。一般情况下，有两种代码实现方法，一种是递归加“备忘录”，另一种是迭代递推。</p><p>状态转移方程法的大致思路可以概括为，找最优子结构 - 写状态转移方程 - 将状态转移方程翻译成代码。</p><h3 id="四种算法对比"><a href="#四种算法对比" class="headerlink" title="四种算法对比"></a>四种算法对比</h3><p>贪心、回溯、动态规划可以解决的问题模型类似，都可以抽象成多阶段决策最优解模型。尽管分治算法也能解决最优问题，但是大部分问题的背景都不适合抽象成多阶段决策模型。</p><p>（1）回溯算法是个“万金油”。基本上能用的动态规划、贪心解决的问题，都可以用回溯算法解决。回溯算法相当于穷举搜索。穷举所有的情况，然后对比得到最优解。不过，回溯算法的时间复杂度非常高，是指数级别的，只能用来解决小规模数据的问题。对于大规模数据的问题，用回溯算法解决的执行效率就很低了。</p><p>（2）尽管动态规划比回溯算法高效，但是，并不是所有问题，都可以用动态规划来解决。能用动态规划解决的问题，需要满足三个特征，最优子结构、无后效性和重复子问题。在重复子问题这一点上，动态规划和分治算法的区分非常明显。分治算法要求分割成的子问题，不能有重复子问题，而动态规划正好相反，动态规划之所以高效，就是因为回溯算法实现中存在大量的重复子问题。</p><p>（3）贪心算法实际上是动态规划算法的一种特殊情况。它解决问题起来更加高效，代码实现也更加简洁。不过，它可以解决的问题也更加有限。它能解决的问题需要满足三个条件，最优子结构、无后效性和贪心选择性（这里不怎么强调重复子问题）。其中，最优子结构、无后效性跟动态规划中的无异。“贪心选择性”的意思是，通过局部最优的选择，能产生全局的最优选择。每一个阶段，都选择当前看起来最优的决策，所有阶段的决策完成之后，最终由这些局部最优解构成全局最优解。</p><h2 id="拓扑排序Topological-Sorting"><a href="#拓扑排序Topological-Sorting" class="headerlink" title="拓扑排序Topological Sorting"></a>拓扑排序Topological Sorting</h2><p>拓扑排序应用非常广泛，解决的问题的模型也非常一致。凡是需要通过局部顺序来推导全局顺序的，一般都能用拓扑排序来解决。除此之外，拓扑排序还能检测图中环的存在。</p><p>拓扑排序本身就是基于有向无环图的一个算法。</p><p>拓扑排序有两种实现方法，分别是 Kahn 算法和 DFS 深度优先搜索算法。</p><p>对于 Kahn 算法来说，如果最后输出出来的顶点个数，少于图中顶点个数，图中还有入度不是 0 的顶点，那就说明，图中存在环。</p><h2 id="最短路径Shortest-Path-Algorithm"><a href="#最短路径Shortest-Path-Algorithm" class="headerlink" title="最短路径Shortest Path Algorithm"></a>最短路径Shortest Path Algorithm</h2><p>前面两种关于图的搜索算法，深度优先搜索和广度优先搜索，主要是针对无权图的搜索算法。针对有权图，也就是图中的每条边都有一个权重，常用最短路径算法（Shortest Path Algorithm）计算两点之间的最短路径（经过的边的权重和最小）。</p><p>单源最短路径算法（一个顶点到一个顶点），最出名的是Dijkstra 算法。</p><p>最短路径算法还有很多，比如 Bellford 算法、Floyd 算法等等。</p><h3 id="A-算法"><a href="#A-算法" class="headerlink" title="A*算法"></a>A*算法</h3><p>A星算法属于一种启发式搜索算法（Heuristically Search Algorithm）。实际上，启发式搜索算法并不仅仅只有 A星 算法，还有很多其他算法，比如 IDA* 算法、蚁群算法、遗传算法、模拟退火算法等。</p><p>启发式搜索算法利用估价函数，避免“跑偏”，贪心地朝着最有可能到达终点的方向前进。这种算法找出的路线，并不是最短路线。但是，实际的软件开发中的路线规划问题，我们往往并不需要非得找最短路线。所以，鉴于启发式搜索算法能很好地平衡路线质量和执行效率，它在实际的软件开发中的应用更加广泛。</p><h2 id="并行算法Parallel-Algorithm"><a href="#并行算法Parallel-Algorithm" class="headerlink" title="并行算法Parallel Algorithm"></a>并行算法Parallel Algorithm</h2><p>并行计算是一个工程上的实现思路，尽管跟算法关系不大，但是，在实际的软件开发中，它确实可以非常巧妙地提高程序的运行效率，是一种非常好用的性能优化手段。特别是，当要处理的数据规模达到一定程度之后，我们无法通过继续优化算法，来提高执行效率 的时候，我们就需要在实现的思路上做文章，利用更多的硬件资源，来加快执行的效率。所以，在很多超大规模数据处理中，并行处理的思想，应用非常广泛，比如 MapReduce 实际上就是一种并行计算框架。</p>]]></content>
    
    
    <summary type="html">本文是对极客时间app上王争老师的&lt;数据结构与算法之美&gt;的课堂笔记。

基础概念
算法与数据结构是编程的内功。

从广义上讲，数据结构就是指一组数据的存储和逻辑结构。算法就是操作数据的一组方法。

数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。 因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。（比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。）





数据结构与算法中最重要的概念——复杂度分析：数据结构和算法解决的是如何更省、更</summary>
    
    
    
    <category term="programming" scheme="http://qixinbo.github.io/categories/programming/"/>
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析：24 -- 骨架图转图论sknw解析</title>
    <link href="http://qixinbo.github.io/2020/11/20/ImagePy_24/"/>
    <id>http://qixinbo.github.io/2020/11/20/ImagePy_24/</id>
    <published>2020-11-19T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.416Z</updated>
    
    <content type="html"><![CDATA[<p>sknw是一个从骨架图中创建图网络的库，代码在<a href="https://github.com/Image-Py/sknw">这里</a>。</p><p>它不仅可以实现将单线转变成图graph的效果，而且里面的trace函数还可以实现像素追踪，将图像中的单线的坐标序列依次提取出来，从而将图像转变为矢量图。（sknw可以对闭合曲线进行坐标提取，对于闭合曲线，也可以使用find_contour来提取这些坐标序列）</p><h1 id="输入图像"><a href="#输入图像" class="headerlink" title="输入图像"></a>输入图像</h1><p>输入图像必须是一个二值的骨架图。<br>比如，这里的示例图像矩阵为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">img = np.array([</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]])</span><br></pre></td></tr></table></figure><h1 id="标识节点"><a href="#标识节点" class="headerlink" title="标识节点"></a>标识节点</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">node_img = mark_node(img)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark_node</span>(<span class="params">ske</span>):</span></span><br><span class="line">    buf = np.pad(ske, (<span class="number">1</span>,<span class="number">1</span>), mode=<span class="string">&#x27;constant&#x27;</span>)</span><br><span class="line">    nbs = neighbors(buf.shape)</span><br><span class="line">    acc = np.cumprod((<span class="number">1</span>,)+buf.shape[::-<span class="number">1</span>][:-<span class="number">1</span>])[::-<span class="number">1</span>]</span><br><span class="line">    mark(buf, nbs)</span><br><span class="line">    <span class="keyword">return</span> buf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark</span>(<span class="params">img, nbs</span>):</span> <span class="comment"># mark the array use (0, 1, 2)</span></span><br><span class="line">    img = img.ravel()</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img)):</span><br><span class="line">        <span class="keyword">if</span> img[p]==<span class="number">0</span>:<span class="keyword">continue</span></span><br><span class="line">        s = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">            <span class="keyword">if</span> img[p+dp]!=<span class="number">0</span>:s+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> s==<span class="number">2</span>:img[p]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:img[p]=<span class="number">2</span></span><br></pre></td></tr></table></figure><p>这一步是将上面的骨架图中的特有节点标识出来（注意：新形成的图是在原图周围附加了一圈0作为缓冲）：<br>（1）像素值原来为0的地方，仍然为0；<br>（2）如果某非0像素，其八邻域有2个非0像素，那么标识该像素为1；这种像素代表了骨架图中的中间段的像素（其中有一部分1代表了环形闭合结构，在后面会特殊处理）；<br>（3）如果某非0像素，其八邻域中的非0像素个数不是2（比如是1、3等），那么标识该像素为2，这种像素代表了骨架图中端点和交点部分的像素。</p><p>经过标识后，得到的图像矩阵为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><h1 id="泛洪填充"><a href="#泛洪填充" class="headerlink" title="泛洪填充"></a>泛洪填充</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">img = img.ravel()</span><br><span class="line">buf = np.zeros(<span class="number">131072</span>, dtype=np.int64)</span><br><span class="line">num = <span class="number">10</span></span><br><span class="line">nodes = []</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img)):</span><br><span class="line">    <span class="keyword">if</span> img[p] == <span class="number">2</span>:</span><br><span class="line">        isiso, nds = fill(img, p, num, nbs, acc, buf)</span><br><span class="line">        <span class="keyword">if</span> isiso <span class="keyword">and</span> <span class="keyword">not</span> iso: <span class="keyword">continue</span></span><br><span class="line">        num += <span class="number">1</span></span><br><span class="line">        nodes.append(nds)</span><br></pre></td></tr></table></figure><p>依次观察值为2的像素，对其进行等值填充（主要函数就是fill函数），并记录这些节点在原图中的坐标位置。<br>fill函数为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fill</span>(<span class="params">img, p, num, nbs, acc, buf</span>):</span></span><br><span class="line">    img[p] = num</span><br><span class="line">    buf[<span class="number">0</span>] = p</span><br><span class="line">    cur = <span class="number">0</span>; s = <span class="number">1</span>; iso = <span class="literal">True</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        p = buf[cur]</span><br><span class="line">        <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">            cp = p+dp</span><br><span class="line">            <span class="keyword">if</span> img[cp]==<span class="number">2</span>:</span><br><span class="line">                img[cp] = num</span><br><span class="line">                buf[s] = cp</span><br><span class="line">                s+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> img[cp]==<span class="number">1</span>: iso=<span class="literal">False</span></span><br><span class="line">        cur += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> cur==s:<span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> iso, idx2rc(buf[:s], acc)</span><br></pre></td></tr></table></figure><p>原理就是探究这些值为2的像素的邻居是否仍然是2，若是，则将其亦纳入探究范围，这样就标识出了这些节点。<br>经过上述代码后，得到的nodes数值为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[array([[<span class="number">0</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">1</span>, <span class="number">7</span>]], dtype=int16), array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">3</span>, <span class="number">0</span>]], dtype=int16), array([[<span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">6</span>]], dtype=int16), array([[<span class="number">6</span>, <span class="number">8</span>]], dtype=int16), array([[<span class="number">8</span>, <span class="number">3</span>]], dtype=int16)]</span><br></pre></td></tr></table></figure><p>如何理解呢？很好理解，比如第一个坐标[0,3]就是第一个值为2的像素在原图中的位置，而坐标组合([[2, 3], [3, 2], [3, 3]])代表那三个相邻的值为2的像素。<br>同时img中的像素值也发生了变化，比如第一个值为2的像素，它的值由2变成了10（如上代码硬编码），而第一个值为2的像素则变成了11，同理，那三个相邻的值为2的像素变成了12，依次类推，最后一个值为2的像素变成了16。</p><h1 id="像素追溯"><a href="#像素追溯" class="headerlink" title="像素追溯"></a>像素追溯</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">edges = []</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img)):</span><br><span class="line">    <span class="keyword">if</span> img[p] &lt;<span class="number">10</span>: <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">        <span class="keyword">if</span> img[p+dp]==<span class="number">1</span>:</span><br><span class="line">            edge = trace(img, p+dp, nbs, acc, buf)</span><br><span class="line">            edges.append(edge)</span><br></pre></td></tr></table></figure><p>像素追溯部分的观察点就变成了与上述节点相邻且值为1的那些像素，即骨架图中的中间部分的像素（原理就是通过是否大于10而选择过滤出上面那些节点，然而通过其邻居是否是1来过滤得到这些值为1的像素），然后通过trace函数寻找其两端所连接的具体节点标识。</p><p>trace函数为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trace</span>(<span class="params">img, p, nbs, acc, buf</span>):</span></span><br><span class="line">    c1 = <span class="number">0</span>; c2 = <span class="number">0</span>;</span><br><span class="line">    newp = <span class="number">0</span></span><br><span class="line">    cur = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        buf[cur] = p</span><br><span class="line">        img[p] = <span class="number">0</span></span><br><span class="line">        cur += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">            cp = p + dp</span><br><span class="line">            <span class="keyword">if</span> img[cp] &gt;= <span class="number">10</span>:</span><br><span class="line">                <span class="keyword">if</span> c1==<span class="number">0</span>:</span><br><span class="line">                    c1 = img[cp]</span><br><span class="line">                    buf[<span class="number">0</span>] = cp</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    c2 = img[cp]</span><br><span class="line">                    buf[cur] = cp</span><br><span class="line">            <span class="keyword">if</span> img[cp] == <span class="number">1</span>:</span><br><span class="line">                newp = cp</span><br><span class="line">        p = newp</span><br><span class="line">        <span class="keyword">if</span> c2!=<span class="number">0</span>:<span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> (c1-<span class="number">10</span>, c2-<span class="number">10</span>, idx2rc(buf[:cur+<span class="number">1</span>], acc))</span><br></pre></td></tr></table></figure><p>trace的原理就是：观察这些值为1的像素的邻居，若为大于10，即找到了那些节点nodes，分别通过c1和c2来存储两侧的节点；若为1，则也将其设为进一步的观察点。<br>经过上述代码后，得到的edges的数值为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="number">0</span>, <span class="number">2</span>, array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>]], dtype=int16)), (<span class="number">3</span>, <span class="number">2</span>, array([[<span class="number">3</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">2</span>]], dtype=int16)), (<span class="number">2</span>, <span class="number">4</span>, array([[<span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">5</span>]], dtype=int16)), (<span class="number">4</span>, <span class="number">6</span>, array([[<span class="number">6</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">8</span>, <span class="number">3</span>]], dtype=int16)), (<span class="number">4</span>, <span class="number">5</span>, array([[<span class="number">6</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">8</span>]], dtype=int16))]</span><br></pre></td></tr></table></figure><p>如何理解呢？也很好理解。比如第一个元组((0, 2, array([[0, 3], [1, 3], [2, 3]])，前两个元素0和2分别是img中的值为10和12的像素减去10所得，第三个元素就是第一个值为1的元素的坐标，以及它所连接的两个值为2的节点的坐标。其他元组也是这个意思。通过这样的元组表示，就很自然地为后面的图graph中的首尾节点及中间连接做了准备。</p><p>同时img中的像素值又发生了变化：与上面值为2的节点相连接的值为1的像素的值都变为了0（见trace函数中的硬编码），这是为了接下来的闭合曲线的处理。</p><h2 id="闭合曲线的处理"><a href="#闭合曲线的处理" class="headerlink" title="闭合曲线的处理"></a>闭合曲线的处理</h2><p>上面的代码可以处理非闭合的曲线，因为很容易根据八邻域中的节点数目来获得交点部分所在。而对于闭合曲线，比如原图中左下方的四个1所形成的闭合曲线，其中无法找到值为2的这种像素，且无法对应到图graph中的节点的概念，因此需要特殊处理一下（这里是否处理这种闭合曲线，是用ring这个参数来指定）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img)):</span><br><span class="line">    <span class="keyword">if</span> img[p]!=<span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line">    img[p] = num; num += <span class="number">1</span></span><br><span class="line">    nodes.append(idx2rc([p], acc))</span><br><span class="line">    <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">        <span class="keyword">if</span> img[p+dp]==<span class="number">1</span>:</span><br><span class="line">            edge = trace(img, p+dp, nbs, acc, buf)</span><br><span class="line">            edges.append(edge)</span><br></pre></td></tr></table></figure><p>注意，因为上面已经将值为1且与2相连的像素置为0，所以这里寻找的是剩下的值为1的像素。若为1，然后会将它继续添加到节点nodes中。<br>然后再对其邻居点进行追溯trace，不断地将邻居的为1的像素加入到edge中，最终得到的edge结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">7</span>, <span class="number">7</span>, array([[<span class="number">5</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">1</span>]], dtype=int16))</span><br></pre></td></tr></table></figure><p>代表由7号节点到7号节点的一个循环。</p><h1 id="创建图graph"><a href="#创建图graph" class="headerlink" title="创建图graph"></a>创建图graph</h1><p>经过上述节点标识和像素追溯，可以得到节点及其边为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">nodes =</span><br><span class="line">[array([[<span class="number">0</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">1</span>, <span class="number">7</span>]], dtype=int16), array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">3</span>, <span class="number">0</span>]], dtype=int16), array([[<span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">6</span>]], dtype=int16), array([[<span class="number">6</span>, <span class="number">8</span>]], dtype=int16), array([[<span class="number">8</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">5</span>, <span class="number">1</span>]], dtype=int16)]</span><br><span class="line"> </span><br><span class="line">edges =</span><br><span class="line">[(<span class="number">0</span>, <span class="number">2</span>, array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>]], dtype=int16)), (<span class="number">3</span>, <span class="number">2</span>, array([[<span class="number">3</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">2</span>]], dtype=int16)), (<span class="number">2</span>, <span class="number">4</span>, array([[<span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">5</span>]], dtype=int16)), (<span class="number">4</span>, <span class="number">6</span>, array([[<span class="number">6</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">8</span>, <span class="number">3</span>]], dtype=int16)), (<span class="number">4</span>, <span class="number">5</span>, array([[<span class="number">6</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">8</span>]], dtype=int16)), (<span class="number">7</span>, <span class="number">7</span>, array([[<span class="number">5</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">1</span>]], dtype=int16))]</span><br></pre></td></tr></table></figure><p>使用networkx库来构建graph：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_graph</span>(<span class="params">nodes, edges, multi=<span class="literal">False</span></span>):</span></span><br><span class="line">    graph = nx.MultiGraph() <span class="keyword">if</span> multi <span class="keyword">else</span> nx.Graph()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nodes)):</span><br><span class="line">        graph.add_node(i, pts=nodes[i], o=nodes[i].mean(axis=<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">for</span> s,e,pts <span class="keyword">in</span> edges:</span><br><span class="line">        l = np.linalg.norm(pts[<span class="number">1</span>:]-pts[:-<span class="number">1</span>], axis=<span class="number">1</span>).<span class="built_in">sum</span>()</span><br><span class="line">        graph.add_edge(s,e, pts=pts, weight=l)</span><br><span class="line">    <span class="keyword">return</span> graph</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">sknw是一个从骨架图中创建图网络的库，代码在这里。

它不仅可以实现将单线转变成图graph的效果，而且里面的trace函数还可以实现像素追踪，将图像中的单线的坐标序列依次提取出来，从而将图像转变为矢量图。（sknw可以对闭合曲线进行坐标提取，对于闭合曲线，也可以使用find_contour来提取这些坐标序列）

输入图像
输入图像必须是一个二值的骨架图。
比如，这里的示例图像矩阵为：

1
2
3
4
5
6
7
8
9
10


img = np.array([
    [0,0,0,1,0,0,0,0,0],
    [0,0,0,1,0,0,0,1,0],
    [0,0,0,1,</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>胞状物体通用分割算法Cellpose解析：使用篇</title>
    <link href="http://qixinbo.github.io/2020/10/24/cellpose-1/"/>
    <id>http://qixinbo.github.io/2020/10/24/cellpose-1/</id>
    <published>2020-10-23T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.485Z</updated>
    
    <content type="html"><![CDATA[<p>Cellpose是一个对于胞状物体（比如细胞、晶粒、核、砖块等）进行分割的非常优秀的通用算法，其体现了深度学习在分割这类物体时的强大能力，同时其泛化效果也远超过传统图像处理算法，展现了数据驱动的深度学习所特有的“暴力美学”。</p><h1 id="试用"><a href="#试用" class="headerlink" title="试用"></a>试用</h1><p>Cellpose的源代码见<a href="https://github.com/MouseLand/cellpose">这里</a>。<br>同时开发者还搭建了网站来方便用户试用Cellpose：<br><a href="http://www.cellpose.org/">Cellpose快速体验网站</a>：用户可以直接上传自己的图像来直接调用Cellpose，第一时间获得Cellpose的处理效果。<br>如果用户觉得好，那么可以接着往下深度体验或钻研Cellpose了。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>Cellpose的安装有多种方式：</p><h2 id="Google-Colab在线运行"><a href="#Google-Colab在线运行" class="headerlink" title="Google Colab在线运行"></a>Google Colab在线运行</h2><p>开发者提供了一个运行在Google Colab上的运行示例脚本，用户可以直接拷贝一份这个脚本到自己的Colab上，然后在线运行。<br>这种方式的优缺点如下：<br>优点：可以白嫖Google的算力，不用自己费劲在本地搭建环境及购买硬件；<br>缺点：Colab有运行时间和资源，且其不支持运行Cellpose的图形交互界面。</p><h2 id="可直接执行的二进制程序"><a href="#可直接执行的二进制程序" class="headerlink" title="可直接执行的二进制程序"></a>可直接执行的二进制程序</h2><p>开发者使用PyInstaller在Intel处理器上对源代码进行了打包，形成了一个可执行的二进制程序（有Intel MKL加速，但没有GPU支持）。<br>适用于Windows 10操作系统的程序从<a href="http://www.cellpose.org/windows">这里</a>下载。下载后的程序就是传统的exe程序，可以双击运行它来启动GUI。也有命令行模式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cellpose.exe --<span class="built_in">dir</span> Pictures/ --chan <span class="number">2</span> --save_png</span><br></pre></td></tr></table></figure><p>这种方式的优缺点如下：<br>优点：直接运行开发者打包好的程序，无需自己配置本地环境；<br>缺点：无法调用GPU计算，计算速度受限；程序启动速度慢；无法自己训练模型，只能使用已有算法模型。</p><h2 id="pip包安装"><a href="#pip包安装" class="headerlink" title="pip包安装"></a>pip包安装</h2><p>开发者也在pip仓库中上传了Cellpose代码，因此可以使用pip包管理方式来直接安装Cellpose包。<br>这里还有四种不同的安装方式：分别取决于是否安装GUI、是否支持GPU计算。</p><p>第一种：使用CPU计算且无GUI，则：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install cellpose</span><br></pre></td></tr></table></figure><p>第二种：使用CPU计算且有GUI，则：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install cellpose[gui]</span><br></pre></td></tr></table></figure><p>第三种和第四种都是使用GPU计算，因此需要提前配置好GPU环境，即三步走：安装最新GPU驱动、安装CUDA、安装cuDNN，这三步对于深度学习框架都是通用的，可以从搜索引擎上直接搜索教程。<br>以上依赖安装时注意CUDA版本一定要与mxnet对应好，所以最好是先确定mxnet所需的CUDA版本，然后再具体安装CUDA和cuDNN。<br>配置好GPU环境后，再安装mxnet的GPU版本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mxnet-cu102</span><br></pre></td></tr></table></figure><p>最后按上面第一种或第二种的pip命令来安装cellpose的无GUI版或有GUI版。</p><h2 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a>源码安装</h2><p>最自由的方式就是直接从源码安装（虽然从pip包中实质也能获得源码，但pip包有可能不是最新的）。<br>首先还是配置环境，根据是否要支持GPU，选择是否安装GPU驱动、CUDA和cuDNN。<br>然后将github源码克隆一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/MouseLand/cellpose.git</span><br></pre></td></tr></table></figure><p>进入cellpose文件夹，运行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose</span><br></pre></td></tr></table></figure><p>这种方式拥有最大的自由度和灵活性，能训练、能推理、也能自定义代码来满足自己的定制化需求。</p><h1 id="上手"><a href="#上手" class="headerlink" title="上手"></a>上手</h1><h2 id="上手前准备"><a href="#上手前准备" class="headerlink" title="上手前准备"></a>上手前准备</h2><p>对于深度学习来说，它的三大要素是算法、算力和数据。对于Cellpose，关于这三方面：<br>算力：经过上面的安装过程，算力已经确定，可以是Google Colab的免费算力，也可以是本地环境的CPU或者GPU；<br>算法：Cellpose的算法模型的基础框架是UNet，具体算法在源码中可以查阅；Cellpose的开发者还提供了其在大量图像上进行训练的预训练模型，该模型会在第一次运行Cellpose时自动从开发者服务器上进行下载；<br>数据：开发者没有提供其训练数据集，不过提供了16张测试图片，可以从该<a href="https://drive.google.com/open?id=18syVlaix8cIlrnNF20pEWKMWUsKx9R9z">Google Drive网盘</a>上下载。</p><h2 id="GUI模式"><a href="#GUI模式" class="headerlink" title="GUI模式"></a>GUI模式</h2><p>终端输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose</span><br></pre></td></tr></table></figure><p>启动GUI。<br>（1）在GUI中加载图像（拖入图像或从File菜单中加载）；<br>（2）设置模型：Cellpose中有两个模型，cytoplasm和nuclei，即细胞质模型和细胞核模型。比如下面这种图：<br><img src="https://user-images.githubusercontent.com/6218739/95010065-1ccd3a80-0659-11eb-9847-b4255b058238.png" alt="cyto-nuclei"><br>根据生物课本上的知识，绿色部分就是细胞质，红色部分是细胞核，根据这两种物质，Cellpose分别有cyto和nuclei两种名称的模型来识别。用户自己的图像有可能不是这种生物图片，但可以根据相似性，来选择用细胞质（细胞质模型其实就是细胞cell模型，即将细胞核也纳入到整个细胞中）还是细胞核模型来分割。<br>（3）设置通道：选择要分割的图像通道，比如上图中，如果想分割细胞质，即选择green通道；如果想分割细胞核，则选择red通道。如果是分割细胞质，且图中还有细胞核，则将chan设置为细胞质所在通道，而chan2通道设置为细胞核所在通道；如果分割细胞质但里面没有细胞核，则只设置chan即可，chan2设为None；<br>（4）点击calibrate按钮来预估图中物体的尺寸；也可以手动输入cell diameter来设置。该预估的尺寸会通过左下方的红色圆盘体现；<br>（5）点击run segmentation来运行模型。当进度条为100%时，模型预测完毕，可以通过是否勾选MASKS ON来调节是否显示分割后的掩膜。<br>对于上面这张图，如果是分割细胞质/细胞，那么结果为：<br><img src="https://user-images.githubusercontent.com/6218739/95039137-8b1a0780-0702-11eb-9ee0-260f64e3b548.png" alt="cyto"><br>如果是分割细胞核，那么结果为：<br><img src="https://user-images.githubusercontent.com/6218739/95039218-bef52d00-0702-11eb-92ae-d077946cd115.png" alt="nuclei"></p><h2 id="命令行模式"><a href="#命令行模式" class="headerlink" title="命令行模式"></a>命令行模式</h2><p>上面GUI界面中的参数输入同样可以通过命令行模式来实现：<br>比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose --<span class="built_in">dir</span> ~/images_cyto/test/ --pretrained_model cyto --chan <span class="number">2</span> --chan2 <span class="number">3</span> --save_png</span><br></pre></td></tr></table></figure><p>还有其他参数可以设置，比如：<br>dir：图像所在路径；<br>img_filter：文件名最后的字符（除了扩展名）作为过滤器；<br>chan：要处理的通道，0是灰度通道，1是red通道，2是green通道，3是blue通道；<br>chan2：在要处理cyto、同时图中有nuclei时设置，其为nuclei所在通道，0代表None，代表不设置，其他数值所代表的意思同上；<br>pretrained_model：cyto是细胞质分割模型，nuclei是细胞核分割模型；<br>diameter：图中物体的平均直径，默认是30；如果设为0，则Cellpose会自动估计；<br>use_gpu：使用GPU，如果不添加该参数，则使用CPU；<br>save_png：将分割掩膜存为png，轮廓存为ImageJ所使用的text文件；<br>save_tif：将分割掩膜存为tif，轮廓存为ImageJ所使用的text文件；<br>fast_model：通过关闭数据增强以及平均化4 networks来加速代码运行；<br>all_channels：在所有图像通道上都运行Cellpose，仅用于自定义模型；<br>no_npy：不存储_seg.npy文件；<br>batch_size：批处理尺寸。</p><p>所有的参数可以通过help参数来查看：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose -h</span><br></pre></td></tr></table></figure><h2 id="代码模式"><a href="#代码模式" class="headerlink" title="代码模式"></a>代码模式</h2><p>与上面两种方式类似，也可以在Python代码中直接调用Cellpose进行编程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cellpose <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">import</span> skimage.io</span><br><span class="line"></span><br><span class="line">model = models.Cellpose(gpu=<span class="literal">False</span>, model_type=<span class="string">&#x27;cyto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">files = [<span class="string">&#x27;img0.tif&#x27;</span>, <span class="string">&#x27;img1.tif&#x27;</span>]</span><br><span class="line"></span><br><span class="line">imgs = [skimage.io.imread(f) <span class="keyword">for</span> f <span class="keyword">in</span> files]</span><br><span class="line"></span><br><span class="line">masks, flows, styles, diams = model.<span class="built_in">eval</span>(imgs, diameter=<span class="literal">None</span>, channels=[<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                                         threshold=<span class="number">0.4</span>, do_3D=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>可以看出，使用代码调用Cellpose也非常简单，主要就是两步：配置模型models.Cellpose和使用模型进行推理model.eval。</p><h1 id="制作数据集"><a href="#制作数据集" class="headerlink" title="制作数据集"></a>制作数据集</h1><p>Cellpose的GUI界面不仅能像上面那样用于运行模型，更重要的是可以利用它来制作数据集，从而基于自己的数据来训练模型。<br>制作数据集的步骤也非常简单：<br>（1）打开GUI，手动标注物体：右键点击开始标注，再次右键点击或者鼠标回到开始时的圆圈位置则结束标注；（标注时一定将图像中的物体全部都标注完，否则算法会将未标注的物体视为另一类，则会将算法弄晕）<br>（2）存储标注图像：选择File菜单下的Save masks as PNG，则会将标注图像存为文件；（这个地方有一个坑：此处存储的masks数据格式为np.uint16，如果使用opencv的imread函数读入并显示，会都显示为0；而需要使用skimage的imread函数才能正确读入）<br>（3）对文件进行组织：将原始图像和标注图像放到一个文件夹内，两者的匹配还需要遵循一定的命名规则，默认为：例如，原始图像名为wells_000.tif，则标注图像需要命名为wells_000_masks.tif。（也可以通过img_filter和mask_filter这两个参数来修改该默认规则）</p><h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>上一步制作好自己的数据集后，可以训练针对该数据集的Cellpose模型。<br>（在开始训练之前，有一参数需要特别注意，即diameter参数：开发者提供的Cellpose预训练模型中将所有图像进行了resize，使得图像中物体的中位直径都为30像素（细胞质模型）或17像素（细胞核模型）；因此如果想训练快速且结果准确，就需要提前将图像resize成其中物体的中位直径约为30像素或17像素；或使用–diameter参数指定图像中大约的中位直径为多少像素。）<br>训练Cellpose模型可以有两种方式：<br>（1）在预训练模型基础上进行训练：<br>这种方式又可以分为两种：<br>一种是在开发者提供的预训练模型上进行训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose --train --<span class="built_in">dir</span> ~/images_cyto/train/ --test_dir ~/images_cyto/test/ --pretrained_model cyto --chan <span class="number">2</span> --chan2 <span class="number">1</span></span><br></pre></td></tr></table></figure><p>可以看出，相比于之前的只运行模型，多了–train这个参数及训练集和测试集数据所在路径。<br>另外一种是在某一给定的预训练模型上进行训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose --<span class="built_in">dir</span> ~/images_cyto/test/ --pretrained_model ~/images_cyto/test/model/cellpose_35_0 --save_png</span><br></pre></td></tr></table></figure><p>（2）从头训练模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose --train --<span class="built_in">dir</span> ~/images_nuclei/train/ --pretrained_model <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>即，将参数pretrained_model置为None。</p><h1 id="贡献标注数据"><a href="#贡献标注数据" class="headerlink" title="贡献标注数据"></a>贡献标注数据</h1><p>上面两步介绍了制作自己的数据集及自己训练模型，实际上开发者还提供了一个额外功能：上传自己的标注数据到开发者服务器上，用于再次训练模型。这样的好处有：（1）对于用户：用户可以不必自己训练模型，等开发者根据用户上传的数据再次训练好模型后，用户就可以直接使用；（2）对于开发者：通过用户“投喂”更多类别的图像，就可以形成更大的数据集来训练Cellpose，从而使得Cellpose的泛化能力和精度都得以提高。<br>这里有几点注意事项：<br>（1）先测试一下现有的Cellpose模型在自己的数据上的效果，期间可以尝试更改一下diameter，可能结果会有一点不同；<br>（2）如果测试效果挺好，即错误较少，那么就没有必要上传这些数据了，因为再次训练的模型性能提高也不大；<br>（3）如果测试效果很差，那么极有可能自己的数据与Cellpose的训练集中的数据差别很大，那么此时再次基于这些数据的再次训练就有可能有很大提高；<br>（4）对于上传的数据，物体直径至少有10像素，每张图像上至少有数十个物体：如果图像太小，可以考虑将多张图像拼接起来；如果图像太大，可以考虑将它裁剪成小图，另外，如果图像中有大量非感兴趣的物体，可以将它们直接裁掉；<br>（5）手动标注时，将物体的边界轮廓勾画出来（对于细胞结构，务必使得轮廓将细胞膜、细胞质和细胞核都包裹进去，这是为了与Cellpose开发者的标注方法一致）；<br>（6）不要直接使用模型预测的结果来上传数据，这会造成“误差”的恶性循环。</p>]]></content>
    
    
    <summary type="html">Cellpose是一个对于胞状物体（比如细胞、晶粒、核、砖块等）进行分割的非常优秀的通用算法，其体现了深度学习在分割这类物体时的强大能力，同时其泛化效果也远超过传统图像处理算法，展现了数据驱动的深度学习所特有的“暴力美学”。

试用
Cellpose的源代码见这里。
同时开发者还搭建了网站来方便用户试用Cellpose：
Cellpose快速体验网站：用户可以直接上传自己的图像来直接调用Cellpose，第一时间获得Cellpose的处理效果。
如果用户觉得好，那么可以接着往下深度体验或钻研Cellpose了。

安装
Cellpose的安装有多种方式：

Google Colab在线运行
开</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="cellpose" scheme="http://qixinbo.github.io/tags/cellpose/"/>
    
  </entry>
  
  <entry>
    <title>胞状物体通用分割算法Cellpose解析：开发篇</title>
    <link href="http://qixinbo.github.io/2020/10/24/cellpose-2/"/>
    <id>http://qixinbo.github.io/2020/10/24/cellpose-2/</id>
    <published>2020-10-23T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.485Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h1><p>上一篇介绍了如何安装和使用Cellpose，相当于将Cellpose当做一个开箱即用的软件。实际上Cellpose还是一个开源的代码库，开发者可以深入研究它的算法，并进行调用、修改和完善等。<br>本文尝试对Cellpose的运行机理做一个研究，包括它的标注数据的格式、神经网络的架构、神经网络的输入和输出等。</p><h1 id="标注数据格式"><a href="#标注数据格式" class="headerlink" title="标注数据格式"></a>标注数据格式</h1><p>假设有这么一张要分割的图像，大小为10像素乘以10像素（选择这么小的像素矩阵以方便打印和查看数值），背底为黑色，图像中间有一个白色圆盘，即：<br><img src="https://user-images.githubusercontent.com/6218739/95300876-65cbfb80-08b2-11eb-9148-49b2c43ca197.png" alt="demo"><br>它的像素矩阵为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">array([[  <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">0.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">0.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>, <span class="number">255.</span>, <span class="number">255.</span>, <span class="number">255.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>]],</span><br><span class="line">      dtype=float32)</span><br></pre></td></tr></table></figure><p>对其进行手动标注，得到标注后的目标矩阵为：<br><img src="https://user-images.githubusercontent.com/6218739/95643902-f68a1d80-0ae4-11eb-9796-4c604bf21d58.png" alt="mask"><br>即，白色区域标为1，背景区域标为0（这里因为是手动标注，得到的标注不一定非常严格准确）。如果是标注了多个区域，则该mask矩阵里的标注值依次递增，即1、2、3等等。（注意这个地方一定要通过skimage.io.imread读取，不要用opencv，否则读取的是错误的值）</p><h1 id="向量场数据格式"><a href="#向量场数据格式" class="headerlink" title="向量场数据格式"></a>向量场数据格式</h1><p>Cellpose不是直接使用上面的标注数据作为神经网络的输入，而是要将这些标注转为向量场（这才是Cellpose最最重要的创新点，不是将物体的边缘轮廓直接作为目标拟合，而是将物体内部的场作为目标，非常巧妙），即热源在中心的热扩散场Flow Field，原理图如下：</p><p><img src="https://user-images.githubusercontent.com/6218739/95644657-a615be80-0aea-11eb-93db-75f5b4fca58a.png" alt="flow-field"></p><p>该数据转换可以使用如下API函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&#x27;D:\\repos\\cellpose&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> cellpose <span class="keyword">import</span> dynamics, io, plot</span><br><span class="line">flow1 = dynamics.labels_to_flows([mask])</span><br></pre></td></tr></table></figure><p>根据该函数的API介绍：<br><img src="https://user-images.githubusercontent.com/6218739/95644110-b3c94500-0ae6-11eb-97be-5002b4131cca.png" alt="flow-api"><br>可知，返回的flow1中包含了向量场的Y分量和X分量：<br><img src="https://user-images.githubusercontent.com/6218739/95644130-f3902c80-0ae6-11eb-888b-1b9f76e53981.png" alt="flow-Y"><br><img src="https://user-images.githubusercontent.com/6218739/95644140-0f93ce00-0ae7-11eb-8532-2495ddc6e2f8.png" alt="flow-X"></p><p>从这些数值可以看出，如果要实现可视化，还需要使用以下函数进行转换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow2 = plot.dx_to_circ([flow1[<span class="number">0</span>][<span class="number">2</span>], flow1[<span class="number">0</span>][<span class="number">3</span>]])</span><br></pre></td></tr></table></figure><p>得到的就是RGB图像，即：<br><img src="https://user-images.githubusercontent.com/6218739/95644288-3d2d4700-0ae8-11eb-8439-1e8e84ebf83b.png" alt="flow-visual"></p><p>因为上面的样例是一张非常小的图，可以通过另外一张大的样例图来更直观地看一下效果：<br><img src="https://user-images.githubusercontent.com/6218739/95644699-f9880c80-0aea-11eb-855d-449da0bf1ef9.png" alt="contrast"></p><h2 id="向量场计算原理"><a href="#向量场计算原理" class="headerlink" title="向量场计算原理"></a>向量场计算原理</h2><p>上面概览了向量场的计算和可视化方式。这一节具体解析它的计算原理。<br>仍然以最开始的10乘10的小图为例，其mask为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><p>（1）计算向量场（cellpose中称为流场flow field），使用的是masks_to_flows这个函数：<br>首先寻找该mask中的物体：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slices = scipy.ndimage.find_objects(masks)</span><br></pre></td></tr></table></figure><p>返回的是物体所在的行列切片：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slices =  [(<span class="built_in">slice</span>(<span class="number">1</span>, <span class="number">7</span>, <span class="literal">None</span>), <span class="built_in">slice</span>(<span class="number">1</span>, <span class="number">8</span>, <span class="literal">None</span>))]</span><br></pre></td></tr></table></figure><p>然后计算这些物体的中值直径大小：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dia = utils.diameters(masks)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>这里可以再插一句这个直径是怎样计算的：首先使用np.unique获得mask中特有元素的个数，元素个数就代表了每个物体的面积（unique函数去除其中重复的元素，并按元素由小到大返回一个新的无元素重复的元组或者列表），然后使用np.median计算这些面积的中值面积（如果有奇数个面积，则挑选中间的那个面积作为中值面积；如果有偶数个面积，则中间两个面积取平均作为中值面积），然后再求一个同样面积大小的圆的直径，即为中值直径。<br>接着计算在具体某个物体内它的质心的索引标识：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i,si <span class="keyword">in</span> <span class="built_in">enumerate</span>(slices):</span><br><span class="line">    <span class="keyword">if</span> si <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        sr,sc = si</span><br><span class="line">        ly, lx = sr.stop - sr.start + <span class="number">1</span>, sc.stop - sc.start + <span class="number">1</span></span><br><span class="line">        y,x = np.nonzero(masks[sr, sc] == (i+<span class="number">1</span>))</span><br><span class="line">        y = y.astype(np.int32) + <span class="number">1</span></span><br><span class="line">        x = x.astype(np.int32) + <span class="number">1</span></span><br><span class="line">        ymed = np.median(y)</span><br><span class="line">        xmed = np.median(x)</span><br><span class="line">        imin = np.argmin((x-xmed)**<span class="number">2</span> + (y-ymed)**<span class="number">2</span>)</span><br><span class="line">        xmed = x[imin]</span><br><span class="line">        ymed = y[imin]</span><br></pre></td></tr></table></figure><p>注意，这里的索引标识是以该物体内部自成一个坐标系，用到的关键一步就是代码中的nonzero那一行。然后同样使用np.median获取中位数，但因为不能确定该物体内是奇数还是偶数个像素（如果是偶数个像素，那么索引就是小数），所以先计算出中位数，再找出原来的索引序列中与该中位数最近的像素（即argmin那一行，通过距离判断），从而获得了真正的质心的索引标识。（这里还有一个伏笔：x和y在原有基础上又各加1，是为了后面计算扩散场时不从边界上开始计算）</p><p>接下来计算每个物体内的像素离其质心的距离，这种距离不是绝对距离，而是用之前的中位直径进行了某种归一化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s2 = (<span class="number">.15</span> * dia)**<span class="number">2</span></span><br><span class="line">        d2 = (x-xmed)**<span class="number">2</span> + (y-ymed)**<span class="number">2</span></span><br><span class="line">        mu_c[sr.start+y-<span class="number">1</span>, sc.start+x-<span class="number">1</span>] = np.exp(-d2/s2)</span><br></pre></td></tr></table></figure><p>这里的mu_c就是与原mask同样大小的距离变换图，因此在计算归一化距离时，虽然是相对于物体自己的质心的距离，但也通过sr.start的索引转换成了全局索引，即mu_c就是一幅以物体各自质心为中心的距离的一个个孤岛。</p><p>接下来计算热扩散场：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">            T = np.zeros((ly+<span class="number">2</span>)*(lx+<span class="number">2</span>), np.float64)</span><br><span class="line">            T = _extend_centers(T, y, x, ymed, xmed, np.int32(lx), niter)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_extend_centers</span>(<span class="params">T,y,x,ymed,xmed,Lx, niter</span>):</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(niter):</span><br><span class="line">        T[ymed*Lx + xmed] += <span class="number">1</span></span><br><span class="line">        T[y*Lx + x] = <span class="number">1</span>/<span class="number">9.</span> * (T[y*Lx + x] + T[(y-<span class="number">1</span>)*Lx + x]   + T[(y+<span class="number">1</span>)*Lx + x] +</span><br><span class="line">                                            T[y*Lx + x-<span class="number">1</span>]     + T[y*Lx + x+<span class="number">1</span>] +</span><br><span class="line">                                            T[(y-<span class="number">1</span>)*Lx + x-<span class="number">1</span>] + T[(y-<span class="number">1</span>)*Lx + x+<span class="number">1</span>] +</span><br><span class="line">                                            T[(y+<span class="number">1</span>)*Lx + x-<span class="number">1</span>] + T[(y+<span class="number">1</span>)*Lx + x+<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> T</span><br></pre></td></tr></table></figure><p>T是一个ly+2乘以lx+2大小的一维数组，即它将原来的二维的物体区域给拉直成一个一维长条进行计算。<br>这里模拟的动作就是在质心处每次循环都投入一个数值为1的新的热源，然后计算整个物体内在这一热源下的热扩散，用的是八邻域计算。温度场在每次循环中都累加。<br>迭代循环结束后，还要叠加一个log型的温度场，这一步没有弄明白什么意思：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">T[(y+<span class="number">1</span>)*lx + x+<span class="number">1</span>] = np.log(<span class="number">1.</span>+T[(y+<span class="number">1</span>)*lx + x+<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>接下来计算物体内的温度梯度场（即某点的x方向梯度就是左右两个邻居的温度的差，y方向梯度就是上下两个邻居的温度的差）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dy = T[(y+<span class="number">1</span>)*lx + x] - T[(y-<span class="number">1</span>)*lx + x]</span><br><span class="line">dx = T[y*lx + x+<span class="number">1</span>] - T[y*lx + x-<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>并将其存入场变量mu中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mu = np.zeros((<span class="number">2</span>, Ly, Lx), np.float64)</span><br><span class="line">mu[:, sr.start+y-<span class="number">1</span>, sc.start+x-<span class="number">1</span>] = np.stack((dy,dx))</span><br></pre></td></tr></table></figure><p>注意mu的shape，dy和dx是分别存储的，分别存入mu的第0维和第1维。<br>最后将dx和dy进行标准化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mu /= (<span class="number">1e-20</span> + (mu**<span class="number">2</span>).<span class="built_in">sum</span>(axis=<span class="number">0</span>)**<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><p>即：先求(dy)^2和(dx)^2，然后通过sum求((dy)^2+(dx)^2)，然后对其开平方，最后将原值除以该值，得到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dy/[((dy)^<span class="number">2</span>+(dx)^<span class="number">2</span>)**<span class="number">0.5</span>]</span><br><span class="line">和</span><br><span class="line">dx/[((dy)^<span class="number">2</span>+(dx)^<span class="number">2</span>)**<span class="number">0.5</span>]</span><br></pre></td></tr></table></figure><p>（2）将流场与物体概率结合起来：<br>上面计算了流场后，在labels_to_flows中将该流场与是否是物体的概率结合起来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">veci = [masks_to_flows(labels[n][<span class="number">0</span>])[<span class="number">0</span>] <span class="keyword">for</span> n <span class="keyword">in</span> trange(nimg)]</span><br><span class="line">flows = [np.concatenate((labels[n][[<span class="number">0</span>]], labels[n][[<span class="number">0</span>]]&gt;<span class="number">0.5</span>, veci[n]), axis=<span class="number">0</span>).astype(np.float32)</span><br><span class="line">                    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(nimg)]</span><br></pre></td></tr></table></figure><p>即这里的flows是四个量的结合：flows的形状是(4, Ly, Lx)，其中flows[k][0] 是标签labels[k]，flows[k][1]判断是否是细胞，所以值也就只有两个，0和1，其中在计算时判断是否是物体的阈值设为了0.5，flows[k][2]是Y方向的流场，flows[k][3]是X方向的流场。</p><h2 id="从流场复原掩膜"><a href="#从流场复原掩膜" class="headerlink" title="从流场复原掩膜"></a>从流场复原掩膜</h2><p>上面解析了如何通过掩膜计算向量场（即流场）。流场是作为该算法中的输出，因此，算法推理后得到的输出也是流场形式，那么进一步地，需要根据流场反推出掩膜，以标识物体的形貌。<br>这里的分析要用到上面计算出来的流场flows。<br>为了更具通用性，在这一节中使用的掩膜中有两个物体，从而探究更一般的掩膜复原过程。<br>原始掩膜的矩阵为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><p>下面的步骤默认是不知道这个原始掩膜的，已知条件只有它的流场形式，通过上节的计算方法，得到该流场为（这里只显示第3和第4个元素，即X和Y方向的流场）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[[[ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.7728456</span>   <span class="number">0.7343627</span>   <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>         -<span class="number">0.07701479</span>  <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>         -<span class="number">0.8023549</span>  -<span class="number">0.7343627</span>   <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.6282049</span>   <span class="number">0.9970669</span>   <span class="number">0.72136474</span>  <span class="number">0.26260668</span>]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>         -<span class="number">0.67413443</span> -<span class="number">0.99975467</span> -<span class="number">0.80442435</span> -<span class="number">0.29906148</span>]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]]</span><br><span class="line"></span><br><span class="line"> [[ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.6345941</span>  -<span class="number">0.67875725</span>  <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">1.</span>         -<span class="number">0.99702996</span>  <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.59684724</span> -<span class="number">0.67875725</span>  <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.778048</span>    <span class="number">0.07653494</span> -<span class="number">0.69255537</span> -<span class="number">0.96490294</span>]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.73860866</span> -<span class="number">0.0221485</span>  -<span class="number">0.5940551</span>  -<span class="number">0.9542338</span> ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]</span><br><span class="line">  [ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">    <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>        ]]]</span><br></pre></td></tr></table></figure><p>接下来看怎样通过流场复原掩膜的。</p><p>（1）动力学计算<br>这一步在follow_flows函数中进行。该函数用到的参数只有一个与dP相关的数（还有一个迭代步数，有默认值）。<br>dP是流场flows的一部分，包含Y方向的流场和X方向的流场，可由下面的方式获得：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dP = flows[<span class="number">0</span>][<span class="number">2</span>:]</span><br></pre></td></tr></table></figure><p>follow_flows函数所传入的实际参数在Cellpose中为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-<span class="number">1</span> * dP * (cellprob &gt; cellprob_threshold) / <span class="number">5.</span></span><br></pre></td></tr></table></figure><p>这其中有两个系数非常重要，一个是-1，另一个是5。<br>它们两者的作用分别是：-1是为了使符号反转，即原来正向热流，现在要使它往回流，即原流场是热源中的热往四周散，现在要复原了，所以要把热流反向，让热流都汇聚到热源上；5是为了将热流梯度值变小，这样能缓缓地流，保证热流流向临近点，防止一下冲到别的点上。<br>将这个表达式记为新dP，其值变为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[[[-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.15456912</span> -<span class="number">0.14687255</span> -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>          <span class="number">0.01540296</span> -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>          <span class="number">0.16047098</span>  <span class="number">0.14687255</span> -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.12564097</span> -<span class="number">0.19941339</span> -<span class="number">0.14427295</span> -<span class="number">0.05252134</span>]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>          <span class="number">0.13482688</span>  <span class="number">0.19995093</span>  <span class="number">0.16088487</span>  <span class="number">0.0598123</span> ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]]</span><br><span class="line"></span><br><span class="line"> [[-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.12691882</span>  <span class="number">0.13575146</span> -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.2</span>         <span class="number">0.199406</span>   -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.11936945</span>  <span class="number">0.13575146</span> -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.1556096</span>  -<span class="number">0.01530699</span>  <span class="number">0.13851108</span>  <span class="number">0.19298059</span>]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.14772174</span>  <span class="number">0.0044297</span>   <span class="number">0.11881103</span>  <span class="number">0.19084677</span>]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]</span><br><span class="line">  [-<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span></span><br><span class="line">   -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>         -<span class="number">0.</span>        ]]]</span><br></pre></td></tr></table></figure><p>首先根据dP的尺寸来生成动力学计算所在的网格（Cellpose能进行三维分割，不过这里只分析二维情形，即生成二维网格），即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shape = np.array(dP.shape[<span class="number">1</span>:]).astype(np.int32)</span><br><span class="line">p = np.meshgrid(np.arange(shape[<span class="number">0</span>]), np.arange(shape[<span class="number">1</span>]), indexing=<span class="string">&#x27;ij&#x27;</span>)</span><br><span class="line">p = np.array(p).astype(np.float32)</span><br></pre></td></tr></table></figure><p>因为原图是一个10乘10的图像，那么这里的网格节点就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[[[<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">  [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line">  [<span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span>]</span><br><span class="line">  [<span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span>]</span><br><span class="line">  [<span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span>]</span><br><span class="line">  [<span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span>]</span><br><span class="line">  [<span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span>]</span><br><span class="line">  [<span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span>]</span><br><span class="line">  [<span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span>]</span><br><span class="line">  [<span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]]]</span><br></pre></td></tr></table></figure><p>然后只计算流场梯度不为0的节点以加快计算速度，因此先得到这些不为0节点的索引：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inds = np.array(np.nonzero(np.<span class="built_in">abs</span>(dP[<span class="number">0</span>])&gt;<span class="number">1e-3</span>)).astype(np.int32).T</span><br></pre></td></tr></table></figure><p>这些索引在该例中为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">6</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">8</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">9</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">6</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">8</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">9</span>]]</span><br></pre></td></tr></table></figure><p>然后执行以下函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p = steps2D(p, dP, inds, niter)</span><br></pre></td></tr></table></figure><p>具体它干的工作就是不断地在格点上累加热流。<br>结果就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[[[<span class="number">0.</span>        <span class="number">0.</span>        <span class="number">1.0098284</span> <span class="number">1.1413077</span> <span class="number">0.</span>        <span class="number">0.</span>        <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>        <span class="number">0.</span>        <span class="number">0.</span>       ]</span><br><span class="line">  [<span class="number">1.</span>        <span class="number">1.</span>        <span class="number">1.</span>        <span class="number">1.0362048</span> <span class="number">1.</span>        <span class="number">1.</span>        <span class="number">1.</span></span><br><span class="line">   <span class="number">1.</span>        <span class="number">1.</span>        <span class="number">1.</span>       ]</span><br><span class="line">  [<span class="number">2.</span>        <span class="number">2.</span>        <span class="number">1.1182916</span> <span class="number">1.1164871</span> <span class="number">2.</span>        <span class="number">2.</span>        <span class="number">2.</span></span><br><span class="line">   <span class="number">2.</span>        <span class="number">2.</span>        <span class="number">2.</span>       ]</span><br><span class="line">  [<span class="number">3.</span>        <span class="number">3.</span>        <span class="number">3.</span>        <span class="number">3.</span>        <span class="number">3.</span>        <span class="number">3.</span>        <span class="number">4.105441</span></span><br><span class="line">   <span class="number">3.8231199</span> <span class="number">4.041441</span>  <span class="number">4.0182114</span>]</span><br><span class="line">  [<span class="number">4.</span>        <span class="number">4.</span>        <span class="number">4.</span>        <span class="number">4.</span>        <span class="number">4.</span>        <span class="number">4.</span>        <span class="number">3.8856084</span></span><br><span class="line">   <span class="number">3.9896855</span> <span class="number">3.9375546</span> <span class="number">3.935263</span> ]</span><br><span class="line">  [<span class="number">5.</span>        <span class="number">5.</span>        <span class="number">5.</span>        <span class="number">5.</span>        <span class="number">5.</span>        <span class="number">5.</span>        <span class="number">5.</span></span><br><span class="line">   <span class="number">5.</span>        <span class="number">5.</span>        <span class="number">5.</span>       ]</span><br><span class="line">  [<span class="number">6.</span>        <span class="number">6.</span>        <span class="number">6.</span>        <span class="number">6.</span>        <span class="number">6.</span>        <span class="number">6.</span>        <span class="number">6.</span></span><br><span class="line">   <span class="number">6.</span>        <span class="number">6.</span>        <span class="number">6.</span>       ]</span><br><span class="line">  [<span class="number">7.</span>        <span class="number">7.</span>        <span class="number">7.</span>        <span class="number">7.</span>        <span class="number">7.</span>        <span class="number">7.</span>        <span class="number">7.</span></span><br><span class="line">   <span class="number">7.</span>        <span class="number">7.</span>        <span class="number">7.</span>       ]</span><br><span class="line">  [<span class="number">8.</span>        <span class="number">8.</span>        <span class="number">8.</span>        <span class="number">8.</span>        <span class="number">8.</span>        <span class="number">8.</span>        <span class="number">8.</span></span><br><span class="line">   <span class="number">8.</span>        <span class="number">8.</span>        <span class="number">8.</span>       ]</span><br><span class="line">  [<span class="number">9.</span>        <span class="number">9.</span>        <span class="number">9.</span>        <span class="number">9.</span>        <span class="number">9.</span>        <span class="number">9.</span>        <span class="number">9.</span></span><br><span class="line">   <span class="number">9.</span>        <span class="number">9.</span>        <span class="number">9.</span>       ]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.8871436</span> <span class="number">3.0260515</span> <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">6.</span></span><br><span class="line">   <span class="number">7.</span>        <span class="number">8.</span>        <span class="number">9.</span>       ]</span><br><span class="line">  [<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.</span>        <span class="number">3.1274133</span> <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">6.</span></span><br><span class="line">   <span class="number">7.</span>        <span class="number">8.</span>        <span class="number">9.</span>       ]</span><br><span class="line">  [<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.811595</span>  <span class="number">3.157068</span>  <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">6.</span></span><br><span class="line">   <span class="number">7.</span>        <span class="number">8.</span>        <span class="number">9.</span>       ]</span><br><span class="line">  [<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.</span>        <span class="number">3.</span>        <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">7.9200172</span></span><br><span class="line">   <span class="number">7.898424</span>  <span class="number">7.9439383</span> <span class="number">7.9862995</span>]</span><br><span class="line">  [<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.</span>        <span class="number">3.</span>        <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">7.990998</span></span><br><span class="line">   <span class="number">7.884873</span>  <span class="number">7.924165</span>  <span class="number">7.893717</span> ]</span><br><span class="line">  [<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.</span>        <span class="number">3.</span>        <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">6.</span></span><br><span class="line">   <span class="number">7.</span>        <span class="number">8.</span>        <span class="number">9.</span>       ]</span><br><span class="line">  [<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.</span>        <span class="number">3.</span>        <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">6.</span></span><br><span class="line">   <span class="number">7.</span>        <span class="number">8.</span>        <span class="number">9.</span>       ]</span><br><span class="line">  [<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.</span>        <span class="number">3.</span>        <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">6.</span></span><br><span class="line">   <span class="number">7.</span>        <span class="number">8.</span>        <span class="number">9.</span>       ]</span><br><span class="line">  [<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.</span>        <span class="number">3.</span>        <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">6.</span></span><br><span class="line">   <span class="number">7.</span>        <span class="number">8.</span>        <span class="number">9.</span>       ]</span><br><span class="line">  [<span class="number">0.</span>        <span class="number">1.</span>        <span class="number">2.</span>        <span class="number">3.</span>        <span class="number">4.</span>        <span class="number">5.</span>        <span class="number">6.</span></span><br><span class="line">   <span class="number">7.</span>        <span class="number">8.</span>        <span class="number">9.</span>       ]]]</span><br></pre></td></tr></table></figure><p>p的值域也是有规则的，即大于0且小于原图尺寸，因为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p[<span class="number">0</span>,y,x] = <span class="built_in">min</span>(shape[<span class="number">0</span>]-<span class="number">1</span>, <span class="built_in">max</span>(<span class="number">0</span>, p[<span class="number">0</span>,y,x] - dP[<span class="number">0</span>,p0,p1]))</span><br></pre></td></tr></table></figure><p>单看p中具体数值，没有意义，应该看p现在的值与之前的网格格点标识之间的差值，这才是有意义的，表明在该点上的热流累加（或散失），由此来标识经过动力学计算后热源所在位置。<br>另外剧透一下，从下面的分析可以看出，目前p中的值经过整型化后，与原先的格点索引不同的位置上的数值正是热源所在位置，比如第一排第三个元素的原先索引是[0, 2]，现在变成了[1, 2]，那么这个[1, 2]正是热源所在位置。</p><p>（2）复原掩膜：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dims):</span><br><span class="line">    pflows.append(p[i].flatten().astype(<span class="string">&#x27;int32&#x27;</span>))</span><br><span class="line">    edges.append(np.arange(-<span class="number">.5</span>-rpad, shape0[i]+<span class="number">.5</span>+rpad, <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>pflows是对浮点数的p展平后进行整型化，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>,</span><br><span class="line">       <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>,</span><br><span class="line">       <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>,</span><br><span class="line">       <span class="number">8</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>]), </span><br><span class="line"> array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,</span><br><span class="line">       <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>,</span><br><span class="line">       <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>,</span><br><span class="line">       <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])]</span><br></pre></td></tr></table></figure><p>而edges是直方图中的各个区间范围，其中的参数rpad控制了直方图的边缘填充大小，比如rpad如果为0，那么直方图的大小就是与原图大小相等，即周围没有填充0，而如果设置rpad为非零，比如设rpad为1，那么：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[array([-<span class="number">1.5</span>, -<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.5</span>,  <span class="number">2.5</span>,  <span class="number">3.5</span>,  <span class="number">4.5</span>,  <span class="number">5.5</span>,  <span class="number">6.5</span>,  <span class="number">7.5</span>,  <span class="number">8.5</span>,</span><br><span class="line">        <span class="number">9.5</span>, <span class="number">10.5</span>]), </span><br><span class="line"> array([-<span class="number">1.5</span>, -<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.5</span>,  <span class="number">2.5</span>,  <span class="number">3.5</span>,  <span class="number">4.5</span>,  <span class="number">5.5</span>,  <span class="number">6.5</span>,  <span class="number">7.5</span>,  <span class="number">8.5</span>,</span><br><span class="line">        <span class="number">9.5</span>, <span class="number">10.5</span>])]</span><br></pre></td></tr></table></figure><p>而因为pflows中的值都是大于0且小于原图尺寸的（step2D中的操作），即-1.5和-0.5之间以及9.5和10.5之间是没有元素的，就相等于在直方图周围填充了一圈0的边界，如果rpad为更多，比如默认为20，那么填充的边界宽度则为20。<br>这里将rpad设为0，即不要填充边界，那么：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">edges = [array([-<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.5</span>,  <span class="number">2.5</span>,  <span class="number">3.5</span>,  <span class="number">4.5</span>,  <span class="number">5.5</span>,  <span class="number">6.5</span>,  <span class="number">7.5</span>,  <span class="number">8.5</span>,  <span class="number">9.5</span>]), </span><br><span class="line">         array([-<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.5</span>,  <span class="number">2.5</span>,  <span class="number">3.5</span>,  <span class="number">4.5</span>,  <span class="number">5.5</span>,  <span class="number">6.5</span>,  <span class="number">7.5</span>,  <span class="number">8.5</span>,  <span class="number">9.5</span>])]</span><br></pre></td></tr></table></figure><p>这样以0.5为后缀，是为了方便取得下面的整型，比如0.5到1.5之间就是取的1。<br>然后就是至关重要的直方图计算环节：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h,_ = np.histogramdd(<span class="built_in">tuple</span>(pflows), bins=edges)</span><br></pre></td></tr></table></figure><p>这一步就是根据edges区间统计这些区间内相应流场强度，先从结果来向前推比较好理解，这里h.T（注意是将原来的h进行了以下转置，方便描述）的值为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">3.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">3.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">5.</span> <span class="number">3.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]]</span><br></pre></td></tr></table></figure><p>第一个元素就代表当y方向的pflows为-0.5到0.5之间（就是0）时x方向的pflows为-0.5到0.5之间（就是0）的数的个数，那么看pflows就是(0, 0)这个元素；第二个元素就代表y方向的pflows为0时x方向的pflows为1的数的个数，发现就是(1, 0)这一对。比如第三行的3代表当y方向的pflows为1.5到2.5之间（就是2）时，x方向的pflows为0.5到1.5之间（就是1）的数的个数是3个，分别在第3个、第13个、第23个元素对。</p><p>这部分的理解可以根据下面更通俗的一个例子来辅助。<br>np.histgram就是在一维上看数据落在bins上的个数。<br>np.histgram2d就是在二维上看数据落在bins上的个数，以如下例子为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">xedges = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>]</span><br><span class="line">yedges = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">x = np.random.normal(<span class="number">2</span>, <span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">y = np.arange(<span class="number">10</span>)</span><br><span class="line">H, xedges, yedges = np.histogram2d(x, y, bins=(xedges, yedges))</span><br></pre></td></tr></table></figure><p>上述代码中xedges定义了x维度上的值所划分的范围（即统计0到1之间（注意不含1）的值的个数、1到3之间（注意不含3）的值的个数、3到5之间（注意这里包含5）的值的个数），yedges定义了y维度上的值所划分的范围，x是一个含有10个以2为期望、以1为标准差的正态分布的数值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([<span class="number">1.4965097</span> , <span class="number">0.46480962</span>, <span class="number">1.65365048</span>, <span class="number">1.56658642</span>, <span class="number">2.05414053</span>,</span><br><span class="line">       <span class="number">3.209907</span>  , <span class="number">2.87861765</span>, <span class="number">0.17336843</span>, <span class="number">2.97341494</span>, <span class="number">2.12467305</span>])</span><br></pre></td></tr></table></figure><p>y就是一个从0到9依次递增的10个数值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure><p>而得到的H为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure><p>将其转置一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>H.T</span><br><span class="line">array([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">2.</span>, <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure><p>H.T是一个4乘3的矩阵，第一个元素代表x维度上0到1之间（注意不含1）且y维度上0到2之间（注意不含2）的数的个数，即(0.46480962, 1)这个数，第二个元素代表x维度上1到3之间（注意不含3）且y维度上0到2之间（注意不含2）的数的个数，即(1.4965097, 0)这个数，第三个元素代表x维度上3到5之间（注意!!这里包含5）且y维度上0到2之间（注意不含2）的数的个数，没有这样的数，所以为0。看一下H.T中倒数第二个元素，它代表x维度上1到3之间（注意不含3）且y维度上4到6之间（注意!!包含6）的数的个数，即(2.05414053, 4)和(2.87861765, 6)这两个数。因此，在edges范围两端的值，都是包含在范围内，而在内部的值，左边值包含，而右边值不包含。<br>对于bins这个参数，上面是指定的范围序列，也可以指定一个整数值，表示分成多少份。</p><p>以上是关于那个直方图矩阵的理解，对于其实际物理意义，可以想象成这样：如果pflows还是保持原来的格点索引，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[[[<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">  [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line">  [<span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span>]</span><br><span class="line">  [<span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span>]</span><br><span class="line">  [<span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span>]</span><br><span class="line">  [<span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span>]</span><br><span class="line">  [<span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span>]</span><br><span class="line">  [<span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span> <span class="number">7.</span>]</span><br><span class="line">  [<span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span> <span class="number">8.</span>]</span><br><span class="line">  [<span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span> <span class="number">9.</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">  [<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]]]</span><br></pre></td></tr></table></figure><p>那么上面的统计矩阵上的元素应该都为1，可以想象成这个棋盘上每个格点上都有一粒米，那么再看pflows经过了动力学计算后的形式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>,</span><br><span class="line">       <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>,</span><br><span class="line">       <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>,</span><br><span class="line">       <span class="number">8</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>]),</span><br><span class="line"> array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,</span><br><span class="line">       <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>,</span><br><span class="line">       <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>,</span><br><span class="line">       <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])]</span><br></pre></td></tr></table></figure><p>以及再贴一遍直方图统计结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">3.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">3.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">5.</span> <span class="number">3.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]]</span><br></pre></td></tr></table></figure><p>看pflows，比如第一行，x维度上两个0变成了两个1，表示x维度上原来0号标识的位置上的米移到了1号标识上，y维度保持不变，对应于直方图统计就是将两粒米右移一格，x维度上有两个2也变成了1，意味着这两个x维度上2号标识上的米左移到了1号标识上。同理，x、y坐标为(3, 6)的点现在变成了(4, 7)，也是把这个米从这两个坐标点上进行了移动。</p><p>上面是以相对位置角度来理解，另一个角度来看，从绝对位置来看，pflows中的要移动米粒的位置上面的值正是热源所在坐标位置：还是看x维度上的那两个变为1标识的0标识，它原来的标识是[0, 2]，现在变成了[1, 2]，这[1, 2]正是热源位置（下面的求解可知道）。</p><p>关于直方图统计这一部分理解结束！</p><p>下面接着看。<br>得到直方图统计结果后，对其进行一个核为5的最大化池化（池化的目的是为了滤波，去掉噪声）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dims):</span><br><span class="line">    hmax = maximum_filter1d(hmax, <span class="number">5</span>, axis=i)</span><br></pre></td></tr></table></figure><p>结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span>]</span><br><span class="line"> [<span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span>]</span><br><span class="line"> [<span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span> <span class="number">5.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span> <span class="number">3.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]]</span><br></pre></td></tr></table></figure><p>然后找出原直方图统计中局部最大值的位置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seeds = np.nonzero(np.logical_and(h-hmax&gt;-<span class="number">1e-6</span>, h&gt;<span class="number">2</span>))</span><br></pre></td></tr></table></figure><p>具体判断标准有两个：一是看原值与经过池化后的值的差值，如果差值为0，则表明这个位置是局部极大值；二是该局部极大值需要大于2（注意，原代码中这个地方是10，这里因为原图只有10乘10，所以改了一下，变为2，这样才能检测出来，所以这个10也是一个可调参数），即它的热流汇聚要足够大，是一个大的热源，也是为了排除小的干扰。</p><p>seeds的值为（即局部极大值的坐标）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seeds =  (array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>], dtype=int64), array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>], dtype=int64))</span><br></pre></td></tr></table></figure><p>seeds的第0个元素是局部极大值的x坐标，第1个元素是其对应的y坐标。下面将这些坐标成对提取出来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pix = <span class="built_in">list</span>(np.array(seeds).T)</span><br></pre></td></tr></table></figure><p>即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pix =  [array([<span class="number">1</span>, <span class="number">2</span>], dtype=int64), array([<span class="number">1</span>, <span class="number">3</span>], dtype=int64), array([<span class="number">3</span>, <span class="number">7</span>], dtype=int64)]</span><br></pre></td></tr></table></figure><p>然后构建一个3乘3（注意这是二维，三维下是3乘3乘3）的窗口：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expand = np.nonzero(np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br></pre></td></tr></table></figure><p>这个窗口内的数值是节点索引：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expand =  (array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], dtype=int64), array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], dtype=int64))</span><br></pre></td></tr></table></figure><p>接下来是两层循环。先看内部循环，它是对pix的长度进行循环（再次明确一下，pix是局部极大值的坐标索引）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pix)):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">iter</span>==<span class="number">0</span>:</span><br><span class="line">        pix[k] = <span class="built_in">list</span>(pix[k])</span><br><span class="line">    newpix = []</span><br><span class="line">    iin = []</span><br><span class="line">    <span class="keyword">for</span> i,e <span class="keyword">in</span> <span class="built_in">enumerate</span>(expand):</span><br><span class="line">        epix = e[:,np.newaxis] + np.expand_dims(pix[k][i], <span class="number">0</span>) - <span class="number">1</span></span><br><span class="line">        epix = epix.flatten()</span><br><span class="line">        iin.append(np.logical_and(epix&gt;=<span class="number">0</span>, epix&lt;shape[i]))</span><br><span class="line">        newpix.append(epix)</span><br><span class="line">    iin = np.<span class="built_in">all</span>(<span class="built_in">tuple</span>(iin), axis=<span class="number">0</span>)</span><br><span class="line">    newpix = <span class="built_in">tuple</span>(newpix)</span><br><span class="line">    igood = h[newpix]&gt;<span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dims):</span><br><span class="line">        pix[k][i] = newpix[i][igood]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">iter</span>==<span class="number">4</span>:</span><br><span class="line">        pix[k] = <span class="built_in">tuple</span>(pix[k])</span><br></pre></td></tr></table></figure><p>这里面的变量较多，各自具体的意义为：pix刚开始是局部极大值的坐标索引，epix是在某一个维度上expand滑动窗加上pix索引减去1，newpix是在两个维度上对epix进行合成，这样来说，newpix就是以pix中的坐标为中心的九个像素坐标索引，比如pix中某个像素是[1, 2]，那么newpix就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">newpix =  [array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], dtype=int64), array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=int64)]</span><br></pre></td></tr></table></figure><p>然后看之前的直方图统计矩阵h在这九个像素点上是否大于2，即为igood的值，即是否有热流流入，以上面的[1, 2]中心像素所产生的九个像素为例，igood就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">igood =  [<span class="literal">False</span> <span class="literal">False</span> <span class="literal">False</span> <span class="literal">False</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span> <span class="literal">False</span> <span class="literal">False</span>]</span><br></pre></td></tr></table></figure><p>即仍然是[1, 2]和[1, 3]中的热流强度大于2，然后把这两个坐标提取出来再次放入pix中，即下面这句：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dims):</span><br><span class="line">    pix[k][i] = newpix[i][igood]</span><br></pre></td></tr></table></figure><p>此时pix变为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pix =  [[array([<span class="number">1</span>, <span class="number">1</span>], dtype=int64), array([<span class="number">2</span>, <span class="number">3</span>], dtype=int64)], array([<span class="number">1</span>, <span class="number">3</span>], dtype=int64), array([<span class="number">3</span>, <span class="number">7</span>], dtype=int64)]</span><br></pre></td></tr></table></figure><p>对比一下pix最开始的坐标索引，可以发现pix中第一个元素由原来的局部极大值索引[1, 2]，变成了以它为中心的九个像素中直方图统计大于2的像素坐标索引。<br>那么对原来pix中所有极大值索引都循环一遍后，得到了新的pix：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[array([<span class="number">1</span>, <span class="number">1</span>], dtype=int64), array([<span class="number">2</span>, <span class="number">3</span>], dtype=int64)], </span><br><span class="line"> [array([<span class="number">1</span>, <span class="number">1</span>], dtype=int64), array([<span class="number">2</span>, <span class="number">3</span>], dtype=int64)],</span><br><span class="line"> [array([<span class="number">3</span>, <span class="number">4</span>], dtype=int64), array([<span class="number">7</span>, <span class="number">7</span>], dtype=int64)]]</span><br></pre></td></tr></table></figure><p>以上就是内层循环的作用：以最开始的局部极大值所在像素为中心，在其上罩一个3乘3的窗口，看该窗口内直方图统计是否大于2，如果是，就将该邻居像素的坐标索引加入pix中。<br>那么外层循环就是不断地重复这个内层循环5次（这里的5也是一个可调参数），即一步步地查找是否由邻居像素的热流大于2。<br>内层循环和外层循环加起来实现的效果就是：模仿漫水填充，查找最开始的最大热源所辐射的范围，看哪些邻居像素属于该热源。</p><p>在该例中，经过上述内外循环后，pix的值为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[(array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], dtype=int64), </span><br><span class="line">  array([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>,</span><br><span class="line">       <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>], dtype=int64)),</span><br><span class="line"> (array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], dtype=int64),</span><br><span class="line">  array([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>,</span><br><span class="line">       <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>], dtype=int64)),</span><br><span class="line"> (array([<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>,</span><br><span class="line">       <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>], dtype=int64), </span><br><span class="line">  array([<span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>,</span><br><span class="line">       <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>], dtype=int64))]</span><br></pre></td></tr></table></figure><p>虽然看起来里面有很多元素，但pix的length只有3，表明这些元素都是由最开始的3个局部极大值所辐射的；另一方面，很多元素都是重复的，实际只有[1, 2]、[1, 3]、[3, 7]、[4, 7]这四个元素。<br>然后对这些元素进行label：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">M = np.zeros(h.shape, np.int32)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pix)):</span><br><span class="line">    M[pix[k]] = <span class="number">1</span>+k</span><br></pre></td></tr></table></figure><p>可得M矩阵的数值（注意它这里是h.shape，即M是与直方图统计所对应的，不是原图）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><p>从上面已经知道，pflows中异常值就代表了热源位置，所以这里根据pflows的索引，得到其上的label值（即将pflows传入M）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dims):</span><br><span class="line">    pflows[i] = pflows[i] + rpad</span><br><span class="line"></span><br><span class="line">M0 = M[<span class="built_in">tuple</span>(pflows)]</span><br></pre></td></tr></table></figure><p>所以，与原图对应的label值（就是掩膜）就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">3</span></span><br><span class="line"> <span class="number">3</span> <span class="number">3</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">3</span> <span class="number">3</span> <span class="number">3</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>这里得到掩膜后，中间还插了一段去掉非常大的掩膜的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">_,counts = np.unique(M0, return_counts=<span class="literal">True</span>)</span><br><span class="line">big = np.prod(shape0) * <span class="number">0.4</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.nonzero(counts &gt; big)[<span class="number">0</span>]:</span><br><span class="line">    M0[M0==i] = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>因为这个例子的掩膜比较小，因此这段代码没起作用。<br>从目前掩膜M0的值来看，它里面的数值是2和3，没有从1开始。<br>下面就是转换一下（这里用到的技术就是np.unique中的return_inverse这个参数，是返回这些unique数的索引，非常巧妙）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">_,M0 = np.unique(M0, return_inverse=<span class="literal">True</span>)</span><br><span class="line">M0 = np.reshape(M0, shape0)</span><br></pre></td></tr></table></figure><p>此时M0变为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>最后再变成原图的尺寸即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">M0 = np.reshape(M0, shape0)</span><br></pre></td></tr></table></figure><p>即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><h2 id="UnetModel模型类"><a href="#UnetModel模型类" class="headerlink" title="UnetModel模型类"></a>UnetModel模型类</h2><p>Cellpose的算法是基于Unet架构的。<br>基础模型调用在：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UnetModel</span>():</span></span><br><span class="line">        self.net = resnet_style.CPnet(nbase, nout=self.nclasses,</span><br><span class="line">                                      residual_on=residual_on,</span><br><span class="line">                                      style_on=style_on,</span><br><span class="line">                                      concatenation=concatenation)</span><br><span class="line">        self.net.hybridize(static_alloc=<span class="literal">True</span>, static_shape=<span class="literal">True</span>)</span><br><span class="line">        self.net.initialize(ctx = self.device)</span><br></pre></td></tr></table></figure><p>即，UnetModel这个类实际是CPnet类的一个实例化对象，因此，CPnet类才是最基础的算法架构所在：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CPnet</span>(<span class="params">gluon.HybridBlock</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, nbase, nout, residual_on=<span class="literal">True</span>, style_on=<span class="literal">True</span>, concatenation=<span class="literal">False</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CPnet, self).__init__(**kwargs)</span><br><span class="line">        <span class="keyword">with</span> self.name_scope():</span><br><span class="line">            self.nbase = nbase</span><br><span class="line">            self.downsample = downsample(nbase, residual_on=residual_on)</span><br><span class="line">            self.upsample = upsample(nbase, residual_on=residual_on, concatenation=concatenation)</span><br><span class="line">            self.output = batchconv(nout, <span class="number">1</span>)</span><br><span class="line">            self.make_style = make_style()</span><br><span class="line">            self.style_on = style_on</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hybrid_forward</span>(<span class="params">self, F, data</span>):</span></span><br><span class="line">        <span class="comment">#data     = self.conv1(data)</span></span><br><span class="line">        T0    = self.downsample(data)</span><br><span class="line">        style = self.make_style(T0[-<span class="number">1</span>])</span><br><span class="line">        style0 = style</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.style_on:</span><br><span class="line">            style = style * <span class="number">0</span></span><br><span class="line">        T0    = self.upsample(style, T0)</span><br><span class="line">        T0    = self.output(T0)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> T0, style0</span><br></pre></td></tr></table></figure><p>CPnet基于MXNet/Gluon（Gluon是MXNet的动态图接口），这里还使用了MXNet的混合式编程方法，即继承自gluon.HybridBlock类。混合式编程是将命令式编程与符号式编程混合在一起，既可以通过命令式编程使代码编写起来更容易和直观，也可以通过符号式编程来获得更好的计算性能和可移植性。MXNet通过HybridSequential类和HybridBlock类构建的模型可以调用hybridize函数将命令式程序转成符号式程序。具体教程见下方链接：<br><a href="http://zh.gluon.ai/chapter_computational-performance/hybridize.html?highlight=hybrid">命令式和符号式混合编程</a><br>CPnet类有两种算法结构可以选择，一种是经典的Unet结构，一种是以ResNet为backbone的Unet结构，两者可以通过residual_on这个参数来开关。</p><h2 id="CellposeModel模型类"><a href="#CellposeModel模型类" class="headerlink" title="CellposeModel模型类"></a>CellposeModel模型类</h2><p>CellposeModel类是基于上面的UnetModel类，但两者也有不同：UnetModel是通用的算法架构，其训练集的data和label是通用的、未经特殊处理的；而CellposeModel的训练集的label实际是在原mask基础上计算的flow field，即定制化的label。<br>主要区别在这里：<br>对于UnetModel，其label为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.nclasses==<span class="number">3</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;computing boundary pixels&#x27;</span>)</span><br><span class="line">    train_classes = [np.stack((label, label&gt;<span class="number">0</span>, utils.distance_to_boundary(label)), axis=<span class="number">0</span>).astype(np.float32)</span><br><span class="line">                        <span class="keyword">for</span> label <span class="keyword">in</span> tqdm(train_labels)]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    train_classes = [np.stack((label, label&gt;<span class="number">0</span>), axis=<span class="number">0</span>).astype(np.float32)</span><br><span class="line">                        <span class="keyword">for</span> label <span class="keyword">in</span> tqdm(train_labels)]</span><br></pre></td></tr></table></figure><p>对于CellposeModel，其label为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_flows = dynamics.labels_to_flows(train_labels, files=train_files)</span><br></pre></td></tr></table></figure><h2 id="SizeModel模型类"><a href="#SizeModel模型类" class="headerlink" title="SizeModel模型类"></a>SizeModel模型类</h2><p>SizeModel类是用来估计图像中物体尺寸（中位直径）的模型。</p><h2 id="Cellpose类"><a href="#Cellpose类" class="headerlink" title="Cellpose类"></a>Cellpose类</h2><p>Cellpose类是对CellposeModel和SizeModel的整合，即对这两个模型的统一调用。</p>]]></content>
    
    
    <summary type="html">概览
上一篇介绍了如何安装和使用Cellpose，相当于将Cellpose当做一个开箱即用的软件。实际上Cellpose还是一个开源的代码库，开发者可以深入研究它的算法，并进行调用、修改和完善等。
本文尝试对Cellpose的运行机理做一个研究，包括它的标注数据的格式、神经网络的架构、神经网络的输入和输出等。

标注数据格式
假设有这么一张要分割的图像，大小为10像素乘以10像素（选择这么小的像素矩阵以方便打印和查看数值），背底为黑色，图像中间有一个白色圆盘，即：

它的像素矩阵为：

1
2
3
4
5
6
7
8
9
10
11


array([[  0.,   0.,   0.,   </summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="cellpose" scheme="http://qixinbo.github.io/tags/cellpose/"/>
    
  </entry>
  
  <entry>
    <title>wxPython知识点</title>
    <link href="http://qixinbo.github.io/2020/09/26/wxpython/"/>
    <id>http://qixinbo.github.io/2020/09/26/wxpython/</id>
    <published>2020-09-25T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.886Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本文是对ZetCode上wxPython的摘抄学习，原系列文章见<a href="http://zetcode.com/wxpython/">这里</a>。</p><p>wxPython是一个开发桌面端图形界面的跨平台函数库，开发语言为Python，它是基于C++的函数库wxWidgets的封装。<br>wxpython有大量组件，它们可以从逻辑上（注意是逻辑上）这样划分：<br>（1）基础组件<br><img src="https://user-images.githubusercontent.com/6218739/93730533-9eee4580-fbfb-11ea-8aba-88f4e73ccc42.jpg" alt="base"><br>这些组件为其所派生的子组件提供基础功能，通常不直接使用。<br>（2）顶层组件<br><img src="https://user-images.githubusercontent.com/6218739/93730576-d2c96b00-fbfb-11ea-9a25-b4c88eccf867.jpg" alt="toplevel"><br>这些组件相互独立存在。<br>（3）容器<br><img src="https://user-images.githubusercontent.com/6218739/93730612-ef65a300-fbfb-11ea-9132-1457ffe71d7e.jpg" alt="containers"><br>这些组件包含其他组件。<br>（4）动态组件<br><img src="https://user-images.githubusercontent.com/6218739/93730642-1623d980-fbfc-11ea-8f9d-bbeed738ef73.jpg" alt="dynamic"><br>这些组件可以被用户所交互编辑。<br>（5）静态组件<br><img src="https://user-images.githubusercontent.com/6218739/93730655-276ce600-fbfc-11ea-946c-96378f28d953.jpg" alt="staticwidgets"><br>这些组件用来展示信息，无法被用户所交互编辑。<br>（6）其他组件<br><img src="https://user-images.githubusercontent.com/6218739/93730678-453a4b00-fbfc-11ea-82e4-3060641039e0.jpg" alt="bars"><br>这些组件包括状态栏、工具栏、菜单栏等。</p><p>除了逻辑上的划分，各个组件之间还存在着继承关系，以一个button组件为例：<br><img src="https://user-images.githubusercontent.com/6218739/93730809-dc070780-fbfc-11ea-84b4-77c4ae347d04.png" alt="inheritance"><br>Button是一个小window，具体地，它是继承自wx.Control这一类的window（有些组件是window，但不是继承自wx.Control，比如wx.Dialog，更具体来说，controls这类组件是可放置在containers这类组件上的组件）。同时所有的windows都可以响应事件，button也不例外，因此它还继承自wx.EvtHandler。最后，所有的wxpython对象都继承自wx.Object类。</p><h1 id="wxPython的“你好世界”"><a href="#wxPython的“你好世界”" class="headerlink" title="wxPython的“你好世界”"></a>wxPython的“你好世界”</h1><p>这个例子是wxPython的最小可用例子，用来say hello to the world:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">frame = wx.Frame(<span class="literal">None</span>, title=<span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line">frame.Show()</span><br><span class="line"></span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>麻雀虽小五脏俱全，该例子包含了最基本的代码和组件：<br>（1）首先导入wxPython库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br></pre></td></tr></table></figure><p>wx可视为一个命名空间，后面所有的函数和类都以它开头。<br>（2）创建应用实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">app = wx.App()</span><br></pre></td></tr></table></figure><p>每一个wxPython程序都必须有一个应用实例。<br>（3）创建应用框架并显示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">frame = wx.Frame(<span class="literal">None</span>, title=<span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line">frame.Show()</span><br></pre></td></tr></table></figure><p>这里创建了一个wx.Frame对象。wx.Frame是一个重要的“容器”组件，它用来承载其他组件，它本身没有父组件（如果我们给组件的parent参数设为None，即代表该组件没有父组件）。创建该对象后，还需调用Show方法才能显示出来。</p><p>wx.Frame的构造函数一共有七个参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wx.Frame(wx.Window parent, <span class="built_in">int</span> <span class="built_in">id</span>=-<span class="number">1</span>, string title=<span class="string">&#x27;&#x27;</span>, wx.Point pos=wx.DefaultPosition,</span><br><span class="line">    wx.Size size=wx.DefaultSize, style=wx.DEFAULT_FRAME_STYLE, string name=<span class="string">&quot;frame&quot;</span>)</span><br></pre></td></tr></table></figure><p>除了第一个parent参数需要显式指定，其余六个都有默认值，包括ID、名称、位置、尺寸和样式等。因此，可以通过改变这些参数来进一步地对该frame进行个性化定制。<br>（4）启动程序主循环：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>程序的主循环是一个无限循环模式，它捕获并分发程序生命周期内的所有事件。</p><h1 id="菜单栏和工具栏"><a href="#菜单栏和工具栏" class="headerlink" title="菜单栏和工具栏"></a>菜单栏和工具栏</h1><h2 id="菜单栏"><a href="#菜单栏" class="headerlink" title="菜单栏"></a>菜单栏</h2><p>菜单栏主要由三部分组成：wx.MenuBar、wx.Menu和wx.MenuItem。<br>在菜单栏MenuBar中可以添加菜单Menu，在菜单Menu中又可以添加菜单项MenuItem。<br>添加完后不要忘了使用SetMenuBar来将菜单栏加入到框架中。<br>进一步地，在某个菜单Menu中，还可以添加子菜单SubMenu，然后继续添加菜单项。<br>还可以给菜单设置图标、快捷键、对wx.EVT_MENU事件的动作、菜单样式（打勾、单选）等。</p><h2 id="上下文菜单"><a href="#上下文菜单" class="headerlink" title="上下文菜单"></a>上下文菜单</h2><p>上下文菜单有时叫做“弹出菜单”，比如右键某个位置，出现上下文选项。</p><h2 id="工具栏"><a href="#工具栏" class="headerlink" title="工具栏"></a>工具栏</h2><p>工具栏的添加也是类似流程：先添加工具栏CreateToolBar，然后在上面添加工具AddTool。<br>别忘了使用toolbar.Realize()使之呈现出来（这一步与操作系统有关，Linux上不强制使用，Windows必须使用，为了跨平台性，最好将这一步明确写出）。<br>对于某个工具，可以设置逻辑使之Enable或Disable，常见的比如undo和redo，这两个按钮不是一直可以点的，在最开始时redo就必须是disabled，因为没有历史操作，所以可以设置具体的逻辑使之disable掉。</p><h2 id="状态栏"><a href="#状态栏" class="headerlink" title="状态栏"></a>状态栏</h2><p>状态栏即底部显示当前状态的状态条。</p><h1 id="布局管理"><a href="#布局管理" class="headerlink" title="布局管理"></a>布局管理</h1><p>布局可以分为绝对布局和布局管理器sizer。绝对布局有很多缺点，比如：<br>（1）组件的尺寸和位置不随窗口的改变而改变；<br>（2）不同平台上应用程序可能显示不同；<br>（3）字体的改变可能破坏布局；<br>（4）如果想改变布局，必须将之前的全部推翻。</p><p>因此，推荐使用布局管理器sizer来管理布局。<br>wxPython常用的sizer有：wx.BoxSizer、wx.StaticBoxSizer、wx.GridSizer、wx.FlexGridSizer、wx.GridBagSizer。</p><h2 id="wx-BoxSizer"><a href="#wx-BoxSizer" class="headerlink" title="wx.BoxSizer"></a>wx.BoxSizer</h2><p>wx.BoxSizer是最常见的布局管理器。它的常用设置有：<br>（1）排列方向：wx.VERTICAL垂直排列还是wx.HORIZONTAL水平排列；<br>（2）排列比例：一个布局中所包含的组件的尺寸由其比例所决定，比例为0表示在窗口尺寸变化时保持尺寸不变，其他比例系数表示组件在该布局管理器中的尺寸占比；且通常使用wx.EXPAND旗标来使得组件占据管理器分配给它的所有空间；<br>（3）边界：组件的边界大小可以自定义设置，同时具体哪个边界（上下左右或全部）都可以任意指定；<br>（4）对齐方式：可以设定左端对齐、右端对齐、顶部对齐、底部对齐、中心对齐等多种对齐方式；<br>（5）在某一级容器组件中，使用SetSizer()来为其指定布局管理器；<br>（6）在布局管理器中用Add()方法来添加组件。</p><p>wx.StaticBoxSizer是在BoxSizer周围加上了一个静态文本框的显示。</p><h2 id="wx-GridSizer"><a href="#wx-GridSizer" class="headerlink" title="wx.GridSizer"></a>wx.GridSizer</h2><p>wx.GridSizer是网格布局管理器，可以设置几排几列以及横纵的间距，网格中的组件尺寸都是相同的。<br>（如果有的网格不需要添加组件，可以添加没有内容的StaticText作为占位符）</p><h2 id="wx-FlexGridSizer"><a href="#wx-FlexGridSizer" class="headerlink" title="wx.FlexGridSizer"></a>wx.FlexGridSizer</h2><p>wx.FlexGridSizer与wx.GridSizer类似，但其更灵活，它不要求网格中所有的组件尺寸都相同，而是在同一行中的所有组件都高度相同，而同一列中的所有组件都宽度相同。<br>它还可以设置能growable的行和列，即在当前sizer中如果有空间，就将特定的行和列调整相应的大小来占据这个空间（注意将该行或列中的组件设为expandable）。</p><h2 id="wx-GridBagSizer"><a href="#wx-GridBagSizer" class="headerlink" title="wx.GridBagSizer"></a>wx.GridBagSizer</h2><p>wx.GridBagSizer是wxPython中最灵活的sizer（不仅仅是wxPython，其他函数库也有类似的配置），它可以显式地指定sizer中组件所占据的区域，比如横跨几行几列等。<br>它的构造函数很简单：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wx.GridBagSizer(integer vgap, integer hgap)</span><br></pre></td></tr></table></figure><p>只需设定间距，然后通过Add()方法添加组件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Add(self, item, <span class="built_in">tuple</span> pos, <span class="built_in">tuple</span> span=wx.DefaultSpan, integer flag=<span class="number">0</span>,</span><br><span class="line">    integer border=<span class="number">0</span>, userData=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>pos参数指定组件在这个虚拟网格中的起始位置，(0, 0)就代表左上角，span就指定它横跨几行几列，比如(3, 2)代表占据3行2列。<br>如果想组件可以随窗口伸缩，别忘了设置expandle属性，及：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">AddGrowableRow(integer row)</span><br><span class="line">AddGrowableCol(integer col)</span><br></pre></td></tr></table></figure><h2 id="Sizer常见问题"><a href="#Sizer常见问题" class="headerlink" title="Sizer常见问题"></a>Sizer常见问题</h2><p>大部分的问题出现在：<br>（1）设置比例proportional错误，只有需要随窗口变化的组件和sizer才需要设置为非0，其他都设置为0。且sizer和里面的组件可分别设置，比如下面的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">self.panel = wx.Panel( self, wx.ID_ANY, wx.DefaultPosition, wx.DefaultSize, wx.TAB_TRAVERSAL )</span><br><span class="line">vbox = wx.BoxSizer( wx.VERTICAL )</span><br><span class="line"></span><br><span class="line">hbox1 = wx.BoxSizer( wx.HORIZONTAL )</span><br><span class="line"></span><br><span class="line">self.st1 = wx.StaticText( self.panel, wx.ID_ANY, <span class="string">u&quot;Class Name&quot;</span>, wx.DefaultPosition, wx.DefaultSize, <span class="number">0</span> )</span><br><span class="line">self.st1.Wrap( -<span class="number">1</span> )</span><br><span class="line">hbox1.Add( self.st1, <span class="number">0</span>, wx.RIGHT, <span class="number">8</span> )</span><br><span class="line"></span><br><span class="line">self.tc = wx.TextCtrl( self.panel, wx.ID_ANY, wx.EmptyString, wx.DefaultPosition, wx.DefaultSize, <span class="number">0</span> )</span><br><span class="line">hbox1.Add( self.tc, <span class="number">1</span>, <span class="number">0</span>, <span class="number">5</span> )</span><br><span class="line"></span><br><span class="line">vbox.Add( hbox1, <span class="number">0</span>, wx.EXPAND|wx.LEFT|wx.RIGHT|wx.TOP, <span class="number">10</span> )</span><br></pre></td></tr></table></figure><p>在vbox中添加了hbox1，hbox1中又添加了静态文本框st1和输入框tc，hbox1的比例为0，代表在vbox这一垂直排列的管理器变化时，hbox1尺寸不变化，但tc的比例又为1，所以vbox在垂直变化时，tc按着hbox1不变化，但vbox水平变化时，tc就会随着变化。这样就有非常高的适应性。<br>（总结起来：看是否expandable要看组件所在的sizer！！）<br>（2）边界border尺寸设置不统一，导致对不齐<br>（3）Expandable属性和proportion两个中有一个忘了设置，导致组件不能随窗口伸缩。</p><p>这个sizer的编写此处可以借助wxFormBuilder工具来进行设计，实现所想即所得。（wxFormBuilder能够实现即时的改变，但此处遇到一个小问题，在wxGridBagSizer设置了某列进行可伸缩后，在wxFormBuilder中却不能正确伸缩，反而generate code后直接调用能正确伸缩，所以也不能完全相信，但可以99%相信，实在调不通后可以换种运行方式接着调）</p><h1 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h1><h2 id="事件-1"><a href="#事件-1" class="headerlink" title="事件"></a>事件</h2><p>事件是一个图形界面程序的核心部分，任何图形界面程序都是事件驱动的。<br>事件可以有多重产生方式，大部分是用户触发的，也有可能由其他方式产生，比如网络连接、窗口管理和计时器调用等。<br>关于事件，这里面有几个过程和要素：<br>事件循环Event Loop（比如wxPython的MainLoop()方法），它一直在寻找和捕获事件Event（比如wx.EVT_SIZE、wx.EVT_CLOSE等）；当捕获到事件后，就通过分发器dispatcher将事件分发到事件句柄Event Handler（事件句柄是对事件进行响应的动作方法）；事件本身与事件句柄的映射由Event Binder来完成（即Bind()方法）。<br>对用户编程来说，最常打交道的就是Bind()方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Bind(event, handler, source=<span class="literal">None</span>, <span class="built_in">id</span>=wx.ID_ANY, id2=wx.ID_ANY)</span><br></pre></td></tr></table></figure><p>溯源起来，该Bind()方法是定义在EvtHandler类中，而EvtHandler又派生了Window类，Window类又是绝大多数组件的父类，因此可以在组件中直接使用该方法（如果想将事件解绑，则可以调用Unbind()方法，其参数跟下面的参数相同）。<br>event参数就是事件对象，它指定了事件类型；<br>handler就是对该事件的响应方法，这个通常要由编程自定义完成；<br>source是指该事件来自于哪个组件，比如很多组件都能产生同样的事件，就需要指定具体的来源，比如很多button都能产生鼠标点击事件。这里面就有一个很tricky的地方，假设self是一个panel，该panel上有很多buttons，名为bt1、bt2，那么self.Bind(event, handler, source=self.bt1)和self.bt1.Bind(event, handler)有什么区别呢？两者看起来的效果是相同的，<a href="https://wiki.wxpython.org/self.Bind%20vs.%20self.button.Bind">这里有一个帖子详细说明了两者的区别</a>；<br>id是通过ID来指定事件来源，而上面的source是通过直接指定实例，两者目的相同；关于组件的ID，主要有两种创建方式：<br>（1）让系统自动创建：即使用-1或wx.ID_ANY，系统自动创建的ID都是负数，因此用户自己创建的ID都应该是正数，此种情况通常用于不用改变状态的组件。可以使用GetId()来获取该隐形id；<br>（2）标准ID：wxPython提供了一些标准IDs，比如wx.ID_SAVE、wx.ID_NEW等；<br>id2是指定多个IDs，上面的id是一次只能指定单个ID。</p><p>这里面有个很好玩的用法，如果想批量给多个同类组件绑定事件，可以用lambda函数，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line">__author__ = <span class="string">&#x27;huangbinghe@gmail.com&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestFrm</span>(<span class="params">wx.Frame</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;TestFrm&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *arg, **kw</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(*arg, **kw)</span><br><span class="line">        panel = wx.Panel(self, -<span class="number">1</span>)</span><br><span class="line">        box = wx.BoxSizer(wx.VERTICAL)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            btn = wx.Button(panel, -<span class="number">1</span>, label=<span class="string">&quot;test-&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">            btn.Bind(wx.EVT_BUTTON, <span class="keyword">lambda</span> e, mark=i: self.on_click(e, mark))</span><br><span class="line">            box.Add(btn, <span class="number">0</span>, wx.LEFT)</span><br><span class="line"></span><br><span class="line">        panel.SetSizer(box)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_click</span>(<span class="params">self, event, mark</span>):</span></span><br><span class="line">        wx.MessageDialog(self, <span class="string">&#x27;click mark:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">            mark), <span class="string">&#x27;click btn&#x27;</span>, wx.ICON_INFORMATION).ShowModal()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = wx.App()</span><br><span class="line">    frm = TestFrm(<span class="literal">None</span>, title=<span class="string">&quot;hello world&quot;</span>)</span><br><span class="line">    frm.Show()</span><br><span class="line">    app.MainLoop()</span><br></pre></td></tr></table></figure><h2 id="事件传播"><a href="#事件传播" class="headerlink" title="事件传播"></a>事件传播</h2><p>有两种类型的事件：basic events和command events。它们两者的区别在于是否传播上。事件的传播是指事件从触发该事件的子组件开始，传递给其父组件，并观察其响应。Basic events不传播，而command events传播。比如wx.CloseEvent就是一个basic event，它不传播，因为如果传播给父组件就很没有道理。<br>默认情形下，在事件句柄中的事件是阻止传播的，如果想让它继续传播，需要调用skip()方法（这个也解释了上面的self.Bind(event, handler, source=self.bt1)和self.bt1.Bind(event, handler)的区别）。</p><h2 id="常见事件"><a href="#常见事件" class="headerlink" title="常见事件"></a>常见事件</h2><p>窗口移动事件：wx.EVT_MOVE<br>窗口销毁事件：wx.EVT_CLOSE，发生在点击工具栏的关闭按钮、Alt+F4或从开始菜单关闭计算机时（注意销毁窗口是destroy()方法）<br>按钮事件：wx.EVT_BUTTON，点击一个按钮时<br>菜单事件：wx.EVT_MENU，点击一个菜单时<br>绘图事件：wx.EVT_PAINT，改变窗口尺寸或最大化窗口时（最小化窗口时不会产生该事件）<br>焦点事件：wx.EVT_SET_FOCUS，当某组件成为焦点时；wx.EVT_KILL_FOCUS，当某组件失去焦点时<br>键盘事件：wx.EVT_KEY_DOWN，键盘按下；wx.EVT_KEY_UP，键盘弹起；wx.EVT_CHAR，这个应该是为了兼容非英语字符。</p><h1 id="对话框"><a href="#对话框" class="headerlink" title="对话框"></a>对话框</h1><p>对话框是一种非常重要的人机交互的手段，可以使得用户输入数据、修改数据、更改程序配置等。</p><h2 id="预定义的消息对话框"><a href="#预定义的消息对话框" class="headerlink" title="预定义的消息对话框"></a>预定义的消息对话框</h2><p>消息对话框是为了向用户展示消息，可以通过一些预定义的旗标来定制消息对话框的按钮和图标，如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/94092464-6b0a5e80-fe4d-11ea-86d0-1ed4627434f5.png" alt="messagebox"></p><h2 id="自定义对话框"><a href="#自定义对话框" class="headerlink" title="自定义对话框"></a>自定义对话框</h2><p>若想自定义对话框，只需继承wx.Dialog即可。</p><h1 id="常用组件"><a href="#常用组件" class="headerlink" title="常用组件"></a>常用组件</h1><h2 id="基础组件"><a href="#基础组件" class="headerlink" title="基础组件"></a>基础组件</h2><p>wxPython提供了大量基础组件，如：<br>基础按钮Button；<br>图形按钮BitmapButton；<br>切换按钮ToggleButton（有两种状态可以切换：按下和未按下）；<br>静态文本框StaticText（展示一行或多行只读文本）；<br>文本输入框TextCtrl；<br>富文本输入框RichTextCtrl可以加入图像、文字色彩等效果；<br>带格式文本输入框StyledTextCtrl；<br>超链接HyperLinkCtrl；<br>静态位图：StaticBitmap；<br>静态分割线StaticLine（可垂直可水平）；<br>静态框StaticBox（为了装饰用，将多个组件组合在一起显示）；<br>下拉列表框ComboBox；<br>可编辑的下拉列表框Choice；<br>复选框CheckBox（有两个状态：勾选或未勾选）；<br>单选按钮RadioButton（单选按钮是从一组选项中只能选择一个，将多个单选按钮组合成一个选项组时，只需设定第一个单选按钮style为wx.RB_GROUP，后面跟着的那些单选按钮就自动跟它一组，如果想另开一组，只需再将另一组的第一个单选按钮的style设置为wx.RB_GROUP）；<br>进度条Gauge；<br>滑动条Slider；<br>整数数值调节钮SpinCtrl；<br>浮点数数值调节钮SpinCtrlDouble；<br>滚动条ScrollBar。</p><h2 id="高级组件"><a href="#高级组件" class="headerlink" title="高级组件"></a>高级组件</h2><p>列表框ListBox：是对一组选项的展示和交互，它有两个主要的事件，一个是wx.EVT_COMMAND_LISTBOX_SELECTED，即鼠标单击某一项时产生；另一个是wx.EVT_COMMAND_LISTBOX_DOUBLE_CLICKED，即鼠标双击某一项时产生。<br>列表视图ListCtrl：也是用来展示一组选项，与ListBox不同的是，ListBox仅能展示一列，而ListCtrl能展示多列。ListCtrl有三种视图模式：list、report和icon。向ListCtrl中插入数据需要使用两种方法：首先使用InsertItem()方法获得行号，然后再在当前行中使用SetItem()方法在列中插入数据。<br>Mixins：Mixins增强了ListCtrl的功能，它们都在wx.lib.mixins.listctrl这个模块中，一共有六种Mixins：<br>（1）wx.ColumnSorterMixin：使得在report视图中对列进行排序；<br>（2）wx.ListCtrlAutoWidthMixin：自动调整最后一列的宽度来占据剩余的空间；<br>（3）wx.ListCtrlSelectionManagerMix：定义了与系统无关的选择策略；<br>（4）wx.TextEditMixin：使得可以编辑文本；<br>（5）wx.CheckListCtrlMixin：给每一行增加了一个复选框；<br>（6）wx.ListRowHighlighter：候选行自动背景高亮。<br>wx.html.HtmlWindow：用来展示HTML页面。<br>wx.SplitterWindow：包含两个子窗口（如果使用wxFormBuilder，注意手动添加上两个panel）</p><p>另外还有比如：<br>树状结构TreeCtrl；<br>表格Grid；<br>搜索框SearchCtrl；<br>调色板ColourPickerCtrl；<br>字体设置器FontPickerCtrl；<br>文件选择器FilePickerCtrl；<br>文件目录选择器DirPickerCtrl；<br>文件树选择器GenericDirCtrl；<br>日期选择器DatePickerCtrl；<br>日历CalenderCtrl。</p><h1 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h1><p>wxPython的绘图之前写过，参见以下两篇：<br><a href="https://qixinbo.info/2019/09/07/imagepy_6/">ImagePy解析：6 – wxPython GDI绘图和FloatCanvas</a><br><a href="https://qixinbo.info/2019/10/16/imagepy_11/">ImagePy解析：11 – 使用wxPython设备上下文绘图</a></p><h1 id="自定义组件"><a href="#自定义组件" class="headerlink" title="自定义组件"></a>自定义组件</h1><p>如上，wxPython的常用组件已经有很多，但仍然不能涵盖真实情况下的千奇百怪的需求，这时候就要根据自己的需求自定义组件。<br>自定义组件有两种方式：一种是在现有组件的基础上修改或增强，这种方式仍然有一定的限制；另一种是结合wxPython的GDI绘图，自己从头创建组件，这种方式就具有极大的灵活性。<br>从头绘制组件一般都是在wx.Panel基础上进行创建。</p><h1 id="俄罗斯方块"><a href="#俄罗斯方块" class="headerlink" title="俄罗斯方块"></a>俄罗斯方块</h1><p>下面给了一个俄罗斯方块的游戏程序代码，可以说是一个使用wxPython编写GUI程序的集大成者：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">ZetCode wxPython tutorial</span></span><br><span class="line"><span class="string">This is Tetris game clone in wxPython.</span></span><br><span class="line"><span class="string">author: Jan Bodnar</span></span><br><span class="line"><span class="string">website: www.zetcode.com</span></span><br><span class="line"><span class="string">last modified: April 2018</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tetris</span>(<span class="params">wx.Frame</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        wx.Frame.__init__(self, parent, size=(<span class="number">180</span>, <span class="number">380</span>),</span><br><span class="line">            style=wx.DEFAULT_FRAME_STYLE ^ wx.RESIZE_BORDER ^ wx.MAXIMIZE_BOX)</span><br><span class="line"></span><br><span class="line">        self.initFrame()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initFrame</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.statusbar = self.CreateStatusBar()</span><br><span class="line">        self.statusbar.SetStatusText(<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">        self.board = Board(self)</span><br><span class="line">        self.board.SetFocus()</span><br><span class="line">        self.board.start()</span><br><span class="line">        self.SetTitle(<span class="string">&quot;Tetris&quot;</span>)</span><br><span class="line">        self.Centre()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Board</span>(<span class="params">wx.Panel</span>):</span></span><br><span class="line">    BoardWidth = <span class="number">10</span></span><br><span class="line">    BoardHeight = <span class="number">22</span></span><br><span class="line">    Speed = <span class="number">300</span></span><br><span class="line">    ID_TIMER = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *args, **kw</span>):</span></span><br><span class="line">        <span class="comment"># wx.Panel.__init__(self, parent)</span></span><br><span class="line">        <span class="built_in">super</span>(Board, self).__init__(*args, **kw)</span><br><span class="line">        self.initBoard()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initBoard</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.timer = wx.Timer(self, Board.ID_TIMER)</span><br><span class="line">        self.isWaitingAfterLine = <span class="literal">False</span></span><br><span class="line">        self.curPiece = Shape()</span><br><span class="line">        self.nextPiece = Shape()</span><br><span class="line">        self.curX = <span class="number">0</span></span><br><span class="line">        self.curY = <span class="number">0</span></span><br><span class="line">        self.numLinesRemoved = <span class="number">0</span></span><br><span class="line">        self.board = []</span><br><span class="line">        self.isStarted = <span class="literal">False</span></span><br><span class="line">        self.isPaused = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        self.Bind(wx.EVT_PAINT, self.OnPaint)</span><br><span class="line">        self.Bind(wx.EVT_KEY_DOWN, self.OnKeyDown)</span><br><span class="line">        self.Bind(wx.EVT_TIMER, self.OnTimer, <span class="built_in">id</span>=Board.ID_TIMER)</span><br><span class="line"></span><br><span class="line">        self.clearBoard()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shapeAt</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.board[(y * Board.BoardWidth) + x]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setShapeAt</span>(<span class="params">self, x, y, shape</span>):</span></span><br><span class="line">        self.board[(y * Board.BoardWidth) + x] = shape</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">squareWidth</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.GetClientSize().GetWidth() // Board.BoardWidth</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">squareHeight</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.GetClientSize().GetHeight() // Board.BoardHeight</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.isPaused:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        self.isStarted = <span class="literal">True</span></span><br><span class="line">        self.isWaitingAfterLine = <span class="literal">False</span></span><br><span class="line">        self.numLinesRemoved = <span class="number">0</span></span><br><span class="line">        self.clearBoard()</span><br><span class="line">        self.newPiece()</span><br><span class="line">        self.timer.Start(Board.Speed)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pause</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.isStarted:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        self.isPaused = <span class="keyword">not</span> self.isPaused</span><br><span class="line">        statusbar = self.GetParent().statusbar</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.isPaused:</span><br><span class="line">            self.timer.Stop()</span><br><span class="line">            statusbar.SetStatusText(<span class="string">&#x27;paused&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.timer.Start(Board.Speed)</span><br><span class="line">            statusbar.SetStatusText(<span class="built_in">str</span>(self.numLinesRemoved))</span><br><span class="line"></span><br><span class="line">        self.Refresh()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clearBoard</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Board.BoardHeight * Board.BoardWidth):</span><br><span class="line">            self.board.append(Tetrominoes.NoShape)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">OnPaint</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        dc = wx.PaintDC(self)</span><br><span class="line">        size = self.GetClientSize()</span><br><span class="line">        boardTop = size.GetHeight() - Board.BoardHeight * self.squareHeight()</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Board.BoardHeight):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Board.BoardWidth):</span><br><span class="line">                shape = self.shapeAt(j, Board.BoardHeight - i - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> shape != Tetrominoes.NoShape:</span><br><span class="line">                    self.drawSquare(dc,</span><br><span class="line">                        <span class="number">0</span> + j * self.squareWidth(),</span><br><span class="line">                        boardTop + i * self.squareHeight(), shape)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.curPiece.shape() != Tetrominoes.NoShape:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                x = self.curX + self.curPiece.x(i)</span><br><span class="line">                y = self.curY - self.curPiece.y(i)</span><br><span class="line"></span><br><span class="line">                self.drawSquare(dc, <span class="number">0</span> + x * self.squareWidth(),</span><br><span class="line">                    boardTop + (Board.BoardHeight - y - <span class="number">1</span>) * self.squareHeight(),</span><br><span class="line">                    self.curPiece.shape())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">OnKeyDown</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.isStarted <span class="keyword">or</span> self.curPiece.shape() == Tetrominoes.NoShape:</span><br><span class="line">            event.Skip()</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        keycode = event.GetKeyCode()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> keycode == <span class="built_in">ord</span>(<span class="string">&#x27;P&#x27;</span>) <span class="keyword">or</span> keycode == <span class="built_in">ord</span>(<span class="string">&#x27;p&#x27;</span>):</span><br><span class="line">            self.pause()</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.isPaused:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> keycode == wx.WXK_LEFT:</span><br><span class="line">            self.tryMove(self.curPiece, self.curX - <span class="number">1</span>, self.curY)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> keycode == wx.WXK_RIGHT:</span><br><span class="line">            self.tryMove(self.curPiece, self.curX + <span class="number">1</span>, self.curY)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> keycode == wx.WXK_DOWN:</span><br><span class="line">            self.tryMove(self.curPiece.rotatedRight(), self.curX, self.curY)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> keycode == wx.WXK_UP:</span><br><span class="line">            self.tryMove(self.curPiece.rotatedLeft(), self.curX, self.curY)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> keycode == wx.WXK_SPACE:</span><br><span class="line">            self.dropDown()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> keycode == <span class="built_in">ord</span>(<span class="string">&#x27;D&#x27;</span>) <span class="keyword">or</span> keycode == <span class="built_in">ord</span>(<span class="string">&#x27;d&#x27;</span>):</span><br><span class="line">            self.oneLineDown()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            event.Skip()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">OnTimer</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        <span class="keyword">if</span> event.GetId() == Board.ID_TIMER:</span><br><span class="line">            <span class="keyword">if</span> self.isWaitingAfterLine:</span><br><span class="line">                self.isWaitingAfterLine = <span class="literal">False</span></span><br><span class="line">                self.newPiece()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.oneLineDown()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            event.Skip()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dropDown</span>(<span class="params">self</span>):</span></span><br><span class="line">        newY = self.curY</span><br><span class="line">        <span class="keyword">while</span> newY &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self.tryMove(self.curPiece, self.curX, newY - <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            newY -= <span class="number">1</span></span><br><span class="line">        self.pieceDropped()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">oneLineDown</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.tryMove(self.curPiece, self.curX, self.curY - <span class="number">1</span>):</span><br><span class="line">            self.pieceDropped()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pieceDropped</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            x = self.curX + self.curPiece.x(i)</span><br><span class="line">            y = self.curY - self.curPiece.y(i)</span><br><span class="line">            self.setShapeAt(x, y, self.curPiece.shape())</span><br><span class="line"></span><br><span class="line">        self.removeFullLines()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.isWaitingAfterLine:</span><br><span class="line">            self.newPiece()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeFullLines</span>(<span class="params">self</span>):</span></span><br><span class="line">        numFullLines = <span class="number">0</span></span><br><span class="line">        statusbar = self.GetParent().statusbar</span><br><span class="line">        rowsToRemove = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Board.BoardHeight):</span><br><span class="line">            n = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Board.BoardWidth):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> self.shapeAt(j, i) == Tetrominoes.NoShape:</span><br><span class="line">                    n = n + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> n == <span class="number">10</span>:</span><br><span class="line">                rowsToRemove.append(i)</span><br><span class="line"></span><br><span class="line">        rowsToRemove.reverse()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> rowsToRemove:</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(m, Board.BoardHeight):</span><br><span class="line">                <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(Board.BoardWidth):</span><br><span class="line">                        self.setShapeAt(l, k, self.shapeAt(l, k + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">            numFullLines = numFullLines + <span class="built_in">len</span>(rowsToRemove)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> numFullLines &gt; <span class="number">0</span>:</span><br><span class="line">                self.numLinesRemoved = self.numLinesRemoved + numFullLines</span><br><span class="line">                statusbar.SetStatusText(<span class="built_in">str</span>(self.numLinesRemoved))</span><br><span class="line">                self.isWaitingAfterLine = <span class="literal">True</span></span><br><span class="line">                self.curPiece.setShape(Tetrominoes.NoShape)</span><br><span class="line">                self.Refresh()</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">newPiece</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.curPiece = self.nextPiece</span><br><span class="line">        statusbar = self.GetParent().statusbar</span><br><span class="line">        self.nextPiece.setRandomShape()</span><br><span class="line"></span><br><span class="line">        self.curX = Board.BoardWidth // <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">        self.curY = Board.BoardHeight - <span class="number">1</span> + self.curPiece.minY()</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.tryMove(self.curPiece, self.curX, self.curY):</span><br><span class="line">            self.curPiece.setShape(Tetrominoes.NoShape)</span><br><span class="line">            self.timer.Stop()</span><br><span class="line">            self.isStarted = <span class="literal">False</span></span><br><span class="line">            statusbar.SetStatusText(<span class="string">&#x27;Game over&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tryMove</span>(<span class="params">self, newPiece, newX, newY</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            x = newX + newPiece.x(i)</span><br><span class="line">            y = newY - newPiece.y(i)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">or</span> x &gt;= Board.BoardWidth <span class="keyword">or</span> y &lt; <span class="number">0</span> <span class="keyword">or</span> y &gt;= Board.BoardHeight:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.shapeAt(x, y) != Tetrominoes.NoShape:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        self.curPiece = newPiece</span><br><span class="line">        self.curX = newX</span><br><span class="line">        self.curY = newY</span><br><span class="line">        self.Refresh()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">drawSquare</span>(<span class="params">self, dc, x, y, shape</span>):</span></span><br><span class="line">        colors = [<span class="string">&#x27;#000000&#x27;</span>, <span class="string">&#x27;#CC6666&#x27;</span>, <span class="string">&#x27;#66CC66&#x27;</span>, <span class="string">&#x27;#6666CC&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;#CCCC66&#x27;</span>, <span class="string">&#x27;#CC66CC&#x27;</span>, <span class="string">&#x27;#66CCCC&#x27;</span>, <span class="string">&#x27;#DAAA00&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        light = [<span class="string">&#x27;#000000&#x27;</span>, <span class="string">&#x27;#F89FAB&#x27;</span>, <span class="string">&#x27;#79FC79&#x27;</span>, <span class="string">&#x27;#7979FC&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;#FCFC79&#x27;</span>, <span class="string">&#x27;#FC79FC&#x27;</span>, <span class="string">&#x27;#79FCFC&#x27;</span>, <span class="string">&#x27;#FCC600&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        dark = [<span class="string">&#x27;#000000&#x27;</span>, <span class="string">&#x27;#803C3B&#x27;</span>, <span class="string">&#x27;#3B803B&#x27;</span>, <span class="string">&#x27;#3B3B80&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;#80803B&#x27;</span>, <span class="string">&#x27;#803B80&#x27;</span>, <span class="string">&#x27;#3B8080&#x27;</span>, <span class="string">&#x27;#806200&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        pen = wx.Pen(light[shape])</span><br><span class="line">        pen.SetCap(wx.CAP_PROJECTING)</span><br><span class="line">        dc.SetPen(pen)</span><br><span class="line"></span><br><span class="line">        dc.DrawLine(x, y + self.squareHeight() - <span class="number">1</span>, x, y)</span><br><span class="line">        dc.DrawLine(x, y, x + self.squareWidth() - <span class="number">1</span>, y)</span><br><span class="line"></span><br><span class="line">        darkpen = wx.Pen(dark[shape])</span><br><span class="line">        darkpen.SetCap(wx.CAP_PROJECTING)</span><br><span class="line">        dc.SetPen(darkpen)</span><br><span class="line"></span><br><span class="line">        dc.DrawLine(x + <span class="number">1</span>, y + self.squareHeight() - <span class="number">1</span>,</span><br><span class="line">            x + self.squareWidth() - <span class="number">1</span>, y + self.squareHeight() - <span class="number">1</span>)</span><br><span class="line">        dc.DrawLine(x + self.squareWidth() - <span class="number">1</span>,</span><br><span class="line">        y + self.squareHeight() - <span class="number">1</span>, x + self.squareWidth() - <span class="number">1</span>, y + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        dc.SetPen(wx.TRANSPARENT_PEN)</span><br><span class="line">        dc.SetBrush(wx.Brush(colors[shape]))</span><br><span class="line">        dc.DrawRectangle(x + <span class="number">1</span>, y + <span class="number">1</span>, self.squareWidth() - <span class="number">2</span>,</span><br><span class="line">        self.squareHeight() - <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tetrominoes</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    NoShape = <span class="number">0</span></span><br><span class="line">    ZShape = <span class="number">1</span></span><br><span class="line">    SShape = <span class="number">2</span></span><br><span class="line">    LineShape = <span class="number">3</span></span><br><span class="line">    TShape = <span class="number">4</span></span><br><span class="line">    SquareShape = <span class="number">5</span></span><br><span class="line">    LShape = <span class="number">6</span></span><br><span class="line">    MirroredLShape = <span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Shape</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    coordsTable = (</span><br><span class="line">        ((<span class="number">0</span>, <span class="number">0</span>),     (<span class="number">0</span>, <span class="number">0</span>),     (<span class="number">0</span>, <span class="number">0</span>),     (<span class="number">0</span>, <span class="number">0</span>)),</span><br><span class="line">        ((<span class="number">0</span>, -<span class="number">1</span>),    (<span class="number">0</span>, <span class="number">0</span>),     (-<span class="number">1</span>, <span class="number">0</span>),    (-<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">        ((<span class="number">0</span>, -<span class="number">1</span>),    (<span class="number">0</span>, <span class="number">0</span>),     (<span class="number">1</span>, <span class="number">0</span>),     (<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">        ((<span class="number">0</span>, -<span class="number">1</span>),    (<span class="number">0</span>, <span class="number">0</span>),     (<span class="number">0</span>, <span class="number">1</span>),     (<span class="number">0</span>, <span class="number">2</span>)),</span><br><span class="line">        ((-<span class="number">1</span>, <span class="number">0</span>),    (<span class="number">0</span>, <span class="number">0</span>),     (<span class="number">1</span>, <span class="number">0</span>),     (<span class="number">0</span>, <span class="number">1</span>)),</span><br><span class="line">        ((<span class="number">0</span>, <span class="number">0</span>),     (<span class="number">1</span>, <span class="number">0</span>),     (<span class="number">0</span>, <span class="number">1</span>),     (<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">        ((-<span class="number">1</span>, -<span class="number">1</span>),   (<span class="number">0</span>, -<span class="number">1</span>),    (<span class="number">0</span>, <span class="number">0</span>),     (<span class="number">0</span>, <span class="number">1</span>)),</span><br><span class="line">        ((<span class="number">1</span>, -<span class="number">1</span>),    (<span class="number">0</span>, -<span class="number">1</span>),    (<span class="number">0</span>, <span class="number">0</span>),     (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.coords = [[<span class="number">0</span>,<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)]</span><br><span class="line">        self.pieceShape = Tetrominoes.NoShape</span><br><span class="line">        self.setShape(Tetrominoes.NoShape)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shape</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.pieceShape</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setShape</span>(<span class="params">self, shape</span>):</span></span><br><span class="line">        table = Shape.coordsTable[shape]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">                self.coords[i][j] = table[i][j]</span><br><span class="line"></span><br><span class="line">        self.pieceShape = shape</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setRandomShape</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.setShape(random.randint(<span class="number">1</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">x</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.coords[index][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">y</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.coords[index][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setX</span>(<span class="params">self, index, x</span>):</span></span><br><span class="line">        self.coords[index][<span class="number">0</span>] = x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setY</span>(<span class="params">self, index, y</span>):</span></span><br><span class="line">        self.coords[index][<span class="number">1</span>] = y</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minX</span>(<span class="params">self</span>):</span></span><br><span class="line">        m = self.coords[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            m = <span class="built_in">min</span>(m, self.coords[i][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxX</span>(<span class="params">self</span>):</span></span><br><span class="line">        m = self.coords[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            m = <span class="built_in">max</span>(m, self.coords[i][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minY</span>(<span class="params">self</span>):</span></span><br><span class="line">        m = self.coords[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            m = <span class="built_in">min</span>(m, self.coords[i][<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxY</span>(<span class="params">self</span>):</span></span><br><span class="line">        m = self.coords[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            m = <span class="built_in">max</span>(m, self.coords[i][<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rotatedLeft</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.pieceShape == Tetrominoes.SquareShape:</span><br><span class="line">            <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">        result = Shape()</span><br><span class="line">        result.pieceShape = self.pieceShape</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            result.setX(i, self.y(i))</span><br><span class="line">            result.setY(i, -self.x(i))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rotatedRight</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.pieceShape == Tetrominoes.SquareShape:</span><br><span class="line">            <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">        result = Shape()</span><br><span class="line">        result.pieceShape = self.pieceShape</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            result.setX(i, -self.y(i))</span><br><span class="line">            result.setY(i, self.x(i))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    app = wx.App()</span><br><span class="line">    ex = Tetris(<span class="literal">None</span>)</span><br><span class="line">    ex.Show()</span><br><span class="line">    app.MainLoop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>效果如图：<br><img src="https://user-images.githubusercontent.com/6218739/94236695-4216c600-ff40-11ea-93e8-963195be2d10.png" alt="image"></p><p>不过我在运行上述代码时，出现了无法使用箭头键来控制方块的情形，解决方式在Board这个panel中设置一个旗标：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">super</span>(Board, self).__init__(*args, **kw, style=wx.WANTS_CHARS)</span><br></pre></td></tr></table></figure><p>该问题的讨论在：<br><a href="http://wxpython-users.1045709.n5.nabble.com/how-to-catch-arrow-keys-td2365210.html">how to catch arrow keys ?</a><br><a href="https://discuss.wxpython.org/t/stumped-arrows-tab-kills-keyboard-focus/27163/6">Stumped: arrows/tab kills keyboard focus</a><br>另外，捕获keycode，如果是判断字母，最好是大小写形式都判断，即里面：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> keycode == <span class="built_in">ord</span>(<span class="string">&#x27;P&#x27;</span>) <span class="keyword">or</span> keycode == <span class="built_in">ord</span>(<span class="string">&#x27;p&#x27;</span>):</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">简介
本文是对ZetCode上wxPython的摘抄学习，原系列文章见这里。

wxPython是一个开发桌面端图形界面的跨平台函数库，开发语言为Python，它是基于C++的函数库wxWidgets的封装。
wxpython有大量组件，它们可以从逻辑上（注意是逻辑上）这样划分：
（1）基础组件

这些组件为其所派生的子组件提供基础功能，通常不直接使用。
（2）顶层组件

这些组件相互独立存在。
（3）容器

这些组件包含其他组件。
（4）动态组件

这些组件可以被用户所交互编辑。
（5）静态组件

这些组件用来展示信息，无法被用户所交互编辑。
（6）其他组件

这些组件包括状态栏、工具栏、菜</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="Image" scheme="http://qixinbo.github.io/tags/Image/"/>
    
    <category term="GUI" scheme="http://qixinbo.github.io/tags/GUI/"/>
    
  </entry>
  
  <entry>
    <title>(转载)Harris角点检测原理</title>
    <link href="http://qixinbo.github.io/2020/08/05/harris/"/>
    <id>http://qixinbo.github.io/2020/08/05/harris/</id>
    <published>2020-08-04T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.632Z</updated>
    
    <content type="html"><![CDATA[<p>原文在<a href="https://senitco.github.io/2017/06/18/image-feature-harris/">这里</a>，中间增加了一些额外的内容辅助理解。</p><p>角点检测(Corner Detection)也称为特征点检测，是图像处理和计算机视觉中用来获取图像局部特征点的一类方法，广泛应用于运动检测、图像匹配、视频跟踪、三维建模以及目标识别等领域中。</p><h1 id="局部特征"><a href="#局部特征" class="headerlink" title="局部特征"></a>局部特征</h1><p>不同于HOG、LBP、Haar等基于区域(Region)的图像局部特征，Harris是基于角点的特征描述子，属于feature detector，主要用于图像特征点的匹配(match)，在SIFT算法中就有用到此类角点特征；而HOG、LBP、Haar等则是通过提取图像的局部纹理特征(feature extraction)，用于目标的检测和识别等领域。无论是HOG、Haar特征还是Harris角点都属于图像的局部特征，满足局部特征的一些特性。主要有以下几点：</p><ul><li>可重复性(Repeatability)：同一个特征可以出现在不同的图像中，这些图像可以在不同的几何或光学环境下成像。也就是说，同一物体在不同的环境下成像(不同时间、不同角度、不同相机等)，能够检测到同样的特征。</li><li>独特性(Saliency)：特征在某一特定目标上表现为独特性，能够与场景中其他物体相区分，能够达到后续匹配或识别的目的。</li><li>局部性(Locality)；特征能够刻画图像的局部特性，而且对环境影响因子(光照、噪声等)鲁棒。</li><li>紧致性和有效性(Compactness and efficiency)；特征能够有效地表达图像信息，而且在实际应用中运算要尽可能地快。</li></ul><p>相比于考虑局部邻域范围的局部特征，全局特征则是从整个图像中抽取特征，较多地运用在图像检索领域，例如图像的颜色直方图。<br>除了以上几点通用的特性外，对于一些图像匹配、检测识别等任务，可能还需进一步考虑图像的局部不变特征。例如尺度不变性(Scale invariance)和旋转不变性(Rotation invariance)，当图像中的物体或目标发生旋转或者尺度发生变换，依然可以有效地检测或识别。此外，也会考虑局部特征对光照、阴影的不变性。</p><h1 id="Harris角点检测"><a href="#Harris角点检测" class="headerlink" title="Harris角点检测"></a>Harris角点检测</h1><p>特征点在图像中一般有具体的坐标，并具有某些数学特征，如局部最大或最小灰度、以及某些梯度特征等。角点可以简单的认为是两条边的交点，比较严格的定义则是在邻域内具有两个主方向的特征点，也就是说在两个方向上灰度变化剧烈。如下图所示，在各个方向上移动小窗口，如果在所有方向上移动，窗口内灰度都发生变化，则认为是角点；如果任何方向都不变化，则是均匀区域；如果灰度只在一个方向上变化，则可能是图像边缘。<br><img src="https://user-images.githubusercontent.com/6218739/89362741-360d4580-d701-11ea-8779-9d993f5e7dce.png" alt="image"></p><p>对于给定图像$I(x,y)$（即图像强度）和固定尺寸的邻域窗口，计算窗口平移前后各个像素差值的平方和，也就是自相关函数：<br>$$<br>E(u,v)=\Sigma_x\Sigma_yw(x,y)[I(x+u,y+v)-I(x,y)]^2<br>$$<br>其中，窗口加权函数$w(x,y)$可取均值函数或者高斯函数，如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/89362908-97351900-d701-11ea-8d13-57cc49354cec.png" alt="image"><br>根据泰勒展开，可得到窗口平移后图像的一阶近似（梯度乘以位移，注意$I_x$表示x方向的梯度）：<br>$$<br>I(x+u,y+v)\approx I(x,y)+I_x(x,y)u+I_y(x,y)v<br>$$<br>因此，$E(u,v)$可化为：<br>$$<br>E(u,v) \approx \Sigma_{x,y}w(x,y)[I_x(x,y)u+I_y(x,y)v]^2=\left[u,v\right] M(x,y) \left[ \begin{matrix} u\ v\end{matrix} \right]<br>$$<br>其中：<br>$$<br>M(x,y)=\Sigma_{x,y} w \left[ \begin{matrix} I_x^2&amp; I_xI_y \ I_xI_y &amp; I_y^2\end{matrix} \right] = \left[ \begin{matrix} A&amp; C\ C&amp; B\end{matrix} \right]<br>$$<br>因此，$M$就是偏导数矩阵。<br>可以有多个角度来理解这个矩阵：<br>（1）几何角度：<br>$E(u,v)$可表示为一个二次项函数：<br>$$<br>E(u,v)=Au^2+2Cuv+Bv^2<br>$$<br>其中：<br>$$<br>A=\Sigma_{x,y} w I_x^2, B = \Sigma_{x,y} w I_y^2, C=\Sigma_{x,y} w I_x I_y<br>$$</p><p>二次项函数本质上是一个椭圆函数，椭圆的曲率和尺寸可由$M(x,y)$的特征值$\lambda_1,\lambda_2$决定，椭圆方向由$M(x,y)$的特征向量决定，椭圆方程和其图形分别如下所示：<br><img src="https://user-images.githubusercontent.com/6218739/89366840-3a8a2c00-d70a-11ea-86af-28329b0e68fa.png" alt="image"></p><p>（2）线性代数角度：<br>首先来点线性代数中特征值和特征向量的基本知识：<br>对于一个给定的方阵，它的特征向量经过这个方阵的线性变换后，得到的新向量与原来的特征向量保持在同一条直线上，但其长度或方向也许会改变，这个长度的缩放比例就是特征值。<br><img src="https://user-images.githubusercontent.com/6218739/89378163-d7a68e00-d725-11ea-84fb-06bdb29339d9.png" alt="image"><br>注意：方阵代表了对向量的变换，而不是向量代表了对方阵的变换。对于方阵所产生的变换效果，就可以分解为特征向量和特征值的效果：特征向量代表了旋转，特征值代表了缩放。因此，对于任一向量，如果对其施加了方阵这一变换，就有可能使其旋转和缩放；特别地，对于特征向量这一向量，施加方阵后，就只会缩放，而不会旋转。<br>通过矩阵相似对角化分解，可以得到：<br>$$<br>A=PBP^{-1}<br>$$<br>其中，$B$为对角阵，里面是特征值，决定了缩放；$P$的列向量是单位化的特征向量，并且互相正交，决定了旋转。<br><img src="https://user-images.githubusercontent.com/6218739/89378770-20ab1200-d727-11ea-8b4e-fb3c4183a5a1.png" alt="image"></p><p>一些参考文章：<br><a href="https://www.jianshu.com/p/a2ef1b585b03">矩阵特征值与特征向量和相似对角化</a><br><a href="https://www.matongxue.com/madocs/228.html">如何理解矩阵特征值和特征向量？</a></p><p>有了上面的背景，先考虑角点的边界和坐标轴对齐的这种特殊情况，如下图所示，在平移窗口内，只有上侧和左侧边缘，上边缘$I_y$很大而$I_x$很小，左边缘$I_x$很大而$I_y$很小，所以矩阵$M$可化简为（即没有旋转）：<br>$$<br>M=\left[ \begin{matrix} \lambda_1&amp; 0\ 0&amp; \lambda_2\end{matrix} \right]<br>$$<br><img src="https://user-images.githubusercontent.com/6218739/89379432-61eff180-d728-11ea-98e0-23361456bed1.png" alt="image"><br>当角点边界和坐标轴没有对齐时，可对角点进行旋转变换，将其变换到与坐标轴对齐，这种旋转操作可用矩阵的相似对角化来表示，即：<br>$$<br>M=X\Sigma X^T = X \left[ \begin{matrix} \lambda_1&amp; 0\ 0&amp; \lambda_2\end{matrix} \right] X^T<br>$$<br><img src="https://user-images.githubusercontent.com/6218739/89379537-88159180-d728-11ea-9c0f-59f4d5d071ad.png" alt="image"></p><p>再回过头来重新看一下$M$矩阵：<br>$$<br>M(x,y)=\Sigma_{x,y} w \left[ \begin{matrix} I_x^2&amp; I_xI_y \ I_xI_y &amp; I_y^2\end{matrix} \right] = \left[ \begin{matrix} A&amp; C\ C&amp; B\end{matrix} \right]<br>$$<br>时刻注意，式中的$I_x$是梯度，是导数，是灰度强度的差别。<br>对于矩阵$M$，可以将其和协方差矩阵类比，协方差表示多维随机变量之间的相关性，协方差矩阵对角线的元素表示的是各个维度自身的方差，而非对角线上的元素表示的是各个维度之间的相关性，在PCA(主成分分析)中，将协方差矩阵对角化，使不同维度的相关性尽可能的小（相关性为0时就是非对角线元素为0），并取特征值较大的维度，来达到降维的目的。而这里的矩阵M中的对角线元素是灰度强度在某一方向上的梯度的平方，而非对角线上的元素则是灰度在两个不同方向上的梯度的乘积，所以可以将矩阵$M看成是一个二维随机分布的协方差矩阵，通过将其对角化，一方面可以得到两个正交的特征向量，另一方面也可以求取矩阵的两个特征值（与两个方向上的梯度直接相关），并根据这两个特征值来判断角点。</p><p>更多地关于PCA的补充知识：<br><img src="https://user-images.githubusercontent.com/6218739/89623622-80d8ba00-d8c7-11ea-9520-728ae9fc1f88.jpg" alt="20200807152900_1"></p><p>一些参考文章：<br><a href="https://zhuanlan.zhihu.com/p/37777074">主成分分析（PCA）原理详解</a><br><a href="https://juejin.im/post/6847902219635785741">PCA算法 | 数据集特征数量太多怎么办？用这个算法对它降维打击！</a><br><a href="http://commanber.com/2017/04/05/pca-translation/">主成分分析（PCA）简明教程（翻译）</a><br><a href="https://zhuanlan.zhihu.com/p/45140262">深度学习的预处理：从协方差矩阵到图像白化</a><br><a href="https://my.oschina.net/gujianhan/blog/225241#OSC_h2_1">PCA （主成分分析）详解 （写给初学者）</a><br><a href="https://cggos.github.io/computervision/image-process-moments.html">图像空间域分析之图像统计特征</a></p><p><img src="https://user-images.githubusercontent.com/6218739/89386440-a6cd5580-d733-11ea-8456-b46674c64b32.png" alt="image"><br>在判断角点时，无需具体计算矩阵$M$的特征值，而使用下式近似计算角点响应值。<br><img src="https://user-images.githubusercontent.com/6218739/89386536-c9f80500-d733-11ea-9245-75a24c616c6b.png" alt="image"><br>式中，$detM$为矩阵$M$的行列式，$traceM$为矩阵$M$的迹，$\alpha$为一常数，通常取值为0.04~0.06。</p><h1 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h1><p><img src="https://user-images.githubusercontent.com/6218739/89386732-0d527380-d734-11ea-83fb-93a791fe7f36.png" alt="image"></p>]]></content>
    
    
    <summary type="html">原文在这里，中间增加了一些额外的内容辅助理解。

角点检测(Corner Detection)也称为特征点检测，是图像处理和计算机视觉中用来获取图像局部特征点的一类方法，广泛应用于运动检测、图像匹配、视频跟踪、三维建模以及目标识别等领域中。

局部特征
不同于HOG、LBP、Haar等基于区域(Region)的图像局部特征，Harris是基于角点的特征描述子，属于feature detector，主要用于图像特征点的匹配(match)，在SIFT算法中就有用到此类角点特征；而HOG、LBP、Haar等则是通过提取图像的局部纹理特征(feature extraction)，用于目标的检测和识别等</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="Image" scheme="http://qixinbo.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析：23 -- ROI操作</title>
    <link href="http://qixinbo.github.io/2020/08/02/ImagePy_23/"/>
    <id>http://qixinbo.github.io/2020/08/02/ImagePy_23/</id>
    <published>2020-08-01T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.400Z</updated>
    
    <content type="html"><![CDATA[<p>%%%%%%%%<br>2021.2.14更新：增加了ICanvas绘制ROI的原理介绍。<br>%%%%%%%%</p><p>前面有两篇文章介绍了ImagePy/sciwx的<a href="https://qixinbo.info/2020/03/28/imagepy_19/">Mark模式</a>和<a href="https://qixinbo.info/2020/06/14/imagepy_20/">几何矢量</a>，这两个的结合就是图像处理中经典的ROI(Region Of Interest)操作，即选定一个范围（矩形、圆形、自由区域），然后对该区域进行进一步的操作。<br>这个过程说起来非常简单，但实际实现起来却是非常不容易，因为这里面涉及到了图像这一位图格式和几何这一矢量格式的统一。<br>这一篇文章就着重剖析一下ImagePy/sciwx是怎样实现的。</p><p>本文选定的入手案例是“绘制矩形ROI，然后裁剪”。</p><h1 id="矩形ROI"><a href="#矩形ROI" class="headerlink" title="矩形ROI"></a>矩形ROI</h1><p>首先看矩形ROI的绘制时怎样实现的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> RectangleROI <span class="keyword">as</span> Plugin</span><br></pre></td></tr></table></figure><p>可以看出，就是从sciapp的action包中直接导入了RectangleROI模块。</p><h2 id="RectangleROI"><a href="#RectangleROI" class="headerlink" title="RectangleROI"></a>RectangleROI</h2><p>再深入看一下RectangleROI是怎样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RectangleROI</span>(<span class="params">BaseROI</span>):</span></span><br><span class="line">title = <span class="string">&#x27;Rectangle ROI&#x27;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span> </span><br><span class="line">BaseROI.__init__(self, RectangleEditor)</span><br></pre></td></tr></table></figure><p>即，RectangleROI的父类是BaseROI，然后给RectangleROI一个特定的名称。另外一个非常重要的点就是在RectangleROI初始化函数中，对父类BaseROI的初始化中传入了RectangleEditor，而这正是RectangleROI与其他ROI的本质区别，比如EllipseROI传入的是EllipseEditor，PointROI传入的是PointEditor，而这些Editor实际又是BaseEditor的子类。</p><p>换句话说，这些ROI是两个重要的类（BaseROI和BaseEditor）的组合，具备这两个类的综合特性；这也呼应了文章开头所说的ROI操作需要兼具“位图”和“矢量图”的特点。</p><p>接下来分别深入这两个重要的类。</p><h2 id="BaseROI"><a href="#BaseROI" class="headerlink" title="BaseROI"></a>BaseROI</h2><p>首先是BaseROI。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseROI</span>(<span class="params">ImageTool</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, base</span>):</span> </span><br><span class="line">base.__init__(self)</span><br><span class="line">self.base = base</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, img, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> img.roi <span class="keyword">is</span> <span class="literal">None</span>: img.roi = ROI()</span><br><span class="line"><span class="keyword">else</span>: img.roi.msk = <span class="literal">None</span></span><br><span class="line">self.base.mouse_down(self, img.roi, x, y, btn, **key)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, img, x, y, btn, **key</span>):</span></span><br><span class="line">self.base.mouse_up(self, img.roi, x, y, btn, **key)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> img.roi <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(img.roi.body)==<span class="number">0</span>: img.roi = <span class="literal">None</span></span><br><span class="line"><span class="keyword">else</span>: img.roi.msk = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, img, x, y, btn, **key</span>):</span></span><br><span class="line">self.base.mouse_move(self, img.roi, x, y, btn, **key)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, img, x, y, d, **key</span>):</span></span><br><span class="line">self.base.mouse_wheel(self, img.roi, x, y, d, **key)</span><br></pre></td></tr></table></figure><p>BaseROI的源代码对它的来源讲得一目了然，它的父类是ImageTool，即它本质是ImageTool。为什么这一点是如此重要。因为无论是自定制的图像处理工具，还是现成的ImagePy，其画布都是对最底层的ICanvas类的封装，而ICanvas中绑定的tool就是ImageTool，见：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ICanvas</span>(<span class="params">Canvas</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent, autofit=<span class="literal">False</span></span>):</span></span><br><span class="line">        Canvas.__init__(self, parent, autofit)</span><br><span class="line">        self.images.append(Image())</span><br><span class="line">        <span class="comment">#self.images[0].back = Image()</span></span><br><span class="line">        self.Bind(wx.EVT_IDLE, self.on_idle)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_obj_tol</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.image, ImageTool.default</span><br></pre></td></tr></table></figure><p>当然这里所说的画布是具有常规用途的对位图的图像处理，如果纯粹是对矢量图的画布，则是对最底层的VCanvas的封装（具体可以见sciwx关于shape的各种demo），该类绑定的Tool则是ShapeTool：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VCanvas</span>(<span class="params">Canvas</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent, autofit=<span class="literal">False</span>, ingrade=<span class="literal">True</span>, up=<span class="literal">True</span></span>):</span></span><br><span class="line">        Canvas.__init__(self, parent, autofit, ingrade, up)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_obj_tol</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.shape, ShapeTool.default</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_shp</span>(<span class="params">self, shp</span>):</span></span><br><span class="line">        self.marks[<span class="string">&#x27;shape&#x27;</span>] = shp</span><br><span class="line">        self.update()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_tool</span>(<span class="params">self, tool</span>):</span> self.tool = tool</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shape</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="string">&#x27;shape&#x27;</span> <span class="keyword">in</span> self.marks: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.marks[<span class="string">&#x27;shape&#x27;</span>]</span><br></pre></td></tr></table></figure><p>可以看出，对于VCanvas，其obj就是返回的self.shape，而self.shape属性就是对self.marks这一字典中shape这一键值的调用。而这个shape键又是通过set_shp方法设定的。</p><p>看到这里，需要进一步深入的思考一下，VCanvas是矢量图的画布，而ICanvas实际是位图的画布，其归根结底是位图，即它get_obj得到的obj是image，那它又是怎样显示这些ROI的呢。<br>奥秘就在于ICanvas中的以下方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ICanvas</span>(<span class="params">Canvas</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent, autofit=<span class="literal">False</span></span>):</span></span><br><span class="line">        Canvas.__init__(self, parent, autofit)</span><br><span class="line">        self.images.append(Image())</span><br><span class="line">        self.Bind(wx.EVT_IDLE, self.on_idle)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_obj_tol</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.image, ImageTool.default</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_idle</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.image.unit == (<span class="number">1</span>, <span class="string">&#x27;pix&#x27;</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;unit&#x27;</span> <span class="keyword">in</span> self.marks: <span class="keyword">del</span> self.marks[<span class="string">&#x27;unit&#x27;</span>]</span><br><span class="line">        <span class="keyword">else</span>: self.marks[<span class="string">&#x27;unit&#x27;</span>] = self.draw_ruler</span><br><span class="line">        <span class="keyword">if</span> self.image.roi <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;roi&#x27;</span> <span class="keyword">in</span> self.marks: <span class="keyword">del</span> self.marks[<span class="string">&#x27;roi&#x27;</span>]</span><br><span class="line">        <span class="keyword">else</span>: self.marks[<span class="string">&#x27;roi&#x27;</span>] = self.image.roi</span><br><span class="line">        <span class="keyword">if</span> self.image.mark <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;mark&#x27;</span> <span class="keyword">in</span> self.marks: <span class="keyword">del</span> self.marks[<span class="string">&#x27;mark&#x27;</span>]</span><br><span class="line">        <span class="keyword">elif</span> self.image.mark.dtype==<span class="string">&#x27;layers&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> self.image.cur <span class="keyword">in</span> self.image.mark.body:</span><br><span class="line">                self.marks[<span class="string">&#x27;mark&#x27;</span>] = self.image.mark.body[self.image.cur]</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">&#x27;mark&#x27;</span> <span class="keyword">in</span> self.marks: <span class="keyword">del</span> self.marks[<span class="string">&#x27;mark&#x27;</span>]</span><br><span class="line">        <span class="keyword">else</span>: self.marks[<span class="string">&#x27;mark&#x27;</span>] = self.image.mark</span><br><span class="line">        self.tool = self.image.tool</span><br><span class="line">        Canvas.on_idle(self, event)</span><br></pre></td></tr></table></figure><p>在ICanvas的空闲鼠标事件中，它会监视它的image中的属性（注意这里是image的属性），比如unit、roi、mark属性，如果这些属性中有了数值，则在Canvas的marks属性（注意这里是Canvas的属性）中增加相应的键，比如unit、mark、roi等键，然后在Canvas的update方法中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> self.marks.values():</span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">is</span> <span class="literal">None</span>: <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">callable</span>(i):</span><br><span class="line">        i(dc, self.to_panel_coor, k=self.scale, cur=<span class="number">0</span>,</span><br><span class="line">            winbox=self.winbox, oribox=self.oribox, conbox=self.conbox)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        drawmark(dc, self.to_panel_coor, i, k=self.scale, cur=<span class="number">0</span>,</span><br><span class="line">            winbox=self.winbox, oribox=self.oribox, conbox=self.conbox)</span><br></pre></td></tr></table></figure><p>会对self.marks的值进行绘制。</p><p>说回BaseROI，可以看出其在初始化函数中需要传入base，比如它的子类RectangleROI在初始化时给它传入的RectangleEditor。</p><p>进一步地，可以看出BaseROI的鼠标事件都是调用的该base的鼠标事件。</p><p>这个地方需要注意的是，因为BaseROI本质是ImageTool，所以它的鼠标事件函数的第二个形参所传入的是Image对象，而base其实是个ShapeTool（后面详细解析），所以base的鼠标事件函数的第二个形参是个shape对象。两者的结合是在鼠标按下这个事件中进行的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, img, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> img.roi <span class="keyword">is</span> <span class="literal">None</span>: img.roi = ROI()</span><br><span class="line"><span class="keyword">else</span>: img.roi.msk = <span class="literal">None</span></span><br><span class="line">self.base.mouse_down(self, img.roi, x, y, btn, **key)</span><br></pre></td></tr></table></figure><p>即首先判断一下img的roi属性是否为None，如果为None，则将一个ROI类型的变量赋给它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ROI</span>(<span class="params">Layer</span>):</span></span><br><span class="line">default = &#123;<span class="string">&#x27;color&#x27;</span>:(<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="string">&#x27;fcolor&#x27;</span>:(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>), </span><br><span class="line">    <span class="string">&#x27;fill&#x27;</span>:<span class="literal">False</span>, <span class="string">&#x27;lw&#x27;</span>:<span class="number">1</span>, <span class="string">&#x27;tcolor&#x27;</span>:(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="string">&#x27;size&#x27;</span>:<span class="number">8</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, body=<span class="literal">None</span>, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(body, Layer):  body = body.body</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> body <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(body, <span class="built_in">list</span>):</span><br><span class="line">body = [body]</span><br><span class="line">Layer.__init__(self, body, **key)</span><br><span class="line">self.fill = <span class="literal">False</span></span><br><span class="line">self.msk = <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>这个ROI类的父类是Layer，而Layer的父类又是Shape类，所以ROI本质是个Shape对象，那么它的具体属性和操作就可以参见之前那篇专门的文章了，在<a href="https://qixinbo.info/2020/06/14/imagepy_20/">这里</a>。</p><p>如果img的roi属性不为None的话，就将roi的msk属性设为None。<br>然后将该roi传入base工具中。</p><h2 id="BaseEditor"><a href="#BaseEditor" class="headerlink" title="BaseEditor"></a>BaseEditor</h2><p>前面已经说到RectangleEditor的父类是BaseEditor，BaseEditor本身写了详细的鼠标事件函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseEditor</span>(<span class="params">ShapeTool</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dtype=<span class="string">&#x27;all&#x27;</span></span>):</span></span><br><span class="line">self.status, self.oldxy, self.p = <span class="string">&#x27;&#x27;</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">self.pick_m, self.pick_obj = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line">self.p = x, y</span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">2</span>:</span><br><span class="line">self.status = <span class="string">&#x27;move&#x27;</span></span><br><span class="line">self.oldxy = key[<span class="string">&#x27;px&#x27;</span>], key[<span class="string">&#x27;py&#x27;</span>]</span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> self.status==<span class="string">&#x27;pick&#x27;</span>:</span><br><span class="line">m, obj, l = pick_point(shp, x, y, <span class="number">5</span>)</span><br><span class="line">self.pick_m, self.pick_obj = m, obj</span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> self.pick_m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">m, l = pick_obj(shp, x, y, <span class="number">5</span>)</span><br><span class="line">self.pick_m, self.pick_obj = m, <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">3</span>:</span><br><span class="line">obj, l = pick_obj(shp, x, y, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line"><span class="keyword">if</span> obj <span class="keyword">is</span> <span class="literal">None</span>: <span class="keyword">del</span> shp.body[:]</span><br><span class="line"><span class="keyword">else</span>: shp.body.remove(obj)</span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">layer = geom2shp(geom_union(shp.to_geom()))</span><br><span class="line">shp.body = layer.body</span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">or</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">or</span> key[<span class="string">&#x27;ctrl&#x27;</span>]):</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].fit()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line">self.status = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">1</span>:</span><br><span class="line">self.pick_m = self.pick_obj = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]): <span class="keyword">return</span></span><br><span class="line">pts = mark(shp)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>: </span><br><span class="line">pts = Points(np.vstack(pts), color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = pts</span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line">self.cursor = <span class="string">&#x27;arrow&#x27;</span></span><br><span class="line"><span class="keyword">if</span> self.status == <span class="string">&#x27;move&#x27;</span>:</span><br><span class="line">ox, oy = self.oldxy</span><br><span class="line">up = (<span class="number">1</span>,-<span class="number">1</span>)[key[<span class="string">&#x27;canvas&#x27;</span>].up]</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].move(key[<span class="string">&#x27;px&#x27;</span>]-ox, (key[<span class="string">&#x27;py&#x27;</span>]-oy)*up)</span><br><span class="line">self.oldxy = key[<span class="string">&#x27;px&#x27;</span>], key[<span class="string">&#x27;py&#x27;</span>]</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">self.status = <span class="string">&#x27;pick&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="string">&#x27;anchor&#x27;</span> <span class="keyword">in</span> key[<span class="string">&#x27;canvas&#x27;</span>].marks: </span><br><span class="line">pts = mark(shp)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>: </span><br><span class="line">pts = Points(np.vstack(pts), color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = pts</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;anchor&#x27;</span> <span class="keyword">in</span> key[<span class="string">&#x27;canvas&#x27;</span>].marks:</span><br><span class="line">m, obj, l = pick_point(key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>], x, y, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> m <span class="keyword">is</span> <span class="literal">None</span>: self.cursor = <span class="string">&#x27;hand&#x27;</span></span><br><span class="line"><span class="keyword">elif</span> <span class="string">&#x27;anchor&#x27;</span> <span class="keyword">in</span> key[<span class="string">&#x27;canvas&#x27;</span>].marks: </span><br><span class="line">self.status = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">del</span> key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>]</span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> self.pick_obj <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> self.pick_m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">drag(self.pick_m, self.pick_obj, x, y)</span><br><span class="line">pts = mark(self.pick_m)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>:</span><br><span class="line">pts = np.vstack(pts)</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = Points(pts, color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">self.pick_m.dirty = <span class="literal">True</span></span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> self.pick_obj <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> self.pick_m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">offset(self.pick_m, x-self.p[<span class="number">0</span>], y-self.p[<span class="number">1</span>])</span><br><span class="line">pts = mark(self.pick_m)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>:</span><br><span class="line">pts = np.vstack(pts)</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = Points(pts, color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">self.p = x, y</span><br><span class="line">self.pick_m.dirty =shp.dirty = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, shp, x, y, d, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> d&gt;<span class="number">0</span>: key[<span class="string">&#x27;canvas&#x27;</span>].zoomout(x, y, coord=<span class="string">&#x27;data&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> d&lt;<span class="number">0</span>: key[<span class="string">&#x27;canvas&#x27;</span>].zoomin(x, y, coord=<span class="string">&#x27;data&#x27;</span>)</span><br></pre></td></tr></table></figure><p>可以看出，对应不同的情形，有很多种处理方式：</p><p>（1）鼠标中键按下：将status设为move，同时记录当前坐标。关于x和kx的区别，可以看之前<a href="https://qixinbo.info/2020/02/26/imagepy_17/#%E8%87%AA%E5%AE%9A%E4%B9%89%E9%BC%A0%E6%A0%87%E4%BA%8B%E4%BB%B6">这篇解析</a>；<br>（2）鼠标左键按下且状态为pick：选取锚点，这个状态为pick目前只能通过同时按住ctrl+Alt，以及移动一下鼠标才能激活（见下面的鼠标拖动事件）<br>（3）鼠标左键按下且pick_m属性为None：选取ROI对象<br>（4）鼠标右键按下且alt按下、ctrl未按：删掉ROI<br>（5）鼠标右键按下且shift按下、alt和ctrl未按：合并ROI（具体操作是将Shape格式转为Shapely的geometry格式，然后几何操作，再转为Shape格式）<br>（6）只按下鼠标右键：画布尺寸适配<br>（7）鼠标弹起且alt和ctrl未按：将status置为空<br>（8）鼠标左键弹起且同时按住alt和ctrl：显示锚点（这里在画布上显示是通过对画布的marks字典进行更改）<br>（9）鼠标中键按下且鼠标拖动：画布移动<br>（10）选择锚点后拖动：可以更改锚点位置<br>（11）选择对象后拖动：可以更改对象位置<br>（12）鼠标滚轮：画布缩放</p><h2 id="RectangleEditor"><a href="#RectangleEditor" class="headerlink" title="RectangleEditor"></a>RectangleEditor</h2><p>RectangleEditor针对矩形这一特定形状的区域对鼠标事件进行了重载，比如鼠标左键按下创建Rectangle对象，并添加进shape的body中；鼠标左键弹起是，将最终点的坐标添加进之前Rectangle的范围中。</p><p>经过上面的操作，使得Image对象的roi属性的body发生变化，而在画布显示端是通过修改canvas的marks字典来实现。具体呈现时注意，Image和Shape对象有个dirty属性，如果它为True的话，就会调用canvas的update来对画布进行刷新。这个dirty的监控是在EVT_IDLE事件中进行的，因为IDLE是系统无时无刻不停运行的，即随时监听，必要时刷新。</p><h1 id="裁剪"><a href="#裁剪" class="headerlink" title="裁剪"></a>裁剪</h1><p>看一下Image菜单下的Crop插件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Crop</span>(<span class="params">Simple</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Crop&#x27;</span></span><br><span class="line">    note = [<span class="string">&#x27;all&#x27;</span>, <span class="string">&#x27;req_roi&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, imgs, para = <span class="literal">None</span></span>):</span></span><br><span class="line">        sc, sr = ips.rect</span><br><span class="line">        <span class="keyword">if</span> ips.isarray: imgs = imgs[:, sc, sr].copy()</span><br><span class="line">        <span class="keyword">else</span>: imgs = [i[sc,sr].copy() <span class="keyword">for</span> i <span class="keyword">in</span> imgs]</span><br><span class="line">        ips.set_imgs(imgs)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> ips.back.isarray: imgs = ips.back.imgs[:, sc, sr].copy()</span><br><span class="line">            <span class="keyword">else</span>: imgs = [i[sc,sr].copy() <span class="keyword">for</span> i <span class="keyword">in</span> ips.back.imgs]</span><br><span class="line">            ips.back.set_imgs(imgs)</span><br><span class="line">        offset(ips.roi, ips.roi.box[<span class="number">0</span>]*-<span class="number">1</span>, ips.roi.box[<span class="number">1</span>]*-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>可以看出，在该插件的note里明确表明了需要ROI。<br>然后，</p><h2 id="取得ROI矩形范围"><a href="#取得ROI矩形范围" class="headerlink" title="取得ROI矩形范围"></a>取得ROI矩形范围</h2><p>之所以说是ROI矩形范围，不仅仅是因为该例中是矩形ROI，而是如果使用的是其他形状的ROI，比如椭圆、自由区域等，都是获得该ROI的矩形范围，即最终裁剪后的整个图形仍然是矩形。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc, sr = ips.rect</span><br></pre></td></tr></table></figure><p>可以看出，矩形范围是通过Image对象的rect属性获得，那么rect又是怎样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rect</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">if</span> self.roi <span class="keyword">is</span> <span class="literal">None</span>: <span class="keyword">return</span> <span class="built_in">slice</span>(<span class="literal">None</span>), <span class="built_in">slice</span>(<span class="literal">None</span>)</span><br><span class="line">    box, shape = self.roi.box, self.shape</span><br><span class="line">    l, r = <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">int</span>(box[<span class="number">0</span>])), <span class="built_in">min</span>(shape[<span class="number">1</span>], <span class="built_in">int</span>(box[<span class="number">2</span>]))</span><br><span class="line">    t, b = <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">int</span>(box[<span class="number">1</span>])), <span class="built_in">min</span>(shape[<span class="number">0</span>], <span class="built_in">int</span>(box[<span class="number">3</span>]))</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">slice</span>(t,b), <span class="built_in">slice</span>(l,r)</span><br></pre></td></tr></table></figure><p>在rect属性中，先取得ROI的box属性和Image本身的shape，然后再对比该box（注意是ROI的box，而不是Image的box）和Image的大小，获得上下左右四个角点，返回的是垂直和水平两个方向的对应的切片对象。<br>那么再看看ROI的box：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">box</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">if</span> self._box <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> self.dirty:</span><br><span class="line">        self._box = self.count_box()</span><br><span class="line">    <span class="keyword">return</span> self._box</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_box</span>(<span class="params">self, body=<span class="literal">None</span>, box=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> body <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        box = [<span class="number">1e10</span>, <span class="number">1e10</span>,-<span class="number">1e10</span>,-<span class="number">1e10</span>]</span><br><span class="line">        self.count_box(self.body, box)</span><br><span class="line">        <span class="keyword">return</span> box</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(body, np.ndarray):</span><br><span class="line">        body = body.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">        minx, miny = body.<span class="built_in">min</span>(axis=<span class="number">0</span>)</span><br><span class="line">        maxx, maxy = body.<span class="built_in">max</span>(axis=<span class="number">0</span>)</span><br><span class="line">        newbox = [minx, miny, maxx, maxy]</span><br><span class="line">        box.extend(merge(box, newbox))</span><br><span class="line">        <span class="keyword">del</span> box[:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> body: self.count_box(i, box)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="显示裁剪区域"><a href="#显示裁剪区域" class="headerlink" title="显示裁剪区域"></a>显示裁剪区域</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> ips.isarray: imgs = imgs[:, sc, sr].copy()</span><br><span class="line">ips.set_imgs(imgs)</span><br></pre></td></tr></table></figure><p>即切片后再通过set_imgs显示裁剪区域。</p><h2 id="更新ROI"><a href="#更新ROI" class="headerlink" title="更新ROI"></a>更新ROI</h2><p>图像显示区域更新后，ROI也要更新到新的图像上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">offset(ips.roi, ips.roi.box[<span class="number">0</span>]*-<span class="number">1</span>, ips.roi.box[<span class="number">1</span>]*-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">%%%%%%%%
2021.2.14更新：增加了ICanvas绘制ROI的原理介绍。
%%%%%%%%

前面有两篇文章介绍了ImagePy/sciwx的Mark模式和几何矢量，这两个的结合就是图像处理中经典的ROI(Region Of Interest)操作，即选定一个范围（矩形、圆形、自由区域），然后对该区域进行进一步的操作。
这个过程说起来非常简单，但实际实现起来却是非常不容易，因为这里面涉及到了图像这一位图格式和几何这一矢量格式的统一。
这一篇文章就着重剖析一下ImagePy/sciwx是怎样实现的。

本文选定的入手案例是“绘制矩形ROI，然后裁剪”。

矩形ROI
首先看矩形ROI</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析：22 -- 从零搭建一个图像处理软件</title>
    <link href="http://qixinbo.github.io/2020/06/20/ImagePy_22/"/>
    <id>http://qixinbo.github.io/2020/06/20/ImagePy_22/</id>
    <published>2020-06-19T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.400Z</updated>
    
    <content type="html"><![CDATA[<p>ImagePy经过一次大的重构后，软件架构有了很大改变，将前端UI和后端数据结构进行了解耦：</p><ul><li>sciapp是一套数据接口，包含图像Image、网格Mesh、表格Table、几何矢量Shape等基础数据结构；</li><li>sciwx是符合sciapp接口标准的可视化组件库；</li><li>ImagePy是后端基于sciapp、前端基于sciwx的一个插件集，包含了大量常用的图像处理算法等。</li></ul><p>因此可以很容易地基于分离后的sciapp和sciwx构建自定义的独立图像处理软件。</p><h1 id="Sciapp版Hello-World"><a href="#Sciapp版Hello-World" class="headerlink" title="Sciapp版Hello World"></a>Sciapp版Hello World</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasNoteFrame</span><br><span class="line"><span class="keyword">from</span> sciapp <span class="keyword">import</span> App</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloApp</span>(<span class="params">CanvasNoteFrame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        App.__init__(self)</span><br><span class="line">        CanvasNoteFrame.__init__ (self, parent, title = <span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">hello = HelloApp(<span class="literal">None</span>)</span><br><span class="line">hello.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>结果如图：<br><img src="https://user-images.githubusercontent.com/6218739/84989874-e980a180-b176-11ea-9e9c-3533e6ff8982.png" alt="helloworld"><br>可以看出，自定义的app需要继承sciwx库的CanvasNoteFrame以及sciapp的App类，并对其初始化。</p><h1 id="添加图像"><a href="#添加图像" class="headerlink" title="添加图像"></a>添加图像</h1><p>上例是张空白的画布，这里对其添加一张图像，供后面进行操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasNoteFrame</span><br><span class="line"><span class="keyword">from</span> sciapp <span class="keyword">import</span> App</span><br><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> astronaut</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloApp</span>(<span class="params">CanvasNoteFrame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        App.__init__(self)</span><br><span class="line">        CanvasNoteFrame.__init__ (self, parent, title = <span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">hello = HelloApp(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">canvas = hello.notebook.add_canvas()</span><br><span class="line">canvas.set_img(astronaut())</span><br><span class="line"></span><br><span class="line">hello.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>如上，添加两行代码即可完全对图像的添加和显示。<br>结果如图：<br><img src="https://user-images.githubusercontent.com/6218739/84991154-b63f1200-b178-11ea-8468-00dbbb369f27.png" alt="display"><br>首先，获取notebook并对其添加画布：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">canvas = hello.notebook.add_canvas()</span><br></pre></td></tr></table></figure><p>然后，在画布上添加图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">canvas.set_img(astronaut())</span><br></pre></td></tr></table></figure><p>如果是展示图像序列，则：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">canvas.set_imgs([astronaut(), <span class="number">255</span>-astronaut()])</span><br></pre></td></tr></table></figure><p>结果如图：<br><img src="https://user-images.githubusercontent.com/6218739/84991303-ec7c9180-b178-11ea-9800-6a76ad413554.png" alt="multiple-display"><br>注意，这里展示的是图像序列，因此两张图像都显示在同一个标签页下，通过下方的滑动条进行切换。<br>如果是想多标签页显示，那么：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">canvas2 = hello.notebook.add_canvas()</span><br><span class="line">canvas2.set_img(camera())</span><br></pre></td></tr></table></figure><p>即新添加一个画布，再设置图像，结果如图：<br><img src="https://user-images.githubusercontent.com/6218739/84992152-20a48200-b17a-11ea-91df-fab6f310b420.png" alt="multi-tab-display"></p><h1 id="添加工具"><a href="#添加工具" class="headerlink" title="添加工具"></a>添加工具</h1><p>为自己的app添加一个画笔工具：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasNoteFrame</span><br><span class="line"><span class="keyword">from</span> sciapp <span class="keyword">import</span> App</span><br><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> ImageTool</span><br><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> astronaut</span><br><span class="line"><span class="keyword">from</span> skimage.draw <span class="keyword">import</span> line</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pencil</span>(<span class="params">ImageTool</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Pencil&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.status = <span class="literal">False</span></span><br><span class="line">        self.oldp = (<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        self.status = <span class="literal">True</span></span><br><span class="line">        self.oldp = (y, x)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        self.status = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.status:<span class="keyword">return</span></span><br><span class="line">        se = self.oldp + (y,x)</span><br><span class="line">        rs,cs = line(*[<span class="built_in">int</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> se])</span><br><span class="line">        rs.clip(<span class="number">0</span>, ips.shape[<span class="number">1</span>], out=rs)</span><br><span class="line">        cs.clip(<span class="number">0</span>, ips.shape[<span class="number">0</span>], out=cs)</span><br><span class="line">        ips.img[rs,cs] = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        self.oldp = (y, x)</span><br><span class="line">        key[<span class="string">&#x27;canvas&#x27;</span>].update()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, ips, x, y, d, **key</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloApp</span>(<span class="params">CanvasNoteFrame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        App.__init__(self)</span><br><span class="line">        CanvasNoteFrame.__init__ (self, parent, title = <span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">hello = HelloApp(<span class="literal">None</span>)</span><br><span class="line">canvas = hello.notebook.add_canvas()</span><br><span class="line">canvas.set_img(astronaut())</span><br><span class="line"></span><br><span class="line">tool = hello.add_toolbar()</span><br><span class="line">tool.add_tool(<span class="string">&#x27;P&#x27;</span>, Pencil)</span><br><span class="line"></span><br><span class="line">hello.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>效果如图：<br><img src="https://user-images.githubusercontent.com/6218739/85089368-15eafb00-b215-11ea-9986-9ddf56794ba3.png" alt="tool"><br>解析如下：<br>在app中添加自定义的工具时，需要继承sciapp中提供的ImageTool基类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> ImageTool</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pencil</span>(<span class="params">ImageTool</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Pencil&#x27;</span></span><br></pre></td></tr></table></figure><p>然后再根据自己的需求重载四个鼠标事件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span> <span class="keyword">pass</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span> <span class="keyword">pass</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span> <span class="keyword">pass</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, ips, x, y, d, **key</span>):</span> <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>这四个函数的参数意义为：<br>从中也可以看出自定义工具中可以调用的接口：<br>（1）ips：即画布承载的Image对象，该对象即sciapp中定义的统一的图像数据结构<br>（2）x和y：当前鼠标所在的图像像素坐标，水平方向是x方向，垂直方向是y方向。btn是鼠标按键，1为左键按下，2为中键按下，3为右键按下，key是字典，里面有多个字段，key[‘alt’]代表是否按下alt键，key[‘ctrl’]代表是否按下ctrl键，key[‘shift’]代表是否按下shift键，key[‘px’]返回鼠标当前的画布x坐标，key[‘py’]返回画布y坐标，key[‘canvas’]返回该画布自身。</p><p>然后在app中添加工具条：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tool = hello.add_toolbar()</span><br><span class="line">tool.add_tool(<span class="string">&#x27;P&#x27;</span>, Pencil)</span><br></pre></td></tr></table></figure><p>如果想添加多个工具，多次调用add_tool即可。</p><p>#添加菜单<br>为自己的app添加菜单（即插件），这里以添加高斯模糊插件为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasNoteFrame</span><br><span class="line"><span class="keyword">from</span> sciapp <span class="keyword">import</span> App</span><br><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> ImgAction</span><br><span class="line"><span class="keyword">from</span> scipy.ndimage <span class="keyword">import</span> gaussian_filter</span><br><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> astronaut</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Gaussian</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Gaussian&#x27;</span></span><br><span class="line">    note = [<span class="string">&#x27;auto_snap&#x27;</span>, <span class="string">&#x27;preview&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, img, snap, para</span>):</span></span><br><span class="line">        gaussian_filter(snap, <span class="number">2</span>, output=img)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloApp</span>(<span class="params">CanvasNoteFrame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        App.__init__(self)</span><br><span class="line">        CanvasNoteFrame.__init__ (self, parent, title = <span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">hello = HelloApp(<span class="literal">None</span>)</span><br><span class="line">canvas = hello.notebook.add_canvas()</span><br><span class="line">canvas.set_img(astronaut())</span><br><span class="line"> </span><br><span class="line">hello.add_img(canvas.image)</span><br><span class="line">hello.add_img_win(canvas)</span><br><span class="line"></span><br><span class="line">menu = hello.add_menubar()</span><br><span class="line">menu.load((<span class="string">&#x27;menu&#x27;</span>,[(<span class="string">&#x27;Filter&#x27;</span>,[(<span class="string">&#x27;Gaussian&#x27;</span>, Gaussian)])]))</span><br><span class="line"></span><br><span class="line">hello.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>效果如图：<br><img src="https://user-images.githubusercontent.com/6218739/85089717-ed173580-b215-11ea-95da-112f2611301a.png" alt="menu-1"><br>解析如下：<br>首先自定义插件需要继承sciapp提供的ImgAction基类，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> ImgAction</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Gaussian</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Gaussian&#x27;</span></span><br><span class="line">    note = [<span class="string">&#x27;auto_snap&#x27;</span>, <span class="string">&#x27;preview&#x27;</span>]</span><br></pre></td></tr></table></figure><p>然后在自己的插件类中重载run()方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, img, snap, para</span>):</span></span><br><span class="line">    gaussian_filter(snap, <span class="number">2</span>, output=img)</span><br></pre></td></tr></table></figure><p>这里的四个参数的意义分别是：<br>（1）ips即sciapp中定义的Image图像封装；<br>（2）img即ips中的当前实际的图像；<br>（3）snap是当前图像在处理之前的拷贝，这样就可以做回退操作；<br>（4）para是参数对话框，用于与用户进行参数设置的交互。上面代码中没有提供该对话框，稍后添加代码实现这一功能。</p><p>编写完自己的插件后，需要添加到app中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hello.add_img(canvas.image)</span><br><span class="line">hello.add_img_win(canvas)</span><br><span class="line">menu = hello.add_menubar()</span><br><span class="line">menu.load((<span class="string">&#x27;menu&#x27;</span>,[(<span class="string">&#x27;Filter&#x27;</span>,[(<span class="string">&#x27;Gaussian&#x27;</span>, Gaussian)])]))</span><br></pre></td></tr></table></figure><p>上面两行是将当前画布的图像及其窗口添加到总控全局的App管理器中，这样插件才能识别到当前图像。<br>下面两行是添加菜单栏，Filter是一级菜单，Gaussian是二级菜单，如果想添加多个菜单项，可以在相应位置以字典的形式加入，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">menu.load((<span class="string">&#x27;menu&#x27;</span>,[(<span class="string">&#x27;Filter&#x27;</span>,[(<span class="string">&#x27;Gaussian&#x27;</span>, Gaussian),</span><br><span class="line">                             (<span class="string">&#x27;Unto&#x27;</span>, Undo)]),</span><br><span class="line">                  ]))</span><br></pre></td></tr></table></figure><p>前面说了，上述代码中的滤波器的标准差sigma的值是“写死”的，即固定为2，下面添加代码使得显示出参数对话框方便用户交互：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciwx.widgets <span class="keyword">import</span> ParaDialog</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Gaussian</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Gaussian&#x27;</span></span><br><span class="line">    note = [<span class="string">&#x27;auto_snap&#x27;</span>, <span class="string">&#x27;preview&#x27;</span>]</span><br><span class="line">    para = &#123;<span class="string">&#x27;sigma&#x27;</span>:<span class="number">2</span>&#125;</span><br><span class="line">    view = [(<span class="built_in">float</span>, <span class="string">&#x27;sigma&#x27;</span>, (<span class="number">0</span>, <span class="number">30</span>), <span class="number">1</span>, <span class="string">&#x27;sigma&#x27;</span>, <span class="string">&#x27;pix&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, img, snap, para</span>):</span></span><br><span class="line">        gaussian_filter(snap, para[<span class="string">&#x27;sigma&#x27;</span>], output=img)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloApp</span>(<span class="params">CanvasNoteFrame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        App.__init__(self)</span><br><span class="line">        CanvasNoteFrame.__init__ (self, parent, title = <span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_para</span>(<span class="params">self, title, view, para, on_handle=<span class="literal">None</span>, on_ok=<span class="literal">None</span>, on_cancel=<span class="literal">None</span>, preview=<span class="literal">False</span>, modal=<span class="literal">True</span></span>):</span></span><br><span class="line">        dialog = ParaDialog(self, title)</span><br><span class="line">        dialog.init_view(view, para, preview, modal=modal, app=self)</span><br><span class="line">        dialog.Bind(<span class="string">&#x27;cancel&#x27;</span>, on_cancel)</span><br><span class="line">        dialog.Bind(<span class="string">&#x27;parameter&#x27;</span>, on_handle)</span><br><span class="line">        dialog.Bind(<span class="string">&#x27;commit&#x27;</span>, on_ok)</span><br><span class="line">        <span class="keyword">return</span> dialog.show()</span><br></pre></td></tr></table></figure><p>这里应用了sciwx提供的ParaDialog组件，关于ParaDialog的详细解析可以参见之前的一篇文章：<br><a href="https://qixinbo.info/2020/03/24/imagepy_18/">ImagePy解析：18 – 参数对话框ParaDialog详解</a></p><p>效果如下：<br><img src="https://user-images.githubusercontent.com/6218739/85090835-a840ce00-b218-11ea-8312-c658d793d1d1.png" alt="menu-2"></p><h1 id="添加“打开文件”插件"><a href="#添加“打开文件”插件" class="headerlink" title="添加“打开文件”插件"></a>添加“打开文件”插件</h1><p>“打开文件”是一个非常重要的功能，因为它赋予用户通过图形界面打开图像的权利（前面的例子都是在程序中将图像“硬读入”）。<br>之所以将“打开文件”插件单独拿出来，是因为它涉及的操作比高斯模糊插件更多：获取文件路径并添加图像等，所重载的函数也稍稍不同。见下方源码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasNoteFrame</span><br><span class="line"><span class="keyword">from</span> sciapp <span class="keyword">import</span> App</span><br><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> ImgAction</span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpenFile</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&quot;Open File&quot;</span></span><br><span class="line">    filt = [<span class="string">&quot;png&quot;</span>]</span><br><span class="line">    para = &#123;<span class="string">&#x27;path&#x27;</span>:<span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show</span>(<span class="params">self</span>):</span></span><br><span class="line">        filt = [i.lower() <span class="keyword">for</span> i <span class="keyword">in</span> self.filt]</span><br><span class="line">        self.para[<span class="string">&#x27;path&#x27;</span>] = self.app.getpath(<span class="string">&#x27;Open..&#x27;</span>, filt, <span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;path = &quot;</span>, self.para[<span class="string">&#x27;path&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> self.para[<span class="string">&#x27;path&#x27;</span>] <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">self, app, para = <span class="literal">None</span></span>):</span></span><br><span class="line">        self.app = app</span><br><span class="line">        <span class="keyword">if</span> self.show():</span><br><span class="line">            fp, fn = os.path.split(self.para[<span class="string">&#x27;path&#x27;</span>])</span><br><span class="line">            fn, fe = os.path.splitext(fn)</span><br><span class="line">            self.app.show_img(imread(self.para[<span class="string">&#x27;path&#x27;</span>]), fn)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloApp</span>(<span class="params">CanvasNoteFrame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        App.__init__(self)</span><br><span class="line">        CanvasNoteFrame.__init__ (self, parent, title = <span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_img</span>(<span class="params">self, img, title</span>):</span></span><br><span class="line">        canvas = self.notebook.add_canvas()</span><br><span class="line">        self.remove_img(canvas.image)</span><br><span class="line">        self.remove_img_win(canvas)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> title <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            canvas.set_img(img)</span><br><span class="line">            canvas.image.name = title</span><br><span class="line">        <span class="keyword">else</span>: canvas.set_img(img)</span><br><span class="line">        self.add_img(canvas.image)</span><br><span class="line">        self.add_img_win(canvas)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getpath</span>(<span class="params">self, title, filt, io, name=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">        filt = <span class="string">&#x27;|&#x27;</span>.join([<span class="string">&#x27;%s files (*.%s)|*.%s&#x27;</span>%(i.upper(),i,i) <span class="keyword">for</span> i <span class="keyword">in</span> filt])</span><br><span class="line">        dic = &#123;<span class="string">&#x27;open&#x27;</span>:wx.FD_OPEN, <span class="string">&#x27;save&#x27;</span>:wx.FD_SAVE&#125;</span><br><span class="line">        dialog = wx.FileDialog(self, title, <span class="string">&#x27;&#x27;</span>, name, filt, dic[io])</span><br><span class="line">        rst = dialog.ShowModal()</span><br><span class="line">        path = dialog.GetPath() <span class="keyword">if</span> rst == wx.ID_OK <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        dialog.Destroy()</span><br><span class="line">        <span class="keyword">return</span> path</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">hello = HelloApp(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">menu = hello.add_menubar()</span><br><span class="line">menu.load((<span class="string">&#x27;menu&#x27;</span>,[(<span class="string">&#x27;File&#x27;</span>, [(<span class="string">&#x27;Open&#x27;</span>, OpenFile)])]))</span><br><span class="line"></span><br><span class="line">hello.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>主要增添了如下代码块：<br>（1）在app中增加路径读取模块，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getpath</span>(<span class="params">self, title, filt, io, name=<span class="string">&#x27;&#x27;</span></span>):</span></span><br></pre></td></tr></table></figure><p>（2）在插件OpenFile中重载start()方法，而不是run()方法，因为它不涉及图像操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">self, app, para = <span class="literal">None</span></span>):</span></span><br></pre></td></tr></table></figure><p>（3）在app中增加添加和显示图像的模块，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_img</span>(<span class="params">self, img, title</span>):</span></span><br></pre></td></tr></table></figure><p>原理就是之前的添加canvas和向App管理器中添加图像。</p><h1 id="一个完整demo"><a href="#一个完整demo" class="headerlink" title="一个完整demo"></a>一个完整demo</h1><p>下面给出一个完整demo，包括“打开文件”和“高斯滤波”这两个菜单插件，及“画笔”和“矩形ROI”这两个工具。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasNoteFrame</span><br><span class="line"><span class="keyword">from</span> sciapp <span class="keyword">import</span> App</span><br><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> ImgAction</span><br><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> ImageTool, RectangleROI</span><br><span class="line"><span class="keyword">from</span> scipy.ndimage <span class="keyword">import</span> gaussian_filter</span><br><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> astronaut</span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">from</span> skimage.draw <span class="keyword">import</span> line</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sciwx.widgets <span class="keyword">import</span> ParaDialog</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Gaussian</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Gaussian&#x27;</span></span><br><span class="line">    note = [<span class="string">&#x27;auto_snap&#x27;</span>, <span class="string">&#x27;preview&#x27;</span>]</span><br><span class="line">    para = &#123;<span class="string">&#x27;sigma&#x27;</span>:<span class="number">2</span>&#125;</span><br><span class="line">    view = [(<span class="built_in">float</span>, <span class="string">&#x27;sigma&#x27;</span>, (<span class="number">0</span>, <span class="number">30</span>), <span class="number">1</span>, <span class="string">&#x27;sigma&#x27;</span>, <span class="string">&#x27;pix&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, img, snap, para</span>):</span></span><br><span class="line">        gaussian_filter(snap, para[<span class="string">&#x27;sigma&#x27;</span>], output=img)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpenFile</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&quot;Open File&quot;</span></span><br><span class="line">    filt = [<span class="string">&quot;png&quot;</span>]</span><br><span class="line">    para = &#123;<span class="string">&#x27;path&#x27;</span>:<span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show</span>(<span class="params">self</span>):</span></span><br><span class="line">        filt = [i.lower() <span class="keyword">for</span> i <span class="keyword">in</span> self.filt]</span><br><span class="line">        self.para[<span class="string">&#x27;path&#x27;</span>] = self.app.getpath(<span class="string">&#x27;Open..&#x27;</span>, filt, <span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;path = &quot;</span>, self.para[<span class="string">&#x27;path&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> self.para[<span class="string">&#x27;path&#x27;</span>] <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">self, app, para = <span class="literal">None</span></span>):</span></span><br><span class="line">        self.app = app</span><br><span class="line">        <span class="keyword">if</span> self.show():</span><br><span class="line">            fp, fn = os.path.split(self.para[<span class="string">&#x27;path&#x27;</span>])</span><br><span class="line">            fn, fe = os.path.splitext(fn)</span><br><span class="line">            img = imread(self.para[<span class="string">&#x27;path&#x27;</span>])</span><br><span class="line">            self.app.show_img(img, fn)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pencil</span>(<span class="params">ImageTool</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Pencil&#x27;</span></span><br><span class="line">       </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.status = <span class="literal">False</span></span><br><span class="line">        self.oldp = (<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        self.status = <span class="literal">True</span></span><br><span class="line">        self.oldp = (y, x)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        self.status = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.status:<span class="keyword">return</span></span><br><span class="line">        se = self.oldp + (y,x)</span><br><span class="line">        rs,cs = line(*[<span class="built_in">int</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> se])</span><br><span class="line">        rs.clip(<span class="number">0</span>, ips.shape[<span class="number">1</span>], out=rs)</span><br><span class="line">        cs.clip(<span class="number">0</span>, ips.shape[<span class="number">0</span>], out=cs)</span><br><span class="line">        ips.img[rs,cs] = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        self.oldp = (y, x)</span><br><span class="line">        key[<span class="string">&#x27;canvas&#x27;</span>].update()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, ips, x, y, d, **key</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloApp</span>(<span class="params">CanvasNoteFrame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        App.__init__(self)</span><br><span class="line">        CanvasNoteFrame.__init__ (self, parent, title = <span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_img</span>(<span class="params">self, img, title</span>):</span></span><br><span class="line">        canvas = self.notebook.add_canvas()</span><br><span class="line">        self.remove_img(canvas.image)</span><br><span class="line">        self.remove_img_win(canvas)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> title <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            canvas.set_img(img)</span><br><span class="line">            canvas.image.name = title</span><br><span class="line">        <span class="keyword">else</span>: canvas.set_img(img)</span><br><span class="line">        self.add_img(canvas.image)</span><br><span class="line">        self.add_img_win(canvas)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getpath</span>(<span class="params">self, title, filt, io, name=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">        filt = <span class="string">&#x27;|&#x27;</span>.join([<span class="string">&#x27;%s files (*.%s)|*.%s&#x27;</span>%(i.upper(),i,i) <span class="keyword">for</span> i <span class="keyword">in</span> filt])</span><br><span class="line">        dic = &#123;<span class="string">&#x27;open&#x27;</span>:wx.FD_OPEN, <span class="string">&#x27;save&#x27;</span>:wx.FD_SAVE&#125;</span><br><span class="line">        dialog = wx.FileDialog(self, title, <span class="string">&#x27;&#x27;</span>, name, filt, dic[io])</span><br><span class="line">        rst = dialog.ShowModal()</span><br><span class="line">        path = dialog.GetPath() <span class="keyword">if</span> rst == wx.ID_OK <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        dialog.Destroy()</span><br><span class="line">        <span class="keyword">return</span> path</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_para</span>(<span class="params">self, title, view, para, on_handle=<span class="literal">None</span>, on_ok=<span class="literal">None</span>, on_cancel=<span class="literal">None</span>, preview=<span class="literal">False</span>, modal=<span class="literal">True</span></span>):</span></span><br><span class="line">        dialog = ParaDialog(self, title)</span><br><span class="line">        dialog.init_view(view, para, preview, modal=modal, app=self)</span><br><span class="line">        dialog.Bind(<span class="string">&#x27;cancel&#x27;</span>, on_cancel)</span><br><span class="line">        dialog.Bind(<span class="string">&#x27;parameter&#x27;</span>, on_handle)</span><br><span class="line">        dialog.Bind(<span class="string">&#x27;commit&#x27;</span>, on_ok)</span><br><span class="line">        <span class="keyword">return</span> dialog.show()</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">hello = HelloApp(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">menu = hello.add_menubar()</span><br><span class="line">menu.load((<span class="string">&#x27;menu&#x27;</span>,[(<span class="string">&#x27;File&#x27;</span>, [(<span class="string">&#x27;Open&#x27;</span>, OpenFile)]),</span><br><span class="line">                    (<span class="string">&#x27;Filter&#x27;</span>,[(<span class="string">&#x27;Gaussian&#x27;</span>, Gaussian)])]))</span><br><span class="line"></span><br><span class="line">tool = hello.add_toolbar()</span><br><span class="line">tool.add_tool(<span class="string">&#x27;P&#x27;</span>, Pencil)</span><br><span class="line">tool.add_tool(<span class="string">&#x27;R&#x27;</span>, RectangleROI)</span><br><span class="line"></span><br><span class="line">hello.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>效果如图：<br><img src="https://user-images.githubusercontent.com/6218739/85116340-ba8a2e80-b24f-11ea-9071-ef63059f4fdf.png" alt="final"></p><h1 id="更多"><a href="#更多" class="headerlink" title="更多"></a>更多</h1><p>管理器、表格、网格等。</p>]]></content>
    
    
    <summary type="html">ImagePy经过一次大的重构后，软件架构有了很大改变，将前端UI和后端数据结构进行了解耦：

 * sciapp是一套数据接口，包含图像Image、网格Mesh、表格Table、几何矢量Shape等基础数据结构；
 * sciwx是符合sciapp接口标准的可视化组件库；
 * ImagePy是后端基于sciapp、前端基于sciwx的一个插件集，包含了大量常用的图像处理算法等。

因此可以很容易地基于分离后的sciapp和sciwx构建自定义的独立图像处理软件。

Sciapp版Hello World
1
2
3
4
5
6
7
8
9
10
11
12
13


import wx
fr</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析：21 -- 管理器</title>
    <link href="http://qixinbo.github.io/2020/06/19/ImagePy_21/"/>
    <id>http://qixinbo.github.io/2020/06/19/ImagePy_21/</id>
    <published>2020-06-18T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.400Z</updated>
    
    <content type="html"><![CDATA[<p>ImagePy中的管理器分两类：Source里的管理器维护全局静态数据，比如读写器、配置文件等， App里面的管理器维护运行时数据，比如图像、表格。</p><h1 id="静态管理器"><a href="#静态管理器" class="headerlink" title="静态管理器"></a>静态管理器</h1><h2 id="创建管理器"><a href="#创建管理器" class="headerlink" title="创建管理器"></a>创建管理器</h2><p>这里创建一个money管理器，里面可以添加美元USD、欧元EUR、人民币RMB，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Source.manager(<span class="string">&#x27;money&#x27;</span>).add(<span class="string">&#x27;USD&#x27;</span>, MoneyReader, <span class="string">&#x27;MoneyDisplay&#x27;</span>)</span><br><span class="line">Source.manager(<span class="string">&#x27;money&#x27;</span>).add(<span class="string">&#x27;EUR&#x27;</span>, MoneyReader, <span class="string">&#x27;MoneyDisplay&#x27;</span>)</span><br><span class="line">Source.manager(<span class="string">&#x27;money&#x27;</span>).add(<span class="string">&#x27;RMB&#x27;</span>, MoneyReader, <span class="string">&#x27;MoneyDisplay&#x27;</span>)</span><br></pre></td></tr></table></figure><p>意思就是管理器名为money，添加的成员有USD、EUR、RMB，处理方式是MoneyReader，显示方式是MoneyDisplay。<br>add方法的这三个参数分别对应的形参为name、obj和tag，可以这样统一理解：name表示对象名，obj表示处理方式，MoneyDisplay是显示方式。可以这样来感性认识，也可以认为这三个参数的地位是平齐的，因为有这三个参数可以用于索引，所以可表示的范围会非常大，导致manager的用处也非常广。</p><h2 id="读取管理器"><a href="#读取管理器" class="headerlink" title="读取管理器"></a>读取管理器</h2><p>money管理器中添加元素以后，可以再在全局读取出来。<br>最重要的读取方式就是Manager类的gets()方法，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gets</span>(<span class="params">self, name=<span class="literal">None</span>, tag=<span class="literal">None</span>, obj=<span class="literal">None</span></span>):</span></span><br><span class="line">    rst = [i <span class="keyword">for</span> i <span class="keyword">in</span> self.objs <span class="keyword">if</span> name <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> name == i[<span class="number">0</span>]]</span><br><span class="line">    rst = [i <span class="keyword">for</span> i <span class="keyword">in</span> rst <span class="keyword">if</span> obj <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> obj <span class="keyword">is</span> i[<span class="number">1</span>]]</span><br><span class="line">    <span class="keyword">return</span> [i <span class="keyword">for</span> i <span class="keyword">in</span> rst <span class="keyword">if</span> tag <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> tag == i[<span class="number">2</span>]]</span><br></pre></td></tr></table></figure><p>可以看出，可以根据name、tag和obj来读取。从上面代码可以看出，如果不明确指定某一参数的话，就认为该参数不做过滤条件。<br>以tag过滤为例，假设读取设置为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;gets = &quot;</span>, Source.manager(<span class="string">&#x27;money&#x27;</span>).gets(tag=<span class="string">&#x27;MoneyDisplay&#x27;</span>))</span><br></pre></td></tr></table></figure><p>那么返回结果就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gets =  [(<span class="string">&#x27;RMB&#x27;</span>, &lt;function MoneyReader at <span class="number">0x000002E0C3C6F510</span>&gt;, <span class="string">&#x27;MoneyDisplay&#x27;</span>), (<span class="string">&#x27;EUR&#x27;</span>, &lt;function MoneyReader at <span class="number">0x000002E0C3C6F510</span>&gt;, <span class="string">&#x27;MoneyDisplay&#x27;</span>), (<span class="string">&#x27;USD&#x27;</span>, &lt;function MoneyReader at <span class="number">0x000002E0C3C6F510</span>&gt;, <span class="string">&#x27;MoneyDisplay&#x27;</span>)]</span><br></pre></td></tr></table></figure><p>即将tag为MoneyDisplay的所有对象都返回。<br>还有一个直接获取管理器中的对象名称的快捷方式，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;names = &quot;</span>, Source.manager(<span class="string">&#x27;money&#x27;</span>).names())</span><br></pre></td></tr></table></figure><p>返回结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">names =  [<span class="string">&#x27;RMB&#x27;</span>, <span class="string">&#x27;EUR&#x27;</span>, <span class="string">&#x27;USD&#x27;</span>]</span><br></pre></td></tr></table></figure><h2 id="管理器持久化"><a href="#管理器持久化" class="headerlink" title="管理器持久化"></a>管理器持久化</h2><p>管理器中的对象可以通过持久化将内存中的数据存储到磁盘上，该功能对于配置类文件非常重要，因为可以及时存储软件设置。<br>管理器的持久化使用的是write函数，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Source.manager(<span class="string">&#x27;money&#x27;</span>).write(<span class="string">&quot;1.txt&quot;</span>)</span><br></pre></td></tr></table></figure><p>这里需要注意的是上面我们设定的MoneyReader是一个函数，所以无法json化，所以我们这里将其设为None，才能正确存储。<br>这样该txt文件中的内容就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="string">&quot;RMB&quot;</span>, null, <span class="string">&quot;MoneyDisplay&quot;</span>], [<span class="string">&quot;EUR&quot;</span>, null, <span class="string">&quot;MoneyDisplay&quot;</span>], [<span class="string">&quot;USD&quot;</span>, null, <span class="string">&quot;MoneyDisplay&quot;</span>]]</span><br></pre></td></tr></table></figure><p>持久化以后还可以读取回来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Source.manager(<span class="string">&#x27;money&#x27;</span>).read(<span class="string">&quot;1.txt&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="App中的静态管理器"><a href="#App中的静态管理器" class="headerlink" title="App中的静态管理器"></a>App中的静态管理器</h2><p>App类中也有一个与Source类似的静态管理器，用来管理color和roi，即颜色管理器和roi管理器，这样就能在全局来调用颜色和roi。<br>具体用法见上面的静态管理器。</p><h1 id="动态管理器"><a href="#动态管理器" class="headerlink" title="动态管理器"></a>动态管理器</h1><p>App类中的动态管理器用来管理ImagePy所打开的图像、图像窗口（即画布）、表格、表格窗口、网格、网格窗口和任务，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">App</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.img_manager = Manager()</span><br><span class="line">        self.wimg_manager = Manager()</span><br><span class="line">        self.tab_manager = Manager()</span><br><span class="line">        self.wtab_manager = Manager()</span><br><span class="line">        self.mesh_manager = Manager()</span><br><span class="line">        self.wmesh_manager = Manager()</span><br><span class="line">        self.task_manager = Manager()</span><br><span class="line">        self.managers = &#123;&#125;</span><br></pre></td></tr></table></figure><p>下面以图像管理器为例，看一下动态管理器的运行机制。</p><h2 id="创建管理器并添加元素"><a href="#创建管理器并添加元素" class="headerlink" title="创建管理器并添加元素"></a>创建管理器并添加元素</h2><p>动态管理器的创建实际在App类创建时就在初始化时创建。<br>下面是添加图像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">app = wx.App(<span class="literal">False</span>)</span><br><span class="line">frame = ImagePy(<span class="literal">None</span>)</span><br><span class="line">frame.Show()</span><br><span class="line">frame.show_img([np.zeros((<span class="number">512</span>, <span class="number">512</span>), dtype=np.uint8)], <span class="string">&#x27;zeros&#x27;</span>)</span><br><span class="line">frame.show_img([np.ones((<span class="number">512</span>, <span class="number">512</span>), dtype=np.uint8)], <span class="string">&#x27;ones&#x27;</span>)</span><br><span class="line"></span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>这里我们通过ImagePy框架中的show_img添加了两张图像，一张名为zeros，一张名为ones。<br>实际查看该函数的源码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_show_img</span>(<span class="params">self, img, title=<span class="literal">None</span></span>):</span></span><br><span class="line">    canvas = self.canvasnb.add_canvas()</span><br><span class="line">    self.remove_img(canvas.image)</span><br><span class="line">    self.remove_img_win(canvas)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> title <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        canvas.set_imgs(img)</span><br><span class="line">        canvas.image.name = title</span><br><span class="line">    <span class="keyword">else</span>: canvas.set_img(img)</span><br><span class="line">    self.add_img(canvas.image)</span><br><span class="line">    self.add_img_win(canvas)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_img</span>(<span class="params">self, img, title=<span class="literal">None</span></span>):</span></span><br><span class="line">    wx.CallAfter(self._show_img, img, title)</span><br></pre></td></tr></table></figure><p>可以看出，它是调用了App类的add_img和add_img_win来添加图像及图像窗口（画布）。<br>注意，这里之所以frame能调用App类中的这两个方法，因为frame是ImagePy类的实例对象，而ImagePy类既继承了wx.Frame类，也继承了App类。</p><h2 id="读取管理器-1"><a href="#读取管理器-1" class="headerlink" title="读取管理器"></a>读取管理器</h2><p>在插件中如果需要获取图像或其窗口，则可以使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.app.get_img_win()</span><br><span class="line">self.app.get_img()</span><br></pre></td></tr></table></figure><p>这里之所以这样调用，是因为App类的实例化对象app是贯穿全局的，任何一个tool或menu在start()启动的时候都需要传入app，所以app能统领全局。</p>]]></content>
    
    
    <summary type="html">ImagePy中的管理器分两类：Source里的管理器维护全局静态数据，比如读写器、配置文件等， App里面的管理器维护运行时数据，比如图像、表格。

静态管理器
创建管理器
这里创建一个money管理器，里面可以添加美元USD、欧元EUR、人民币RMB，比如：

1
2
3


Source.manager(&#39;money&#39;).add(&#39;USD&#39;, MoneyReader, &#39;MoneyDisplay&#39;)
Source.manager(&#39;money&#39;).add(&#39;EUR&#39;, MoneyReader, &#39;MoneyDisplay&#39;)
Source.manager(&#39;money&#39;).add(&#39;RM</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析：20 -- 几何矢量Shape</title>
    <link href="http://qixinbo.github.io/2020/06/14/ImagePy_20/"/>
    <id>http://qixinbo.github.io/2020/06/14/ImagePy_20/</id>
    <published>2020-06-13T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.384Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>ImagePy中表示几何矢量的结构类是Shape，最直观的一个应用就是各种ROI操作，这里通过一个小例子看看各种几何图形是怎样操纵和显示的。</p><h1 id="最小demo"><a href="#最小demo" class="headerlink" title="最小demo"></a>最小demo</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciapp.<span class="built_in">object</span> <span class="keyword">import</span> mark2shp</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> VCanvas <span class="keyword">as</span> Canvas</span><br><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"></span><br><span class="line">circle = &#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;circle&#x27;</span>, <span class="string">&#x27;color&#x27;</span>:(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="string">&#x27;fcolor&#x27;</span>:(<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="string">&#x27;fill&#x27;</span>:<span class="literal">False</span>, <span class="string">&#x27;body&#x27;</span>:(<span class="number">100</span>,<span class="number">100</span>,<span class="number">50</span>)&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark_test</span>(<span class="params">mark</span>):</span></span><br><span class="line">    frame = wx.Frame(<span class="literal">None</span>, title=<span class="string">&#x27;gray test&#x27;</span>)</span><br><span class="line">    canvas = Canvas(frame, autofit=<span class="literal">False</span>, up=<span class="literal">True</span>)</span><br><span class="line">    canvas.set_shp(mark2shp(mark))</span><br><span class="line">    frame.Show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = wx.App()</span><br><span class="line">    mark_test(circle)</span><br><span class="line">    app.MainLoop()</span><br></pre></td></tr></table></figure><p>上述是个可运行的最小demo，运行结果为：<br><img src="https://user-images.githubusercontent.com/6218739/84457021-2985e700-ac94-11ea-90e7-b38f2869b1ed.png" alt="shape"><br>可以看出，成功绘制出了一个红色轮廓的圆形。<br>下面逐步解析一下。</p><h1 id="mark格式"><a href="#mark格式" class="headerlink" title="mark格式"></a>mark格式</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">circle = &#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;circle&#x27;</span>, <span class="string">&#x27;color&#x27;</span>:(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="string">&#x27;fcolor&#x27;</span>:(<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="string">&#x27;fill&#x27;</span>:<span class="literal">False</span>, <span class="string">&#x27;body&#x27;</span>:(<span class="number">100</span>,<span class="number">100</span>,<span class="number">50</span>)&#125;</span><br></pre></td></tr></table></figure><p>可以看出，这里的圆形是通过imagepy的mark格式来定义的，即通过一个特定的字典来定义，具体写法见之前的关于mark的解析，在<a href="https://qixinbo.info/2020/03/28/imagepy_19/">这里</a>。</p><p>之所以使用mark格式，是因为它的可读性非常高，如果直接写Shape类会非常不直观。</p><h1 id="mark转Shape"><a href="#mark转Shape" class="headerlink" title="mark转Shape"></a>mark转Shape</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mark2shp(mark)</span><br></pre></td></tr></table></figure><p>这一步是将上面的mark格式的定义转为imagepy内置的Shape类型的对象。具体的函数定义为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark2shp</span>(<span class="params">mark</span>):</span></span><br><span class="line">    style = mark.copy()</span><br><span class="line">    style.pop(<span class="string">&#x27;body&#x27;</span>)</span><br><span class="line">    keys = &#123;<span class="string">&#x27;point&#x27;</span>:Point, <span class="string">&#x27;points&#x27;</span>:Points, <span class="string">&#x27;line&#x27;</span>:Line, <span class="string">&#x27;lines&#x27;</span>:Lines,</span><br><span class="line">            <span class="string">&#x27;polygon&#x27;</span>:Polygon, <span class="string">&#x27;polygons&#x27;</span>:Polygons, <span class="string">&#x27;circle&#x27;</span>:Circle,</span><br><span class="line">            <span class="string">&#x27;circles&#x27;</span>:Circles, <span class="string">&#x27;rectangle&#x27;</span>:Rectangle, <span class="string">&#x27;rectangles&#x27;</span>:Rectangles,</span><br><span class="line">            <span class="string">&#x27;ellipse&#x27;</span>:Ellipse, <span class="string">&#x27;ellipses&#x27;</span>:Ellipses, <span class="string">&#x27;text&#x27;</span>:Text, <span class="string">&#x27;texts&#x27;</span>:Texts&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mark[<span class="string">&#x27;type&#x27;</span>] <span class="keyword">in</span> keys: <span class="keyword">return</span> keys[mark[<span class="string">&#x27;type&#x27;</span>]](mark[<span class="string">&#x27;body&#x27;</span>], **style)</span><br><span class="line">    <span class="keyword">if</span> mark[<span class="string">&#x27;type&#x27;</span>]==<span class="string">&#x27;layer&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> Layer([mark2shp(i) <span class="keyword">for</span> i <span class="keyword">in</span> mark[<span class="string">&#x27;body&#x27;</span>]], **style)</span><br><span class="line">    <span class="keyword">if</span> mark[<span class="string">&#x27;type&#x27;</span>]==<span class="string">&#x27;layers&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> Layers(<span class="built_in">dict</span>(<span class="built_in">zip</span>(mark[<span class="string">&#x27;body&#x27;</span>].keys(),</span><br><span class="line">            [mark2shp(i) <span class="keyword">for</span> i <span class="keyword">in</span> mark[<span class="string">&#x27;body&#x27;</span>].values()])), **style)</span><br></pre></td></tr></table></figure><p>里面的Point、Circle、Rectangle、Ellipse就是ImagePy内置的几何类，它们有一个共同的基类，即Shape类，里面有三个重要的属性和方法，这也是它的不同子类之间需要进行的重载实现（以Circle为例）：</p><p>（1）body属性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.body = np.array(body, dtype=np.float32)</span><br></pre></td></tr></table></figure><p>将mark格式的body传入numpy的array数组中，然后赋给Shape对象的body属性。<br>这里使用numpy数组的原因有如下几个（源自龙哥的答疑）：</p><ul><li>在draw的时候，需要根据canvas的位移和比例，进行一个加乘运算，得到最后需要draw的画布坐标，即下面代码：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> pts.dtype == <span class="string">&#x27;circles&#x27;</span>:</span><br><span class="line">lst = []</span><br><span class="line">x, y, r = pts.body.T</span><br><span class="line">x, y = f(x, y)</span><br><span class="line">r = r * key[<span class="string">&#x27;k&#x27;</span>]</span><br><span class="line">lst = np.vstack([x-r, y-r, r*<span class="number">2</span>, r*<span class="number">2</span>]).T</span><br><span class="line">dc.DrawEllipseList(lst)</span><br></pre></td></tr></table></figure></li><li>Shape也可以自动计算边界，就用数组的min、max，带上axis参数就可以实现</li><li>编辑的时候，一个snap，其实也要判断所有的点，距离鼠标最近的，也有必要用numpy广播。</li></ul><p>另外，Shape类的style也是mark传入，也可以转为JSON格式的数据，具体可以详看Shape类的代码。<br>（2）转为mark格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_mark</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Shape.to_mark(self, <span class="built_in">tuple</span>(self.body.tolist()))</span><br></pre></td></tr></table></figure><p>即将Shape的body转为mark格式。</p><p>（3）转为shapely的geom格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_geom</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> geom.Point(self.body[:<span class="number">2</span>]).buffer(self.body[<span class="number">2</span>])</span><br></pre></td></tr></table></figure><p>shapely是一个对几何矢量几何进行操作和分析的python库。<br>上面这条语句就是将body的前两个数作为点的坐标生成shapely中的Point，然后将body的第三个数（即半径）生成该Point的缓冲区，即形成一个圆形区域。<br>转为shapely的geometry结构后，就可以进行复杂的几何运算。比如编辑时候的拖拽，判断鼠标是否点击在图形的内部，就需要将Shape转成shapely的geometry。</p><p>关于shapely的教程可以参考：<br><a href="https://www.osgeo.cn/pygis/shapely.html">矢量数据的空间分析：使用Shapely</a><br><a href="https://zhuanlan.zhihu.com/p/24782733">基于Python的缓冲区分析</a></p><h1 id="将Shape传入画布"><a href="#将Shape传入画布" class="headerlink" title="将Shape传入画布"></a>将Shape传入画布</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">canvas.set_shp(mark2shp(mark))</span><br></pre></td></tr></table></figure><p>注意，这里的canvas对象其实是VCanvas类的对象，实际做的是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VCanvas</span>(<span class="params">Canvas</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent, autofit=<span class="literal">False</span>, ingrade=<span class="literal">True</span>, up=<span class="literal">True</span></span>):</span></span><br><span class="line">        Canvas.__init__(self, parent, autofit, ingrade, up)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_shp</span>(<span class="params">self, shp</span>):</span></span><br><span class="line">        self.marks[<span class="string">&#x27;shape&#x27;</span>] = shp</span><br><span class="line">        self.update()</span><br></pre></td></tr></table></figure><p>可以看出，VCanvas继承了Canvas，所以就是将Circle对象传给了Canvas的marks属性（这个属性是个字典）的shape这个key。<br>并且调用Canvas的update进行更新。</p><h1 id="画布绘制几何图形"><a href="#画布绘制几何图形" class="headerlink" title="画布绘制几何图形"></a>画布绘制几何图形</h1><p>那么在画布中是怎样绘制几何图形的呢？<br>具体代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> self.marks.values():</span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">is</span> <span class="literal">None</span>: <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">callable</span>(i):</span><br><span class="line">        i(dc, self.to_panel_coor, k = self.scale)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        drawmark(dc, self.to_panel_coor, i, k=self.scale, cur=<span class="number">0</span>,</span><br><span class="line">            winbox=self.winbox, oribox=self.oribox, conbox=self.conbox)</span><br></pre></td></tr></table></figure><p>首先通过字典的values方法返回marks属性中的所有的值values，以这里绘制Circle为例，那么返回的i就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">sciapp</span>.<span class="title">object</span>.<span class="title">shape</span>.<span class="title">Circle</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure><p>即i是Circle对象。注意这里不要使用print来直接打印i，而需要使用type来显示，因为在Shape类中有一个方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(self.to_mark())</span><br></pre></td></tr></table></figure><p>即如果想看i的值时，会先将其转为mark格式再打印出来，但实际i是个Shape对象。<br>因为i不是callable的，所以就会调用drawmark来显示，最终是使用dc的DrawCircle来绘图。具体绘制过程也可以参见mark模式解析那一篇。</p><h1 id="添加shape动作"><a href="#添加shape动作" class="headerlink" title="添加shape动作"></a>添加shape动作</h1><p>这一部分是shape对象进阶，主要看怎样在画布中实时绘制shape，涉及了shape动作和鼠标事件。<br>最小可用的demo如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciapp.<span class="built_in">object</span> <span class="keyword">import</span> mark2shp</span><br><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> EllipseEditor</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> VCanvas <span class="keyword">as</span> Canvas</span><br><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"></span><br><span class="line">circle = &#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;circle&#x27;</span>, <span class="string">&#x27;color&#x27;</span>:(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="string">&#x27;fcolor&#x27;</span>:(<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="string">&#x27;fill&#x27;</span>:<span class="literal">False</span>, <span class="string">&#x27;body&#x27;</span>:(<span class="number">100</span>,<span class="number">100</span>,<span class="number">50</span>)&#125;</span><br><span class="line"></span><br><span class="line">layer = &#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;layer&#x27;</span>, <span class="string">&#x27;num&#x27;</span>:-<span class="number">1</span>, <span class="string">&#x27;color&#x27;</span>:(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="string">&#x27;fcolor&#x27;</span>:(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>), <span class="string">&#x27;fill&#x27;</span>:<span class="literal">False</span>, <span class="string">&#x27;body&#x27;</span>:[circle]&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark_test</span>(<span class="params">mark</span>):</span></span><br><span class="line">    frame = wx.Frame(<span class="literal">None</span>, title=<span class="string">&#x27;gray test&#x27;</span>)</span><br><span class="line">    canvas = Canvas(frame, autofit=<span class="literal">False</span>, up=<span class="literal">True</span>)</span><br><span class="line">    canvas.set_shp(mark2shp(mark))</span><br><span class="line">    frame.Show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = wx.App()</span><br><span class="line">    EllipseEditor().start(<span class="literal">None</span>)</span><br><span class="line">    mark_test(layer)</span><br><span class="line">    app.MainLoop()</span><br></pre></td></tr></table></figure><p>可以看出，就是在最上面例子上添加了一个自由绘制椭圆的动作。<br>具体分析一下：<br>首先添加椭圆编辑器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciapp.action <span class="keyword">import</span> EllipseEditor</span><br><span class="line">EllipseEditor().start(<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>这个椭圆编辑器实际是一个工具Tool，它最开始的源头可视为Tool类，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tool</span>(<span class="params">SciAction</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Base Tool&#x27;</span></span><br><span class="line">    default = <span class="literal">None</span></span><br><span class="line">    cursor = <span class="string">&#x27;arrow&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, canvas, x, y, btn, **key</span>):</span> <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, canvas, x, y, btn, **key</span>):</span> <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, canvas, x, y, btn, **key</span>):</span> <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, canvas, x, y, d, **key</span>):</span> <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">self, app</span>):</span></span><br><span class="line">        self.app, self.default = app, self</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> app <span class="keyword">is</span> <span class="literal">None</span>: app.tool = self</span><br></pre></td></tr></table></figure><p>Tool中定义了鼠标动作，最原始的Tool中只是提供了鼠标动作定义入口，并没有具体的动作。<br>Tool派生了DefaultTool，可以实现最朴素的移动画布和缩放画布功能（具体见DefaultTool代码）。<br>DefaultTool派生了ShapeTool，不过这个派生并没有实质性的扩展，只是为了与ImageTool、TableTool进行区分。<br>ShapeTool派生了BaseEditor，该工具对Shape对象进行了深度的动作定制：<br>（1）鼠标中键拖动；<br>（2）alt+右键：删除一个shape<br>（3）shift+右键：合并shape<br>（4）右键：将shape根据当前区域大小缩放<br>（5）alt+ctrl：显示锚点（注意这个地方得移动一下鼠标，因为没有定义单独的键盘事件，否则无法触发动作）<br>（6）alt+ctrl+鼠标拖动锚点：改变shape</p><p>BaseEditor派生了EllipseEditor，该工具又对椭圆形状进行了自定义：<br>（1）鼠标左键按下并拖动：新建一个椭圆；<br>（2）alt+新建椭圆：两者做差；<br>（3）shift+新建椭圆：两者取并集<br>（4）alt+shift+新建椭圆：两者取交集</p><p>那么，画布是怎样获取shape和tool的呢？答案就在Canvas中的这两行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">obj, tol = self.get_obj_tol()</span><br><span class="line">btn, tool = me.GetButton(), self.tool <span class="keyword">or</span> tol</span><br></pre></td></tr></table></figure><p>第一行得到了当前的对象，对于shape对象，注意VCanvas的这两个方法和属性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VCanvas</span>(<span class="params">Canvas</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent, autofit=<span class="literal">False</span>, ingrade=<span class="literal">True</span>, up=<span class="literal">True</span></span>):</span></span><br><span class="line">        Canvas.__init__(self, parent, autofit, ingrade, up)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_obj_tol</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.shape, ShapeTool.default</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_shp</span>(<span class="params">self, shp</span>):</span></span><br><span class="line">        self.marks[<span class="string">&#x27;shape&#x27;</span>] = shp</span><br><span class="line">        self.update()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_tool</span>(<span class="params">self, tool</span>):</span> self.tool = tool</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shape</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="string">&#x27;shape&#x27;</span> <span class="keyword">in</span> self.marks: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.marks[<span class="string">&#x27;shape&#x27;</span>]</span><br></pre></td></tr></table></figure><p>即VCanvas重载了Canvas的获取对象的方法，同时shape属性又获得了之前的Shape对象。<br>另外需要注意的是在EllipseEditor中添加椭圆时用的是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shp.body.append(self.obj)</span><br></pre></td></tr></table></figure><p>所以这也就是为什么在程序中又新加了一个layer，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">layer = &#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;layer&#x27;</span>, <span class="string">&#x27;num&#x27;</span>:-<span class="number">1</span>, <span class="string">&#x27;color&#x27;</span>:(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="string">&#x27;fcolor&#x27;</span>:(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>), <span class="string">&#x27;fill&#x27;</span>:<span class="literal">False</span>, <span class="string">&#x27;body&#x27;</span>:[circle]&#125;</span><br></pre></td></tr></table></figure><p>否则body中无法append进去。</p>]]></content>
    
    
    <summary type="html">前言
ImagePy中表示几何矢量的结构类是Shape，最直观的一个应用就是各种ROI操作，这里通过一个小例子看看各种几何图形是怎样操纵和显示的。

最小demo
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16


from sciapp.object import mark2shp
from sciwx.canvas import VCanvas as Canvas
import wx

circle = {&#39;type&#39;:&#39;circle&#39;, &#39;color&#39;:(255,0,0), &#39;fcolor&#39;:(255,255,0), &#39;fill&#39;:False, &#39;body&#39;</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>《重构：数字化转型的逻辑》读书笔记</title>
    <link href="http://qixinbo.github.io/2020/04/09/book-refactoring/"/>
    <id>http://qixinbo.github.io/2020/04/09/book-refactoring/</id>
    <published>2020-04-08T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.485Z</updated>
    
    <content type="html"><![CDATA[<p>以下是对安筱鹏博士的《重构：数字化转型的逻辑》一书的笔记摘抄。<br>逐字摘抄能够加深自己的理解，防止“水过地皮湿”，强烈推荐这种读书方法。</p><h1 id="不重构，无未来：拥抱数据驱动的智能-新时代"><a href="#不重构，无未来：拥抱数据驱动的智能-新时代" class="headerlink" title="不重构，无未来：拥抱数据驱动的智能+新时代"></a>不重构，无未来：拥抱数据驱动的智能+新时代</h1><p>伴随着<strong>新一代信息通信技术</strong>（以互联网、大数据、人工智能、5G为代表）的持续创新和渗透扩散，新一轮工业革命正在全球范围孕育兴起，制造业正迈向<strong>体系重构</strong>、<strong>动力变革</strong>、<strong>范式迁移</strong>的新阶段，加速向<strong>数字化</strong>、<strong>网络化</strong>、<strong>智能化</strong>方向延伸扩展，<strong>万物互联</strong>、<strong>数据驱动</strong>、<strong>软件定义</strong>、<strong>平台支撑</strong>、<strong>组织重构</strong>、<strong>智能主导</strong>正在构建制造业的新体系，它也成为了全球新一轮产业竞争的制高点。</p><h2 id="体系重构"><a href="#体系重构" class="headerlink" title="体系重构"></a>体系重构</h2><p>（1）谁来生产（Who）在变：<strong>生产主体</strong>从生产者向产消者Prosumer演进，个性化定制模式的兴起让消费者全程参与到生产过程中；<br>（2）生产什么（What）在变：<strong>生产对象</strong>从功能产品向智能互联产品演进，可动态感知并实时响应消费需求的无人驾驶、服务机器人等智能化产品的商业化步伐不断加快；<br>（3）用何工具（Which）在变：<strong>生产工具</strong>从以工业社会传统的以能量转换为特征的工具向智能工具演进，即具备对信息进行采集、传输、处理、执行的工具，3D打印、数控机床、智能机器人等智能装备快速涌现；<br>（4）如何生产（How）在变：<strong>生产方式</strong>从传统制造的“试错法”向基于数字仿真的“模拟择优法”转变，构建制造业快速迭代、持续优化、数据驱动的新生产方式；<br>（5）在哪生产（Where）在变：网络化协同制造、分享制造等制造业新模式推动<strong>生产地点</strong>从集中化走向分散化，跨部门、跨企业、跨地域的协同成为常态，尤其是分享制造的发展，构建起了检测、加工、认证、配送等制造能力标准化封装、在线化交易的新体系，推动制造能力在全社会范围内进行协同。</p><h2 id="动力变革"><a href="#动力变革" class="headerlink" title="动力变革"></a>动力变革</h2><p>制造业迈向转型升级的新阶段——数据驱动的新阶段。<br>（1）资源优化是目标，即不断优化制造资源的配置效率，就是要实现更好的质量、更低的成本、更快的交付、更高的满意度，就是要提高制造业全要素生产率；<br>（2）数据流动是关键，即能够把正确的数据在正确的时间以正确的方式传递给正确的人和机器，把数据转化为信息，把信息转化为知识，把知识转化为决策，以信息流带动技术流、资金流、人才流、物资流，以应对和解决制造过程的复杂性和不确定性等问题，提高制造资源的配置效率；<br>（3）工业软件是核心，软件本质上是人类隐形知识显性化的载体，是一套数据自动流动的规则体系。</p><h2 id="范式迁移"><a href="#范式迁移" class="headerlink" title="范式迁移"></a>范式迁移</h2><p>制造范式指在一定时期、在特定技术条件下对制造业价值观、方法论、发展模式和运行规律的认识框架。人类认识和改造世界的方法正从传统的理论推理（以牛顿定律、爱因斯坦相对论为代表，以“观察+抽象+数学”为关键要素，是人类认识世界最根本的方法，依赖于少数天才科学家，具备严密的逻辑关系，是试验验证和模拟择优的基础）、试验验证（以爱迪生发明灯泡为代表，以“假设+试验+归纳”为关键要素，依赖于设备材料的高投入，实验过程大协作、长周期，验证结果直观）向模拟择优（以波音777研发为代表，以“样本数据+机理模型”为关键要素，依赖于高质量机理模型的支撑，和传统试错法相比，投入少、周期短，可推动产品研发、验证、制造、服务业务在赛博空间的快速迭代，实现更短的研发周期、更低的制造成本、更高的产品质量和更好的客户体验）和大数据分析（以GE通过平台优化风电设备性能为代表，以“海量数据+大数据分析模型”为关键要素，依赖于海量数据的获取，以及计算、存储资源的低成本和高效利用，是一种基于数据驱动的价值创造范式）转变。</p><h2 id="智能制造和工业互联网"><a href="#智能制造和工业互联网" class="headerlink" title="智能制造和工业互联网"></a>智能制造和工业互联网</h2><p>20世纪80年代提出的智能制造和2012年提出的工业互联网是面对制造转型升级需求，基于不同时代的技术体系、需求结构、竞争结局提出的解决方案，既有联系又有区别，从智能制造和工业互联网，是<strong>信息技术体系从传统架构向云架构的迁移</strong>，是<strong>制造资源从局部优化到全局优化的演进</strong>，是<strong>业务协同从企业内部到产业链的扩展</strong>，是<strong>竞争模式从单一企业竞争到生态体系竞争的升级</strong>，是<strong>产业分工从基于产品的分工到基于知识的分工深化</strong>，但其内在逻辑是一致的——<strong>以数据的自动流动化解复杂系统的不确定性</strong>。</p><h2 id="重构"><a href="#重构" class="headerlink" title="重构"></a>重构</h2><p>（1）思维重构：以大视野、大科学、大融合维度视角，审视新一轮科技革命和产业变革机理，打通穿透数字化转型的技术、产业、经济、商业、政策的语境与逻辑，在数据+算法定义的世界中，探索<strong>升维思考</strong>之后的<strong>降维落地</strong>之路；<br>（2）战略重构：数字化转型带来了工具革命和决策革命，人们要重新思考战略的形成、演化与落地；<br>（3）技术重构：大科学、大技术交叉融合的时代，技术体系的解耦、分化、再封装正在构建新技术体系，如何洞察技术变局，以OT与IT融合、云架构升级、微服务落地，粉碎僵化开发模式和陈规桎梏，重建技术支撑体系；<br>（4）能力重构：技术赋能时代，传统能力升级与新型能力培育相互交织激荡，企业竞争力体系正在加速重构；<br>（5）组织重构：企业组织迎来了异常转基因工程，无边界的<strong>液态组织</strong>正在激活企业的内生动力。</p><h1 id="智能制造的逻辑：从生产装备自动化到数据流动自动化"><a href="#智能制造的逻辑：从生产装备自动化到数据流动自动化" class="headerlink" title="智能制造的逻辑：从生产装备自动化到数据流动自动化"></a>智能制造的逻辑：从生产装备自动化到数据流动自动化</h1><p>人类社会的发展史就是一部<strong>应对不确定性</strong>、<strong>寻求确定性</strong>的历史，克服对不确定性的恐惧是人类认知深化的重要动力，<strong>对客观世界的理解、预测、控制</strong>是人类化解不确定性恐惧的三步曲。<br>信息的价值在于减少认知的不确定性，个性化定制、产品智能化、产业分工深化及竞争格局加剧不断提升制造系统的复杂性及生产过程的不确定性，<strong>智能制造的本质就在于以数据的自动流动化解复杂系统的不确定性，提高智能资源配置效率。</strong></p><h1 id="智能制造的本质"><a href="#智能制造的本质" class="headerlink" title="智能制造的本质"></a>智能制造的本质</h1><p><strong>智能制造的本质在于以数据的自动流动化化解复杂制造系统的不确定性，优化制造资源配置效率。</strong></p><h2 id="信息、不确定性与人类社会发展"><a href="#信息、不确定性与人类社会发展" class="headerlink" title="信息、不确定性与人类社会发展"></a>信息、不确定性与人类社会发展</h2><h3 id="认知的分野：认知规律中的不确定性"><a href="#认知的分野：认知规律中的不确定性" class="headerlink" title="认知的分野：认知规律中的不确定性"></a>认知的分野：认知规律中的不确定性</h3><p>（1） 哲学视角<br>人们对客观世界的认知并非在确定性和不确定性之间二选一，而是两种思维方式在不断相互转化、交叉融合（灰度思维）。对于现实世界，人们的未知远大于已知，<strong>人类不懈追求认知的绝对确定性而逐步显现出其不确定性</strong>。<br>（2） 科学视角<br>以牛顿三大定律和万有引力定律为核心的牛顿力学作为经典科学，完美地解释了确定性运动学规律和现象。由此而来，近现代科学成就不断强化人们基于确定性逻辑规律的认知，人们不自觉地把科学性和确定性等同起来。<br>对不确定性的重新认识，是现代科学对于人类思想的重要贡献，是20世纪的重大进步。海森堡的测不准原则、哥德尔的不完全性定力、阿罗的社会选择理论、埃弗雷特的平行宇宙理论等不确定性的发现，促使我们的观念发生了根本变化。（<strong>用科学的理论认识总结这种不确定性，是区别被动接受和主动接受不确定性的判据，是不确定性和确定性的融合</strong>）<br>（3） 经济学视角<br>经济学通过研究人的经济行为来分析经济现象，又将人的行为过程描述为决策过程，经济学的一个基本问题是在不确定性条件下人们的决策原则是什么。<br>1972年诺贝尔经济学奖获得者阿罗认为，所谓信息就是根据条件概率原则有效地改变概率的任何观察结果，<strong>不确定就意味着成本，信息的价值就在于降低了经济的不确定性</strong>。</p><h3 id="信息的价值：减少认知的不确定性"><a href="#信息的价值：减少认知的不确定性" class="headerlink" title="信息的价值：减少认知的不确定性"></a>信息的价值：减少认知的不确定性</h3><p>香农在论文《通信的数学理论》中指出：<strong>信息是用来减少随机不确定性的东西，信息的价值是确定性的增加</strong>。<strong>信息就是两次不确定性之差</strong>，<strong>信息就是传递中的知识差</strong>。</p><h3 id="社会的演进：基于信息能力拓展的分工与协作"><a href="#社会的演进：基于信息能力拓展的分工与协作" class="headerlink" title="社会的演进：基于信息能力拓展的分工与协作"></a>社会的演进：基于信息能力拓展的分工与协作</h3><p>工业革命孕育的市场经济本质是如何在高度不确定性的环境中实现科学决策，哈耶克（1974年诺贝尔经济学奖获得者）认为，<strong>市场经济就是一个信息处理系统</strong>，大量独立个体通过价格发现机制，基于各种有限、当地化、碎片化的信息进行决策，优化资源配置。<br>进入数字经济时代，人类大规模协作的广度、深度、频率进入了一个新阶段，企业边界正在被重新定义，科层组织正在被瓦解，产消者不断涌现，微粒社会正在来临，平台经济体迅速崛起，人类社会已经从工业社会百万人量级的协作生产体系演进到数千万、数亿人的合作，这也带来了产业分工不断深化。</p><h2 id="企业竞争的本质：优化资源配置效率的竞争"><a href="#企业竞争的本质：优化资源配置效率的竞争" class="headerlink" title="企业竞争的本质：优化资源配置效率的竞争"></a>企业竞争的本质：优化资源配置效率的竞争</h2><h3 id="企业竞争的本质"><a href="#企业竞争的本质" class="headerlink" title="企业竞争的本质"></a>企业竞争的本质</h3><p>罗纳德.科斯指出：“企业的本质是一种资源配置的机制，是替代市场进行资源配置的组织“。市场和企业是配置资源的两种可相互替代的手段，在市场上资源的配置由价格机制来调节，在企业内则通过管理协调来完成，企业的边界由交易费用决定。当企业内的交易费用低于在市场上的交易费用时，企业的边界则得以扩展，直至两者的交易费用相等为止。<br>企业竞争的本质是在不确定市场环境下企业资源配置效率的竞争。对于制造企业而言，在研发、设计、采购、生产、配送、服务的每个环节，都面临着如何优化资源配置效率的问题。</p><h3 id="不确定性的来源"><a href="#不确定性的来源" class="headerlink" title="不确定性的来源"></a>不确定性的来源</h3><p>（1）产品本身的复杂性：现代产品是集软件、电子、机械、液压、控制于一体的技术系统，产品的设计、生产、维护难度越来越高，产品的研发组织充满了不确定性；<br>（2）生产过程的复杂性：制造是一个涉及企业内外部多主体、多设备、多环节、多学科、多工艺、跨区域协同的复杂系统工程。伴随着产业分工深化、个性化消费兴起、智能化步伐加快，生产过程的复杂性不断提高；<br>（3）市场需求的复杂性：制造企业正从传统的大规模标准化生产向适应用户个性化定制和体验式消费的新型生产方式演进；<br><img src="https://user-images.githubusercontent.com/6218739/78452523-431c1880-76be-11ea-97f3-0e8ee957cdbc.png" alt="1-1"><br>（4）供应链协同的复杂性：随着全球化的发展，企业制造分工日趋细化，产品供应链体系也随之越来越庞大。</p><h2 id="智能制造的本质：以数据的自动流动化解复杂系统的不确定性"><a href="#智能制造的本质：以数据的自动流动化解复杂系统的不确定性" class="headerlink" title="智能制造的本质：以数据的自动流动化解复杂系统的不确定性"></a>智能制造的本质：以数据的自动流动化解复杂系统的不确定性</h2><h3 id="智能的演化"><a href="#智能的演化" class="headerlink" title="智能的演化"></a>智能的演化</h3><p>杨学山在《智能原理》一书中指出“智能是主体<strong>适应</strong>、<strong>改变</strong>、<strong>选择</strong>环境的各种行为能力”。<br>（1）<strong>生物智能</strong>的演化：从单细胞到多系统、从低级到高级、从单个生命体向物种群落的演化。<br>（2）<strong>非生物智能</strong>的演化：对于非生物智能的探索有三大主流学派，即基于逻辑推理算法的符号主义学派、基于神经网络及网络间联结机制与学习算法的连接主义学派、基于“感知—行动”行为模拟算法的行为主义学派。</p><h2 id="数据的自动流动"><a href="#数据的自动流动" class="headerlink" title="数据的自动流动"></a>数据的自动流动</h2><p><strong>完整、准确的数据采集</strong>（智能装备和终端、各种传感器）是数据自动流动的起点，<strong>及时、可靠的数据传输网络</strong>（5G、物联网、时间敏感网络）是数据自动流动的通道，<strong>科学、合理的数据分析</strong>（算法、软件）是数据自动流动的核心，<strong>精准、有效的数据决策</strong>（分布式控制系统DCS、可编程逻辑控制器PLC）是数据自动流动的终点。</p><h2 id="信息化与资源优化配置"><a href="#信息化与资源优化配置" class="headerlink" title="信息化与资源优化配置"></a>信息化与资源优化配置</h2><p>信息物理系统是一种非生物智能与生物智能的集成系统，其本质是通过信息化手段实现数据自动流动，<strong>以信息流带动技术流、资金流、人才流、物资流</strong>，进而解决复杂制造系统的不确定性问题，不断优化资源配置效率。<br>在实际生产过程中企业生产运行时间损失、生产制造资源浪费情况十分严重，通过全面优化企业生产全流程、各环节资源配置提升企业生产效率，提高生产有效可用时间的潜力巨大。<br><img src="https://user-images.githubusercontent.com/6218739/78453057-ede20600-76c1-11ea-993a-36ad1cb2347d.png" alt="1-2"><br>（1）从资源优化配置的系统性来看，将从局部优化向全局优化演进。智能制造系统从单机设备、单一环节、单一场景、单一要素的局部小系统不断向大系统、巨系统演进，从部门级到企业级，再到产业链级，乃至产业生态级系统演进，不断突破地域、组织、机制的界限，实现对人才、技术、资金等资源和要素的高效整合，从而带动产品、模式和业态创新。<br>（2）从资源优化配置的时效性来看，将从静态优化向动态优化演进。传统制造理念是以不变应万变、以确定性应对不确定性，用各种冗余应对可能出现的不确定性，传统制造走向智能制造，就是摒弃冗余思维、静态思维，走向精准思维、动态思维，实时响应变化、拥抱变化，以动态优化策略应对各种不确定性。</p><h1 id="制造业智能化转型的趋势"><a href="#制造业智能化转型的趋势" class="headerlink" title="制造业智能化转型的趋势"></a>制造业智能化转型的趋势</h1><p>高效率、低成本、高质量是制造业不变的追求。当前，互联网、大数据、人工智能等新技术持续创新和高速发展，为制造业发展注入新的活力，使得制造业加速迈向万物互联、数据驱动、软件定义、平台支撑、组织重构的新时代。</p><h2 id="万物互联：互联一切可数字化的事物"><a href="#万物互联：互联一切可数字化的事物" class="headerlink" title="万物互联：互联一切可数字化的事物"></a>万物互联：互联一切可数字化的事物</h2><p>所谓万物互联，就是人、物、数据和应用通过互联网连接在一起，实现所有人和人、人和物及物和物之间的互联，重构整个社会的生产工具、生产方式和生活场景。在万物互联的角度下，信息化就是物理设备不断成为网络终端并引发整个社会变革的过程，信息技术发展的终极目标是基于物联网平台实现设备无所不在的连接，开发各类应用，提供多种数据支撑和服务，未来所有产品都将成为<strong>可监测</strong>、<strong>可控制</strong>、<strong>可优化</strong>、<strong>自主性</strong>的智能产品。<br><img src="https://user-images.githubusercontent.com/6218739/78453567-2df6b800-76c5-11ea-9ee8-fbd1b2e58661.png" alt="2-1"><br><img src="https://user-images.githubusercontent.com/6218739/78453713-0f44f100-76c6-11ea-9d1b-3d52db6934a1.png" alt="2-1"><br><img src="https://user-images.githubusercontent.com/6218739/78453838-f12bc080-76c6-11ea-8584-de60289ff0c1.png" alt="2-2"><br>可监测、可控制、可优化、自主性的智能产品将感知客户需求、推送客户服务，推动企业从<strong>产品生产商</strong>到<strong>客户运营商</strong>的转变。</p><h2 id="数据驱动：驱动制造资源的优化配置"><a href="#数据驱动：驱动制造资源的优化配置" class="headerlink" title="数据驱动：驱动制造资源的优化配置"></a>数据驱动：驱动制造资源的优化配置</h2><p>数据驱动的本质就是通过生产制造全过程、全产业链、产品全生命周期数据的自动流动不断优化制造资源的配置效率，就是要实现更好的质量、更低的成本、更快的交付、更高的满意度，就是要提高制造业全要素生产率，这将带来<strong>数据驱动的服务</strong>（智能互联产品正演变为一个客户需求数据实时感知的平台，演变为基于实时数据的客户服务平台）、<strong>数据驱动的创新</strong>（企业对客户现实需求和潜在需求的深度挖掘、实时感知、快速响应、及时满足，越来越依赖于需求—功能—创意—产品链条数据联动的速度、节奏和效率）、<strong>数据驱动的生产</strong>（数字化模型普遍存在于生产体系各个环节，构建了面向设计、生产、运营、服务和管理的产品库、知识库、专家库，衍生出个性化定制、极少量生产、服务型制造和云制造等新的生产模式）和<strong>数据驱动的决策</strong>（企业内部的横向集成和企业间的纵向集成实现了数据的及时性、完整性、准确性和可执行性，推动数据—信息—知识—决策持续转化，构建企业运营新机制）。</p><h2 id="软件定义：定义数据自动流动的准则"><a href="#软件定义：定义数据自动流动的准则" class="headerlink" title="软件定义：定义数据自动流动的准则"></a>软件定义：定义数据自动流动的准则</h2><p>软件的本质是构建一套数据自动流动的规则体系，基于软件打造“<strong>状态感知</strong>—<strong>实时分析</strong>—<strong>科学决策</strong>—<strong>精准执行</strong>”的数据闭环，解决研发设计、生产制造、运营管理乃至生产制造全过程中的复杂性和不确定性问题，提高资源配置效率。<br>（1）软件定义实现了软硬件的解耦分离：其核心是利用分层思想将<strong>软硬件分离</strong>，通过打破过去的一体化硬件设施，实现“硬件资源的虚拟化”和“服务任务的可编程”，即将传统的“单体式”（Monolithic）硬件设施分解为“基础硬件虚拟化及其API+管控软件”两部分：基础硬件通过API提供标准化的基本功能，进而在其上新增一个软件层替换“单体式”硬件中实现管控的“硬”逻辑，为用户提供更开放、灵活的系统管理服务。这一思想以虚拟化技术为基础，既解决了资源的效率过低的问题，也极大地提升了资源的弹性和灵活性。<br>（2）软件定义重构生产流程和控制模式：软件定义了生产流程，打破了传统的“设计—制造—测试—再设计”的过程，重构一个与实物制造相对应的<strong>虚拟制造空间</strong>，实现了研发设计、仿真、试验、制造、服务在虚拟空间并行运行，通过软件定义设计、产品、生产和管理等制造全环节的方式，推动制造过程快速迭代、持续优化和效率提升。软件定义了控制模式，在工业革命300年的历史进程中，控制装置作为技术完备系统（动力装置、传动装置、执行装置、控制装置）重要子系统之一发展最为迅猛，从珍妮纺织机到继电器开关，从电流调节器到数控机床，从嵌入式控制到基于云平台的远程控制，控制系统在核心技术上走过了一条“机械—机电—电子—数字—软件”的技术发展路线，软件技术的发展促使装备控制模式实现从物理控制到数字控制的革命性变迁。</p><h2 id="平台支撑：支撑制造业生态体系的构建"><a href="#平台支撑：支撑制造业生态体系的构建" class="headerlink" title="平台支撑：支撑制造业生态体系的构建"></a>平台支撑：支撑制造业生态体系的构建</h2><p>平台是基于信息技术构建的连接多个参与方的虚拟空间，是提供信息汇聚（信息门户平台）、产品交易（电商平台）和知识交易（工业互联网平台）的互联网信息服务载体。<br><img src="https://user-images.githubusercontent.com/6218739/78454309-dc046100-76c9-11ea-98a6-01cf8d5e577f.png" alt="2-3"><br>工业互联网平台是工业全要素连接的枢纽，是工业资源配置的核心。工业互联网的本质是推动工业资源和要素的解耦、整合和重构，构建新的发展理念、生产体系、组织架构和商业模式，宏观上提升国家资源高效配置能力，中观上培育产业生态构建能力，微观上打造企业新型能力。工业互联网平台推动资源优化的范围从单机、产线、车间、企业拓展到跨企业、跨区域，正在重塑制造业研发体系、生产范式和商业模式，推动企业研发实现研发主体跨部门协同化、研发流程并行化、研发模式闭环化，不断提升研发效率、缩短研发周期、降低研发成本，推动企业智能制造在更广的范围、更深的领域优化制造资源配置效率，实现价值创造从封闭的价值链向开放的价值网络拓展，推动企业从产品生产商向客户运营商转变，基于平台开展状态监测、故障诊断、预测预警、健康优化等各种新型智能服务。</p><h2 id="组织重构：重构社会分工协作体系"><a href="#组织重构：重构社会分工协作体系" class="headerlink" title="组织重构：重构社会分工协作体系"></a>组织重构：重构社会分工协作体系</h2><p>组织重构的本质就是进入数字经济时代后，数据作为一种新管理要素与传统技术、业务流程、组织结构相互影响、相互作用，极大地变革了不同群体的交流方式、交易方式，有效提升交易速率和质量，从而使得企业内外部交易成本呈现明显下降趋势，推动了组织向<strong>扁平化</strong>（极小化的自组织）、<strong>平台化</strong>（极大化的平台）和<strong>联盟化</strong>（生态化的产业联盟）方向发展。</p><h1 id="信息物理系统（CPS）：智能制造技术体系"><a href="#信息物理系统（CPS）：智能制造技术体系" class="headerlink" title="信息物理系统（CPS）：智能制造技术体系"></a>信息物理系统（CPS）：智能制造技术体系</h1><p>信息物理系统集成先进的信息通信和自动控制等技术构建了一个物理空间与赛博空间相互映射、实时交互、高效协同的复杂系统，是智能制造发展的关键技术支撑。<strong>信息物理系统的核心在于构建一套基于数据自动流动的状态感知、实时分析、科学决策、精准执行的闭环赋能体系，从而解决生产制造过程中的复杂性、不确定性，提高资源配置效率。</strong></p><h2 id="CPS的总体定位：支撑智能制造的综合技术体系"><a href="#CPS的总体定位：支撑智能制造的综合技术体系" class="headerlink" title="CPS的总体定位：支撑智能制造的综合技术体系"></a>CPS的总体定位：支撑智能制造的综合技术体系</h2><p>CPS打通状态感知、实时分析、科学决策、精准执行四个环节，连接了物理空间和赛博空间，构筑起数据自动流动的闭环赋能体系，通过隐性数据显性化、隐性知识显性化，实现由数据转化为信息、信息提炼成知识、知识转化决策，在这一过程中，解决了物理世界四个基本问题：首先是描述（Descriptive）物理世界发生了什么（What happened）；其次是诊断（Diagnostic）为什么会发生（Why it happened）；再次是预测（Predictive）接下来会怎样（What will happen）；最后是决策（Decision）应该怎么办（How to do），决策完成之后就可以驱动物理世界执行（Action），最终实现制造资源的优化配置。<br><img src="https://user-images.githubusercontent.com/6218739/78532410-c8681000-7819-11ea-9344-ee9f292123db.png" alt="3-1"></p><h2 id="CPS的技术要素：一硬、一软、一网、一平台"><a href="#CPS的技术要素：一硬、一软、一网、一平台" class="headerlink" title="CPS的技术要素：一硬、一软、一网、一平台"></a>CPS的技术要素：一硬、一软、一网、一平台</h2><p>状态感知就是通过各种各样的传感器感知物质世界的运行状态，实时分析就是通过工业软件实现数据、信息、知识的转化，科学决策就是通过大数据平台实现异构系统数据的流动与知识的分享，精准执行就是通过控制器、执行器等机械硬件实现对决策的反馈响应，这一切都依赖于一个实时、可靠、安全的网络。<br><img src="https://user-images.githubusercontent.com/6218739/78534790-9b1d6100-781d-11ea-9a17-31a872521639.png" alt="3-2"><br>可以把这一闭环赋能体系概括为“一硬”（感知和自动控制）（感知的本质是物理世界的数字化，通过各种芯片、传感器等智能硬件实现生产制造全流程中人、设备、物料、环境等隐性信息的显性化，自动控制体现为一系列动作或行为，作用于人、设备、物料和环境上，如分布式控制系统DCS、可编程逻辑控制器PLC及数据采集与监视控制系统SCADA等）、“一软”（工业软件）（工业软件是对工业研发设计、生产制造、经营管理、服务等全生命周期环节规律的模型化、代码化、工具化，是工业知识、技术积累和经验体系的载体，是实现工业数字化、网络化、智能化的核心）、“一网”（工业网络）（工业网络是连接工业生产系统和工业产品各要素的信息网络，通过工业现场总线、工业以太网、工业无线网络和异构网络集成等技术，能够实现工厂内各类装备、控制系统和信息系统的互联互通，以及物料、产品与人的无缝集成，并呈现扁平化、无线化、灵活组网的发展趋势）、“一平台”（工业互联网平台）（工业互联网平台是高度集成、开放和共享的数据服务平台，是跨系统、跨平台、跨领域的数据集散中心、数据存储中心、数据分析中心和数据共享中心，基于工业互联网平台推动专业软件库、应用模型库、产品知识库、测试评估库、案例专家库等基础数据和工具的开发集成和开放共享，实现生产全要素、全流程、全产业链、全生命周期管理的资源配置优化，以提升生产效率、创新模式业态，构建全新产业生态），即<strong>“新四基”</strong>。</p><h2 id="CPS的层级体系：单元级、系统级、系统之系统级"><a href="#CPS的层级体系：单元级、系统级、系统之系统级" class="headerlink" title="CPS的层级体系：单元级、系统级、系统之系统级"></a>CPS的层级体系：单元级、系统级、系统之系统级</h2><p>信息物理系统建设的过程就是从单一部件、单机设备、单一环节、单一场景的<strong>局部小系统</strong>不断向<strong>大系统</strong>、<strong>巨系统</strong>演进的过程，是从部门级到企业级，再到产业链级，乃至产业生态级演进的过程，是数据流闭环体系不断延伸和扩展的过程，并逐步形成相互作用的复杂系统网络，突破地域、组织、机制的界限，实现对人才、技术、资金等资源和要素的高效整合，从而带动产品、模式和业态创新。<br>CPS可以分为单元级、系统级、系统之系统（SoS）级三个层级：<br><img src="https://user-images.githubusercontent.com/6218739/78535244-665dd980-781e-11ea-962a-a8be050286a2.png" alt="3-3"><br>（1）<strong>单元级</strong>是具有不可分割性的信息物理系统的最小单元。它可以是一个部件或一个产品，通过“一硬”（如具备传感、控制功能的机械臂和传动轴承等）和“一软”（如嵌入式软件）就可构成“感知—分析—决策—执行”的数据闭环，具备了可感知、可计算、可交互、可延展、自决策的功能，典型的单元级最小单元如智能轴承、智能机器人、智能数控机床等。每个最小单元都是一个<strong>可被识别、定位、访问、联网的信息载体</strong>，通过在赛博空间中对物理实体的身份信息、几何形状、功能信息、运行状态等进行描述和建模，在虚拟空间也可以映射形成一个最小的数字化单元，并伴随着物理实体单元的加工、组装、集成不断叠加、扩展、升级，这一过程也是最小单元在虚拟和实体两个空间不断向系统级和系统之系统级同步演进的过程。<br>（2）<strong>系统级</strong>是“一硬、一软、一网”的有机组合。信息物理系统的多个最小单元（单元级）通过工业网络（如工业现场总线、工业以太网等，简称“一网”），实现更大范围、更宽领域的数据自动流动，构成智能生产线、智能车间、智能工厂，实现了多个单元级CPS的互联、互通和互操作，进一步提高制造资源优化配置的广度、深度和精度。系统级CPS基于多个单元级最小单元的状态感知、信息交互、实时分析，实现了局部制造资源的自组织、自配置、自决策、自优化。由传感器、控制终端、组态软件、工业网络等构成的分布式控制系统（DCS）和数据采集与监控系统（SCADA）是系统级CPS，由数控机床、机器人、AGV小车、传送带等构成的智能生产线是系统级CPS，通过制造执行系统（MES）对人、机、物、料、环等生产要素进行生产调度、设备管理、物料配送、计划排产和质量监控而构成的智能车间也是系统级CPS。<br>（3）<strong>系统之系统级（SoS级）</strong>是多个系统级CPS的有机组合，涵盖了“一硬、一软、一网、一平台”四大要素。SoS级CPS通过工业互联网平台，实现了跨系统、跨平台的互联、互通和互操作，促成了多源异构数据的集成、交换和共享的闭环自动流动，在全局范围内实现信息全面感知、深度分析、科学决策和精准执行。基于工业互联网平台，通过丰富开发工具、开放应用接口、共享数据资源、建设开发社区，加快各类工业App和平台软件的快速发展，形成一个赢者通吃的多边市场，构建一个新的产业生态。<br><img src="https://user-images.githubusercontent.com/6218739/78535482-d40a0580-781e-11ea-826e-1325d5b27d49.png" alt="3-4"><br><img src="https://user-images.githubusercontent.com/6218739/78535977-a7a2b900-781f-11ea-8488-c6ee4a0d421d.png" alt="3-5"></p><p>信息化的终极版图就是要在赛博空间构建起一个与物理空间泛在连接、虚实映射、实时联动、精准反馈、系统自治的<strong>数字孪生体</strong>。伴随着新技术、新方法、新模式的持续创新，物理空间与数字孪生的交互将实现从静态、动态向实时不断演进，这将驱动着赛博空间的数字孪生无限逼近真实物理空间，实现在单元级、系统级、SoS级等不同层次上的感知、分析、决策、控制。<br><img src="https://user-images.githubusercontent.com/6218739/78536476-7c6c9980-7820-11ea-8eb6-d89267a3afe3.png" alt="3-6"></p><h2 id="建设CPS的思路：数据自动流动是关键"><a href="#建设CPS的思路：数据自动流动是关键" class="headerlink" title="建设CPS的思路：数据自动流动是关键"></a>建设CPS的思路：数据自动流动是关键</h2><h3 id="资源优化是目标"><a href="#资源优化是目标" class="headerlink" title="资源优化是目标"></a>资源优化是目标</h3><p>（1）在资源优化的频率上，从静态优化走向动态优化，摒弃传统的以不变应万变的思维模式，根据需求和环境的变化实时调整资源配置方式（柔性生产）；<br>（2）在资源优化的范围上，从单点局部走向全局优化；<br>（3）在资源优化方法论上，从实体优化走向虚实结合优化，从传统的“试错法”向基于数字仿真的“模拟择优法”演变。<br>总体来看，基于CPS的资源优化过程是一个“螺旋式”上升的过程：<br><img src="https://user-images.githubusercontent.com/6218739/78536996-5398d400-7821-11ea-8979-85e9c9c391bf.png" alt="3-7"></p><h3 id="数据自动流动是关键"><a href="#数据自动流动是关键" class="headerlink" title="数据自动流动是关键"></a>数据自动流动是关键</h3><p>如果机器人、数控机床、立体仓库等生产设备的自动化替代的是体力劳动者，那么<strong>数据流动的自动化将替代脑力劳动者</strong>；如果生产设备的自动化是工业3.0，那么<strong>数据流动的自动化才是工业4.0的本质</strong>。<br>信息物理系统的本质就是构建一套数据自动流动的运行体系，即将正确的数据（所承载知识）在正确的时间传递给正确的人和机器，以信息流带动技术流、资金流、人才流、物资流，进而不断优化制造资源的配置效率。<br><strong>从数据流动的视角看，数字化解决了“有数据”的问题，网络化解决了“能流动”的问题，智能化解决了“自动流动”的问题。</strong><br><img src="https://user-images.githubusercontent.com/6218739/78537822-a2933900-7822-11ea-8884-7b067027aa04.png" alt="3-8"></p><h3 id="工业软件是核心"><a href="#工业软件是核心" class="headerlink" title="工业软件是核心"></a>工业软件是核心</h3><p>产品设计和全生命周期管理软件（如CAX、PLM等）建立了高度集成的数字化模型及研发工艺仿真体系，生产制造执行系统（MES）是企业实现纵向整合的核心，联通了设备、原料、订单、排产、配送等各主要生产环节和生产资源，企业管理系统（如ERP、WMS、CRM）为企业的业务活动进行科学管理，改变了企业管理模式和管理理念。</p><h3 id="新型能力培育是主线"><a href="#新型能力培育是主线" class="headerlink" title="新型能力培育是主线"></a>新型能力培育是主线</h3><p>企业推进信息物理系统建设，不能只单纯强调信息技术的先进性，而要围绕企业新型能力不断推进数据、技术、业务流程、组织结构的互动创新和持续优化，将技术的进步、组织结构的变革、业务流程的优化转化成企业的新型能力，诸如个性化定制、精益管理、风险管控、供应链协同、市场快速响应等新型能力，进而重构企业生产方式、服务模式和组织形态，不断获取差异化的可持续竞争优势。<br>当前我国企业关注信息化环境下的六大类能力，包括<strong>研发创新类</strong>（主要关注基于客户需求的数字化快速定制研发、产品研发、工艺设计、生产制造一体化，以及在线、异地协同研发）、<strong>生产管控类</strong>（重点关注大规模个性化定制生产管控、基于用户订单的柔性生产、服务型制造等）、<strong>供应链管理类</strong>、<strong>财务管控类</strong>、<strong>经营管控类</strong>（主要关注基于数据分析的智能决策、企业资源集中共享与协同运营等）及<strong>用户服务类</strong>（主要关注远程诊断与服务、客户互动与敏捷服务、产品全生命周期追溯等）能力。<br><img src="https://user-images.githubusercontent.com/6218739/78538651-e5094580-7823-11ea-9705-21bc8c68f0df.png" alt="3-9"></p><h3 id="系统解决方案是重点"><a href="#系统解决方案是重点" class="headerlink" title="系统解决方案是重点"></a>系统解决方案是重点</h3><p>推动信息物理系统的应用与发展既需要核心关键技术的突破，也需要一批具有广泛应用前景的行业系统解决方案。</p><h1 id="软件定义的未来工业"><a href="#软件定义的未来工业" class="headerlink" title="软件定义的未来工业"></a>软件定义的未来工业</h1><p>“软件定义制造”的本质是研发设计、生产制造、经营管理、运维服务等全生命周期业务环节规律的模型化、代码化、工具化，从根本上优化制造业产品装备、生产方式、组织管理和产业生态，是实现智能制造的核心。</p><h2 id="软件定义的本质"><a href="#软件定义的本质" class="headerlink" title="软件定义的本质"></a>软件定义的本质</h2><p>西门子2014年成立数字化工厂集团——“全球智能制造软硬件整合解决方案提供商”。<br>罗兰贝格公司的专家在谈到工业4.0时曾指出，未来的工业竞争存在两种可能的情景：<strong>软件革命</strong>和<strong>硬件进化</strong>。软件革命的情境是，来自硅谷的国际ICT巨头或新兴企业，以ICT产业领域的技术优势、竞争规则和商业模式重整制造业，通过构建制造业平台、解决方案和产业生态，掌控消费者，从而掌握制造业发展的主导权。硬件进化的情境是，传统制造业进一步强化核心工业技术的竞争优势，更加高效地解决传统工业体系封闭、分散、碎片化的问题，化解软件革命所带来的新生产模式的挑战。</p><p><img src="https://user-images.githubusercontent.com/6218739/78539845-ce63ee00-7825-11ea-9513-2201d5f3d36a.png" alt="表4-1"></p><p>一部工业革命300多年的发展史，就是一部人类社会如何<strong>创造新工具</strong>，更好地开发资源、不断地解放自己的发展史。信息通信技术牵引的新一轮工业革命，推动了人类生产工具从能量转换工具到知识和智能工具的演进，从开发自然资源到<strong>开发信息资源</strong>拓展，从解放人类体力到解放人类脑力跨越。<br><img src="https://user-images.githubusercontent.com/6218739/78540228-6cf04f00-7826-11ea-98b1-923589a6dab0.png" alt="4-1"></p><p>软件开发过程中最重要的逻辑就是if…then…，其核心理念是如何将现实世界可能出现的各种不确定性状态，通过“数据+算法”的分析判断转化为确定性选择，通过对这一逻辑结构的不断组合、嵌套，软件能够在现实世界中建立起一套认识、理解、化解不确定性的方法论。<br><img src="https://user-images.githubusercontent.com/6218739/78540423-b93b8f00-7826-11ea-98f1-358c006e44cd.png" alt="4-2"></p><p><strong>工业软件</strong>是人们对工业研发设计、生产制造、经营管理、运维服务等全生命周期业务环节认知规律的模型化、代码化、工具化，是工业知识、技术积累和经验体系的新载体，是实现工业数字化、网络化、智能化的核心。<strong>数字化</strong>正在从研发手段、管理手段、服务手段等环节走向产品、设备本身，各种芯片、传感器、智能微尘等都具有数字化计算内核（嵌入式系统）（有数据）；<strong>网络化</strong>正在从物质（机械，如螺栓、导线）连接向能量（物理场，如传感器、WiFi）连接、信息（数字，如比特）连接，甚至意识（生物场，如意识）连接演进（数据能流动）；进而，当网络无处不在、知识沉淀为数据和软件、信息可以在任何场景下以数字化形式调用时，<strong>智能化</strong>得以实现（数据能自动流动）。<br><img src="https://user-images.githubusercontent.com/6218739/78540816-4979d400-7827-11ea-9d3d-92b91332ded4.png" alt="4-3"></p><h2 id="软件定义产品"><a href="#软件定义产品" class="headerlink" title="软件定义产品"></a>软件定义产品</h2><p><img src="https://user-images.githubusercontent.com/6218739/78542746-36b4ce80-782a-11ea-8364-769180408f90.png" alt="表4-2"></p><h3 id="软件定义产品功能"><a href="#软件定义产品功能" class="headerlink" title="软件定义产品功能"></a>软件定义产品功能</h3><p><img src="https://user-images.githubusercontent.com/6218739/78542845-59df7e00-782a-11ea-8b44-bc19f6ede24f.png" alt="表4-3"><br>主要表现在：定义产品功能（笔记本电脑、智能手机）、增强产品效能（数控机床、CT机）、拓展产品边界（智能牙刷、智能水杯）。</p><h3 id="软件定义产品结构"><a href="#软件定义产品结构" class="headerlink" title="软件定义产品结构"></a>软件定义产品结构</h3><p>每次技术的重大突破，都会推动产品结构持续创新和演进，构建起新的产品结构。以“<strong>蒸汽机</strong>”为代表的第一次工业革命催生了工业文明；以“电力技术”为代表的第二次工业革命催生出的<strong>电动机</strong>，使工业产品从“蒸汽时代”迈向“电气时代”。信息技术和自动化技术的应用，催生出可控制电压电流的<strong>伺服电机</strong>，“电气一代”跃升为“数控一代”。当前，软件正在与机械、电子、控制等传统工业技术相结合，推动产品逐步向“智能一代”进化，并构建新的产品结构，“一代软件、一代产品”的时代正在到来。<br>（1）功能结构的重构<br>信息技术革命带来的重大变革是，信息技术与自动控制、机械制造技术的集成引发机械产品结构和功能的重大变革，以往仅能靠机械和电子元件等物理实体实现的功能，可以通过软件来实现，产品功能不断丰富，同时物理结构复杂性和成本不断降低。<br>在飞机飞行中，基于对状态信息实时感知、计算、控制的<strong>电传操纵系统</strong>取代了复杂、脆弱和笨重的液压式飞行操纵系统，飞控软件和电子系统使得飞行器的结构更简化、更轻巧、更可靠。同时，飞机、汽车、船舶都可以通过<strong>数字驾驶舱</strong>技术，用简洁的显示屏替代传统的数据仪表。<br>（2）性能结构的优化<br>软件的进化正带来产品设计模式及产品性能结构的重大变化，传统的计算机辅助设计（Computer-Aided Design, CAD）正在向计算机主导设计（Computer-Automated Design,CAD）演进。传统的产品结构设计主要依靠设计工程师的经验和水平，而现在计算机辅助设计正在向计算机自动设计转变。设计仿真工具可根据产品的参数要求，通过不断的迭代优化，自动地给出产品结构的最佳方案，并结合材料技术和制造技术的变革制造出性能更加优秀的产品。<br>（3）价值结构的再造<br>产品基于软件功能的增加带来了更高的价值，软件成为产品价值创造的重要来源。</p><h2 id="软件定义企业管理流程"><a href="#软件定义企业管理流程" class="headerlink" title="软件定义企业管理流程"></a>软件定义企业管理流程</h2><p>发展和成熟于不同技术时代的ERP、CRM、SCM、PLM等管理软件，是某种管理理论、经验和知识的表达、重现和固化，是一种管理规律认知的代码化、软件化。基于软件的业务流程管理正在成为现代企业核心竞争力的重要组成部分。<br><img src="https://user-images.githubusercontent.com/6218739/78544544-df642d80-782c-11ea-8028-6971e74c9fa3.png" alt="4-4"></p><h3 id="软件支撑和定义的研发设计模式"><a href="#软件支撑和定义的研发设计模式" class="headerlink" title="软件支撑和定义的研发设计模式"></a>软件支撑和定义的研发设计模式</h3><p><img src="https://user-images.githubusercontent.com/6218739/78544904-7204cc80-782d-11ea-9ab7-d6aba838924b.png" alt="表4-4"><br><img src="https://user-images.githubusercontent.com/6218739/78545180-ef304180-782d-11ea-9cbe-4aca146792cf.png" alt="4-5"><br><img src="https://user-images.githubusercontent.com/6218739/78545476-6c5bb680-782e-11ea-9489-355744922cd3.png" alt="4-6"></p><h3 id="软件支撑和定义的经营管理模式"><a href="#软件支撑和定义的经营管理模式" class="headerlink" title="软件支撑和定义的经营管理模式"></a>软件支撑和定义的经营管理模式</h3><p>企业经营管理是指运用先进科学管理理念、方法和工具对企业资源、供应链、客户关系等业务活动进行科学管理和系统优化。随着信息技术的发展，ERP、SCM、CRM等管理软件成为推动企业资源管理、供应链管理、客户关系管理的有效工具，改变了企业管理模式和管理理念。这些管理软件的本质是管理理念、方法的模型化、代码化、软件化，通过代码集成了数以千计优秀企业的经营管理精粹，提炼总结了行业知识和最佳实践，并不断进行迭代优化。<br><img src="https://user-images.githubusercontent.com/6218739/78545765-ec821c00-782e-11ea-8725-8f4beed947b4.png" alt="表4-5"><br>管理软件把看不见、摸不着的管理思想、企业文化变成了可看、可学、可复制的标准化模块，管理软件的本质是管理思想的代码化。</p><h3 id="软件支撑和定义的组织架构"><a href="#软件支撑和定义的组织架构" class="headerlink" title="软件支撑和定义的组织架构"></a>软件支撑和定义的组织架构</h3><p>企业功能平台化、运营决策小型化、多部门协同化。</p><h2 id="软件定义企业生产方式"><a href="#软件定义企业生产方式" class="headerlink" title="软件定义企业生产方式"></a>软件定义企业生产方式</h2><h3 id="制造范式的迁移：从实体制造到虚拟制造，以快速迭代、持续优化、数据驱动重建制造效率、成本、质量管控体系"><a href="#制造范式的迁移：从实体制造到虚拟制造，以快速迭代、持续优化、数据驱动重建制造效率、成本、质量管控体系" class="headerlink" title="制造范式的迁移：从实体制造到虚拟制造，以快速迭代、持续优化、数据驱动重建制造效率、成本、质量管控体系"></a>制造范式的迁移：从实体制造到虚拟制造，以快速迭代、持续优化、数据驱动重建制造效率、成本、质量管控体系</h3><p><strong>新概念泛滥反映了制造范式的迁移。</strong><br>虚拟制造：制造业数字化、网络化、智能化的过程，是在赛博空间重建制造流程，并基于此不断提升制造效率的过程。<br>数字样机从传统的<strong>几何样机</strong>向<strong>性能样机</strong>、<strong>制造样机</strong>和<strong>维护样机</strong>拓展，并将进一步进化为与实体产品对应的产品<strong>数字孪生</strong>（Digital Twin）。<br><img src="https://user-images.githubusercontent.com/6218739/78629620-29e7b780-78ca-11ea-8afe-80bcc3e79f07.png" alt="4-7"></p><h3 id="制造模式的变革：从规模生产到定制生产，以数据的自动流动化解制造系统的不确定性、多样性和复杂性"><a href="#制造模式的变革：从规模生产到定制生产，以数据的自动流动化解制造系统的不确定性、多样性和复杂性" class="headerlink" title="制造模式的变革：从规模生产到定制生产，以数据的自动流动化解制造系统的不确定性、多样性和复杂性"></a>制造模式的变革：从规模生产到定制生产，以数据的自动流动化解制造系统的不确定性、多样性和复杂性</h3><p><strong>智能制造与传统制造的本质区别</strong>在于，在生产制造过程中，人员、机器、产品之间<strong>信息交流的载体、方式、效率</strong>不同。智能制造的基础是数字化，传感器、智能装备终端、工业网络、工业软件的大量使用促进了生产制造全过程的数字化，数据采集、传输、存储、分析和挖掘的手段相比传统制造更加丰富，大量蕴含在生产制造过程中的隐性数据不断被采集、汇聚、加工，形成新的知识、决策，不断优化制造资源的配置效率，数据的自动有序流动实现了物资流、资金流的高效利用。<br>美国国家标准与技术研究院（NIST）曾经提出，<strong>智能制造就是要解决差异性更大的定制化服务、更小的生产批量和不可预知的供应链变更</strong>。智能制造的一个重要任务就是应对制造复杂系统的不确定性，这种复杂性既来自产品的复杂性，也来自定制化生产等新生产方式所带来的制造成本、质量和效率的挑战。</p><h3 id="制造系统的重建：从封闭体系走向开放体系，以网络化协同实现制造资源局部优化向全局优化的演进"><a href="#制造系统的重建：从封闭体系走向开放体系，以网络化协同实现制造资源局部优化向全局优化的演进" class="headerlink" title="制造系统的重建：从封闭体系走向开放体系，以网络化协同实现制造资源局部优化向全局优化的演进"></a>制造系统的重建：从封闭体系走向开放体系，以网络化协同实现制造资源局部优化向全局优化的演进</h3><p>软件产业发展的过程就是持续优化资源配置的过程，从计算机辅助设计（CAD）到基于模型的设计（MBD）、基于模型的企业（MBE），从物资需求计划（MRP）到企业资源计划（ERP），从制造执行系统（MES）到制造运营管理（MOM），资源优化的范围越来越广。<br><img src="https://user-images.githubusercontent.com/6218739/78644935-4810e000-78e9-11ea-924d-052af67288e3.png" alt="4-8"></p><h2 id="软件定义企业创新能力"><a href="#软件定义企业创新能力" class="headerlink" title="软件定义企业创新能力"></a>软件定义企业创新能力</h2><p>包括产品研发创新能力、精益及柔性生产能力（精益生产的核心思想是：通过持续改进，杜绝一切无效作业与浪费）、市场需求实时响应能力、全生命周期服务能力（可预测性维护能力额制造资源分享能力）。</p><h2 id="软件定义产业生态"><a href="#软件定义产业生态" class="headerlink" title="软件定义产业生态"></a>软件定义产业生态</h2><p>智能制造发展的一个重要目标就是在商务系统、制造工厂和供应商之间实现企业生态联盟的集成。而这种生态构成，是以集成化软件产品为核心、跨界合作为重要发展模式，其具体表现在以下3个方面。<br>（1）构建基于智能机器的数据采集系统。通过将不同标准接口的设备进行统一集成，将不同类型的机械设备（不同年代、不同生产商）进行连接打通，实现对<strong>OT层数据</strong>的打通及采集，进而将设备厂商、元器件厂商纳入生态系统中。<br>（2）形成智能分析工具。通过整合<strong>IT软件</strong>企业、大数据专业服务商及互联网企业的云服务能力，提升数据分析速度和精度，从而支撑设备、资产、流程优化。<br>（3）搭建开放平台实现工业App的开发。随着新一代信息技术和制造技术的融合，智能制造新型集成化产品不断涌现，显现出以开放化平台为核心，向下整合硬件资源、向上承载软件应用的发展趋势，集成了多种网络通信协议、应用协议、数据协议的工业IoT平台，成为IT、自动化、制造领域领先企业的新宠。</p><h1 id="工业4-0：他山之石的启示"><a href="#工业4-0：他山之石的启示" class="headerlink" title="工业4.0：他山之石的启示"></a>工业4.0：他山之石的启示</h1><h2 id="工业4-0：为什么"><a href="#工业4-0：为什么" class="headerlink" title="工业4.0：为什么"></a>工业4.0：为什么</h2><p>德国工业4.0的概念最大的成功在于，它<strong>把几百年工业发展的历史与现代信息技术趋势进行了完美的集成</strong>，是继承性与创新性的统一、理论性与通俗化的统一、严肃性与时尚性的统一。</p><h2 id="工业4-0：是什么"><a href="#工业4-0：是什么" class="headerlink" title="工业4.0：是什么"></a>工业4.0：是什么</h2><p>与国际社会关于第三次工业革命的说法不同，德国学术界和产业界认为，前三次工业革命的发生，分别源于机械化、电力和信息技术。他们<strong>将18世纪引入机械制造设备定义为工业1.0</strong>，<strong>将20世纪初的电气化定义为工业2.0</strong>，<strong>将始于20世纪70年代的生产工艺自动化定义为工业3.0</strong>，而<strong>物联网和制造业服务化迎来了以智能制造为主导第四次工业革命</strong>，或革命性的生产方法，即工业4.0。德国工业4.0战略旨在通过充分利用信息通信技术和信息物理系统（CPS）相结合的手段，推动制造业向智能化转型。</p><h3 id="工业4-0是互联"><a href="#工业4-0是互联" class="headerlink" title="工业4.0是互联"></a>工业4.0是互联</h3><p>工业4.0的核心是<strong>连接</strong>，要把设备、生产线、工厂、供应商、产品、客户紧密地连接在一起。“工业4.0”适应了万物互联的发展趋势，将无处不在的传感器、嵌入式终端系统、智能控制系统、通信设施通过信息物理系统（CPS）形成一个智能网络，使产品与生产设备之间、不同的生产设备之间，以及数字世界和物理世界之间能够互联，使机器、工作部件、系统及人类会通过网络保持数字信息的交流。<br>（1）生产设备之间的互联。<strong>从工业2.0到工业3.0时代的重要标志是，单机智能设备的广泛普及。</strong>工业4.0工作组把1969年第一个可编程逻辑控制器Modicon 084的使用作为工业3.0的起点，其核心是各种数控机床、工业机器人自动化设备在生产环节的推广，我们可以把它理解为单机设备智能化水平不断提升并普及推广。<strong>工业4.0的核心是单机智能设备的互联</strong>，不同类型和功能的单机智能设备的互联组成智能生产线，不同智能生产线间的互联组成智能车间，智能车间的互联组成智能工厂，不同地域、行业、企业的智能工厂的互联组成一个制造能力无所不在的信息物理系统，这些单机智能设备、智能生产线、智能车间及智能工厂可以自由地、动态地组合，以满足不断变化的制造需求，这是工业4.0区别于工业3.0的重要特征。<br>（2）设备和产品的互联。工业4.0意味着智能工厂能够自行运转，<strong>零件与机器可以进行交流</strong>。由于产品和生产设备之间能够通信，使产品能理解制造的细节及自己将被如何使用。同时，它们能协助生产过程，回答诸如“我是什么时候被制造的”“哪组参数应该被用来处理我”“我应该被传送到哪”等问题。<br>（3）虚拟和现实的互联。信息物理系统（CPS）是工业4.0的核心，它通过将物理设备连接到互联网上，让物理设备具有计算、通信、控制、远程协调和自治五大功能，从而实现虚拟网络世界与现实物理世界的融合。<br>（4）万物互联（Internet of Everything, IoE）。信息技术发展的终极目标是实现无所不在的连接，所有产品都将成为一个网络终端。万物互联就是人、物、数据和程序通过互联网连接在一起，实现人类社会所有人和人、人和物及物和物之间的互联，重构整个社会的生产工具、生产方式和生活场景。</p><h3 id="工业4-0是集成"><a href="#工业4-0是集成" class="headerlink" title="工业4.0是集成"></a>工业4.0是集成</h3><p>工业4.0将无处不在的传感器、嵌入式终端系统、智能控制系统、通信设施通过CPS形成一个智能网络，使人与人、人与机器、机器与机器及服务与服务之间能够互联，从而实现横向、纵向和端对端的高度集成。<br>（1）纵向集成。企业信息化在各个部门发展阶段的里程碑，就是企业内部信息流、资金流和物流的集成，是在哪个层次、哪个环节、哪个水平上，是在生产环节上的集成（如研发设计内部信息集成），还是跨环节的集成（如研发设计与制造环节的集成），还是产品全生命周期的集成（如从产品研发、设计、计划、工艺到生产、服务等全生命周期的信息集成）。工业4.0所要追求的就是在企业内部实现所有环节信息无缝链接，这是所有智能化的基础。<br>（2）横向集成。在市场竞争牵引和信息技术创新驱动下，每个企业都在追求生产过中的信息流、资金流、物流无缝链接与有机协同，在过去，这一目标主要集中在企业内部，但现在企业要实现新的目标：从企业内部的信息集成走向产业链信息集成，从企业内部协同研发体系走向企业间的研发网络，从企业内部的供应链管理走向企业间的协同供应链管理，从企业内部的价值链重构走向企业间的价值链重构。横向集成是企业之间通过价值链及信息网络所实现的一种资源整合，为实现各企业间的无缝合作，提供实时产品与服务，推动企业间研产供销、经营管理与生产控制、业务与财务全流程的无缝衔接和综合集成，实现产品开发、生产制造、经营管理等在不同企业间的信息共享和业务协同。<br>（3）端到端集成。所谓端到端就是围绕产品全生命周期的价值链创造，通过价值链上不同企业资源的整合，实现从产品设计、生产制造、物流配送、使用维护的产品全生命周期的管理和服务，它以产品价值链创造来集成优化供应商（一级、二级、三级……）、制造商（研发、设计、加工、配送）、分销商（一级、二级、三级……），以及客户信息流、物流和资金流，在为客户提供更有价值的产品和服务的同时，重构产业链各环节的价值体系。</p><h3 id="工业4-0是数据"><a href="#工业4-0是数据" class="headerlink" title="工业4.0是数据"></a>工业4.0是数据</h3><p>据将会呈现爆炸式增长态势。伴随着工业互联网、工业大数据、信息物理系统（CPS）的推广，智能装备、智能终端的普及，以及各种各样传感器加速普及使用，将会带来无所不在的感知和无所不在的连接，所有的生产装备、感知设备、联网终端，包括生产者本身都在源源不断地产生数据，这些数据将会渗透到企业运营、价值链乃至产品的整个生命周期，是工业4.0和制造革命的基石。（产品数据、运营数据、价值链数据、外部数据）</p><h3 id="工业4-0是创新"><a href="#工业4-0是创新" class="headerlink" title="工业4.0是创新"></a>工业4.0是创新</h3><p>技术创新（新型传感器、集成电路、人工智能、移动互联、CPS、虚拟制造等）、产品创新（智能产品、智能生产线、智能车间、智能工厂等）、模式创新（生产模式：机器分析判断+机器生产制造，商业模式：网络众包、异地协同设计、大规模个性化定制、精准供应链管理）、业态创新（工业云服务、工业大数据应用、物联网应用）、组织创新（业务流程重组和企业组织再造）</p><h3 id="工业4-0是转型"><a href="#工业4-0是转型" class="headerlink" title="工业4.0是转型"></a>工业4.0是转型</h3><p>（1）从大规模生产向<strong>个性化定制</strong>转型。<br>（2）从生产型制造向<strong>服务型制造</strong>转型。<br>（3）从要素驱动向<strong>创新驱动</strong>转型。</p><h2 id="工业4-0：如何看"><a href="#工业4-0：如何看" class="headerlink" title="工业4.0：如何看"></a>工业4.0：如何看</h2><p>德国工业4.0战略与中国的<strong>信息化和工业化深度融合</strong>战略在核心理念、主要内容和具体做法等诸多方面殊途同归。</p><h2 id="工业4-0：怎么干"><a href="#工业4-0：怎么干" class="headerlink" title="工业4.0：怎么干"></a>工业4.0：怎么干</h2><p>可以从五个方面认识和理解智能制造，即<strong>产品的智能化</strong>（即把传感器、处理器、存储器、通信模块、传输系统融入到各种产品中，使产品具备动态存储、感知和通信能力，实现产品的可追溯、可识别、可定位）、<strong>装备的智能化</strong>（指通过先进制造、人工智能等技术的集成融合，形成具有感知、决策、执行、自主学习及维护等自组织、自适应功能的智能生产系统，以及网络化、协同化的生产设施。装备的智能化至少是在两个维度上进行的，即单机智能化及单机设备互联形成的智能生产线、智能车间、智能工厂）、<strong>生产的智能化</strong>（重组客户、供应商、销售商及企业内部组织的关系，重构生产体系中信息流、产品流、资金流的运行模式，重建新的产业价值链、生态系统和竞争格局）、<strong>管理的智能化</strong>（通过将信息技术与现代管理理念融入企业管理，实现企业流程再造、信息集成、智能管控、组织优化，以形成数据驱动型的企业，从而不断提升信息化背景下企业的核心竞争力）和<strong>服务的智能化</strong>（既体现为企业如何高效、准确、及时挖掘客户的潜在需求并实时响应，也体现为产品交付后对产品实现线上线下（O2O）服务，实现产品的全生命周期管理）。</p><h1 id="工业互联网：从基于产品的分工到基于知识的分工"><a href="#工业互联网：从基于产品的分工到基于知识的分工" class="headerlink" title="工业互联网：从基于产品的分工到基于知识的分工"></a>工业互联网：从基于产品的分工到基于知识的分工</h1><p>从智能制造到工业互联网，是信息技术体系从传统架构向云架构的迁移，是制造资源从局部优化到全局优化的演进，是业务协同从企业内部到产业链的扩展，是竞争模式从单一企业竞争到生态体系竞争的升级，是产业分工从基于产品的分工到基于知识的分工深化，但其内部逻辑是一致的——以数据的自动流动化解复杂制造系统的不确定性，提高制造资源的配置效率。</p><h1 id="探索制造业与互联网融合发展之路"><a href="#探索制造业与互联网融合发展之路" class="headerlink" title="探索制造业与互联网融合发展之路"></a>探索制造业与互联网融合发展之路</h1><p>李克强总理强调：“我国经济保持中高速增长、迈向中高端水平必须要有基本依托，这个基本依托就是推动形成<strong>大众创业</strong>、<strong>万众创新</strong>的新动能。”大型制造企业、电信企业和互联网企业积极构建基于互联网的开放式“双创平台”，在推动制造业转型升级方面发挥了重要作用。<br><img src="https://user-images.githubusercontent.com/6218739/78683279-ac4f9600-7921-11ea-9831-d0751f1f496f.png" alt="6-1"><br><img src="https://user-images.githubusercontent.com/6218739/78684660-511ea300-7923-11ea-9297-0a87a3cb6e9a.png" alt="表6-1"><br>（1）网络化协同制造<br>网络化协同制造是指企业借助互联网或工业云平台，发展企业间协同研发、众包设计、供应链协同等新模式，以此能有效降低资源获取成本，大幅延伸资源利用范围，打破封闭疆界，加速从单打独斗向产业协同转变，促进产业整体竞争力提升。<br><img src="https://user-images.githubusercontent.com/6218739/78685367-3d277100-7924-11ea-9644-1b0595bf5faa.png" alt="6-2"></p><p>（2）个性化定制<br>个性化定制是从传统工业过渡到智能制造阶段的重要标志。其本质是利用互联网平台和智能工厂建设，<strong>将用户需求直接转化为生产排单</strong>，开展以用户为中心的个性定制与按需生产，以有效满足市场多样化需求，解决制造业长期存在的库存和产能问题，从而实现产销动态平衡，满足成本、质量和效率等多方面需求。<br><img src="https://user-images.githubusercontent.com/6218739/78866121-643f8900-7a71-11ea-8ddb-770ce9d82135.png" alt="6-3"><br><img src="https://user-images.githubusercontent.com/6218739/78866244-99e47200-7a71-11ea-96a1-d72b0b5c1590.png" alt="6-4"><br><img src="https://user-images.githubusercontent.com/6218739/78866340-cf895b00-7a71-11ea-971d-96ec659306d9.png" alt="表6-2"></p><p>（3）服务型制造<br>制造业竞争正面临以下四个转变：一是市场需求正从产品导向向产品服务系统导向转变；二是高价值环节从制造环节为主向服务环节为主转变；三是基于产品服务的竞争正成为增强产品竞争优势的重要途径；四是市场交易正从短期交易向长期交易转变。<br>（4）制造业分享经济<br>《国务院关于深化制造业与互联网融合发展的指导意见》强调：“推动中小企业制造资源与互联网平台全面对接，<strong>实现制造能力的在线发布、协同和交易</strong>，积极发展面向制造环节的分享经济，打破企业界限，共享技术、设备和服务，提升中小企业快速响应和柔性高效的供给能力。”</p><p>“新四基”（感知和自动控制（一硬）、工业软件（一软）、工业网络（一网）、工业互联网平台（一平台））是深化制造业与互联网融合的关键支撑。<br><img src="https://user-images.githubusercontent.com/6218739/78867261-660a4c00-7a73-11ea-97e6-ebaa77872296.png" alt="6-5"></p><h1 id="工业互联网平台：为什么，是什么，怎么看？"><a href="#工业互联网平台：为什么，是什么，怎么看？" class="headerlink" title="工业互联网平台：为什么，是什么，怎么看？"></a>工业互联网平台：为什么，是什么，怎么看？</h1><h2 id="为什么"><a href="#为什么" class="headerlink" title="为什么"></a>为什么</h2><p>工业互联网是<strong>新一代信息通信技术与现代工业技术深度融合的产物</strong>，是<strong>制造业数字化、网络化、智能化的重要载体</strong>，也是全球新一轮产业竞争的制高点。工业互联网通过构建<strong>连接机器、物料、人、信息系统</strong>的基础网络，实现工业数据的<strong>全面感知</strong>、<strong>动态传输</strong>、<strong>实时分析</strong>，从而形成<strong>科学决策与智能控制</strong>，以提高制造资源配置效率。</p><p><strong>5G</strong>、<strong>窄带物联网（NB-IoT）</strong>、<strong>时间敏感网络（TSN）</strong>、<strong>OPCUA</strong>等网络技术及<strong>工业以太网</strong>、<strong>工业总线</strong>等通信协议的应用，为制造企业系统和设备数据的互联汇聚创造了条件，构建了<strong>低延时、高可靠、广覆盖的工业网络</strong>，实现了制造系统各类数据便捷、高效、低成本的汇聚。<strong>大数据和人工智能</strong>技术的发展，实现了不同来源、不同结构工业数据的采集与集成、高效处理分析，进而帮助制造企业提升价值。各领域技术的不断发展，并与工业技术融合，构建起了工业互联网平台综合技术体系，工业互联网平台应运而生。<br>在这一进程中，尤其值得关注的是<strong>云计算</strong>技术的发展。云计算技术的发展正在重构软件架构体系和商业模式。高弹性、低成本的IT基础设施日益普及，软件部署由本地化逐渐向云端迁移，软件形态从单体式向微服务不断演变。<strong>开源云架构</strong>、<strong>容器</strong>技术为可重构、可移植、可伸缩的应用服务敏捷地开发和快速部署提供保障，各类新型工业App逐步推广应用，推动了制造资源优化配置。<br><img src="https://user-images.githubusercontent.com/6218739/78869528-512fb780-7a77-11ea-9675-14841707c882.png" alt="7-1"></p><h2 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h2><h3 id="工业互联网的架构"><a href="#工业互联网的架构" class="headerlink" title="工业互联网的架构"></a>工业互联网的架构</h3><p><img src="https://user-images.githubusercontent.com/6218739/78872958-a1f5df00-7a7c-11ea-8232-3194d614d2a8.png" alt="7-2"><br>（1）数据采集（边缘层）是基础<br>数字采集的本质是利用泛在感知技术对多源设备、异构系统、运营环境、人等要素信息进行实时高效采集和云端汇聚。核心就是要构建一个精准、实时、高效的数据采集体系，把数据采集上来，通过协议转换和边缘计算，将一部分数据在<strong>边缘侧</strong>进行处理，这适用于对实时性、短周期数据的快速处理，处理结果将直接返回到机器设备；将另一部分数据传到<strong>云端</strong>，通过云计算更强大的数据运算能力和更快的处理速度，对非实时、长周期数据进行综合利用分析，从而进一步优化形成决策。</p><p>工业现场数据云端汇聚面临的突出问题可以总结为“三不”：<strong>不敢传（数据安全问题）</strong>、<strong>不需传（本地化和实时性问题）</strong>、<strong>不能传（协议标准不统一）</strong>，即无法支撑实时数据采集和实时分析、智能优化和科学决策。一是工业数据采集存在数据安全隐患。工业数据采集会涉及大量重要工业数据和用户隐私信息，在传输和存储时都会存在一定的数据安全隐患，也存在黑客窃取数据、攻击企业生产系统的风险。因此，急需从技术、管理和法律法规等多方面保障数据安全。二是工业协议标准不统一且数据开放性不够。目前在工业数据采集领域，存在Modbus、CAN、ControlNet、DeviceNet、Profibus、Zigbee等各种工业协议标准，各个自动化设备生产及集成商还会自己开发各种私有的工业协议，各种协议标准不统一、互不兼容；同时很多设备和系统的数据开放性不够，缺乏数据接口及文档说明，导致协议适配解析和数据互联互通困难。三是工业数据采集实时性要求难以保证。生产线的高速运转，精密生产和运动控制等场景对数据采集的实时性要求不断提高，传统数据采集技术对于高精度、低时延的工业场景难以保证重要信息实时采集和上传，无法满足生产过程的实时监控需求。<br><img src="https://user-images.githubusercontent.com/6218739/78873281-3102f700-7a7d-11ea-9374-ce31ebd41d69.png" alt="7-3"></p><p>当前，突破数据采集瓶颈的主要思路包括以下两个方面：<br>（a）通过协议兼容、转换实现多源设备、异构系统的数据可采集、可交互、可传输。GE通过将数据采集转换模块Predix Machine部署在现场传感器、控制器和网关中，以多种方式实现不同协议的兼容和转换，来完成工业现场数据采集及云端汇聚。西门子通过在设备端部署数据采集模块MindConnect Nano，实现通用协议兼容和私有协议转换及云端汇聚。<br><img src="https://user-images.githubusercontent.com/6218739/78873502-91923400-7a7d-11ea-8db9-267b70d8ea63.png" alt="7-4"></p><p>（b）通过边缘计算等技术在设备层进行数据预处理，进而大幅提高数据采集、传输效率，以降低网络接入、存储、计算等成本，提高现场控制反馈的及时性。</p><p>（2）IaaS是支撑<br>IaaS是通过虚拟化技术将计算、存储、网络等资源池化，向用户提供可计量、弹性化的资源服务。IaaS是工业互联网平台运行的载体和基础，其实现了工业大数据的存储、计算、分发。</p><p>（3）工业PaaS（平台层）是核心<br>工业PaaS本质是一个可扩展的工业云操作系统，它能够实现对软硬件资源和开发工具的接入、控制和管理，为应用开发提供了必要接口及存储计算、工具资源等支持，它为工业应用软件开发提供一个基础平台。</p><p>工业PaaS面临的突出问题是开发工具不足、行业算法和模型库缺失、模块化组件化能力较弱，现有通用PaaS平台尚不能完全满足工业级应用需要。当前，工业PaaS建设的总体思路是，通过对通用PaaS平台的深度改造，构造满足工业实时、可靠、安全需求的云平台，采用微服务架构，<strong>将大量工业技术原理、行业知识、基础模型规则化、软件化、模块化，并封装为可重复使用的微服务</strong>，通过对微服务的灵活调用和配置，降低应用程序开发门槛和开发成本，提高开发、测试、部署效率，为海量开发者汇聚、开放社区建设提供技术支撑和保障。</p><p>（4）工业App（应用层）是关键<br>工业App主要表现为面向特定工业应用场景，整合全社会资源推动工业技术、经验、知识和最佳实践的模型化、软件化、再封装（工业App），用户通过对工业App的调用实现对特定制造资源的优化配置。工业App由通用云化软件和专用App应用构成，它面向企业客户提供各类软件和应用服务。<br>当前，工业App发展的总体思路包括以下两个方面。<br>（a）传统的CAD、CAE、ERP、MES等研发设计工具和管理软件加快<strong>云化改造</strong>。云化迁移是当前软件产业发展的基本趋势，全球软件产品“云化”步伐不断加快，基于传统集中式架构的软件开发部署模式正在向高可用、易扩展、低成本的分布式云架构转型。<br>（b）围绕多行业、多领域、多场景的云应用需求开发<strong>专用App</strong>应用。大量开发者通过对工业PaaS层微服务的调用、组合、封装和二次开发，将工业技术、工艺知识和制造方法固化和软件化，开发形成了专用App应用。</p><p><img src="https://user-images.githubusercontent.com/6218739/78874309-c5ba2480-7a7e-11ea-8040-2e051d5d9eb0.png" alt="7-5"><br><img src="https://user-images.githubusercontent.com/6218739/78874890-ad96d500-7a7f-11ea-990d-54a3a76f58a1.png" alt="表7-1"><br><img src="https://user-images.githubusercontent.com/6218739/78875053-e46ceb00-7a7f-11ea-8d21-f7136ebf183a.png" alt="7-6"></p><h3 id="工业互联网平台的本质"><a href="#工业互联网平台的本质" class="headerlink" title="工业互联网平台的本质"></a>工业互联网平台的本质</h3><p>工业互联网平台的本质是一套面向制造业数字化、网络化、智能化的解决方案，这套解决方案与传统方案最本质的区别就是基于<strong>云架构</strong>，这是需求场景、技术演进、生态构建共同作用的必然结果，其基本的逻辑就是“数据+模型=服务”，就是如何采集制造系统海量数据，把来自机器设备、业务系统、产品模型、生产过程及运行环境中的大量数据汇聚到工业PaaS平台上，实现物理世界隐性数据的显性化，实现数据的及时性、完整性、准确性，并将技术、知识、经验和方法以数字化模型的形式沉淀到平台上，形成各种软件化的模型（机理模型、数据分析模型等），基于这些数字化模型对各种数据进行分析、挖掘、展现，以提供产品全生命周期管理、协同研发设计、生产设备优化、产品质量检测、企业运营决策、设备预测性维护等多种多样的服务，从而实现数据—信息—知识—决策的迭代，最终把正确的数据、以正确的方式、在正确的时间传递给正确的人和机器，优化制造资源配置效率。<br><img src="https://user-images.githubusercontent.com/6218739/78875258-30b82b00-7a80-11ea-809c-b5951229453a.png" alt="7-7"><br><img src="https://user-images.githubusercontent.com/6218739/78875362-59d8bb80-7a80-11ea-88b4-d6912e89ce50.png" alt="7-8"><br><img src="https://user-images.githubusercontent.com/6218739/78875620-c18f0680-7a80-11ea-8ba3-25788370fd92.png" alt="7-9"><br><img src="https://user-images.githubusercontent.com/6218739/78876166-8214ea00-7a81-11ea-9a37-3d666c26af9b.png" alt="表7-2"><br><img src="https://user-images.githubusercontent.com/6218739/78876352-cacca300-7a81-11ea-9d60-9f8105ce513e.png" alt="7-10"><br><img src="https://user-images.githubusercontent.com/6218739/78876472-f8195100-7a81-11ea-8910-88ea6ad898aa.png" alt="7-11"><br><img src="https://user-images.githubusercontent.com/6218739/78876566-1aab6a00-7a82-11ea-8f2e-4734b7273063.png" alt="7-12"></p><h3 id="工业互联网平台的核心"><a href="#工业互联网平台的核心" class="headerlink" title="工业互联网平台的核心"></a>工业互联网平台的核心</h3><p>工业PaaS中最核心的要素组件是<strong>基于微服务架构的数字化模型</strong>。数字化模型将大量工业技术原理、行业知识、基础工艺、模型工具等规则化、软件化、模块化，并封装为可重复使用的组件。<br><img src="https://user-images.githubusercontent.com/6218739/78877416-64e11b00-7a83-11ea-9f64-56d008966e11.png" alt="7-13"><br>（1）数字化模型是什么？数字化模型可以分为两种，一种是<strong>机理模型</strong>，包括<strong>基础理论模型</strong>（如飞机、汽车、高铁等制造过程中涉及的流体力学、热力学、空气动力学方程等模型），<strong>流程逻辑模型</strong>（如ERP、供应链管理等业务流程中蕴含的逻辑关系）、<strong>部件模型</strong>（如飞机、汽车、工程机械等涉及的零部件三维模型）、<strong>工艺模型</strong>（如集成电路、钢铁、石化等生产过程中涉及的多种工艺、配方、参数模型）、<strong>故障模型</strong>（如设备故障关联、故障诊断模型等）、<strong>仿真模型</strong>（如风洞、温度场模型等）。机理模型本质上是各种经验知识和方法的固化，它更多是从业务逻辑原理出发，强调的是因果关系。随着大数据技术发展，一些<strong>数据分析模型</strong>也被广泛使用，包括<strong>基本的数据分析模型</strong>（如对数据做回归、聚类、分类、降维等基本处理的算法模型）、<strong>机器学习模型</strong>（如利用神经网络等模型对数据进行进一步辨识、预测等）及<strong>智能控制结构模型</strong>，大数据分析模型更多的是从数据本身出发，不过分考虑机理原理，更加强调相关关系。<br>（2）数字化模型从哪来？这些数字化模型一部分来源于物理设备，包括飞机、汽车、高铁制造过程的零件模型，设备故障诊断、性能优化和远程运维等背后的原理、知识、经验及方法；一部分来源于业务流程逻辑，包括ERP、供应链管理、客户关系管理、生产效能优化等这些业务系统中蕴含着的流程逻辑框架；此外还来源于研发工具，包括CAD、CAE、MBD等设计、仿真工具中的三维数字化模型、仿真环境模型等；以及生产工艺中的工艺配方、工艺流程、工艺参数等模型。<br>（3）数字化模型怎么开发？用什么工具开发？所有这些技术、知识、经验、方法、工艺都将通过不同的编程语言、编程方式固化形成一个个数字化模型。这些模型一部分是由具备一定开发能力的编程人员，通过<strong>代码化、参数化的编程方式</strong>直接将数字化模型以源代码的形式表示出来，但对模型背后蕴含的知识、经验了解相对较少；另一部分是由具有深厚工业知识沉淀但不具备直接编程能力的行业专家，将长期积累的知识、经验、方法通过<strong>“拖拉拽”等形象、低门槛的图形化编程方式</strong>（低代码），简易、便捷、高效地固化成一个个数字化模型。<br>（4）数字化模型什么样？采用什么技术架构？当把这些技术、知识、经验、方法等固化成一个个数字化模型沉淀在工业PaaS平台上时，主要以两种方式存在：一种是<strong>单体式架构</strong>，即把一个复杂大型的软件系统直接迁移至平台上；另一种是<strong>微服务架构</strong>，传统的软件架构不断“解耦”成一个个功能单元，并以微服务架构形式呈现在工业PaaS平台上，构成一个微服务池，然后对这些微服务调用，重构成面向角色的App。目前两种架构并存于平台之上，但随着时间的推移，<strong>单体式架构会不断地向微服务架构迁移</strong>。当工业PaaS平台上拥有大量蕴含着工业技术、知识、经验和方法的微服务架构模型时，应用层的工业App可以快速、灵活地<strong>调用多种碎片化的微服务组件</strong>，实现工业App快速开发部署和应用。<br><img src="https://user-images.githubusercontent.com/6218739/78878105-6f4fe480-7a84-11ea-8a5e-4358a2bdca7c.png" alt="7-14"><br>（5）数字化模型怎么用？一旦海量数据都汇聚到工业PaaS平台上，工业技术、知识、经验和方法以数字化模型的形式沉淀在PaaS平台上，当海量数据加载到数字化模型中，进行反复迭代、学习、分析、计算之后，可以解决物理世界四个基本问题：首先是描述（Descriptive）物理世界发生了什么（What happened）；其次是诊断（Diagnostic）为什么会发生（Why ithappened）；再次是预测（Predictive）下一步会发生什么（What will happen）；最后是决策（Decision）该怎么办（How to do），并驱动物理世界执行（Action），优化资源配置效率。概括起来讲，就是状态感知、实时分析、科学决策、精准执行。</p><h3 id="工业互联网与消费互联网的区别"><a href="#工业互联网与消费互联网的区别" class="headerlink" title="工业互联网与消费互联网的区别"></a>工业互联网与消费互联网的区别</h3><p><img src="https://user-images.githubusercontent.com/6218739/78878434-fdc46600-7a84-11ea-9866-7f45ad289b94.png" alt="7-15"></p><h3 id="制造业数字化架构体系的演进：从传统IT架构到工业互联网架构"><a href="#制造业数字化架构体系的演进：从传统IT架构到工业互联网架构" class="headerlink" title="制造业数字化架构体系的演进：从传统IT架构到工业互联网架构"></a>制造业数字化架构体系的演进：从传统IT架构到工业互联网架构</h3><p><img src="https://user-images.githubusercontent.com/6218739/78879002-e20d8f80-7a85-11ea-8ab1-4050141ae4f3.png" alt="表7-3"></p><h3 id="微服务：工业互联网脚骨技术变革的关键"><a href="#微服务：工业互联网脚骨技术变革的关键" class="headerlink" title="微服务：工业互联网脚骨技术变革的关键"></a>微服务：工业互联网脚骨技术变革的关键</h3><p>相比于传统软件开发架构面临的软件代码体积大、更新慢、维护难等问题，微服务具有<strong>轻量化</strong>、<strong>松耦合</strong>、<strong>快部署</strong>、<strong>高灵活度</strong>等特性，其适用于互联网需求变化快、用户群体面广等特点。在工业领域，现有工业软件架构体系越来越难以满足制造业生产体系的复杂性和不确定性需求，微服务架构为各类工业知识、经验、方法、技术等在工业互联网平台上的沉淀创造了条件，实现了工业知识的复用、重构、创造和传播，极大地提高了工业App的开发、测试、部署效率。<br>（1）微服务的本质<br>微服务（Microservice）是一种将复杂应用拆分成多个单一功能组件，通过模块化组合方式实现“松耦合”应用开发的软件架构，也称微服务架构（Microservice Architecture）。每个功能组件都是一个独立的、可部署的业务单元，称之为微服务组件。每个微服务组件可以根据业务逻辑，<strong>选择最适合该微服务组件的语言、框架、工具和存储技术进行开发部署</strong>。因此，微服务架构是一种独立开发、独立测试、独立部署、独立运行、高度自治的架构模式，同时也是一种更灵活、更开放、更松散的演进架构。其本质是一种将整体功能分解到各个离散服务中，实现对原有解决方案解耦，进而提供更加灵活服务的设计思想。<br><img src="https://user-images.githubusercontent.com/6218739/78879741-e4241e00-7a86-11ea-9d73-426026e2683c.png" alt="7-16"></p><p>（2）微服务的特征<br><img src="https://user-images.githubusercontent.com/6218739/78879847-0f0e7200-7a87-11ea-8876-6407c181cc62.png" alt="7-17"><br><img src="https://user-images.githubusercontent.com/6218739/78880024-509f1d00-7a87-11ea-90e7-5b3d037a0b24.png" alt="7-18"><br><img src="https://user-images.githubusercontent.com/6218739/78880274-bc818580-7a87-11ea-9063-55f69293d482.png" alt="7-19"><br><img src="https://user-images.githubusercontent.com/6218739/78880323-d02cec00-7a87-11ea-9f42-cb0e4b0ca083.png" alt="7-20"></p><p>在工业互联网领域，微服务作为汇聚工业大数据与提供工业智能服务的关键核心，驱动着工业大数据开始“数据产生—数据汇聚—数据处理—数据加工—数据调用—数据展示”的数据之旅，其实现路径是将各种<strong>以数字化模型构成的微服务组件容器化</strong>，通过负载均衡、弹性扩展快速实现微服务的部署、组合及调度，以支撑工业App的应用开发与使用<br><img src="https://user-images.githubusercontent.com/6218739/78880547-2732c100-7a88-11ea-9193-1848856ccd5c.png" alt="7-21"></p><p>（3）微服务设计原则<br>单一职责原则、服务自洽原则、轻量级通信原则、接口明确原则。</p><h2 id="怎么看"><a href="#怎么看" class="headerlink" title="怎么看"></a>怎么看</h2><h3 id="工业云视角"><a href="#工业云视角" class="headerlink" title="工业云视角"></a>工业云视角</h3><p><img src="https://user-images.githubusercontent.com/6218739/78881297-2c444000-7a89-11ea-8663-11650d909b24.png" alt="7-22"></p><p>工业互联网平台就是在传统工业云平台软件工具共享、业务系统集成的基础上，叠加了制造能力开放、知识经验复用和开发者集聚的功能，从而大幅提升工业知识生产、传播和利用的效率，它是一个不断演进的过程。</p><h3 id="解决方案视角"><a href="#解决方案视角" class="headerlink" title="解决方案视角"></a>解决方案视角</h3><p><img src="https://user-images.githubusercontent.com/6218739/78881497-7d543400-7a89-11ea-8414-4dad267d847e.png" alt="7-23"><br>工业互联网平台本质上是一套基于云平台的数字化、网络化、智能化解决方案。<br><img src="https://user-images.githubusercontent.com/6218739/78881764-d6bc6300-7a89-11ea-9ea1-166801741f4d.png" alt="7-24"></p><h3 id="操作系统视角"><a href="#操作系统视角" class="headerlink" title="操作系统视角"></a>操作系统视角</h3><p>工业互联网平台实质上是一个可拓展的工业操作系统，向下，可以实现对各种软硬件资源接入、控制和管理；自身，承载着蕴含大量工业知识的数字化模型与微服务；向上，提供开发接口、存储计算及工具资源等支持，并以工业App的形式提供各种各样的服务。<br><img src="https://user-images.githubusercontent.com/6218739/78882050-3450af80-7a8a-11ea-87d2-c10c5d16b83e.png" alt="7-25"></p><p>操作系统通过分层思想将<strong>软硬件的分离解耦</strong>，以打破过去的一体化硬件设施，进而实现“硬件资源的通用化”和“服务任务的可编程”。“硬件通用化”和“服务可编程”技术演进主要解决的问题是：快速应对名种不确定性。即<strong>让“变化快”的软件摆脱束缚，使得变化“更快”；让“利用率高”的硬件逐渐沉淀趋于统一，使得利用率“更高”</strong>。硬件能够提高资产通用性，其遵循规模经济，可大规模生产标准化产品，降低生产成本。软件能够丰富产品个性化，其遵循范围经济，使企业能从提供同质产品向提供多样化产品转变，以满足市场个性化需求。<br><img src="https://user-images.githubusercontent.com/6218739/78882322-7d086880-7a8a-11ea-9e6c-2ceaff6faf39.png" alt="7-26"></p><p>在工业里很多技术、知识、经验、方法创新需要从零开始，知识复用水平较低。而构建一个工业互联网平台，<strong>能够将大量工业技术原理、行业知识、基础工艺、模型工具、业务流程及老专家几十年的经验进行规则化、软件化、模块化，以数字化模型的形式沉淀在这个平台上</strong>。沉淀之后能够减少大部分重复性工作，可以直接调用、复用、传播，重构工业创新体系，进而大幅度降低创新成本和风险，提高研发、生产和服务效率。从这个角度讲，工业互联网平台就是通过提高工业知识复用水平构筑工业知识创造、传播和应用新体系，即重构工业知识新体系。</p><h3 id="产业生态视角"><a href="#产业生态视角" class="headerlink" title="产业生态视角"></a>产业生态视角</h3><p><img src="https://user-images.githubusercontent.com/6218739/78882579-d7a1c480-7a8a-11ea-8a9f-a3affbabcf2d.png" alt="7-27"></p><h3 id="经济学视角"><a href="#经济学视角" class="headerlink" title="经济学视角"></a>经济学视角</h3><p>工业互联网的价值在于其加快了从基于产品的分工向<strong>基于知识的分工</strong>演进，构建了新的产业分工体系，推动了经济增长。郭朝晖也曾多次强调，工业互联网的应用将会带来新的工作场景：有经验的人离开了生产现场，从事更富有创造性的“<strong>知识生产</strong>”。<br>（1）信息化推动经济增长的机理<br>提高生产率：<br><img src="https://user-images.githubusercontent.com/6218739/78883456-1dab5800-7a8c-11ea-8864-0486c15fe540.png" alt="7-28"><br>提高交易效率：<br><img src="https://user-images.githubusercontent.com/6218739/78883701-6cf18880-7a8c-11ea-91da-d52c08f957bd.png" alt="7-29"></p><p>（2）知识创造的专业化是分工深化的新阶段<br>伴随着生产力水平的不断提升，产业分工不断深化，其大致经历了五个阶段：一是<strong>部门专业化</strong>，即农业、手工业和商业之间的分工；二是<strong>产品专业化</strong>，即以完成的最终产品为对象的分工，如汽车、机械、电器产品的生产；三是<strong>零部件专业化</strong>，即一个企业仅仅生产某个最终产品的一部分；四是<strong>工序专业化</strong>，即专门进行产品或零部件生产的一个工艺过程，如铸造、电镀等；五是<strong>生产服务专业化</strong>，即在直接生产过程之外，又提供基于产品的为生产服务，如物流配送、金融服务等。<br>以集成电路产业为例，集成电路产业分工水平明显高于其他行业，其形成了<strong>基于知识的产业分工新体系</strong>。<br><img src="https://user-images.githubusercontent.com/6218739/78884234-2cded580-7a8d-11ea-8f98-458a8543a300.png" alt="7-30"></p><p>1991年，英国ARM公司成立，同时逐渐涌现出一批专注于集成电路知识产权包（IntellectualProperty, IP）设计、研发公司，集成电路产业开始兴起架构授权的Chipless新商业模式，这标志着基于知识创造的专业化分工独立出现在集成电路产业链中，<strong>工业知识脱离电路产品的附庸，开始作为独立的产品进行传播、使用和交易</strong>，随后在集成电路各个环节涌现出大量以各类IP包形式存在的设计、仿真、试产、制造等环节的工业知识，这些知识大幅提高了设计效率、产品性能、制造可行性及良品率，基于知识交易的新业态逐渐显现。<br><img src="https://user-images.githubusercontent.com/6218739/78884529-a70f5a00-7a8d-11ea-9877-73f54c102467.png" alt="表7-4"><br><img src="https://user-images.githubusercontent.com/6218739/78884691-f2c20380-7a8d-11ea-8bab-1ba23a0bca70.png" alt="7-31"></p><p>（3）工业互联网平台加快构建基于知识的产业分工新体系<br>一方面，工业互联网平台为工业知识的App化、微服务化创造了条件，实现了工业知识的产品化封装、平台化汇聚、在线化开放；另一方面，工业互联网平台构建了一个工业技术和知识的交易体系，它为工业App、微服务组件、模型算法等交易对象的呈现、交易、传播和复用提供了统一的场所，促进了工业知识、技术的供给方（大型企业、科研院校、开发者）与使用方（大中小企业）等交易主体在线显现、需求清晰、交易激活。<br><img src="https://user-images.githubusercontent.com/6218739/78885032-7845b380-7a8e-11ea-8579-6993721fa875.png" alt="表7-5"><br>消费互联网革命并非简单地将线下产品迁至线上。同样，工业互联网革命也并非简单地将依附在书籍、标准、专利上的工业知识迁至平台，而是革命性地改变工业知识的生产、交易方式，<strong>将传统的由供给方定制化软件开发（作坊式）的方式及一对一的交易模式，转变成由需求方个性化定制工业App（流水式）及平台化多对多的交易方式</strong>。这一新型交易体系将会带来更多新的商业价值。<br><img src="https://user-images.githubusercontent.com/6218739/78885128-a1664400-7a8e-11ea-80ee-38e2097ae752.png" alt="7-32"><br>工业互联网通过采用类似<strong>“乐高积木”的组建模式</strong>，将大量工业知识、经验、方法、模型以微服务组件化的方式沉在工业互联网平台上。通过“平台+微服务组件+App+…”的方式，将各种业务功能组件化、模块化、微服务化，在一个基础通用平台上，对细化的业务功能进行统一编排调用，既实现了软件产品的快速开发，又充分满足了不同企业不同场景的定制化需求，实现了知识产品和功能适用化的高度统一，找到了一条通往软件开发高效、定制、产品化的发展路径。<br><img src="https://user-images.githubusercontent.com/6218739/78885360-0752cb80-7a8f-11ea-94c9-2995fe6c8a3e.png" alt="7-33"></p><h1 id="工业互联网平台的演进路径"><a href="#工业互联网平台的演进路径" class="headerlink" title="工业互联网平台的演进路径"></a>工业互联网平台的演进路径</h1><p>工业互联网平台与工业云有本质的区别，又有许多联系，工业互联网平台是传统工业云功能的叠加与迭代。从过去几年的工作实践及技术和产业发展趋势来看，工业云平台向工业互联网平台的演进经历了成本驱动导向、集成应用导向、能力交易导向、创新引领导向、生态构建导向五个阶段，这几个阶段可以并行，也可以跳跃。</p><h2 id="成本驱动导向阶段"><a href="#成本驱动导向阶段" class="headerlink" title="成本驱动导向阶段"></a>成本驱动导向阶段</h2><p>工业云发展的第一阶段是成本驱动导向阶段。这一阶段主要是<strong>研发设计类工具上云</strong>。云计算具有资源池化、弹性供给、按需付费等典型特征，它能大幅降低企业购买研发工具的成本，提高企业研发效率，降低成本是工业云平台起步发展阶段考虑的重要因素。<br>在<strong>硬件</strong>方面，云平台通过IT硬件资源租用取代直接购买或自建，可以大幅降低硬件成本。在<strong>软件</strong>方面，从购买软件授权到根据时间、人、次数来订阅云服务，也可以大幅降低成本。在<strong>部署成本与运营成本</strong>方面，工业云平台可以在任意时间、任意地点快速部署，大大缩短了信息系统建设周期，同时，工业云平台由平台运营商统一管理，可大幅减少企业运维成本。</p><h2 id="集成应用导向阶段"><a href="#集成应用导向阶段" class="headerlink" title="集成应用导向阶段"></a>集成应用导向阶段</h2><p>工业云发展的第二阶段是集成应用导向阶段，这一阶段主要是在研发设计类工具上云的基础上，推动<strong>核心业务系统上云，以及实现内部系统集成</strong>。<br>企业对两化融合的投入和企业从两化融合中获得的收益并不是线性关系，<strong>企业两化融合水平只有达到集成阶段之后，企业的收益才会呈现指数化增长</strong>。<br><img src="https://user-images.githubusercontent.com/6218739/78895077-c794df80-7aa0-11ea-8f38-2ce55ef4b0f2.png" alt="8-1"><br>实现集成有两种途径，其一是渐进的路径，即不改变现有的技术架构，不断地通过各类数据总线和接口实现不同业务系统之间的互联互通；其二则是工业云这一激进路径，即企业将业务系统迁移到云端，从而解决系统内部的互联互通问题。因此，集成应用导向阶段工业云平台的典型特征是通过核心业务系统上云，打通信息孤岛，促进制造资源、数据等集成共享，提升企业效益。</p><h2 id="能力交易导向阶段"><a href="#能力交易导向阶段" class="headerlink" title="能力交易导向阶段"></a>能力交易导向阶段</h2><p>工业云发展的第三阶段是能力交易导向阶段。这一阶段在企业研发设计类工具、核心业务系统上云之后，<strong>底层的设备和产品开始上云，工业云平台开始演进为工业互联网平台</strong>。<br>硬件设备上云+核心业务系统上云+研发工具上云，推动互联网在经历信息交流（搜狐、新浪）与产品交易（京东、阿里）之后，正在进入能力交易的新阶段，未来在互联网上不再仅仅是手机、衣服等产品的交易，还将出现研发设计能力、测试试验能力、生产制造能力、物流能力等生产能力的交易。</p><h2 id="创新引领导向阶段"><a href="#创新引领导向阶段" class="headerlink" title="创新引领导向阶段"></a>创新引领导向阶段</h2><p>第四阶段是创新引领导向阶段。这一阶段在企业研发设计类工具、核心业务系统、底层的设备和产品开始上云之后，制造业架构体系发生了革命性变革。创新引领主要体现在三个方面，一是“云计算+边缘计算”成为计算能力新组合；二是微服务架构成为知识经验封装的新模式；三是工业App成为新型软件形式。</p><h2 id="生态构建导向阶段"><a href="#生态构建导向阶段" class="headerlink" title="生态构建导向阶段"></a>生态构建导向阶段</h2><p>第五阶段是生态建设导向阶段。在这一阶段，随着海量第三方开发者与通用工业App的出现，工业互联网平台将进入一个以生态构建为导向的新阶段。当前全球领军企业都在围绕“智能机器+云平台+工业App”的功能架构，培育海量第三方开发者开发工业App，构建基于平台的制造业生态，不断巩固和强化制造业竞争优势。<br><img src="https://user-images.githubusercontent.com/6218739/78896937-f52f5800-7aa3-11ea-85af-2534fe594446.png" alt="8-2"></p>]]></content>
    
    
    <summary type="html">以下是对安筱鹏博士的《重构：数字化转型的逻辑》一书的笔记摘抄。
逐字摘抄能够加深自己的理解，防止“水过地皮湿”，强烈推荐这种读书方法。

不重构，无未来：拥抱数据驱动的智能+新时代
伴随着新一代信息通信技术（以互联网、大数据、人工智能、5G为代表）的持续创新和渗透扩散，新一轮工业革命正在全球范围孕育兴起，制造业正迈向体系重构、动力变革、范式迁移的新阶段，加速向数字化、网络化、智能化方向延伸扩展，万物互联、数据驱动、软件定义、平台支撑、组织重构、智能主导正在构建制造业的新体系，它也成为了全球新一轮产业竞争的制高点。

体系重构
（1）谁来生产（Who）在变：生产主体从生产者向产消者Prosume</summary>
    
    
    
    <category term="IIoT" scheme="http://qixinbo.github.io/categories/IIoT/"/>
    
    
    <category term="IIoT" scheme="http://qixinbo.github.io/tags/IIoT/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析：19 -- Mark模式</title>
    <link href="http://qixinbo.github.io/2020/03/28/ImagePy_19/"/>
    <id>http://qixinbo.github.io/2020/03/28/ImagePy_19/</id>
    <published>2020-03-27T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.384Z</updated>
    
    <content type="html"><![CDATA[<p>%%%%%%%%%%%%%%<br>2021-1-31更新：基于最新的sciwx修改了以前的失效代码。<br>%%%%%%%%%%%%%%</p><p>ImagePy/sciwx有个Mark模式，即在图像上面可以再绘制其他图形，比如矩形、文本、ROI标识等，本质即是利用GDI绘图。<br>本文是对该Mark模式的解析。</p><h1 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h1><p>先给出一个小的demo，主要就是为了看Mark模式的输入输出，方便理解它的运行本质。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciwx.canvas.mark <span class="keyword">import</span> drawmark</span><br><span class="line"><span class="keyword">from</span> sciapp.<span class="built_in">object</span> <span class="keyword">import</span> mark2shp</span><br><span class="line"></span><br><span class="line">mark =  &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;layer&#x27;</span>, <span class="string">&#x27;body&#x27;</span>: [&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;rectangle&#x27;</span>, <span class="string">&#x27;body&#x27;</span>: (<span class="number">50</span>, <span class="number">50</span>, <span class="number">200</span>, <span class="number">200</span>), <span class="string">&#x27;color&#x27;</span>: (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>)&#125;, &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;circle&#x27;</span>, <span class="string">&#x27;body&#x27;</span>: (<span class="number">150</span>, <span class="number">150</span>, <span class="number">5</span>), <span class="string">&#x27;color&#x27;</span>: (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>)&#125;, &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;body&#x27;</span>: (<span class="number">75</span>, <span class="number">75</span>, <span class="string">&#x27;S:30 W:48&#x27;</span>), <span class="string">&#x27;pt&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;color&#x27;</span>: (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>)&#125;]&#125;</span><br><span class="line"></span><br><span class="line">shape = mark2shp(mark)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Example</span>(<span class="params">wx.Frame</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent, obj</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line">        self.obj = obj</span><br><span class="line"></span><br><span class="line">        self.Bind(wx.EVT_PAINT, self.DrawMarks)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">DrawMarks</span>(<span class="params">self, e</span>):</span></span><br><span class="line">        dc = wx.PaintDC(self)</span><br><span class="line">        drawmark(dc, f, self.obj, k=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">ex = Example(<span class="literal">None</span>, shape)</span><br><span class="line">ex.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>一定要使用这种PaintEvent事件来调用画图（或者调用CallLater），否则会看不到所绘制的图形，具体原因见下方链接：<br><a href="http://zetcode.com/wxpython/gdi/">wxPython graphics</a></p><p>效果如图（注意这张是旧图，最新代码生成的图略有不同）：<br><img src="https://user-images.githubusercontent.com/6218739/77822795-eace9f00-7130-11ea-9033-a28077379552.png" alt="mark"></p><p>可以看出，整个程序的逻辑很简单，<br>（1）创建一个mark配置（具体写法后面介绍），传入mark2shp函数对其转换一下<br>（2）创建一个坐标映射函数f，这是为了坐标变换（这里不涉及坐标变换，所以直接原样返回）<br>（3）通过wx.PaintDC创建一个设备上下文dc<br>（4）将dc、f和缩放因子k传入drawmark方法，从而进行绘制</p><p>下面分步具体解析。</p><h1 id="mark配置"><a href="#mark配置" class="headerlink" title="mark配置"></a>mark配置</h1><p>mark写法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mark =  &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;layer&#x27;</span>, <span class="string">&#x27;body&#x27;</span>: [&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;rectangle&#x27;</span>, <span class="string">&#x27;body&#x27;</span>: (<span class="number">50</span>, <span class="number">50</span>, <span class="number">200</span>, <span class="number">200</span>), <span class="string">&#x27;color&#x27;</span>: (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>)&#125;, &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;circle&#x27;</span>, <span class="string">&#x27;body&#x27;</span>: (<span class="number">150</span>, <span class="number">150</span>, <span class="number">5</span>), <span class="string">&#x27;color&#x27;</span>: (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>)&#125;, &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;body&#x27;</span>: (<span class="number">75</span>, <span class="number">75</span>, <span class="string">&#x27;S:30 W:48&#x27;</span>), <span class="string">&#x27;pt&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;color&#x27;</span>: (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>)&#125;]&#125;</span><br></pre></td></tr></table></figure><p>（之所以这样书写，是因为这样写是人类友好的，后面会将这一阅读良好的字典转换成sciapp内部的特有的Shape数据结构。）</p><p>mark的写法是这样的：<br>（1）mark是个字典，里面的重要的键值比如type、body等；<br>（2）第一层的type是layer，表明这是多个图形的结合，那么这一层的body就是所包含的图形的list<br>（3）具体到某个具体所绘制的图形，以上面的配置为例：<br>（3.1）矩形，其键值对有：type是rectangle，body是四个整型数值，即x、y、w和h，其中x和y是矩形的左上角（这里跟之前旧代码不同，原先的是矩形中心），w和h是高和宽，color是绘制的颜色。<br>（3.2）圆形：其键值对有：type是circle，body是三个整型数值，即x、y和r，即圆形中心和半径。<br>（3.3）文字：其键值对有：type是text，body是两个整型数值和一个文本，即x、y和文本内容，x、y是绘制文本的左上角，pt是指定是否在该左上角绘制一个小圆点。</p><h1 id="坐标映射函数和缩放因子"><a href="#坐标映射函数和缩放因子" class="headerlink" title="坐标映射函数和缩放因子"></a>坐标映射函数和缩放因子</h1><p>这个函数f存在的意义是在imagepy/sciwx的canvas中，其需要将图像坐标系中的坐标转换到面板坐标系中，所以在canvas的源码中可以看到，该函数f就是传入的转换到面板坐标的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drawmark(dc, self.to_panel_coor, self.marks[i], k=self.scale)</span><br></pre></td></tr></table></figure><p>同理，缩放因子也是为了适应canvas画布的缩放而需要传入的。<br>因为这里没有使用到canvas，所以f中没有做任何变换，而k也是为1。</p><h1 id="drawmark函数"><a href="#drawmark函数" class="headerlink" title="drawmark函数"></a>drawmark函数</h1><p>这里看一下该函数的源代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drawmark</span>(<span class="params">dc, f, body, **key</span>):</span></span><br><span class="line">default_style = body.default</span><br><span class="line">pen, brush, font = dc.GetPen(), dc.GetBrush(), dc.GetFont()</span><br><span class="line">pen.SetColour(default_style[<span class="string">&#x27;color&#x27;</span>])</span><br><span class="line">brush.SetColour(default_style[<span class="string">&#x27;fcolor&#x27;</span>])</span><br><span class="line">brush.SetStyle((<span class="number">106</span>,<span class="number">100</span>)[default_style[<span class="string">&#x27;fill&#x27;</span>]])</span><br><span class="line">pen.SetWidth(default_style[<span class="string">&#x27;lw&#x27;</span>])</span><br><span class="line">dc.SetTextForeground(default_style[<span class="string">&#x27;tcolor&#x27;</span>])</span><br><span class="line">font.SetPointSize(default_style[<span class="string">&#x27;size&#x27;</span>])</span><br><span class="line">dc.SetPen(pen); dc.SetBrush(brush); dc.SetFont(font);</span><br><span class="line">draw(body, dc, f, **key)</span><br></pre></td></tr></table></figure><p>该方法就是先获得设备上下文的画笔pen、画刷brush和字体font，然后通过SetColour设置颜色、SetStyle设置风格、SetWidth设置笔宽、SetPointSize设置字体尺寸等对上述工具进行属性设置。然后再调用全局的draw()函数。<br>通过该函数也可以看出来，它接收的body需要具有一定的格式，比如有default属性。因此，最开始的mark变量没法直接传入drawmark中，需要使用mark2shp方法来转换一下。</p><h1 id="mark2shp函数"><a href="#mark2shp函数" class="headerlink" title="mark2shp函数"></a>mark2shp函数</h1><p>仍然看一下该函数的源代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark2shp</span>(<span class="params">mark</span>):</span></span><br><span class="line">    style = mark.copy()</span><br><span class="line">    style.pop(<span class="string">&#x27;body&#x27;</span>)</span><br><span class="line">    keys = &#123;<span class="string">&#x27;point&#x27;</span>:Point, <span class="string">&#x27;points&#x27;</span>:Points, <span class="string">&#x27;line&#x27;</span>:Line, <span class="string">&#x27;lines&#x27;</span>:Lines,</span><br><span class="line">            <span class="string">&#x27;polygon&#x27;</span>:Polygon, <span class="string">&#x27;polygons&#x27;</span>:Polygons, <span class="string">&#x27;circle&#x27;</span>:Circle,</span><br><span class="line">            <span class="string">&#x27;circles&#x27;</span>:Circles, <span class="string">&#x27;rectangle&#x27;</span>:Rectangle, <span class="string">&#x27;rectangles&#x27;</span>:Rectangles,</span><br><span class="line">            <span class="string">&#x27;ellipse&#x27;</span>:Ellipse, <span class="string">&#x27;ellipses&#x27;</span>:Ellipses, <span class="string">&#x27;text&#x27;</span>:Text, <span class="string">&#x27;texts&#x27;</span>:Texts&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mark[<span class="string">&#x27;type&#x27;</span>] <span class="keyword">in</span> keys: <span class="keyword">return</span> keys[mark[<span class="string">&#x27;type&#x27;</span>]](mark[<span class="string">&#x27;body&#x27;</span>], **style)</span><br><span class="line">    <span class="keyword">if</span> mark[<span class="string">&#x27;type&#x27;</span>]==<span class="string">&#x27;layer&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> Layer([mark2shp(i) <span class="keyword">for</span> i <span class="keyword">in</span> mark[<span class="string">&#x27;body&#x27;</span>]], **style)</span><br><span class="line">    <span class="keyword">if</span> mark[<span class="string">&#x27;type&#x27;</span>]==<span class="string">&#x27;layers&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> Layers(<span class="built_in">dict</span>(<span class="built_in">zip</span>(mark[<span class="string">&#x27;body&#x27;</span>].keys(),</span><br><span class="line">            [mark2shp(i) <span class="keyword">for</span> i <span class="keyword">in</span> mark[<span class="string">&#x27;body&#x27;</span>].values()])), **style)</span><br></pre></td></tr></table></figure><p>这里就引出了sciapp中的自定义的矢量类Shape这一数据结构。<br>Shape类是这类对象的基类，上述代码中的Point、Line、Rectangle类等都是该类的派生类。<br>Shape类会在下一篇文章中详细解释，见<a href="https://qixinbo.info/2020/06/14/imagepy_20/">这里</a>。<br>总之，该函数就是将mark字典转换成了sciapp内置的Shape数据结构。</p><h1 id="全局draw-函数"><a href="#全局draw-函数" class="headerlink" title="全局draw()函数"></a>全局draw()函数</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">draw_dic = &#123;<span class="string">&#x27;points&#x27;</span>:plot, <span class="string">&#x27;point&#x27;</span>:plot, <span class="string">&#x27;line&#x27;</span>:plot,</span><br><span class="line"><span class="string">&#x27;polygon&#x27;</span>:plot, <span class="string">&#x27;lines&#x27;</span>:plot, <span class="string">&#x27;polygons&#x27;</span>:plot,</span><br><span class="line"><span class="string">&#x27;circle&#x27;</span>:draw_circle, <span class="string">&#x27;circles&#x27;</span>:draw_circle,</span><br><span class="line"><span class="string">&#x27;ellipse&#x27;</span>:draw_ellipse, <span class="string">&#x27;ellipses&#x27;</span>:draw_ellipse,</span><br><span class="line"><span class="string">&#x27;rectangle&#x27;</span>:draw_rectangle, <span class="string">&#x27;rectangles&#x27;</span>:draw_rectangle,</span><br><span class="line"><span class="string">&#x27;text&#x27;</span>:draw_text, <span class="string">&#x27;texts&#x27;</span>:draw_text&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">obj, dc, f, **key</span>):</span> </span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(obj.body)==<span class="number">0</span>: <span class="keyword">return</span></span><br><span class="line">draw_dic[obj.dtype](obj, dc, f, **key)</span><br><span class="line"></span><br><span class="line">draw_dic[<span class="string">&#x27;layer&#x27;</span>] = draw_layer</span><br></pre></td></tr></table></figure><p>可以看出，draw()函数中先从传入的obj中提取它的dtype这个key，从而找到obj中对应的key-value，然后这个value作为draw_dic字典中的键，找到所绘制的类型，从而定位到具体的绘制函数。</p><p>对于layer这个type，可以把layer认为是多个图形的集合，会调用draw_layer这个函数，该函数里也会遍历该集合里的所有图形来再调用draw绘制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_layer</span>(<span class="params">pts, dc, f, **key</span>):</span></span><br><span class="line">         …</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> pts[<span class="string">&#x27;body&#x27;</span>]:draw(i, dc, f, **key)</span><br></pre></td></tr></table></figure><p>以绘制矩形为例，会调用draw_rectangle函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_rectangle</span>(<span class="params">pts, dc, f, **key</span>):</span></span><br><span class="line">pen, brush = dc.GetPen(), dc.GetBrush()</span><br><span class="line">width, color = pen.GetWidth(), pen.GetColour()</span><br><span class="line">fcolor, style = brush.GetColour(), brush.GetStyle()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> pts.color <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">pen.SetColour(pts.color)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> pts.fcolor <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">brush.SetColour(pts.fcolor)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> pts.lw <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">pen.SetWidth(pts.lw)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> pts.fill <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">brush.SetStyle((<span class="number">106</span>,<span class="number">100</span>)[pts.fill])</span><br><span class="line"></span><br><span class="line">dc.SetPen(pen)</span><br><span class="line">dc.SetBrush(brush)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> pts.dtype == <span class="string">&#x27;rectangle&#x27;</span>:</span><br><span class="line">x, y, w, h = pts.body</span><br><span class="line">w, h = f(x+w, y+h)</span><br><span class="line">x, y = f(x, y)</span><br><span class="line">dc.DrawRectangle(x.<span class="built_in">round</span>(), (y).<span class="built_in">round</span>(), </span><br><span class="line">(w-x).<span class="built_in">round</span>(), (h-y).<span class="built_in">round</span>())</span><br><span class="line"><span class="keyword">if</span> pts.dtype == <span class="string">&#x27;rectangles&#x27;</span>:</span><br><span class="line">x, y, w, h = pts.body.T</span><br><span class="line">w, h = f(x+w, y+h)</span><br><span class="line">x, y = f(x, y)</span><br><span class="line">lst = np.vstack((x,y,w-x,h-y)).T</span><br><span class="line">dc.DrawRectangleList(lst.<span class="built_in">round</span>())</span><br><span class="line"></span><br><span class="line">pen.SetWidth(width)</span><br><span class="line">pen.SetColour(color)</span><br><span class="line">brush.SetColour(fcolor)</span><br><span class="line">brush.SetStyle(style)</span><br><span class="line">dc.SetPen(pen)</span><br><span class="line">dc.SetBrush(brush)</span><br></pre></td></tr></table></figure><p>可以看出，在绘制矩形时最基本的步骤就是：<br>（1）将之前的设备上下文传入；<br>（2）提取特定的Rectangle这一Shape数据结构中的body信息，即绘制矩形的坐标点；<br>（3）调用最底层的设备上下文的DrawRectangle方法将其绘制出来。</p><h1 id="保存mark"><a href="#保存mark" class="headerlink" title="保存mark"></a>保存mark</h1><p>上面的mark都是在最原始的wxPython的frame上进行绘制，是为了展示mark的本质，实际应用时这些mark都是在Canvas上进行绘制。<br>（以下内容已合并在ImagePy的master分支中）<br>如果想在ImagePy中保存mark，可以参考我提交的一个pull request，在<a href="https://github.com/Image-Py/imagepy/pull/96/commits/770342625d320659d2c5c406b1a78a809be086b0">这里</a>。<br>原理就是将当前的dc中的内容都save出来。</p>]]></content>
    
    
    <summary type="html">%%%%%%%%%%%%%%
2021-1-31更新：基于最新的sciwx修改了以前的失效代码。
%%%%%%%%%%%%%%

ImagePy/sciwx有个Mark模式，即在图像上面可以再绘制其他图形，比如矩形、文本、ROI标识等，本质即是利用GDI绘图。
本文是对该Mark模式的解析。

demo
先给出一个小的demo，主要就是为了看Mark模式的输入输出，方便理解它的运行本质。

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25


from sciwx.canvas.mark import drawm</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析：18 -- 参数对话框ParaDialog详解</title>
    <link href="http://qixinbo.github.io/2020/03/24/ImagePy_18/"/>
    <id>http://qixinbo.github.io/2020/03/24/ImagePy_18/</id>
    <published>2020-03-23T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.369Z</updated>
    
    <content type="html"><![CDATA[<p>本文对sciwx的独立组件——参数对话框ParaDialog进行解析。</p><h1 id="demo全景"><a href="#demo全景" class="headerlink" title="demo全景"></a>demo全景</h1><p>首先还是直接给出sciwx库中可运行的demo：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciwx.widgets <span class="keyword">import</span> ParaDialog</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    para = &#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;yxdragon&#x27;</span>, <span class="string">&#x27;age&#x27;</span>:<span class="number">10</span>, <span class="string">&#x27;h&#x27;</span>:<span class="number">1.72</span>, <span class="string">&#x27;w&#x27;</span>:<span class="number">70</span>, <span class="string">&#x27;sport&#x27;</span>:<span class="literal">True</span>, <span class="string">&#x27;sys&#x27;</span>:<span class="string">&#x27;Mac&#x27;</span>, <span class="string">&#x27;lan&#x27;</span>:[<span class="string">&#x27;C/C++&#x27;</span>, <span class="string">&#x27;Python&#x27;</span>], <span class="string">&#x27;c&#x27;</span>:(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27; &#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">    view = [(<span class="string">&#x27;lab&#x27;</span>, <span class="string">&#x27;lab&#x27;</span>, <span class="string">&#x27;This is a questionnaire&#x27;</span>),</span><br><span class="line">            (<span class="built_in">str</span>, <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;please&#x27;</span>),</span><br><span class="line">            (<span class="built_in">int</span>, <span class="string">&#x27;age&#x27;</span>, (<span class="number">0</span>,<span class="number">150</span>), <span class="number">0</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;years old&#x27;</span>),</span><br><span class="line">            (<span class="built_in">float</span>, <span class="string">&#x27;h&#x27;</span>, (<span class="number">0.3</span>, <span class="number">2.5</span>), <span class="number">2</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;m&#x27;</span>),</span><br><span class="line">            (<span class="string">&#x27;slide&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, (<span class="number">1</span>, <span class="number">150</span>), <span class="number">0</span>, <span class="string">&#x27;weight&#x27;</span>,<span class="string">&#x27;kg&#x27;</span>),</span><br><span class="line">            (<span class="built_in">bool</span>, <span class="string">&#x27;sport&#x27;</span>, <span class="string">&#x27;do you like sport&#x27;</span>),</span><br><span class="line">            (<span class="built_in">list</span>, <span class="string">&#x27;sys&#x27;</span>, [<span class="string">&#x27;Windows&#x27;</span>,<span class="string">&#x27;Mac&#x27;</span>,<span class="string">&#x27;Linux&#x27;</span>], <span class="built_in">str</span>, <span class="string">&#x27;favourite&#x27;</span>, <span class="string">&#x27;system&#x27;</span>),</span><br><span class="line">            (<span class="string">&#x27;chos&#x27;</span>, <span class="string">&#x27;lan&#x27;</span>, [<span class="string">&#x27;C/C++&#x27;</span>,<span class="string">&#x27;Java&#x27;</span>,<span class="string">&#x27;Python&#x27;</span>], <span class="string">&#x27;lanuage you like(multi)&#x27;</span>),</span><br><span class="line">            (<span class="string">&#x27;color&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;which&#x27;</span>, <span class="string">&#x27;you like&#x27;</span>),</span><br><span class="line">            (<span class="string">&#x27;path&#x27;</span>, <span class="string">&#x27;path&#x27;</span>, <span class="string">&#x27;Select the image&#x27;</span>, [<span class="string">&#x27;jpg&#x27;</span>, <span class="string">&#x27;jpeg&#x27;</span>, <span class="string">&#x27;png&#x27;</span>])]</span><br><span class="line"></span><br><span class="line">    app = wx.App()</span><br><span class="line">    pd = ParaDialog(<span class="literal">None</span>, <span class="string">&#x27;Test&#x27;</span>)</span><br><span class="line">    pd.init_view(view, para, preview=<span class="literal">True</span>, modal=<span class="literal">False</span>)</span><br><span class="line">    pd.pack()</span><br><span class="line">    pd.ShowModal()</span><br><span class="line">    <span class="built_in">print</span>(para)</span><br><span class="line">    app.MainLoop()</span><br></pre></td></tr></table></figure><p>运行结果如图：<br><img src="https://user-images.githubusercontent.com/6218739/77433470-5efc0080-6e1a-11ea-85e1-83e3d54cad10.png" alt="paradiglog"></p><p>可以看出，该对话框中包含了输入框（包含文本输入、数值输入）、滑动条（集成了微调器）、单选框、复选框、下拉列表等效果，完全满足日常人机交互的需求。</p><p>下面再分步细看具体设置。</p><h1 id="参数字典para"><a href="#参数字典para" class="headerlink" title="参数字典para"></a>参数字典para</h1><p>变量para是一个参数字典，用来设置该对话框所提供的想要用户进行交互调节的参数。<br>该字典中的key都是字符串，而value则视参数类型的不同，要设置好默认值，比如数值输入框的默认值是数值，颜色输入框的默认值是(255, 0, 0)这样的RGB元组等。</p><h1 id="视图列表view"><a href="#视图列表view" class="headerlink" title="视图列表view"></a>视图列表view</h1><p>变量view是一个列表，用来控制所形成的对话框的图形界面。<br>可以看出，view列表中又有若干元组，这些元组就是对话框中的各个组件。还有一点非常重要的是，注意到，不同组件所需的参数量不同，因此编写view时需要将这些参数搞明白。<br>编写view时，要将元组中的参数分成三类进行考虑（下文会对原因有详细说明），第一类是该元组的第一个元素，第二类是元组的第二个元素，第三类是后面所有元素。<br>第一个元素就是ImagePy/sciwx的内部组件类型，第二个元素就是para中的各个键值key（lab类型除外），第三个元素就是该组件需要的参数。因为第二个元素是para变量所定义的，所以下面只对其他元素进行说明：<br>（1）标签：内部类型’lab’，参数为title，view中写法为：(‘lab’, ‘lab’, title)<br>（2）文本输入框：内部类型str，参数为(title, unit)，即名称（或称前缀）和单位（或称后缀）， view写法为：(str, key, title, unit)<br>（3）数值输入框：内部类型int或float，即使用int或float皆可，这里只是语义上的差别，两者实际调用的是同一个组件，使用int时后面的精度设为0，使用float时精度设为大于0的整数，即保留多少位小数；参数为(rang, accury, title, unit)，即范围、精度、名称和单位，view写法为：(int, key, (lim1, lim2), accu, title, unit)<br>（4）滑动条（集成了微调器）：内部类型’slide’（注意别忘了单引号），参数为(rang, accury, title, unit=’’)，即范围、精度、名称和单位（单位有默认参数，可以不显式指定），view写法为(‘slide’, key, rang, accury, title, unit)<br>（5）单选框：内部类型bool，参数为title，view写法为(bool, key, title)<br>（6）下拉列表：内部类型list，参数为(choices, type, title, unit)，choices为字符选项，type为期望输出类型，比如str或int，view写法为(list, key, [choices], type, title, unit)<br>（7）复选框：内部类型’chos’，参数为(choices, title)，choices为字符选项，与上面的list不同的是，其支持多选，view写法为(‘chos’, key, [choices], title)<br>（8）颜色框：内部类型’color’，参数为(title, unit)，即前缀和后缀，view写法为：(‘color’, key, title, unit)<br>（9）路径选择框：内部类型’path’，参数为(title, filter)，filter是所指定的文件扩展名，view写法为：(‘path’, key, title, filter)</p><h1 id="初始化类"><a href="#初始化类" class="headerlink" title="初始化类"></a>初始化类</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd = ParaDialog(<span class="literal">None</span>, <span class="string">&#x27;Test&#x27;</span>)</span><br></pre></td></tr></table></figure><p>这一步是初始化ParaDialog类。<br>该类派生自wx.Dialog类，从该类的初始化函数可以看出，其需要传入parent和title两个参数，所以该对话框的标题就是Test。</p><h1 id="初始化视图"><a href="#初始化视图" class="headerlink" title="初始化视图"></a>初始化视图</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.init_view(view, para, preview=<span class="literal">True</span>, modal=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>这一步是调用了ParaDialog类的init_view函数，传入的就是上面的view和para，preview是指定是否显示preview单选框，如果勾选了该框，那么当参数发生变化时就会在后台打印参数值（因为这里的self.handle=print），。<br>该步是关键一步，在后台做了很多事情，如果想理清ParaDialog的生成机理，需要深入研究一下。<br>先看一下该函数的全貌：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_view</span>(<span class="params">self, items, para, preview=<span class="literal">False</span>, modal = <span class="literal">True</span></span>):</span></span><br><span class="line">    self.para = para</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        self.add_ctrl_(widgets[item[<span class="number">0</span>]], item[<span class="number">1</span>], item[<span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> preview:self.add_ctrl_(Check, <span class="string">&#x27;preview&#x27;</span>, (<span class="string">&#x27;preview&#x27;</span>,))</span><br><span class="line">    self.reset(para)</span><br><span class="line">    self.add_confirm(modal)</span><br><span class="line">    self.pack()</span><br><span class="line">    self.Bind(wx.EVT_WINDOW_DESTROY, self.OnDestroy)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;bind close&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="参数字典传递"><a href="#参数字典传递" class="headerlink" title="参数字典传递"></a>参数字典传递</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.para = para</span><br></pre></td></tr></table></figure><p>这一步是将外部传过来的para赋值给内部属性self.para。</p><h2 id="添加组件"><a href="#添加组件" class="headerlink" title="添加组件"></a>添加组件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">    self.add_ctrl_(widgets[item[<span class="number">0</span>]], item[<span class="number">1</span>], item[<span class="number">2</span>:])</span><br></pre></td></tr></table></figure><p>这一步是将view视图中的组件添加进来。<br>因为view是个列表，所以这里先用循环逐个提取。然后在添加时将item拆分成了三部分，将其第0个元素、第1个元素、(第2个元素及后面所有元素)分别传入不同的位置，下面具体看为什么这么做。</p><h3 id="view的第0个元素"><a href="#view的第0个元素" class="headerlink" title="view的第0个元素"></a>view的第0个元素</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">widgets[item[<span class="number">0</span>]]</span><br></pre></td></tr></table></figure><p>这个元素是传入了widgets，而widgets也是一个字典：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">widgets = &#123; <span class="string">&#x27;ctrl&#x27;</span>:<span class="literal">None</span>, <span class="string">&#x27;slide&#x27;</span>:FloatSlider, <span class="built_in">int</span>:NumCtrl, <span class="string">&#x27;path&#x27;</span>:PathCtrl,</span><br><span class="line">            <span class="built_in">float</span>:NumCtrl, <span class="string">&#x27;lab&#x27;</span>:Label, <span class="built_in">bool</span>:Check, <span class="built_in">str</span>:TextCtrl, <span class="built_in">list</span>:Choice,</span><br><span class="line">            <span class="string">&#x27;color&#x27;</span>:ColorCtrl, <span class="string">&#x27;any&#x27;</span>:AnyType, <span class="string">&#x27;chos&#x27;</span>:Choices, <span class="string">&#x27;hist&#x27;</span>:HistPanel&#125;</span><br></pre></td></tr></table></figure><p>可以看出，view的第0个元素是作为widgets的key，这样就能对应提取widgets中的value。而这些value就是sciwx独有的基于wxPython各种组件二次开发的组件。以NumCtrl为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NumCtrl</span>(<span class="params">wx.Panel</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;NumCtrl: diverid from wx.core.TextCtrl &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent, rang, accury, title, unit</span>):</span></span><br><span class="line">        wx.Panel.__init__(self, parent)</span><br><span class="line">        sizer = wx.BoxSizer( wx.HORIZONTAL )</span><br><span class="line">        self.prefix = lab_title = wx.StaticText( self, wx.ID_ANY, title,</span><br><span class="line">                                  wx.DefaultPosition, wx.DefaultSize)</span><br><span class="line"></span><br><span class="line">        lab_title.Wrap( -<span class="number">1</span> )</span><br><span class="line">        sizer.Add( lab_title, <span class="number">0</span>, wx.ALIGN_CENTER|wx.ALL, <span class="number">5</span> )</span><br><span class="line">        self.ctrl = wx.TextCtrl(self, wx.TE_RIGHT)</span><br><span class="line">        self.ctrl.Bind(wx.EVT_KEY_UP, <span class="keyword">lambda</span> x : self.para_changed(key))</span><br><span class="line">        sizer.Add( self.ctrl, <span class="number">2</span>, wx.ALL, <span class="number">5</span> )</span><br><span class="line"></span><br><span class="line">        self.postfix = lab_unit = wx.StaticText( self, wx.ID_ANY, unit,</span><br><span class="line">                                  wx.DefaultPosition, wx.DefaultSize)</span><br><span class="line"></span><br><span class="line">        lab_unit.Wrap( -<span class="number">1</span> )</span><br><span class="line">        sizer.Add( lab_unit, <span class="number">0</span>, wx.ALIGN_CENTER|wx.ALL, <span class="number">5</span> )</span><br><span class="line">        self.SetSizer(sizer)</span><br><span class="line"></span><br><span class="line">        self.<span class="built_in">min</span>, self.<span class="built_in">max</span> = rang</span><br><span class="line">        self.accury = accury</span><br><span class="line">        self.ctrl.Bind(wx.EVT_KEY_UP, self.ontext)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Bind</span>(<span class="params">self, z, f</span>):</span>self.f = f</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">ontext</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        self.f(self)</span><br><span class="line">        <span class="keyword">if</span> self.GetValue()==<span class="literal">None</span>:</span><br><span class="line">            self.ctrl.SetBackgroundColour((<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.ctrl.SetBackgroundColour((<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>))</span><br><span class="line">        self.Refresh()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">SetValue</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        self.ctrl.SetValue(<span class="built_in">str</span>(<span class="built_in">round</span>(n,self.accury) <span class="keyword">if</span> self.accury&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="built_in">int</span>(n)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GetValue</span>(<span class="params">self</span>):</span></span><br><span class="line">        sval = self.ctrl.GetValue()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            num = <span class="built_in">float</span>(sval) <span class="keyword">if</span> self.accury&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="built_in">int</span>(sval)</span><br><span class="line">        <span class="keyword">except</span> ValueError:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> num&lt;self.<span class="built_in">min</span> <span class="keyword">or</span> num&gt;self.<span class="built_in">max</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(<span class="built_in">round</span>(num, self.accury) - num) &gt; <span class="number">1E-5</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> num</span><br></pre></td></tr></table></figure><p>可以看出NumCtrl就是由两个wx.StaticText静态文本框和一个wx.TextCtrl输入框组合而成，表现出来就是一个前缀说明和一个后缀说明及中间的输入框。<br>同时可以可以看出NumCtrl有数值检查这一功能，当超出所设定的范围后，就会报警。</p><h3 id="view的第1个元素"><a href="#view的第1个元素" class="headerlink" title="view的第1个元素"></a>view的第1个元素</h3><p>view的第1个元素就是para中的各个key值</p><h3 id="view的第2个及后面所有元素"><a href="#view的第2个及后面所有元素" class="headerlink" title="view的第2个及后面所有元素"></a>view的第2个及后面所有元素</h3><p>因为不同组件需要的参数量不同，因为这里将第2个及后面所有元素统一打包然后传入。</p><h3 id="添加组件-1"><a href="#添加组件-1" class="headerlink" title="添加组件"></a>添加组件</h3><p>以上三组元素都传入了下面方法，分别作为它的Ctrl、key和p参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_ctrl_</span>(<span class="params">self, Ctrl, key, p</span>):</span></span><br><span class="line">    ctrl = Ctrl(self, *p)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> p[<span class="number">0</span>] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        self.ctrl_dic[key] = ctrl</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(ctrl, <span class="string">&#x27;Bind&#x27;</span>):</span><br><span class="line">        ctrl.Bind(<span class="literal">None</span>, self.para_changed)</span><br><span class="line">    pre = ctrl.prefix <span class="keyword">if</span> <span class="built_in">hasattr</span>(ctrl, <span class="string">&#x27;prefix&#x27;</span>) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    post = ctrl.postfix <span class="keyword">if</span> <span class="built_in">hasattr</span>(ctrl, <span class="string">&#x27;postfix&#x27;</span>) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    self.tus.append((pre, post))</span><br><span class="line">    self.lst.Add( ctrl, <span class="number">0</span>, wx.EXPAND, <span class="number">0</span> )</span><br></pre></td></tr></table></figure><p>这里面挺有创意的一点是通过判断组件类里是否有某个特定的属性来进行下一步操作，比如判断是否有Bind属性，若有则Bind对话框的para_changed方法，还有prefix、postfix属性等，具体参见代码。</p><h1 id="显示"><a href="#显示" class="headerlink" title="显示"></a>显示</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.ShowModal()</span><br></pre></td></tr></table></figure><p>通过调用父类wx.Dialog的ShowModal()方法来将对话框显示出来。</p><h1 id="隐式输出"><a href="#隐式输出" class="headerlink" title="隐式输出"></a>隐式输出</h1><p>该对话框提供了图形界面供用户来调节para变量中的参数，当调节完成后，隐含地就对para变量中的key值所对应的value进行了调节。原理就是在para_changed方法中的GetValue()，即调用各个组件的GetValue()来获取输入值。</p>]]></content>
    
    
    <summary type="html">本文对sciwx的独立组件——参数对话框ParaDialog进行解析。

demo全景
首先还是直接给出sciwx库中可运行的demo：

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23


from sciwx.widgets import ParaDialog

if __name__ == &#39;__main__&#39;:
    para = {&#39;name&#39;:&#39;yxdragon&#39;, &#39;age&#39;:10, &#39;h&#39;:1.72, &#39;w&#39;:70, &#39;sport&#39;:True, &#39;sys&#39;:&#39;Mac&#39;, &#39;lan&#39;:[&#39;C/C++&#39;, &#39;</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>《动手学深度学习》PyTorch版学习笔记</title>
    <link href="http://qixinbo.github.io/2020/03/08/dive-into-dl/"/>
    <id>http://qixinbo.github.io/2020/03/08/dive-into-dl/</id>
    <published>2020-03-07T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.601Z</updated>
    
    <content type="html"><![CDATA[<p>Attention预警！：<br>时刻铭记“Garbage in, garbage out!”，因此，涉及到data时，一定注意实际查看，确保计算时Input和Output的一致性和准确性。</p><p>原书MXNet版在<a href="https://github.com/d2l-ai/d2l-zh">这里</a>。<br>PyTorch版在<a href="https://github.com/ShusenTang/Dive-into-DL-PyTorch">这里</a>。</p><h1 id="深度学习简介"><a href="#深度学习简介" class="headerlink" title="深度学习简介"></a>深度学习简介</h1><p>目前的机器学习和深度学习应用共同的核心思想：用数据编程。<br>通俗来说，机器学习是一门讨论各式各样的适用于不同问题的函数形式，以及如何使用数据来有效地获取函数参数具体值的学科。<br>深度学习是具有多级表示的表征学习方法（表征学习关注如何自动找出表示数据的合适方式，以便更好地将输入变换为正确的输出）。在每一级（从原始数据开始），深度学习通过简单的函数将该级的表示变换为更高级的表示。因此，深度学习模型也可以看作是由许多简单函数复合而成的函数。当这些复合的函数足够多时，深度学习模型就可以表达非常复杂的变换。值得一提的是，作为表征学习的一种，深度学习将自动找出每一级表示数据的合适方式。<br>（1）深度学习的一个外在特点是端到端的训练。也就是说，并不是将单独调试的部分拼凑起来组成一个系统，而是将整个系统组建好之后一起训练。比如说，计算机视觉科学家之前曾一度将特征抽取与机器学习模型的构建分开处理，像是Canny边缘探测和SIFT特征提取曾占据统治性地位达10年以上，但这也就是人类能找到的最好方法了。当深度学习进入这个领域后，这些特征提取方法就被性能更强的自动优化的逐级过滤器替代了。<br>（2）除端到端的训练以外，我们也正在经历从含参数统计模型转向完全无参数的模型。当数据非常稀缺时，我们需要通过简化对现实的假设来得到实用的模型。当数据充足时，我们就可以用能更好地拟合现实的无参数模型来替代这些含参数模型。这也使我们可以得到更精确的模型，尽管需要牺牲一些可解释性。</p><h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><h2 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h2><p>在PyTorch中，torch.Tensor是存储和变换数据的主要工具。Tensor和NumPy的多维数组非常类似。然而，Tensor提供GPU计算和自动求梯度等更多功能，这些使Tensor更加适合深度学习。</p><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>) <span class="comment"># 创建一个5x3的未初始化的Tensor</span></span><br><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>) <span class="comment"># 创建一个5x3的随机初始化的Tensor</span></span><br><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long) <span class="comment"># 创建一个5x3的long型全0的Tensor</span></span><br><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>]) <span class="comment"># 接根据数据创建</span></span><br><span class="line">x = x.new_ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.float64) <span class="comment"># 可以通过现有的Tensor来创建，此方法会默认重用输入Tensor的一些属性，例如torch.dtype和torch.device</span></span><br><span class="line">x = torch.randn_like(x, dtype=torch.<span class="built_in">float</span>) <span class="comment"># 除非自定义数据类型</span></span><br><span class="line"><span class="built_in">print</span>(x.shape) <span class="comment"># 可以通过shape或者size()来获取Tensor的形状</span></span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># 注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。</span></span><br></pre></td></tr></table></figure><p>还有很多函数可以创建Tensor，如eye、arange、linspace，这些创建方法都可以在创建的时候指定数据类型dtype和存放device(cpu/gpu)。</p><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><p>（1）算术操作，以加法为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x + y) <span class="comment"># 加法形式一</span></span><br><span class="line"><span class="built_in">print</span>(torch.add(x, y)) <span class="comment"># 加法形式二</span></span><br><span class="line">result = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">torch.add(x, y, out=result) <span class="comment"># 可以指定输出</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line">y.add_(x) <span class="comment"># 加法形式三 inplace，PyTorch操作inplace版本都有后缀_</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><p>（2）索引<br>可以使用类似NumPy的索引操作来访问Tensor的一部分，需要注意的是：索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = x[<span class="number">0</span>, :]</span><br><span class="line">y += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">0</span>, :])</span><br></pre></td></tr></table></figure><p>PyTorch还提供了一些高级的选择函数，如index_select、masked_select等。<br>（3）改变形状<br>用view()来改变Tensor的形状：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = x.view(<span class="number">15</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>, <span class="number">5</span>) <span class="comment"># -1所指的维度可以根据其他维度的值推出来</span></span><br><span class="line"><span class="built_in">print</span>(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure><p>注意view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变)<br>另外注意：虽然view返回的Tensor与源Tensor是共享data的，但是依然是一个新的Tensor（因为Tensor除了包含data外还有一些其他属性），二者id（内存地址）并不一致。<br>所以如果我们想返回一个真正新的副本（即不共享data内存）该怎么办呢？Pytorch还提供了一个reshape()可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。推荐先用clone创造一个副本然后再使用view。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_cp = x.clone().view(<span class="number">15</span>)</span><br><span class="line">x -= <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x_cp)</span><br></pre></td></tr></table></figure><p>使用clone还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源Tensor。<br>另外一个常用的函数就是item(), 它可以将一个标量Tensor转换成一个Python number：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.item())</span><br></pre></td></tr></table></figure><p>PyTorch中的Tensor支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等，具体可参考官方API。</p><h3 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h3><p>当对两个形状不同的Tensor按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个Tensor形状相同后再按元素运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">1</span>, <span class="number">3</span>).view(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">y = torch.arange(<span class="number">1</span>, <span class="number">4</span>).view(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br></pre></td></tr></table></figure><p>这部分的广播机制可以参照numpy的广播来理解。</p><h3 id="运算的内存开销"><a href="#运算的内存开销" class="headerlink" title="运算的内存开销"></a>运算的内存开销</h3><p>前面说了，索引操作是不会开辟新内存的，而像y = x + y这样的运算是会新开内存的，然后将y指向新内存。可以使用Python自带的id函数来验证：如果两个实例的ID一致，那么它们所对应的内存地址相同；反之则不同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">y = torch.tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">id_before = <span class="built_in">id</span>(y)</span><br><span class="line">y = x + y</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(y) == id_before)</span><br></pre></td></tr></table></figure><p>如果想指定结果到原来的y的内存，可以使用前面介绍的索引来进行替换操作，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">y = torch.tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">id_before = <span class="built_in">id</span>(y)</span><br><span class="line">y[:] = x + y</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(y) == id_before)</span><br></pre></td></tr></table></figure><p>还可以使用运算符全名函数中的out参数或者自加运算符+=(也即add_())达到上述效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">y = torch.tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">id_before = <span class="built_in">id</span>(y)</span><br><span class="line"><span class="comment"># torch.add(x, y, out = y) </span></span><br><span class="line"><span class="comment"># y += x</span></span><br><span class="line">y.add_(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(y) == id_before)</span><br></pre></td></tr></table></figure><h3 id="Tensor和Numpy相互转换"><a href="#Tensor和Numpy相互转换" class="headerlink" title="Tensor和Numpy相互转换"></a>Tensor和Numpy相互转换</h3><p>我们很容易用numpy()和from_numpy()将Tensor和NumPy中的数组相互转换。但是需要注意的一点是： 这两个函数所产生的的Tensor和NumPy中的数组共享相同的内存（所以他们之间的转换很快），改变其中一个时另一个也会改变！！！<br>还有一个常用的将NumPy中的array转换成Tensor的方法就是torch.tensor(), 需要注意的是，此方法总是会进行数据拷贝（就会消耗更多的时间和空间），所以返回的Tensor和原来的数据不再共享内存。<br>（1）Tensor转Numpy</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">b = a.numpy()</span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br><span class="line">a += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br><span class="line">b += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br></pre></td></tr></table></figure><p>（2）Numpy转Tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.ones(<span class="number">5</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br><span class="line">a += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br><span class="line">b += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(a, b)</span><br></pre></td></tr></table></figure><p>所有在CPU上的Tensor（除了CharTensor）都支持与NumPy数组相互转换。</p><h3 id="Tensor-on-GPU"><a href="#Tensor-on-GPU" class="headerlink" title="Tensor on GPU"></a>Tensor on GPU</h3><p>用方法to()可以将Tensor在CPU和GPU（需要硬件支持）之间相互移动。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    y = torch.ones_like(x, device=device) <span class="comment"># 直接创建一个在GPU上的Tensor</span></span><br><span class="line">    x = x.to(device)  <span class="comment"># 等价于.to(&#x27;cuda&#x27;)</span></span><br><span class="line">    z = x + y</span><br><span class="line">    <span class="built_in">print</span>(z)</span><br><span class="line">    <span class="built_in">print</span>(z.to(<span class="string">&#x27;cpu&#x27;</span>), torch.double)</span><br></pre></td></tr></table></figure><h2 id="自动求梯度"><a href="#自动求梯度" class="headerlink" title="自动求梯度"></a>自动求梯度</h2><p>PyTorch提供的autograd包能够根据输入和前向传播过程自动构建计算图，并执行反向传播。</p><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>Tensor是autograd包的核心类，如果将其属性.requires_grad设置为True，它将开始追踪(track)在其上的所有操作（这样就可以利用链式法则进行梯度传播了）。完成计算后，可以调用.backward()来完成所有梯度计算。此Tensor的梯度将累积到.grad属性中。<br>注意在y.backward()时，如果y是标量，则不需要为backward()传入任何参数；否则，需要传入一个与y同形的Tensor。<br>如果不想要被继续追踪，可以调用.detach()将其从追踪记录中分离出来，这样就可以防止将来的计算被追踪，这样梯度就传不过去了。此外，还可以用with torch.no_grad()将不想被追踪的操作代码块包裹起来，这种方法在评估模型的时候很常用，因为在评估模型时，我们并不需要计算可训练参数（requires_grad=True）的梯度。</p><p>Function是另外一个很重要的类。Tensor和Function互相结合就可以构建一个记录有整个计算过程的有向无环图（DAG）。每个Tensor都有一个.grad_fn属性，该属性即创建该Tensor的Function, 就是说该Tensor是不是通过某些运算得到的，若是，则grad_fn返回一个与这些运算相关的对象，否则是None。</p><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>) <span class="comment"># 创建一个Tensor并设置requires_grad=True</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.grad_fn) <span class="comment"># None, x是直接创建的，所以它没有grad_fn</span></span><br><span class="line">y = x + <span class="number">2</span> </span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(y.grad_fn) <span class="comment"># y是通过一个加法操作创建的，所以它有一个为&lt;AddBackward&gt;的grad_fn</span></span><br><span class="line"><span class="built_in">print</span>(x.is_leaf, y.is_leaf) <span class="comment"># 像x这种直接创建的称为叶子节点，叶子节点对应的grad_fn是None</span></span><br><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"><span class="built_in">print</span>(z, out) <span class="comment"># z的grad_fn是MulBackward，out的grad_fn是MeanBackward</span></span><br><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>) <span class="comment"># 缺失情况下默认 requires_grad = False</span></span><br><span class="line">a = ((a * <span class="number">3</span>) / (a - <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(a.requires_grad)</span><br><span class="line">a.requires_grad_(<span class="literal">True</span>) <span class="comment"># 通过.requires_grad_()来用in-place的方式改变requires_grad属性</span></span><br><span class="line"><span class="built_in">print</span>(a.requires_grad)</span><br><span class="line">b = (a * a).<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(b.grad_fn) <span class="comment"># b的grad_fn是SumBackward</span></span><br></pre></td></tr></table></figure><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">out.backward() <span class="comment"># 因为out是一个标量，所以调用backward()时不需要指定求导变量</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">out2 = x.<span class="built_in">sum</span>()</span><br><span class="line">out2.backward() <span class="comment"># grad在反向传播过程中是累加的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">out3 = x.<span class="built_in">sum</span>()</span><br><span class="line">x.grad.data.zero_() <span class="comment"># 所以一般在反向传播之前需把梯度清零</span></span><br><span class="line">out3.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure><p>首先，有一个向量x，它经过某个运算得到了向量y，那么y对x的导数就是一个Jacobian矩阵，记为J。<br>再者，始终记着，且抛开诸如神经网络等所有的知识点，从计算上来说，torch.autograd就是一个纯粹的计算引擎，它是计算向量与Jacobian矩阵的乘积的一个运算库（Jacobian矩阵是在底层计算的），即vector-Jabobian product计算引擎。这个vector可以是任意向量，记为v，注意是任意的。<br>最后，向量y经过运算又得到了标量l。此时，如果上面的向量v恰好是l对y的导数，那么根据链式法则，autograd所计算的vector-Jacobian product恰好就是标量l对向量x的导数。所以，autograd的效果就是只要知道y=f(x)和l=g(y)或者l对y的导数v，就可以得到l对x的导数。</p><p>那么，具体来说，autograd在反向传播计算梯度时，out.backward()其实是需要一个grad_tensors，就是上面那个向量v，则有两种情形：<br>（1）如果out是标量，该参数就可以为空，此时out就是l。因为通常是最后的损失函数调用backward()，而损失函数又通常是标量，所以此时backward()不需要参数。<br>（2）如果out不是标量，比如上面的y，y.backward(v)，那么就需要指定这个v，而这个v是与y同型的，这是为了让y乘以v是一个标量，这样就保证了始终是标量对张量求导。再说一遍，这个v可以是任意的，但如果恰巧是未知的标量l对y的导数，这样往前计算的梯度就有了意义，比如x中的梯度就是遥远的l对x的梯度。<br>那么，总的计算梯度的方式就是这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x -&gt; y -&gt; z -&gt; m -&gt; n -&gt; l</span><br><span class="line">设l就是一个标量，那么：</span><br><span class="line">l.backward()</span><br><span class="line">就会先计算dl/dn, 然后：</span><br><span class="line">n.backward(dl/dn)</span><br><span class="line">这样，仍然n*dl/dn是一个标量，就是l，那么继续往前传，先得到dl/dm，再传入：</span><br><span class="line">m.backward(dl/dm)</span><br><span class="line">所以，每一次backward()时总是一个标量，而且是l，所以，传到最后，就可以得到：</span><br><span class="line">dl/dx</span><br></pre></td></tr></table></figure><p>如果我们想要修改tensor的数值，但是又不希望被autograd记录（即不会影响反向传播），那么我们可以对tensor.data进行操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(x.data) <span class="comment"># 还是一个Tensor</span></span><br><span class="line"><span class="built_in">print</span>(x.data.requires_grad) <span class="comment"># False，此时x已经独立于计算图以外</span></span><br><span class="line"></span><br><span class="line">y = <span class="number">2</span> * x</span><br><span class="line">x.data *= <span class="number">100</span> <span class="comment"># 只改变了值，不会记录在计算图中，所以不会影响梯度传播</span></span><br><span class="line">y.backward()</span><br><span class="line"><span class="built_in">print</span>(x) <span class="comment"># x的值会发生变化</span></span><br><span class="line"><span class="built_in">print</span>(x.grad) <span class="comment"># 但梯度不变</span></span><br></pre></td></tr></table></figure><h1 id="深度学习基础"><a href="#深度学习基础" class="headerlink" title="深度学习基础"></a>深度学习基础</h1><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>线性回归输出是一个连续值，因此适用于回归问题。<br>与回归问题不同，分类问题中模型的最终输出是一个离散值。softmax回归则适用于分类问题。</p><h2 id="线性回归的从零开始实现"><a href="#线性回归的从零开始实现" class="headerlink" title="线性回归的从零开始实现"></a>线性回归的从零开始实现</h2><p>尽管强大的深度学习框架可以减少大量重复性工作，但若过于依赖它提供的便利，会导致我们很难深入理解深度学习是如何工作的。因此，本节将介绍如何只利用Tensor和autograd来实现一个线性回归的训练。<br>首先，导入本节中实验所需的包或模块，其中的matplotlib包可用于作图，且设置成嵌入显示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br></pre></td></tr></table></figure><h3 id="生成数据集"><a href="#生成数据集" class="headerlink" title="生成数据集"></a>生成数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个简单的人工训练数据集，它可以使我们能够直观比较学到的参数和真实的模型参数的区别</span></span><br><span class="line">num_inputs = <span class="number">2</span> <span class="comment"># 输入特征数为2</span></span><br><span class="line">num_examples = <span class="number">100</span> <span class="comment"># 训练集样本数为100</span></span><br><span class="line">true_w = [<span class="number">2</span>, -<span class="number">3.4</span>] <span class="comment"># 真实的权重</span></span><br><span class="line">true_b = <span class="number">4.2</span> <span class="comment"># 真实的偏差</span></span><br><span class="line"></span><br><span class="line">features = torch.randn(num_examples, num_inputs, dtype=torch.float32) <span class="comment"># 根据训练集个数生成随机的批量样本</span></span><br><span class="line">labels = true_w[<span class="number">0</span>]*features[:, <span class="number">0</span>] + true_w[<span class="number">1</span>]*features[:, <span class="number">1</span>] + true_b <span class="comment"># 真实的标签</span></span><br><span class="line">labels += torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=labels.size()), dtype=torch.float32) <span class="comment"># 在真实标签上加上服从正态分布的噪声项</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(features[<span class="number">0</span>], labels[<span class="number">0</span>]) <span class="comment"># 打印第一个样本的输入特征和标签</span></span><br><span class="line"></span><br><span class="line">plt.scatter(features[:, <span class="number">1</span>].numpy(), labels.numpy(), <span class="number">1</span>) <span class="comment"># 将第二个特征与标签进行作图，看一下它们的线性关系</span></span><br></pre></td></tr></table></figure><h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><p>在训练模型的时候，我们需要遍历数据集并不断读取小批量数据样本。这里我们定义一个函数：它每次返回batch_size（批量大小）个随机样本的特征和标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span></span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples)) <span class="comment"># 生成读取索引</span></span><br><span class="line">    random.shuffle(indices) <span class="comment"># 打乱索引顺序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        j = torch.LongTensor(indices[i:<span class="built_in">min</span>(i+batch_size, num_examples)]) <span class="comment"># 将索引包装成一个Tensor，同时注意最后一次可能不足一个batch，要取实际的大小</span></span><br><span class="line">        <span class="keyword">yield</span> features.index_select(<span class="number">0</span>, j), labels.index_select(<span class="number">0</span>, j) <span class="comment"># yield关键字将data_iter()函数做成了一个迭代器</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">    <span class="built_in">print</span>(X, y)</span><br><span class="line">    <span class="keyword">break</span> <span class="comment"># 读取第一个小批量数据样本并打印。每个批量的特征形状为(10, 2)，分别对应批量大小和输入个数；标签形状为批量大小。</span></span><br></pre></td></tr></table></figure><p>对这里面用的yield用法，可以参看这篇博文辅助理解：<a href="https://blog.csdn.net/mieleizhi0522/article/details/82142856">python中yield的用法详解——最简单，最清晰的解释</a></p><h3 id="初始化模型参数"><a href="#初始化模型参数" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">w = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_inputs, <span class="number">1</span>)), dtype=torch.float32) <span class="comment"># 将权重初始化为均值为0、标准差为0.01的正态随机数</span></span><br><span class="line">b = torch.zeros(<span class="number">1</span>, dtype=torch.float32) <span class="comment"># 将偏差初始化为0</span></span><br><span class="line">w.requires_grad_(requires_grad=<span class="literal">True</span>) <span class="comment"># 模型训练过程中需要对这些参数求梯度来迭代取值，所以需要将requires_grad置为True</span></span><br><span class="line">b.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linreg</span>(<span class="params">X, w, b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.mm(X, w) + b <span class="comment"># 线性回归的矢量计算表达式</span></span><br></pre></td></tr></table></figure><h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_loss</span>(<span class="params">y_hat, y</span>):</span></span><br><span class="line">    <span class="comment"># 注意这里返回的是向量，把y变成了y_hat的样子，注意这个地方与PyTorch中MSELoss不同</span></span><br><span class="line">       <span class="comment"># MSELoss返回的是标量，即将这里的向量再做一个操作，默认是取平均值，也可以取和</span></span><br><span class="line">    <span class="keyword">return</span>(y_hat - y.view(y_hat.size())) ** <span class="number">2</span> / <span class="number">2</span></span><br></pre></td></tr></table></figure><h3 id="定义优化算法"><a href="#定义优化算法" class="headerlink" title="定义优化算法"></a>定义优化算法</h3><p>以下的sgd函数实现了小批量随机梯度下降算法，它通过不断迭代模型参数来优化损失函数。这里自动求梯度模块计算得来的梯度是一个批量样本的梯度和（这是因为上面的损失函数是带小批量的，后面的loss.sum()会将这一批样本上的损失都加和，如果是像PyTorch的MSELoss取平均值的话，这里就不需要除以批量大小），将它除以批量大小来得到平均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">params, lr, batch_size</span>):</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.data -= lr * param.grad / batch_size <span class="comment"># 注意这里更改param用的是param.data</span></span><br></pre></td></tr></table></figure><p>下图的计算公式一目了然：<br><img src="https://user-images.githubusercontent.com/6218739/75660181-4d558c00-5ca6-11ea-95a8-a343ea73ad35.png" alt="image"></p><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>在训练中，我们将多次迭代模型参数。在每次迭代中，我们根据当前读取的小批量数据样本（特征X和标签y），通过调用反向函数backward计算小批量随机梯度，并调用优化算法sgd迭代模型参数。由于我们之前设批量大小batch_size为10，每个小批量的损失l的形状为(10, 1)。由于变量l并不是一个标量，所以我们可以调用.sum()将其求和得到一个标量，再运行l.backward()得到该变量有关模型参数的梯度。注意在每次更新完参数后不要忘了将参数的梯度清零。<br>在一个迭代周期（epoch）中，我们将完整遍历一遍data_iter函数，并对训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。这里的迭代周期个数num_epochs和学习率lr都是超参数，分别设3和0.03。在实践中，大多超参数都需要通过反复试错来不断调节。虽然迭代周期数设得越大模型可能越有效，但是训练时间可能过长。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.03</span> <span class="comment"># 学习率</span></span><br><span class="line">num_epochs = <span class="number">30</span> <span class="comment"># 迭代次数</span></span><br><span class="line">net = linreg <span class="comment"># 线性回归模型</span></span><br><span class="line">loss = squared_loss <span class="comment"># 平方损失</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">        l = loss(net(X, w, b), y).<span class="built_in">sum</span>() <span class="comment"># l是有关小批量X和y的损失</span></span><br><span class="line">        l.backward() <span class="comment"># 小批量的损失对模型参数求梯度</span></span><br><span class="line">        sgd([w, b], lr, batch_size) <span class="comment"># 使用小批量随机梯度下降迭代模型参数</span></span><br><span class="line">        w.grad.data.zero_()</span><br><span class="line">        b.grad.data.zero_()</span><br><span class="line"></span><br><span class="line">    train_l = loss(net(features, w, b), labels) <span class="comment"># 每次迭代后都将模型测试一下</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %f&#x27;</span> % (epoch + <span class="number">1</span>, train_l.mean().item()))</span><br></pre></td></tr></table></figure><p>打印一下最终的参数，它们应该很接近于真实的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(true_w, <span class="string">&#x27;\n&#x27;</span>, w)</span><br><span class="line"><span class="built_in">print</span>(true_b, <span class="string">&#x27;\n&#x27;</span>, b)</span><br></pre></td></tr></table></figure><h2 id="线性回归的简洁实现"><a href="#线性回归的简洁实现" class="headerlink" title="线性回归的简洁实现"></a>线性回归的简洁实现</h2><p>在本节中，将介绍如何使用PyTorch更方便地实现线性回归的训练。</p><h3 id="生成数据集-1"><a href="#生成数据集-1" class="headerlink" title="生成数据集"></a>生成数据集</h3><p>这一步跟上面的相同，不再赘述。</p><h3 id="读取数据-1"><a href="#读取数据-1" class="headerlink" title="读取数据"></a>读取数据</h3><p>PyTorch提供了data包来读取数据。由于data常用作变量名，将导入的data模块用Data代替。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line">batch_size = <span class="number">10</span> <span class="comment"># 一个小批量设为10个</span></span><br><span class="line">dataset = Data.TensorDataset(features, labels) <span class="comment"># 将训练数据的特征和标签组合</span></span><br><span class="line">data_iter = Data.DataLoader(dataset, batch_size, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>这里data_iter的使用跟上一节中的一样。让我们读取并打印第一个小批量数据样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">    <span class="built_in">print</span>(X, y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h3 id="定义模型-1"><a href="#定义模型-1" class="headerlink" title="定义模型"></a>定义模型</h3><p>首先，导入torch.nn模块。实际上，“nn”是neural networks（神经网络）的缩写。顾名思义，该模块定义了大量神经网络的层。之前我们已经用过了autograd，而nn就是利用autograd来定义模型。nn的核心数据结构是Module，它是一个抽象概念，既可以表示神经网络中的某个层（layer），也可以表示一个包含很多层的神经网络。在实际使用中，最常见的做法是继承nn.Module，撰写自己的网络/层。一个nn.Module实例应该包含一些层以及返回输出的前向传播（forward）方法。下面先来看看如何用nn.Module实现一个线性回归模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_feature</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LinearNet, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_feature, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span> <span class="comment"># 定义前向传播</span></span><br><span class="line">        y = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">net = LinearNet(num_inputs)</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure><p>事实上我们还可以用nn.Sequential来更加方便地搭建网络，Sequential是一个有序的容器，网络层将按照在传入Sequential的顺序依次被添加到计算图中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写法一</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Linear(num_inputs, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 还可以再添加层</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 写法二</span></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add_module(<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 写法三</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net = nn.Sequential(OrderedDict([</span><br><span class="line">                                 (<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="number">1</span>))</span><br><span class="line">                                 <span class="comment"># 还可以再添加层</span></span><br><span class="line">]))</span><br><span class="line"><span class="built_in">print</span>(net) <span class="comment"># 注意这个地方的输出与前面自定义net的不同</span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">0</span>]) <span class="comment"># 这里的net是Sequential实例，所以需要加索引</span></span><br></pre></td></tr></table></figure><p>可以通过net.parameters()来查看模型所有的可学习参数，此函数将返回一个生成器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> net.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param) <span class="comment"># 这里面的参数的个数和尺寸是根据网络层的结构及输入输出自动确定的。</span></span><br></pre></td></tr></table></figure><p>注意：torch.nn仅支持输入一个batch的样本不支持单个样本输入，如果只有单个样本，可使用input.unsqueeze(0)来添加一维。</p><h3 id="初始化模型参数-1"><a href="#初始化模型参数-1" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>在使用net前，我们需要初始化模型参数，如线性回归模型中的权重和偏差。PyTorch在init模块中提供了多种参数初始化方法。这里的init是initializer的缩写形式。我们通过init.normal_将权重参数每个元素初始化为随机采样于均值为0、标准差为0.01的正态分布。偏差会初始化为零。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="comment"># net[0]这样根据下标访问子模块的写法只有当net是个ModuleList或者Sequential实例时才可以</span></span><br><span class="line"><span class="comment"># 如果net是像第一种那样自定义的，需要将索引去掉</span></span><br><span class="line"></span><br><span class="line">init.normal_(net[<span class="number">0</span>].weight, mean=<span class="number">0</span>, std=<span class="number">0.1</span>)</span><br><span class="line">init.constant_(net[<span class="number">0</span>].bias, val=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="定义损失函数-1"><a href="#定义损失函数-1" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><p>PyTorch在nn模块中提供了各种损失函数，这些损失函数可看作是一种特殊的层，PyTorch也将这些损失函数实现为nn.Module的子类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss() <span class="comment"># 使用均方误差损失作为损失函数</span></span><br></pre></td></tr></table></figure><h3 id="定义优化算法-1"><a href="#定义优化算法-1" class="headerlink" title="定义优化算法"></a>定义优化算法</h3><p>同样，我们也无须自己实现小批量随机梯度下降算法。torch.optim模块提供了很多常用的优化算法比如SGD、Adam和RMSProp等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.03</span>) <span class="comment"># 设置学习率为0.03</span></span><br><span class="line"><span class="built_in">print</span>(optimizer)</span><br></pre></td></tr></table></figure><p>还可以为不同子网络设置不同的学习率，这在finetune时经常用到。例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里不能直接运行，因为subnet1都是假的</span></span><br><span class="line">optimizer = optim.SGD([</span><br><span class="line">                       &#123;<span class="string">&#x27;params&#x27;</span>: net.subnet1.parameters()&#125;, <span class="comment"># 如果对某个参数不指定学习率，就使用最外层的默认学习率</span></span><br><span class="line">                       &#123;<span class="string">&#x27;params&#x27;</span>: net.subnet2.parameters(), <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.01</span>&#125;</span><br><span class="line">], lr=<span class="number">0.03</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>有时候我们不想让学习率固定成一个常数，那如何调整学习率呢？主要有两种做法。一种是修改optimizer.param_groups中对应的学习率，另一种是更简单也是较为推荐的做法——新建优化器，由于optimizer十分轻量级，构建开销很小，故而可以构建新的optimizer。但是后者对于使用动量的优化器（如Adam），会丢失动量等状态信息，可能会造成损失函数的收敛出现震荡等情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">    param_group[<span class="string">&#x27;lr&#x27;</span>] *= <span class="number">0.1</span> <span class="comment"># 学习率调整为之前的0.1倍</span></span><br></pre></td></tr></table></figure><h3 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h3><p>通过调用optim实例的step函数来迭代模型参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, num_epochs+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        output = net(X)</span><br><span class="line">        l = loss(output, y.view(-<span class="number">1</span>, <span class="number">1</span>)) <span class="comment"># output的size是[10, 1]，而y的size是[10]，所以y要改变一下形状</span></span><br><span class="line">        <span class="comment"># 同时，这里的l是算的这一批次上的样本的损失的平均值</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment"># 梯度清零， 等价于net.zero_grad()</span></span><br><span class="line">        l.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %f&#x27;</span> % (epoch, l.item()))</span><br></pre></td></tr></table></figure><p>将学习到的权重和偏差与真实值进行一下对比：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(true_w, net[<span class="number">0</span>].weight)</span><br><span class="line"><span class="built_in">print</span>(true_b, net[<span class="number">0</span>].bias)</span><br></pre></td></tr></table></figure><h2 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h2><p>前几节介绍的线性回归模型适用于输出为连续值的情景。在另一类情景中，模型输出可以是一个像图像类别这样的离散值。对于这样的离散值预测问题，我们可以使用诸如softmax回归在内的分类模型。和线性回归不同，softmax回归的输出单元从一个变成了多个，且引入了softmax运算使输出更适合离散值的预测和训练。</p><p>虽然我们仍然可以使用回归模型来进行建模，并将预测值就近定点化到1、2和3这样的离散值之一，但这种连续值到离散值的转化通常会影响到分类质量。因此我们一般使用更加适合离散值输出的模型来解决分类问题。<br>（1）softmax运算的必要性<br>既然分类问题需要得到离散的预测输出，一个简单的办法是将输出值当作预测类别是i的置信度，并将值最大的输出所对应的类作为预测输出。然而，直接使用输出层的输出有两个问题。一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。<br>softmax运算符（softmax operator）解决了以上两个问题。它通过softmax操作将输出值变换成值为正且和为1的概率分布，这样某一概率大了，也等价于它的输出是大的，这样就不改变预测类别输出。<br>（2）交叉熵损失函数<br>softmax运算将输出变换成一个合法的类别预测分布。另一方面，真实标签也可以用类别分布表达，比如构造一个向量，使其第i个元素为1，其余为0，就代表样本i类别的离散数值。这样，训练目标就可以设为预测概率分布尽可能接近于真实的标签概率分布。<br>因此，就是寻找适合衡量两个概率分布差异的测量函数，其中，交叉熵（cross entropy）是一个常用的衡量方法，它只关心对正确类别的预测概率，只要其值足够大，就可以确保分类结果正确，因为如果不是正确类别，这个交叉熵就是0。<br>（3）模型预测及评价<br>在训练好softmax回归模型后，给定任一样本特征，就可以预测每个输出类别的概率。通常把预测概率最大的类别作为输出类别。如果它与真实类别（标签）一致，说明这次预测是正确的。下面将使用准确率（accuracy）来评价模型的表现。它等于正确预测数量与总预测数量之比。</p><h2 id="图像分类数据集Fashion-MNIST"><a href="#图像分类数据集Fashion-MNIST" class="headerlink" title="图像分类数据集Fashion-MNIST"></a>图像分类数据集Fashion-MNIST</h2><p>本节将使用torchvision包来加载Fashion-MNIST数据集，<br>它是服务于PyTorch深度学习框架的，主要用来构建计算机视觉模型。torchvision主要由以下几部分构成：<br>torchvision.datasets: 一些加载数据的函数及常用的数据集接口；<br>torchvision.models: 包含常用的模型结构（含预训练模型），例如AlexNet、VGG、ResNet等；<br>torchvision.transforms: 常用的图片变换，例如裁剪、旋转等；<br>torchvision.utils: 其他的一些有用的方法。</p><h3 id="获取数据集"><a href="#获取数据集" class="headerlink" title="获取数据集"></a>获取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过train参数指定获取训练集或测试集，download指定是否下载</span></span><br><span class="line"><span class="comment"># transforms.ToTensor()使所有数据转换为Tensor，如果不进行转换则返回的是PIL图片</span></span><br><span class="line">mnist_train = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line">mnist_test = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br></pre></td></tr></table></figure><p>transforms.ToTensor()将尺寸为 (H x W x C) 且数据位于[0, 255]的PIL图片或者数据类型为np.uint8的NumPy数组转换为尺寸为(C x H x W)且数据类型为torch.float32且位于[0.0, 1.0]的Tensor。<br>这个地方有个坑：如果输入的数组是0到255之间，但数据类型不是np.uint8，那么ToTensor()只会更改通道顺序，而不会除以255变换到0到1之间，所以，如果用像素值(0-255整数)表示图片数据，那么一律将其类型设置成uint8，避免不必要的bug。一定要确保input和output都是心里有数的。</p><p>见如下几篇相关帖子：<br><a href="https://discuss.pytorch.org/t/bugs-with-torchvision-transforms-topilimage/26109">Bugs with torchvision.transforms.ToPILImage()?</a><br><a href="https://tangshusen.me/2018/12/05/kaggle-doodle-reco/">2.2.4 图像数据的一个坑</a></p><p>查看数据集中的数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> img_as_ubyte</span><br><span class="line"><span class="comment"># mnist_train和mnist_test都是torch.utils.data.Dataset的子类</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(mnist_train))</span><br><span class="line">feature, label = mnist_train[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(feature.shape, label) <span class="comment"># shape是通道*高*宽</span></span><br><span class="line">io.imsave(<span class="string">&quot;1.png&quot;</span>, img_as_ubyte(feature.view((<span class="number">28</span>, <span class="number">28</span>)).numpy()))</span><br></pre></td></tr></table></figure><p>feature中的图像已经是[0.0, 1.0]范围，所以需要转化成[0, 255]范围才能正常显示。<br>参考见<a href="https://www.cnblogs.com/denny402/p/5122328.html">这篇文章</a>。</p><p>将数值标签与文本标签对应起来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_fashion_mnist_labels</span>(<span class="params">labels</span>):</span></span><br><span class="line">    text_labels = [<span class="string">&#x27;t-shirt&#x27;</span>, <span class="string">&#x27;trouser&#x27;</span>, <span class="string">&#x27;pullover&#x27;</span>, <span class="string">&#x27;dress&#x27;</span>, <span class="string">&#x27;coat&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;sandal&#x27;</span>, <span class="string">&#x27;shirt&#x27;</span>, <span class="string">&#x27;sneaker&#x27;</span>, <span class="string">&#x27;bag&#x27;</span>, <span class="string">&#x27;ankle boot&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> [text_labels[<span class="built_in">int</span>(i)] <span class="keyword">for</span> i <span class="keyword">in</span> labels]</span><br></pre></td></tr></table></figure><h3 id="读取小批量"><a href="#读取小批量" class="headerlink" title="读取小批量"></a>读取小批量</h3><p>在实践中，数据读取经常是训练的性能瓶颈，特别当模型较简单或者计算硬件性能较高时。PyTorch的DataLoader中一个很方便的功能是允许使用多进程来加速数据读取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">num_workers = <span class="number">4</span></span><br><span class="line"><span class="comment"># mnist_train是torch.utils.data.Dataset的子类，所以我们可以将其传入torch.utils.data.DataLoader来创建一个读取小批量数据样本的DataLoader实例</span></span><br><span class="line"><span class="comment"># 通过参数num_workers来设置4个进程读取数据</span></span><br><span class="line">train_iter = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers)</span><br><span class="line">test_iter = torch.utils.data.DataLoader(mnist_test, batch_size = batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br></pre></td></tr></table></figure><p>查看一下，读取一遍训练数据需要的时间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%.2f sec&#x27;</span> % (time.time()-start))</span><br></pre></td></tr></table></figure><h2 id="softmax回归的从零开始实现"><a href="#softmax回归的从零开始实现" class="headerlink" title="softmax回归的从零开始实现"></a>softmax回归的从零开始实现</h2><h3 id="获取和读取数据"><a href="#获取和读取数据" class="headerlink" title="获取和读取数据"></a>获取和读取数据</h3><p>这一步就是按照上一节中下载和小批量读取Fashion-MNIST数据集的方式。</p><h3 id="初始化模型参数-2"><a href="#初始化模型参数-2" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>跟线性回归中的例子一样，我们将使用向量表示每个样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">num_inputs = <span class="number">784</span> <span class="comment"># 这里用向量来表示图像，28*28=784，相当于784个输入特征</span></span><br><span class="line">num_outputs = <span class="number">10</span> <span class="comment"># 输出为10个类别</span></span><br><span class="line">W = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_inputs, num_outputs)), dtype=torch.<span class="built_in">float</span>) <span class="comment"># 权重为784*10，初始为正态分布</span></span><br><span class="line">b = torch.tensor(np.zeros(num_outputs), dtype=torch.<span class="built_in">float</span>) <span class="comment"># 偏差为10， 初始为0</span></span><br><span class="line">W.requires_grad_(requires_grad=<span class="literal">True</span>) <span class="comment"># 设置需要计算梯度</span></span><br><span class="line">b.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="实现softmax运算"><a href="#实现softmax运算" class="headerlink" title="实现softmax运算"></a>实现softmax运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先演示一下怎样对多维Tensor按维度进行操作</span></span><br><span class="line">X = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(X.<span class="built_in">sum</span>(dim = <span class="number">0</span>, keepdim=<span class="literal">True</span>)) <span class="comment"># tensor([[5, 7, 9]])，对同一列的元素求和，并保持原来的维度</span></span><br><span class="line"><span class="built_in">print</span>(X.<span class="built_in">sum</span>(dim = <span class="number">1</span>, keepdim=<span class="literal">True</span>)) <span class="comment"># tensor([[6], [15]])，对同一行的元素求和，并保持原来的维度</span></span><br><span class="line"><span class="comment"># 定义softmax运算</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">X</span>):</span> <span class="comment"># 矩阵X的行数是样本数，列数是输出个数</span></span><br><span class="line">    X_exp = X.exp() <span class="comment"># 先对每个元素做指数运算</span></span><br><span class="line">    partition = X_exp.<span class="built_in">sum</span>(dim = <span class="number">1</span>, keepdim = <span class="literal">True</span>) <span class="comment"># 然后对exp矩阵同一行的元素求和</span></span><br><span class="line">    <span class="keyword">return</span> X_exp / partition <span class="comment"># 最后令exp矩阵的每行各元素与该行元素之和相除，最终使得每行元素的和为1且非负，所以每行都是合法的概率分布</span></span><br><span class="line">    <span class="comment"># 这个除法也应用了广播机制</span></span><br></pre></td></tr></table></figure><h3 id="定义模型-2"><a href="#定义模型-2" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">net</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="comment"># 注意，这里需要使用view函数将图像转换为向量</span></span><br><span class="line">    <span class="keyword">return</span> softmax(torch.mm(X.view((-<span class="number">1</span>, num_inputs)), W) + b)</span><br></pre></td></tr></table></figure><h3 id="定义损失函数-2"><a href="#定义损失函数-2" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先演示一下gather函数的用法</span></span><br><span class="line">y_hat = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.6</span>], [<span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.5</span>]]) <span class="comment"># 这是虚构的两个样本在3个类别下的预测概率</span></span><br><span class="line">y = torch.LongTensor([<span class="number">0</span>, <span class="number">2</span>]) <span class="comment"># 这是虚构的两个样本的标签类别</span></span><br><span class="line">y_hat.gather(<span class="number">1</span>, y.view(-<span class="number">1</span>, <span class="number">1</span>)) <span class="comment"># tensor([[0.1000], [0.5000]]) 这样就得到了两个样本的标签的预测概率</span></span><br></pre></td></tr></table></figure><p>关于gather函数，其实就是索引，具体解析可以参看<a href="https://www.cnblogs.com/HongjianChen/p/9451526.html">这篇博文</a>。<br>那么交叉熵损失函数就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy</span>(<span class="params">y_hat, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> - torch.log(y_hat.gather(<span class="number">1</span>, y.view(-<span class="number">1</span>, <span class="number">1</span>)))</span><br></pre></td></tr></table></figure><h3 id="计算分类准确率"><a href="#计算分类准确率" class="headerlink" title="计算分类准确率"></a>计算分类准确率</h3><p>给定一个类别的预测概率分布y_hat，我们把预测概率最大的类别作为输出类别。如果它与真实类别y一致，说明这次预测是正确的。分类准确率即正确预测数量与总预测数量之比。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">y_hat, y</span>):</span></span><br><span class="line">    <span class="comment"># argmax返回矩阵y_hat每行中最大元素的索引，且返回结果与变量y形状相同</span></span><br><span class="line">    <span class="comment"># 相等条件判断式(y_hat.argmax(dim=1) == y)是一个类型为ByteTensor的Tensor</span></span><br><span class="line">    <span class="comment"># 用float()将其转换为值为0（相等为假）或1（相等为真）的浮点型Tensor</span></span><br><span class="line">    <span class="keyword">return</span> (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">float</span>().mean().item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy(y_hat, y))</span><br><span class="line"><span class="comment"># 继续使用在演示gather函数时定义的变量y_hat和y，并将它们分别作为预测概率分布和标签</span></span><br><span class="line"><span class="comment"># 可以看到，第一个样本预测类别为2（该行最大元素0.6在本行的索引为2），与真实标签0不一致</span></span><br><span class="line"><span class="comment"># 第二个样本预测类别为2（该行最大元素0.5在本行的索引为2），与真实标签2一致</span></span><br><span class="line"><span class="comment"># 因此，这两个样本上的分类准确率为0.5。</span></span><br></pre></td></tr></table></figure><p>评价模型net在数据集data_iter上的准确率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">data_iter, net</span>):</span></span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        acc_sum += (net(X).argmax(dim=<span class="number">1</span>)==y).<span class="built_in">float</span>().<span class="built_in">sum</span>().item() <span class="comment"># 注意这个地方先求和</span></span><br><span class="line">        n +=  y.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> acc_sum /n <span class="comment"># 再求平均</span></span><br></pre></td></tr></table></figure><h3 id="训练模型-2"><a href="#训练模型-2" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, lr = <span class="number">5</span>, <span class="number">0.1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">params, lr, batch_size</span>):</span> <span class="comment"># 定义优化算法</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.data -= lr * param.grad / batch_size </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch3</span>(<span class="params">net, train_iter, test_iter, loss, num_epochs, batch_size, params=<span class="literal">None</span>, lr=<span class="literal">None</span>, optimizer=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y).<span class="built_in">sum</span>() <span class="comment"># 这个地方是求和，所以后面的SGD算法中除以batch size</span></span><br><span class="line">            <span class="keyword">if</span> optimizer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment"># 这里看是否传入了优化器，默认是不传入</span></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">            <span class="keyword">elif</span> params <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> params[<span class="number">0</span>].grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment"># 如果不传入优化器，就显式地对参数梯度置为0</span></span><br><span class="line">                <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">                    param.grad.data.zero_()</span><br><span class="line"></span><br><span class="line">            l.backward()</span><br><span class="line">            <span class="keyword">if</span> optimizer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                sgd(params, lr, batch_size)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                optimizer.step()</span><br><span class="line"></span><br><span class="line">            train_l_sum += l.item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %.4f, train acc %.3f, test acc %.3f&#x27;</span> </span><br><span class="line">              % (epoch+<span class="number">1</span>, train_l_sum/n, train_acc_sum/n, test_acc))</span><br><span class="line"></span><br><span class="line">train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)</span><br></pre></td></tr></table></figure><h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X, y = <span class="built_in">iter</span>(test_iter).<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(net(X).argmax(dim=<span class="number">1</span>)[:<span class="number">10</span>], y[:<span class="number">10</span>])</span><br></pre></td></tr></table></figure><h2 id="softmax回归的简洁实现"><a href="#softmax回归的简洁实现" class="headerlink" title="softmax回归的简洁实现"></a>softmax回归的简洁实现</h2><h3 id="获取和读取数据-1"><a href="#获取和读取数据-1" class="headerlink" title="获取和读取数据"></a>获取和读取数据</h3><p>与上一节相同</p><h3 id="定义和初始化模型"><a href="#定义和初始化模型" class="headerlink" title="定义和初始化模型"></a>定义和初始化模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">num_inputs = <span class="number">784</span></span><br><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_inputs, num_outputs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LinearNet, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(num_inputs, num_outputs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span> <span class="comment"># x的形状是(batch, 1, 28, 28)，所以要view一下</span></span><br><span class="line">        y = self.linear(x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">net = LinearNet(num_inputs, num_outputs)</span><br></pre></td></tr></table></figure><p>还可以将形状转换这一块单独提出来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlattenLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    OrderedDict([</span><br><span class="line">                 (<span class="string">&#x27;flatten&#x27;</span>, FlattenLayer()),</span><br><span class="line">                 (<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, num_outputs))</span><br><span class="line">    ])</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>然后，我们使用均值为0、标准差为0.01的正态分布随机初始化模型的权重参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line">init.normal_(net.linear.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant_(net.linear.bias, val=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="softmax和交叉熵损失函数"><a href="#softmax和交叉熵损失函数" class="headerlink" title="softmax和交叉熵损失函数"></a>softmax和交叉熵损失函数</h3><p>在上一节的练习中，分开定义softmax运算和交叉熵损失函数可能会造成数值不稳定。因此，PyTorch提供了一个包括softmax运算和交叉熵损失计算的函数。它的数值稳定性更好。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure><h3 id="定义优化算法-2"><a href="#定义优化算法-2" class="headerlink" title="定义优化算法"></a>定义优化算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><h3 id="训练模型-3"><a href="#训练模型-3" class="headerlink" title="训练模型"></a>训练模型</h3><p>使用上一节定义的训练函数，只是传入不同的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, <span class="literal">None</span>, <span class="literal">None</span>, optimizer)</span><br></pre></td></tr></table></figure><h2 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h2><p>多层感知机在单层神经网络的基础上引入了一到多个隐藏层（hidden layer）。隐藏层位于输入层和输出层之间。<br>由于输入层不涉及计算，因此，多层感知机的层数等于隐藏层的层数加上输出层。<br>全连接层只是对数据做仿射变换（affine transformation），而多个仿射变换的叠加仍然是一个仿射变换。<br>（1）激活函数<br>对隐藏变量使用按元素运算的非线性函数进行变换，然后再作为下一个全连接层的输入。这个非线性函数被称为激活函数（activation function）。<br>常用的激活函数包括ReLU函数、sigmoid函数和tanh函数。<br>（2）多层感知机<br>多层感知机就是含有至少一个隐藏层的由全连接层组成的神经网络，且每个隐藏层的输出通过激活函数进行变换。<br>多层感知机的层数和各隐藏层中隐藏单元个数都是超参数。</p><h2 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h2><p>过拟合现象，即模型的训练误差远小于它在测试集上的误差。虽然增大训练数据集可能会减轻过拟合，但是获取额外的训练数据往往代价高昂。<br>应对过拟合问题的常用方法：权重衰减（weight decay）和丢弃法（Dropout，下一节介绍）。<br>权重衰减等价于L2范数正则化（regularization）。正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对过拟合的常用手段。<br>L2范数正则化在模型原损失函数基础上添加L2范数惩罚项，从而得到训练所需要最小化的函数。L2范数惩罚项指的是模型权重参数每个元素的平方和与一个正的常数的乘积。<br>L2范数正则化令权重先自乘小于1的数，再减去不含惩罚项的梯度。因此，L2范数正则化又叫权重衰减。<br>权重衰减通过惩罚绝对值较大的模型参数为需要学习的模型增加了限制，这可能对过拟合有效。实际场景中，我们有时也在惩罚项中添加偏差元素的平方和。<br>可以直接在构造优化器实例时通过weight_decay参数来指定权重衰减超参数。默认下，PyTorch会对权重和偏差同时衰减。我们可以分别对权重和偏差构造优化器实例，从而只对权重衰减。</p><h2 id="丢弃法"><a href="#丢弃法" class="headerlink" title="丢弃法"></a>丢弃法</h2><p>当对某隐藏层使用丢弃法时，该层的隐藏单元将有一定概率被丢弃掉。<br>丢弃概率是丢弃法的超参数。<br>丢弃法不改变其输入的期望值。<br>在测试模型时，我们为了拿到更加确定性的结果，一般不使用丢弃法。<br>在PyTorch中，我们只需要在全连接层后添加Dropout层并指定丢弃概率。在训练模型时，Dropout层将以指定的丢弃概率随机丢弃上一层的输出元素；在测试模型时（即model.eval()后），Dropout层并不发挥作用。</p><h2 id="正向传播、反向传播和计算图"><a href="#正向传播、反向传播和计算图" class="headerlink" title="正向传播、反向传播和计算图"></a>正向传播、反向传播和计算图</h2><p>正向传播是指对神经网络沿着从输入层到输出层的顺序，依次计算并存储模型的中间变量（包括输出）。<br>我们通常绘制计算图来可视化运算符和变量在计算中的依赖关系，其中方框代表变量，圆圈代表运算符，箭头表示从输入到输出之间的依赖关系。<br>反向传播指的是计算神经网络参数梯度的方法。总的来说，反向传播依据微积分中的链式法则，沿着从输出层到输入层的顺序，依次计算并存储目标函数有关神经网络各层的中间变量以及参数的梯度。</p><p>在训练深度学习模型时，正向传播和反向传播之间相互依赖：<br>一方面，正向传播的计算可能依赖于模型参数的当前值，而这些模型参数是在反向传播的梯度计算后通过优化算法迭代的；<br>另一方面，反向传播的梯度计算可能依赖于各变量的当前值，而这些变量的当前值是通过正向传播计算得到的。</p><p>因此，在模型参数初始化完成后，我们交替地进行正向传播和反向传播，并根据反向传播计算的梯度迭代模型参数。既然我们在反向传播中使用了正向传播中计算得到的中间变量来避免重复计算，那么这个复用也导致正向传播结束后不能立即释放中间变量内存。这也是训练要比预测占用更多内存的一个重要原因。另外需要指出的是，这些中间变量的个数大体上与网络层数线性相关，每个变量的大小跟批量大小和输入个数也是线性相关的，它们是导致较深的神经网络使用较大批量训练时更容易超内存的主要原因。</p><h2 id="数值稳定性和模型初始化"><a href="#数值稳定性和模型初始化" class="headerlink" title="数值稳定性和模型初始化"></a>数值稳定性和模型初始化</h2><p>深度模型有关数值稳定性的典型问题是衰减（vanishing）和爆炸（explosion）。<br>在神经网络中，通常需要随机初始化模型参数。<br>随机初始化模型参数的方法有很多。之前的实现中，我们使用torch.nn.init.normal_()使模型net的权重参数采用正态分布的随机初始化方式。不过，PyTorch中nn.Module的模块参数都采取了较为合理的初始化策略（不同类型的layer具体采样的哪一种初始化方法的可参考源代码），因此一般不用我们考虑。</p><p>还有一种比较常用的随机初始化方法叫作Xavier随机初始化，它的设计主要考虑到，模型参数初始化后，每层输出的方差不该受该层输入个数影响，且每层梯度的方差也不该受该层输出个数影响。</p><h1 id="深度学习计算"><a href="#深度学习计算" class="headerlink" title="深度学习计算"></a>深度学习计算</h1><h2 id="模型构造"><a href="#模型构造" class="headerlink" title="模型构造"></a>模型构造</h2><p>有多种模型构造的方法：</p><h3 id="继承Module类来构造模型"><a href="#继承Module类来构造模型" class="headerlink" title="继承Module类来构造模型"></a>继承Module类来构造模型</h3><p>Module类是nn模块里提供的一个模型构造类，是所有神经网络模块的基类，我们可以继承它来定义我们想要的模型。</p><h3 id="Module的子类"><a href="#Module的子类" class="headerlink" title="Module的子类"></a>Module的子类</h3><p>Module类是一个通用的部件。事实上，PyTorch还实现了继承自Module的可以方便构建模型的类: 如Sequential、ModuleList和ModuleDict等等。不过虽然Sequential等类可以使模型构造更加简单，但直接继承Module类可以极大地拓展模型构造的灵活性。<br>（1）Sequential类：当模型的前向计算为简单串联各个层的计算时，Sequential类可以通过更加简单的方式定义模型。这正是Sequential类的目的：它可以接收一个子模块的有序字典（OrderedDict）或者一系列子模块作为参数来逐一添加Module的实例，而模型的前向计算就是将这些实例按添加的顺序逐一计算。<br>（2）ModuleList类：ModuleList接收一个子模块的列表作为输入，然后也可以类似List那样进行append和extend操作。<br>既然Sequential和ModuleList都可以进行列表化构造网络，那二者区别是什么呢。ModuleList仅仅是一个储存各种模块的列表，这些模块之间没有联系也没有顺序（所以不用保证相邻层的输入输出维度匹配），而且没有实现forward功能需要自己实现；而Sequential内的模块需要按照顺序排列，要保证相邻层的输入输出大小相匹配，内部forward功能已经实现。<br>ModuleList的出现只是让网络定义前向传播时更加灵活；另外，ModuleList不同于一般的Python的list，加入到ModuleList里面的所有模块的参数会被自动添加到整个网络中。<br>（3）ModuleDict类：ModuleDict接收一个子模块的字典作为输入, 然后也可以类似字典那样进行添加访问操作；和ModuleList一样，ModuleDict实例仅仅是存放了一些模块的字典，并没有定义forward函数需要自己定义。同样，ModuleDict也与Python的Dict有所不同，ModuleDict里的所有模块的参数会被自动添加到整个网络中。</p><h2 id="模型参数的访问、初始化和共享"><a href="#模型参数的访问、初始化和共享" class="headerlink" title="模型参数的访问、初始化和共享"></a>模型参数的访问、初始化和共享</h2><h3 id="访问模型参数"><a href="#访问模型参数" class="headerlink" title="访问模型参数"></a>访问模型参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Linear(<span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">) <span class="comment"># Pytorch 已进行默认初始化</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line">X = torch.rand(<span class="number">2</span>, <span class="number">4</span>) <span class="comment"># 构造数据集的输入</span></span><br><span class="line">Y = net(X).<span class="built_in">sum</span>() <span class="comment"># 根据默认初始化的参数计算输出</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过Module类的parameters()或者named_parameters方法来访问所有参数（以迭代器的形式返回）</span></span><br><span class="line"><span class="comment"># 后者除了返回参数Tensor外还会返回其名字</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(net.named_parameters()))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(name, param.size()) <span class="comment"># 返回的名字自动加上了层数的索引作为前缀</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于使用Sequential类构造的神经网络，可以通过方括号[]来访问网络的任一层。</span></span><br><span class="line"><span class="comment"># 索引0表示隐藏层为Sequential实例最先添加的层。</span></span><br><span class="line"><span class="comment"># 返回的param的类型为torch.nn.parameter.Parameter，其实这是Tensor的子类</span></span><br><span class="line"><span class="comment"># 和Tensor不同的是如果一个Tensor是Parameter，那么它会自动被添加到模型的参数列表里</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net[<span class="number">0</span>].named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(name, param.size(), <span class="built_in">type</span>(param)) <span class="comment"># 这里是单层的参数，所以名字中没有层数索引的前缀</span></span><br><span class="line"></span><br><span class="line">weight_0 = <span class="built_in">list</span>(net[<span class="number">0</span>].parameters())[<span class="number">0</span>] <span class="comment"># 要使用list将这个迭代器转化一下</span></span><br><span class="line"><span class="comment"># 因为Parameter是Tensor，即Tensor拥有的属性它都有，比如可以根据data来访问参数数值，用grad来访问参数梯度。</span></span><br><span class="line"><span class="built_in">print</span>(weight_0.data)</span><br><span class="line"><span class="built_in">print</span>(weight_0.grad) <span class="comment"># 反向传播前梯度为None</span></span><br><span class="line">Y.backward()</span><br><span class="line"><span class="built_in">print</span>(weight_0.grad)</span><br></pre></td></tr></table></figure><h3 id="初始化模型参数-3"><a href="#初始化模型参数-3" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>PyTorch中nn.Module的模块参数采取了默认的较为合理的初始化策略（不同类型的layer具体采样的哪一种初始化方法的可参考源代码）。但我们经常需要使用其他方法来初始化权重。PyTorch的init模块里提供了多种预设的初始化方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;weight&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        init.normal_(param, mean=<span class="number">0</span>, std=<span class="number">0.01</span>) <span class="comment"># 用正态分布初始化权重</span></span><br><span class="line">        <span class="built_in">print</span>(name, param.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;bias&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        init.constant_(param, val=<span class="number">0</span>) <span class="comment"># 将偏差置0</span></span><br><span class="line">        <span class="built_in">print</span>(name, param.data)</span><br></pre></td></tr></table></figure><h3 id="自定义初始化方法"><a href="#自定义初始化方法" class="headerlink" title="自定义初始化方法"></a>自定义初始化方法</h3><p>有时候我们需要的初始化方法并没有在init模块中提供。这时，可以实现一个初始化方法，从而能够像使用其他初始化方法那样使用它。在这之前我们先来看看PyTorch是怎么实现这些初始化方法的，例如torch.nn.init.normal_：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normal_</span>(<span class="params">tensor, mean=<span class="number">0</span>, std=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">return</span> tensor.normal_(mean, std)</span><br></pre></td></tr></table></figure><p>可以看到这就是一个inplace改变Tensor值的函数，而且这个过程是不记录梯度的。 类似的我们来实现一个自定义的初始化方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_weight_</span>(<span class="params">tensor</span>):</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        tensor.uniform_(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">        tensor *= (tensor.<span class="built_in">abs</span>() &gt;= <span class="number">5</span>).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;weight&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        init_weight_(param)</span><br><span class="line">        <span class="built_in">print</span>(name, param.data)</span><br></pre></td></tr></table></figure><p>还可以通过改变这些参数的data来改写模型参数值同时不会影响梯度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;bias&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        param.data += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(name, param.data)</span><br></pre></td></tr></table></figure><h3 id="共享模型参数"><a href="#共享模型参数" class="headerlink" title="共享模型参数"></a>共享模型参数</h3><p>在有些情况下，我们希望在多个层之间共享模型参数。共享模型参数的方式有: Module类的forward函数里多次调用同一个层。此外，如果我们传入Sequential的模块是同一个Module实例的话参数也是共享的。<br>不过注意，因为模型参数里包含了梯度，所以在反向传播计算时，这些共享的参数的梯度是累加的。</p><h2 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a>自定义层</h2><p>虽然PyTorch提供了大量常用的层，但有时候我们依然希望自定义层。本节将介绍如何使用Module来自定义层，从而可以被重复调用。</p><h3 id="不含模型参数的自定义层"><a href="#不含模型参数的自定义层" class="headerlink" title="不含模型参数的自定义层"></a>不含模型参数的自定义层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CenteredLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CenteredLayer, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将计算放在了forward函数里，所以，该自定义层没有模型参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x - x.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以实例化这个层，然后做前向计算</span></span><br><span class="line">layer = CenteredLayer()</span><br><span class="line">layer(torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], dtype=torch.<span class="built_in">float</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以用它来构造更复杂的模型</span></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">8</span>, <span class="number">128</span>), CenteredLayer())</span><br><span class="line">y = net(torch.rand(<span class="number">4</span>, <span class="number">8</span>))</span><br><span class="line">y.mean().item()</span><br></pre></td></tr></table></figure><h3 id="含模型参数的自定义层"><a href="#含模型参数的自定义层" class="headerlink" title="含模型参数的自定义层"></a>含模型参数的自定义层</h3><p>我们还可以自定义含模型参数的自定义层。其中的模型参数可以通过训练学出。<br>之前介绍了Parameter类其实是Tensor的子类，如果一个Tensor是Parameter，那么它会自动被添加到模型的参数列表里。所以在自定义含模型参数的层时，我们应该将参数定义成Parameter，除了像之前那样直接定义成Parameter类外，还可以使用ParameterList和ParameterDict分别定义参数的列表和字典。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ParameterList接收一个Parameter实例的列表作为输入然后得到一个参数列表，使用的时候可以用索引来访问某个参数</span></span><br><span class="line"><span class="comment"># 另外也可以使用append和extend在列表后面新增参数。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.params = nn.ParameterList([nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)])</span><br><span class="line">        self.params.append(nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>)))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.params)):</span><br><span class="line">            x = torch.mm(x, self.params[i])</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = MyDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"><span class="comment"># 而ParameterDict接收一个Parameter实例的字典作为输入然后得到一个参数字典，然后可以按照字典的规则使用了。</span></span><br><span class="line"><span class="comment"># 例如使用update()新增参数，使用keys()返回所有键值，使用items()返回所有键值对等等</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDictDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.params = nn.ParameterDict(&#123;</span><br><span class="line">            <span class="string">&#x27;linear1&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)),</span><br><span class="line">            <span class="string">&#x27;linear2&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        self.params.update(&#123;<span class="string">&#x27;linear3&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">2</span>))&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, choice=<span class="string">&#x27;linear1&#x27;</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mm(x, self.params[choice])</span><br><span class="line"></span><br><span class="line">net = MyDictDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这样就可以根据传入的键值来进行不同的前向传播</span></span><br><span class="line">x = torch.ones(<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(net(x, <span class="string">&#x27;linear1&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(net(x, <span class="string">&#x27;linear2&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(net(x, <span class="string">&#x27;linear3&#x27;</span>))</span><br><span class="line"><span class="comment"># 可以使用自定义层构造模型。它和PyTorch的其他层在使用上很类似</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    MyDictDense(),</span><br><span class="line">    MyDense()</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"><span class="built_in">print</span>(net(x))</span><br></pre></td></tr></table></figure><h2 id="读取和存储"><a href="#读取和存储" class="headerlink" title="读取和存储"></a>读取和存储</h2><p>在实际中，我们有时需要把训练好的模型部署到很多不同的设备。在这种情况下，我们可以把内存中训练好的模型参数存储在硬盘上供后续读取使用。</p><h3 id="读写Tensor"><a href="#读写Tensor" class="headerlink" title="读写Tensor"></a>读写Tensor</h3><p>我们可以直接使用save函数和load函数分别存储和读取Tensor。save使用Python的pickle实用程序将对象进行序列化，然后将序列化的对象保存到disk，使用save可以保存各种对象,包括模型、张量和字典等。而load使用pickle unpickle工具将pickle的对象文件反序列化为内存。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">3</span>)</span><br><span class="line">torch.save(x, <span class="string">&#x27;x.pt&#x27;</span>) <span class="comment"># 保存到文件</span></span><br><span class="line">x2 = torch.load(<span class="string">&#x27;x.pt&#x27;</span>) <span class="comment"># 读取文件数据到内存</span></span><br><span class="line">y = torch.zeros(<span class="number">4</span>)</span><br><span class="line">torch.save([x, y], <span class="string">&#x27;xy.pt&#x27;</span>) <span class="comment"># 存储一个Tensor列表</span></span><br><span class="line"></span><br><span class="line">xy_list = torch.load(<span class="string">&#x27;xy.pt&#x27;</span>) <span class="comment"># 读取该Tensor列表</span></span><br><span class="line">torch.save(&#123;<span class="string">&#x27;x&#x27;</span>:x, <span class="string">&#x27;y&#x27;</span>:y&#125;, <span class="string">&#x27;xy_dict.pt&#x27;</span>) <span class="comment"># 存储一个从字符串映射到Tensor的字典</span></span><br><span class="line"></span><br><span class="line">xy_dict = torch.load(<span class="string">&#x27;xy_dict.pt&#x27;</span>)</span><br><span class="line">xy_dict</span><br></pre></td></tr></table></figure><h3 id="读写模型"><a href="#读写模型" class="headerlink" title="读写模型"></a>读写模型</h3><p>在PyTorch中，Module的可学习参数，即权重和偏差，模块模型包含在参数中(通过model.parameters()访问)。state_dict是一个从参数名称隐射到参数Tesnor的字典对象。<br>注意，只有具有可学习参数的层(卷积层、线性层等)才有state_dict中的条目。优化器(optim)也有一个state_dict，其中包含关于优化器状态以及所使用的超参数的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.output = nn.Linear(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        a = self.relu(self.hidden(X))</span><br><span class="line">        <span class="keyword">return</span> self.output(a)</span><br><span class="line"></span><br><span class="line">net = MLP()</span><br><span class="line">net.state_dict() <span class="comment"># relu层没有可学习的参数</span></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">optimizer.state_dict()</span><br></pre></td></tr></table></figure><p>PyTorch中保存和加载训练模型有两种常见的方法:<br>（1） 仅保存和加载模型参数(state_dict)，这是推荐方式，形式为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), PATH) <span class="comment"># 保存，推荐的文件后缀名是pt或pth</span></span><br><span class="line">model = TheModelClass(*args, **kwargs) <span class="comment"># 加载</span></span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">Y = net(X)</span><br><span class="line">PATH = <span class="string">&#x27;./net.pt&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), PATH) <span class="comment"># 存储模型参数</span></span><br><span class="line"></span><br><span class="line">net2 = MLP() <span class="comment"># net2和net一样都是MLP()类，所以模型参数相同</span></span><br><span class="line">net2.load_state_dict(torch.load(PATH))</span><br><span class="line">Y2 = net2(X)</span><br><span class="line">Y2 == Y <span class="comment"># 两者计算结果相同</span></span><br></pre></td></tr></table></figure><p>（2）保存和加载整个模型，形式为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model, PATH) <span class="comment"># 保存</span></span><br><span class="line">model = torch.load(PATH) <span class="comment"># 加载</span></span><br></pre></td></tr></table></figure><h2 id="GPU计算"><a href="#GPU计算" class="headerlink" title="GPU计算"></a>GPU计算</h2><p>对复杂的神经网络和大规模的数据来说，使用CPU来计算可能不够高效。在本节中，将介绍如何使用单块NVIDIA GPU来计算。需要确保已经安装好了PyTorch GPU版本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi <span class="comment"># 查看显卡信息</span></span><br></pre></td></tr></table></figure><h3 id="计算设备"><a href="#计算设备" class="headerlink" title="计算设备"></a>计算设备</h3><p>PyTorch可以指定用来存储和计算的设备，如使用内存的CPU或者使用显存的GPU。默认情况下，PyTorch会将数据创建在内存，然后利用CPU来计算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.cuda.is_available() <span class="comment"># 查看GPU是否可用</span></span><br><span class="line">torch.cuda.device_count() <span class="comment"># 查看GPU数目</span></span><br><span class="line">torch.cuda.current_device() <span class="comment"># 查看当前GPU索引号，从0开始</span></span><br><span class="line">torch.cuda.get_device_name(<span class="number">0</span>) <span class="comment"># 根据索引号查看GPU名称</span></span><br></pre></td></tr></table></figure><h3 id="Tensor的GPU计算"><a href="#Tensor的GPU计算" class="headerlink" title="Tensor的GPU计算"></a>Tensor的GPU计算</h3><p>默认情况下，Tensor会被存在内存上。因此，之前我们每次打印Tensor的时候看不到GPU相关标识。<br>使用.cuda()可以将CPU上的Tensor转换（复制）到GPU上。如果有多块GPU，我们用.cuda(i)来表示第 iii 块GPU及相应的显存（iii从0开始）且cuda(0)和cuda()等价。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">x = x.cuda(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.device) <span class="comment"># 可以通过Tensor的device属性来查看该Tensor所在的设备</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], device=device) <span class="comment"># 可以在创建时就指定设备</span></span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]).to(device) <span class="comment"># 第二种方法</span></span><br><span class="line">y = x**<span class="number">2</span> <span class="comment"># 如果对在GPU上的数据进行运算，那么结果还是存放在GPU上</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><p>需要注意的是，存储在不同位置中的数据是不可以直接进行计算的。即存放在CPU上的数据不可以直接与存放在GPU上的数据进行运算，位于不同GPU上的数据也是不能直接进行计算的。</p><h3 id="模型的GPU计算"><a href="#模型的GPU计算" class="headerlink" title="模型的GPU计算"></a>模型的GPU计算</h3><p>同Tensor类似，PyTorch模型也可以通过.cuda转换到GPU上。我们可以通过检查模型的参数的device属性来查看存放模型的设备。<br>同时，需要保证模型输入的Tensor和模型都在同一设备上，否则会报错。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Linear(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line">net.cuda() <span class="comment"># 将模型转换到CPU上</span></span><br><span class="line"><span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>).cuda()</span><br><span class="line">net(x)</span><br></pre></td></tr></table></figure><h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p>卷积神经网络中涉及到输入和输出图像的形状的转换，这里将后面模型构造时用到的一段通用测试代码摘出来，供以后参考：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">net = vgg(conv_arch, fc_features, fc_hidden_units)</span><br><span class="line"><span class="comment"># 构造一个高和宽均为224的单通道数据样本来观察每一层的输出形状</span></span><br><span class="line">X = torch.rand(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"><span class="comment"># named_children获取一级子模块及其名字(named_modules会返回所有子模块,包括子模块的子模块)</span></span><br><span class="line"><span class="keyword">for</span> name, blk <span class="keyword">in</span> net.named_children(): </span><br><span class="line">    X = blk(X)</span><br><span class="line">    <span class="built_in">print</span>(name, <span class="string">&#x27;output shape: &#x27;</span>, X.shape)</span><br></pre></td></tr></table></figure><h2 id="二维卷积层"><a href="#二维卷积层" class="headerlink" title="二维卷积层"></a>二维卷积层</h2><p>卷积神经网络（convolutional neural network）是含有卷积层（convolutional layer）的神经网络。<br>虽然卷积层得名于卷积（convolution）运算，但我们通常在卷积层中使用更加直观的互相关（cross-correlation）运算。<br>二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。即，可以通过数据来学习卷积核。<br>实际上，卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。<br>那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。<br>为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。<br>二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素x的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做X的感受野（receptive field）。<br>我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。<br>比如，输入层是一个3乘3的图像，记为X，经过一个2乘2的卷积核，得到的输出层是一个2乘2的图像，记为Y。那么Y中每个元素的感受野是X中的2乘2的范围大小，即这个元素仅与X中的这四个元素相关。此时考虑一个更深的卷积网络：将Y与另一个形状为2乘2的卷积核做互相关运算，输出单个元素z，那么，z在Y上的感受野包括Y的全部四个元素，则在输入X上的感受野包括其中全部的9个元素（X的这9个元素是由Y的四个元素所感受的）</p><h2 id="填充和步幅"><a href="#填充和步幅" class="headerlink" title="填充和步幅"></a>填充和步幅</h2><p>卷积层的输出形状由输入形状和卷积核窗口形状决定。卷积层的两个超参数，即填充和步幅，它们可以对给定形状的输入和卷积核改变输出形状。<br>填充（padding）是指在输入高和宽的两侧填充元素（通常是0元素）。<br>卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。我们将每次滑动的行数和列数称为步幅（stride）。</p><h2 id="多输入通道和多输出通道"><a href="#多输入通道和多输出通道" class="headerlink" title="多输入通道和多输出通道"></a>多输入通道和多输出通道</h2><p>（1）多输入通道<br>当输入数据含多个通道时，我们需要构造一个输入通道数与输入数据的通道数相同的卷积核，从而能够与含多通道的输入数据做互相关运算。<br>即，卷积核的通道数由输入数据的通道数所决定。<br>（2）多输出通道<br>当输入通道有多个时，因为我们对各个通道的结果做了累加，所以不论输入通道数是多少，输出通道数总是为1。<br>如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为c乘以h乘以w的卷积核，将它们在输出通道上进行连结。<br>即，输出数据的通道数由卷积核的个数所决定。<br>（3）1乘1卷积层<br>1乘1卷积层通常用来调整网络层之间的通道数（可以类比于全连接层的隐藏神经元个数），并控制模型复杂度。<br>因为使用了最小窗口，1乘1卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能。实际上，1乘1卷积的主要计算发生在通道维上。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。<br>假设将通道维当作特征维，将高和宽维度上的元素当成数据样本，那么1乘1卷积层的作用与全连接层等价。但它又相比于全连接层有一个优点：它仍然保留了输入图像的空间信息，即不是一个很长的向量，从而使空间信息能够自然传递到后面的层中去。</p><h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化（pooling）层的提出是为了缓解卷积层对位置的过度敏感性。<br>不同于卷积层里计算输入和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也分别叫做最大池化或平均池化。<br>同卷积层一样，池化层也可以在输入的高和宽两侧的填充并调整窗口的移动步幅来改变输出形状。池化层填充和步幅与卷积层填充和步幅的工作机制一样。<br>默认情况下，PyTorch里的池化层的步幅和池化窗口形状相同。<br>当然，我们也可以指定非正方形的池化窗口，并分别指定高和宽上的填充和步幅。<br>在处理多通道输入数据时，池化层对每个输入通道分别池化，而不是像卷积层那样将各通道的输入按通道相加。这意味着池化层的输出通道数与输入通道数相等。</p><h2 id="卷积神经网络（LeNet）"><a href="#卷积神经网络（LeNet）" class="headerlink" title="卷积神经网络（LeNet）"></a>卷积神经网络（LeNet）</h2><p>在之前对Fashion-MNIST数据集分类时，使用的方法是对图像中的像素全部展开得到一个很长的向量，然后输入进全连接层中。<br>然而，这种分类方法有一定的局限性。<br>（1）图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。<br>（2）对于大尺寸的输入图像，使用全连接层容易造成模型过大。这带来过复杂的模型和过高的存储开销。<br>卷积层尝试解决这两个问题。一方面，卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性均可能被有效识别；另一方面，卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。</p><h3 id="定义模型-3"><a href="#定义模型-3" class="headerlink" title="定义模型"></a>定义模型</h3><p>LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="comment"># 卷积操作的维度变化公式为:</span></span><br><span class="line"><span class="comment"># Height_out = (Height_in - Height_kernal + 2*padding) / stride +1 </span></span><br><span class="line"><span class="comment"># LeNet当时的输入图片是单通道的32*32像素的灰度图</span></span><br><span class="line"><span class="comment"># 但现在的Fashion-MNIST是28*28</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>), <span class="comment"># (输入通道，输出通道，卷积核尺寸)，所以输出尺寸为(28-5)+1=24，通道为6</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># Sigmoid激活</span></span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>), <span class="comment"># (卷积核尺寸，步幅)，所以输出尺寸为(24-2)/2+1=12，通道仍然为6</span></span><br><span class="line">            nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>), <span class="comment"># 所以输出尺寸为(12-5)+1=8，通道为16</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># Sigmoid激活</span></span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>) <span class="comment"># 所以输出尺寸为(8-2)/2+1=4，通道仍然为16</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">120</span>), <span class="comment"># 输入为16*4*4，输出为120个神经元</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># Sigmoid激活</span></span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>), <span class="comment"># 又一个全连接层</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># Sigmoid激活</span></span><br><span class="line">            nn.Linear(<span class="number">84</span>, <span class="number">10</span>) <span class="comment"># 输出层，类别为10</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        feature = self.conv(img)</span><br><span class="line">        output = self.fc(feature.view(img.shape[<span class="number">0</span>], -<span class="number">1</span>)) <span class="comment"># view一下形状，第一维为batch_size，剩下的就是图像转换成的向量</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">net = LeNet()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure><h3 id="获取数据和训练模型"><a href="#获取数据和训练模型" class="headerlink" title="获取数据和训练模型"></a>获取数据和训练模型</h3><p>（1）还是使用之前的数据下载和加载方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">mnist_train = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line">mnist_test = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">num_workers = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">train_iter = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers)</span><br><span class="line">test_iter = torch.utils.data.DataLoader(mnist_test, batch_size = batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br></pre></td></tr></table></figure><p>（2）修改分类准确度计算代码，使其支持GPU计算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">data_iter, net, device=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        <span class="comment"># 如果没指定device，则使用net的device</span></span><br><span class="line">        device = <span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line"></span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">                net.<span class="built_in">eval</span>() <span class="comment"># 评估模式，这会关闭dropout</span></span><br><span class="line">                acc_sum += (net(X.to(device)).argmax(dim=<span class="number">1</span>)==y.to(device)).<span class="built_in">float</span>().<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">                net.train() <span class="comment"># 改回训练模式</span></span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> acc_sum / n</span><br></pre></td></tr></table></figure><p>（3）修改训练过程，使其支持GPU计算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch5</span>(<span class="params">net, train_iter, test_iter, batch_size, optimizer, device, num_epochs</span>):</span></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;training on&#x27;</span>, device)</span><br><span class="line">    loss = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            train_l_sum += l.cpu().item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&#x27;</span> </span><br><span class="line">              % (epoch+<span class="number">1</span>, train_l_sum/n, train_acc_sum/n, test_acc, time.time()-start))</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">lr, num_epochs = <span class="number">0.001</span>, <span class="number">5</span></span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class="line">train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)</span><br></pre></td></tr></table></figure><h2 id="深度卷积神经网络（AlexNet）"><a href="#深度卷积神经网络（AlexNet）" class="headerlink" title="深度卷积神经网络（AlexNet）"></a>深度卷积神经网络（AlexNet）</h2><p>我们在上一节看到，神经网络可以直接基于图像的原始像素进行分类。这种称为端到端（end-to-end）的方法节省了很多中间步骤。然而，在很长一段时间里更流行的是研究者通过勤劳与智慧所设计并生成的手工特征。这类图像分类研究的主要流程是：<br>获取图像数据集；<br>使用已有的特征提取函数生成图像的特征；<br>使用机器学习模型对图像的特征分类。<br>当时认为的机器学习部分仅限最后这一步。如果那时候跟机器学习研究者交谈，他们会认为机器学习既重要又优美。优雅的定理证明了许多分类器的性质。机器学习领域生机勃勃、严谨而且极其有用。然而，如果跟计算机视觉研究者交谈，则是另外一幅景象。他们会告诉你图像识别里“不可告人”的现实是：计算机视觉流程中真正重要的是数据和特征。也就是说，使用较干净的数据集和较有效的特征甚至比机器学习模型的选择对图像分类结果的影响更大。</p><h3 id="学习特征表示"><a href="#学习特征表示" class="headerlink" title="学习特征表示"></a>学习特征表示</h3><p>既然特征如此重要，它该如何表示呢？<br>我们已经提到，在相当长的时间里，特征都是基于各式各样手工设计的函数从数据中提取的。事实上，不少研究者通过提出新的特征提取函数不断改进图像分类结果。这一度为计算机视觉的发展做出了重要贡献。</p><p>然而，另一些研究者则持异议。他们认为特征本身也应该由学习得来。他们还相信，为了表征足够复杂的输入，特征本身应该分级表示。持这一想法的研究者相信，多层神经网络可能可以学得数据的多级表征，并逐级表示越来越抽象的概念或模式。以图像分类为例，以物体边缘检测为例。在多层神经网络中，图像的第一级的表示可以是在特定的位置和⻆度是否出现边缘；而第二级的表示说不定能够将这些边缘组合出有趣的模式，如花纹；在第三级的表示中，也许上一级的花纹能进一步汇合成对应物体特定部位的模式。这样逐级表示下去，最终，模型能够较容易根据最后一级的表示完成分类任务。需要强调的是，输入的逐级表示由多层模型中的参数决定，而这些参数都是学出来的。</p><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>2012年，AlexNet横空出世。AlexNet使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。它首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状。<br>AlexNet跟LeNet结构类似，但使用了更多的卷积层和更大的参数空间来拟合大规模数据集ImageNet。它是浅层神经网络和深度神经网络的分界线。<br>两者具体对比如下：<br>第一，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。<br>AlexNet第一层中的卷积窗口形状是11×11。因为ImageNet中绝大多数图像的高和宽均比MNIST图像的高和宽大10倍以上，ImageNet图像的物体占用更多的像素，所以需要更大的卷积窗口来捕获物体。第二层中的卷积窗口形状减小到5×5，之后全采用3×3。此外，第一、第二和第五个卷积层之后都使用了窗口形状为3×3、步幅为2的最大池化层。而且，AlexNet使用的卷积通道数也大于LeNet中的卷积通道数数十倍。<br>紧接着最后一个卷积层的是两个输出个数为4096的全连接层。这两个巨大的全连接层带来将近1 GB的模型参数。由于早期显存的限制，最早的AlexNet使用双数据流的设计使一个GPU只需要处理一半模型。幸运的是，显存在过去几年得到了长足的发展，因此通常我们不再需要这样的特别设计了。<br>第二，AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。一方面，ReLU激活函数的计算更简单，例如它并没有sigmoid激活函数中的求幂运算。另一方面，ReLU激活函数在不同的参数初始化方法下使模型更容易训练。这是由于当sigmoid激活函数输出极接近0或1时，这些区域的梯度几乎为0，从而造成反向传播无法继续更新部分模型参数；而ReLU激活函数在正区间的梯度恒为1。因此，若模型参数初始化不当，sigmoid函数可能在正区间得到几乎为0的梯度，从而令模型无法得到有效训练。<br>第三，AlexNet通过丢弃法来控制全连接层的模型复杂度。而LeNet并没有使用丢弃法。<br>第四，AlexNet引入了大量的图像增广，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。</p><p>虽然看上去AlexNet的实现比LeNet的实现也就多了几行代码而已，但这个观念上的转变和真正优秀实验结果的产生令学术界付出了很多年。<br>（1）定义模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># AlexNet所使用的数据集是ImageNet</span></span><br><span class="line"><span class="comment"># 这里使用的输入图像是单通道的尺寸为224*224</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            <span class="comment"># 使用较大的11 x 11窗口来捕获物体。同时使用步幅4来较大幅度减小输出高和宽</span></span><br><span class="line">            <span class="comment"># 这里使用的输出通道数比LeNet中的也要大很多</span></span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, <span class="number">11</span>, <span class="number">4</span>), <span class="comment"># (输入通道，输出通道，卷积核尺寸，步幅，填充)，所以输出尺寸为(224-11)/4+1=54 这里不能整除，所以向下取整</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>), <span class="comment"># 所以输出尺寸为(54-3)/2+1=26，通道数仍为96，池化层是默认向下取整，可以改变ceil_mode参数来改成向上取整</span></span><br><span class="line">            <span class="comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，这是因为(x-5+2*2)/1+1=x</span></span><br><span class="line">            <span class="comment"># 且增大输出通道数</span></span><br><span class="line">            nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>), <span class="comment"># 输出为(26-5+2*2)/1+1=26</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>), <span class="comment"># (26-3)/2+1 = 12</span></span><br><span class="line">            <span class="comment"># 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数</span></span><br><span class="line">            <span class="comment"># 前两个卷积层后不使用池化层来减小输入的高和宽</span></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># 输出为(12-3+2*1)/1+1=12</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># 12</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># 12</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>) <span class="comment"># (12-3)/2+1=5</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">256</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        feature = self.conv(img)</span><br><span class="line">        output = self.fc(feature.view(img.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">net = AlexNet()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure><p>（2）读取数据<br>虽然论文中AlexNet使用ImageNet数据集，但因为ImageNet数据集训练时间较长，我们仍用前面的Fashion-MNIST数据集来演示AlexNet。读取数据的时候我们额外做了一步将图像高和宽扩大到AlexNet使用的图像高和宽224。这个可以通过torchvision.transforms.Resize实例来实现。也就是说，我们在ToTensor实例前使用Resize实例，然后使用Compose实例来将这两个变换串联以方便调用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将读取数据的步骤封装成一个函数，方便调用</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span>(<span class="params">batch_size, resize=<span class="literal">None</span>, root=<span class="string">&#x27;.&#x27;</span></span>):</span></span><br><span class="line">    trans = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        trans.append(torchvision.transforms.Resize(size=resize))</span><br><span class="line"></span><br><span class="line">    trans.append(torchvision.transforms.ToTensor())</span><br><span class="line">    transform = torchvision.transforms.Compose(trans)</span><br><span class="line">    mnist_train = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    mnist_test = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;.&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br><span class="line">    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size = batch_size, shuffle=<span class="literal">False</span>, num_workers=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br></pre></td></tr></table></figure><p>（3）训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分类准确度测量函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">data_iter, net, device=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        <span class="comment"># 如果没指定device，则使用net的device</span></span><br><span class="line">        device = <span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line"></span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">                net.<span class="built_in">eval</span>() <span class="comment"># 评估模式，这会关闭dropout</span></span><br><span class="line">                acc_sum += (net(X.to(device)).argmax(dim=<span class="number">1</span>)==y.to(device)).<span class="built_in">float</span>().<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">                net.train() <span class="comment"># 改回训练模式</span></span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> acc_sum / n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将训练过程封装起来，方便调用</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch5</span>(<span class="params">net, train_iter, test_iter, batch_size, optimizer, device, num_epochs</span>):</span></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;training on&#x27;</span>, device)</span><br><span class="line">    loss = torch.nn.CrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            train_l_sum += l.cpu().item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&#x27;</span> </span><br><span class="line">              % (epoch+<span class="number">1</span>, train_l_sum/n, train_acc_sum/n, test_acc, time.time()-start))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">lr, num_epochs = <span class="number">0.001</span>, <span class="number">5</span></span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class="line">train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)</span><br><span class="line"><span class="comment"># 相对于LeNet，由于图片尺寸变大了而且模型变大了，所以需要更大的显存，也需要更长的训练时间了。</span></span><br></pre></td></tr></table></figure><h2 id="使用重复元素的网络（VGG）"><a href="#使用重复元素的网络（VGG）" class="headerlink" title="使用重复元素的网络（VGG）"></a>使用重复元素的网络（VGG）</h2><p>AlexNet在LeNet的基础上增加了3个卷积层。但AlexNet作者对它们的卷积窗口、输出通道数和构造顺序均做了大量的调整。虽然AlexNet指明了深度卷积神经网络可以取得出色的结果，但并没有提供简单的规则以指导后来的研究者如何设计新的网络。</p><p>接下来会介绍几种不同的深度网络设计思路。</p><p>本节介绍VGG，它的名字来源于论文作者所在的实验室Visual Geometry Group。VGG提出了可以通过重复使用简单的基础块来构建深度模型的思路。</p><h3 id="VGG块"><a href="#VGG块" class="headerlink" title="VGG块"></a>VGG块</h3><p>VGG块的组成规律是：连续使用数个相同的填充为1、窗口形状为3乘3的卷积层后接上一个步幅为2、窗口形状为2乘2的最大池化层。卷积层保持输入的高和宽不变（因为(h-3+2x1）+1=h），而池化层则对其减半（因为(h-2)/2+1=h/2）。<br>对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核优于采用大的卷积核，因为可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。例如，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg_block</span>(<span class="params">num_convs, in_channels, out_channels</span>):</span></span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        blk.append(nn.ReLU())</span><br><span class="line">    blk.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*blk)</span><br></pre></td></tr></table></figure><h3 id="VGG网络"><a href="#VGG网络" class="headerlink" title="VGG网络"></a>VGG网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这个自定义层是将(n, c, h, w)拉伸成(n, c*h*w)，即将图像转成向量</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlattenLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 整个vgg网络前面是若干个卷积块，后面是3个全连接层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span>(<span class="params">conv_arch, fc_features, fc_hidden_units=<span class="number">4096</span></span>):</span></span><br><span class="line">    net = nn.Sequential()</span><br><span class="line">    <span class="comment"># 整个网络的卷积层部分</span></span><br><span class="line">    <span class="comment"># conv_arch参数包含了上面的vgg块的三个参数：块的数目、输入通道、输出通道</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, (num_convs, in_channels, out_channels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(conv_arch):</span><br><span class="line">        net.add_module(<span class="string">&#x27;vgg_block_&#x27;</span> + <span class="built_in">str</span>(i+<span class="number">1</span>), vgg_block(num_convs, in_channels, out_channels))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整个网络的全连接层部分</span></span><br><span class="line">    net.add_module(<span class="string">&quot;fc&quot;</span>, nn.Sequential(</span><br><span class="line">        FlattenLayer(),</span><br><span class="line">        <span class="comment"># fc_features就是前面经过卷积操作后图像的尺寸c*h*w, fc_hidden_units是隐藏层的神经元个数</span></span><br><span class="line">        nn.Linear(fc_features, fc_hidden_units),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(fc_hidden_units, fc_hidden_units),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(fc_hidden_units, <span class="number">10</span>)</span><br><span class="line">    ))</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"><span class="comment"># 有5个卷积块，前2块是单卷积层，后3块是双卷积层，即连续做两次卷积</span></span><br><span class="line"><span class="comment"># 经过5个vgg_block，宽和高会减半5次，变成224/(2^5)=224/32=7</span></span><br><span class="line"><span class="comment"># 同时，通道数也在翻倍，起始是1个通道，之后不断翻倍，直到512个通道</span></span><br><span class="line"><span class="comment"># 因为这个网络使用了8个卷积层和3个全连接层，所以经常被称为VGG-11。 </span></span><br><span class="line">conv_arch = ((<span class="number">1</span>, <span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">64</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">128</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">256</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>, <span class="number">512</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 经过上面的卷积操作后，输出通道为512，图像尺寸为7，所以输入到下面的全连接层的向量就是512*7*7</span></span><br><span class="line">fc_features = <span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span></span><br><span class="line"><span class="comment"># 全连接层的隐藏层的神经元个数，这个可以任意设定</span></span><br><span class="line">fc_hidden_units = <span class="number">4096</span></span><br><span class="line"><span class="comment"># 构造网络</span></span><br><span class="line">net = vgg(conv_arch, fc_features, fc_hidden_units)</span><br></pre></td></tr></table></figure><p>模型加载和训练过程与上一节的AlexNet相同。</p><h2 id="网络中的网络（NiN）"><a href="#网络中的网络（NiN）" class="headerlink" title="网络中的网络（NiN）"></a>网络中的网络（NiN）</h2><p>前几节介绍的LeNet、AlexNet和VGG在设计上的共同之处是：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。其中，AlexNet和VGG对LeNet的改进主要在于如何对这两个模块加宽（增加通道数）和加深。<br>网络中的网络（NiN）则提出了另外一个思路，即重复使用由卷积层和代替全连接层的1乘1卷积层构成的NiN块来构建深层网络。<br>NiN去除了容易造成过拟合的全连接输出层，而是将其替换成输出通道数等于标签类别数的NiN块和全局平均池化层。<br>NiN的以上设计思想影响了后面一系列卷积神经网络的设计。</p><p>加粗！！：NiN因为使用了全局平均池化层，从而使得每个通道的宽和高都为1，这样就使得输出与输入图片的尺寸无关，极大地提高了模型的灵活性，而之前的LeNet、AlexNet和VGG必须要给定特定尺寸的图片才能运行，否则会与全连接层的输入不匹配。</p><h3 id="NiN块"><a href="#NiN块" class="headerlink" title="NiN块"></a>NiN块</h3><p>卷积层的输入和输出通常是四维数组（样本，通道，高，宽），而全连接层的输入和输出则通常是二维数组（样本，特征）。如果想在全连接层后再接上卷积层，则需要将全连接层的输出变换为四维。而1乘1卷积层可以看成全连接层，其中空间维度（高和宽）上的每个元素相当于样本，通道相当于特征。因此，NiN使用1乘1卷积层来替代全连接层，从而使空间信息能够自然传递到后面的层中去。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NiN块是NiN中的基础块。</span></span><br><span class="line"><span class="comment"># 它由一个卷积层加两个充当全连接层的1×11×1卷积层串联而成。</span></span><br><span class="line"><span class="comment"># 其中第一个卷积层的超参数可以自行设置，而第二和第三个卷积层的超参数一般是固定的。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nin_block</span>(<span class="params">in_channels, out_channels, kernel_size, stride, padding</span>):</span></span><br><span class="line">    blk = nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.ReLU()</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> blk</span><br></pre></td></tr></table></figure><h3 id="NiN网络"><a href="#NiN网络" class="headerlink" title="NiN网络"></a>NiN网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GlobalAvgPool2d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现</span></span><br><span class="line">    <span class="comment"># 这样就可以将输入的图像平均池化成一个1*1大小的元素</span></span><br><span class="line">    <span class="comment"># 再配合上下面的FlattenLayer，就起到了最后全连接输出的效果</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> F.avg_pool2d(x, kernel_size = x.size()[<span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个自定义层是将(n, c, h, w)拉伸成(n, c*h*w)，即将图像转成向量</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlattenLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    <span class="comment"># NiN是在AlexNet问世不久后提出的。它们的卷积层设定有类似之处。</span></span><br><span class="line">    <span class="comment"># NiN使用卷积窗口形状分别为11×1111×11、5×55×5和3×33×3的卷积层，相应的输出通道数也与AlexNet中的一致。</span></span><br><span class="line">    nin_block(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">0</span>), <span class="comment"># 输出为(224-11)/4+1=54</span></span><br><span class="line">    <span class="comment"># 每个NiN块后接一个步幅为2、窗口形状为3×33×3的最大池化层</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>), <span class="comment"># 输出为(54-3)/2+1=26 </span></span><br><span class="line">    nin_block(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>), <span class="comment"># 输出为(26-5+2*2)/1+1=26</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>), <span class="comment"># 输出为(26-3)/2+1=12</span></span><br><span class="line">    nin_block(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>), <span class="comment"># (12-3+2*1)/1+1 = 12</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>), <span class="comment"># (12-3)/2+1=5</span></span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    nin_block(<span class="number">384</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>), <span class="comment"># (5-3+2*1)/1+1=5</span></span><br><span class="line">    GlobalAvgPool2d(), <span class="comment"># (5-5)/1+1=1</span></span><br><span class="line">    FlattenLayer()</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure><h2 id="含并行连结的网络（GoogLeNet）"><a href="#含并行连结的网络（GoogLeNet）" class="headerlink" title="含并行连结的网络（GoogLeNet）"></a>含并行连结的网络（GoogLeNet）</h2><p>在2014年的ImageNet图像识别挑战赛中，一个名叫GoogLeNet的网络结构大放异彩。它虽然在名字上向LeNet致敬，但在网络结构上已经很难看到LeNet的影子。GoogLeNet吸收了NiN中网络串联网络的思想，并在此基础上做了很大改进。</p><h3 id="Inception块"><a href="#Inception块" class="headerlink" title="Inception块"></a>Inception块</h3><p>GoogLeNet中的基础卷积块叫作Inception块，得名于同名电影《盗梦空间》（Inception）。其结构如图所示：<br><img src="https://user-images.githubusercontent.com/6218739/75971838-4e3c2700-5f0d-11ea-8d34-cbe8e187f07b.png" alt="image"></p><p>可以看出，Inception块里有4条并行的线路。前3条线路使用窗口大小分别是1乘1、3乘3和5乘5的卷积层来抽取不同空间尺寸下的信息，其中中间2个线路会对输入先做1乘1卷积来减少输入通道数，以降低模型复杂度。第四条线路则使用3乘3最大池化层，后接1乘1卷积层来改变通道数。4条线路都使用了合适的填充来使输入与输出的高和宽一致。最后我们将每条线路的输出在通道维上连结，并输入接下来的层中去。<br>其中Inception块的通道数分配之比是在ImageNet数据集上通过大量的实验得来的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Inception块中可以自定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inception</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># c1 - c4为每条线路里的层的输出通道数</span></span><br><span class="line">    <span class="comment"># c2和c3的内部因为都有两个层，所以输出通道也要有两个，来分别设定</span></span><br><span class="line">    <span class="comment"># c4的最大池化层不需要通道设定，所以c4的通道也只有一个即可</span></span><br><span class="line">    <span class="comment"># 假设输入图像的尺寸为h，经过下面的计算可得，输出图像的尺寸仍为h</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, c1, c2, c3, c4</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 线路1，单1 x 1卷积层</span></span><br><span class="line">        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=<span class="number">1</span>) <span class="comment"># (h-1)+1=h</span></span><br><span class="line">        <span class="comment"># 线路2，1 x 1卷积层后接3 x 3卷积层</span></span><br><span class="line">        self.p2_1 = nn.Conv2d(in_c, c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>) <span class="comment"># (h-1)+1=h</span></span><br><span class="line">        self.p2_2 = nn.Conv2d(c2[<span class="number">0</span>], c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) <span class="comment"># (h-3+2*1)+1=h</span></span><br><span class="line">        <span class="comment"># 线路3，1 x 1卷积层后接5 x 5卷积层</span></span><br><span class="line">        self.p3_1 = nn.Conv2d(in_c, c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>) <span class="comment"># (h-1)+1=h</span></span><br><span class="line">        self.p3_2 = nn.Conv2d(c3[<span class="number">0</span>], c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>) <span class="comment"># (h-5+2*2)+1=h</span></span><br><span class="line">        <span class="comment"># 线路4，3 x 3最大池化层后接1 x 1卷积层</span></span><br><span class="line">        self.p4_1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>) <span class="comment"># (h-3+2*1)/1+1=h</span></span><br><span class="line">        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=<span class="number">1</span>) <span class="comment"># (h-1)+1=h</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        p1 = F.relu(self.p1_1(x))</span><br><span class="line">        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x)))) <span class="comment"># 注意这里输入的也是x</span></span><br><span class="line">        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x)))) <span class="comment"># 注意这里输入的也是x</span></span><br><span class="line">        p4 = F.relu(self.p4_2(self.p4_1(x)))</span><br><span class="line">        <span class="keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="number">1</span>) <span class="comment"># 在通道维上进行连结</span></span><br></pre></td></tr></table></figure><h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GoogLeNet跟VGG一样，在主体卷积部分中使用5个模块（block），每个模块之间使用步幅为2的3×3最大池化层来减小输出高宽。</span></span><br><span class="line"><span class="comment"># 图片尺寸就以文中给出的96为例</span></span><br><span class="line"><span class="comment"># 第一模块使用一个64通道的7×77×7卷积层，输入通道为1，输出通道为64</span></span><br><span class="line">b1 = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>), <span class="comment"># (96-7+2*3)/2+1=48</span></span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>) <span class="comment"># (48-3+2*1)/2+1=24</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 第二模块使用2个卷积层和1个池化层，输入通道为64，输出通道为192</span></span><br><span class="line">b2 = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>), <span class="comment"># (24-1)+1=24</span></span><br><span class="line">    nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), <span class="comment">#(24-3+2*1)+1=24</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>) <span class="comment"># (24-3+2*1)/2+1=12</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 第三模块串联2个完整的Inception块</span></span><br><span class="line">b3 = nn.Sequential(</span><br><span class="line">    <span class="comment"># 第1个Inception块的输入通道为192，输出通道为64+128+32+32=256</span></span><br><span class="line">    Inception(<span class="number">192</span>, <span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>), <span class="comment"># 12</span></span><br><span class="line">    <span class="comment"># 第1个Inception块的输入通道为256，输出通道为128+192+96+64=480</span></span><br><span class="line">    Inception(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>), <span class="comment"># 12</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>) <span class="comment"># (12-3+2*1)/2+1=6</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 第四模块串联5个Inception块</span></span><br><span class="line">b4 = nn.Sequential(</span><br><span class="line">    <span class="comment"># 第1个Inception块的输入通道为480， 输出通道为192+208+48+64=512</span></span><br><span class="line">    Inception(<span class="number">480</span>, <span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>), <span class="comment"># 6</span></span><br><span class="line">    <span class="comment"># 输入512， 输出160+224+64+64=512</span></span><br><span class="line">    Inception(<span class="number">512</span>, <span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>), <span class="comment"># 6</span></span><br><span class="line">    <span class="comment"># 输入512， 输出128+256+64+64=512</span></span><br><span class="line">    Inception(<span class="number">512</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>), <span class="comment"># 6</span></span><br><span class="line">    <span class="comment"># 输入512， 输出112+288+64+64=528</span></span><br><span class="line">    Inception(<span class="number">512</span>, <span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>), <span class="comment"># 6</span></span><br><span class="line">    <span class="comment"># 输入528， 输出256+320+128+128=832</span></span><br><span class="line">    Inception(<span class="number">528</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>), <span class="comment"># 6</span></span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>) <span class="comment"># (6-3+2*1)/2+1=3 </span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 第五模块串联2个Inception块</span></span><br><span class="line">b5 = nn.Sequential(</span><br><span class="line">    <span class="comment"># 输入832， 输出256+320+128+128=832</span></span><br><span class="line">    Inception(<span class="number">832</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>), <span class="comment"># 3</span></span><br><span class="line">    <span class="comment"># 输入832， 输出384+384+128+128=1024</span></span><br><span class="line">    Inception(<span class="number">832</span>, <span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>), <span class="comment"># 3</span></span><br><span class="line">    <span class="comment"># 这一步非常重要，使用全局平均池化层来将每个通道的高和宽变成1，这样就与输入图像的尺寸无关</span></span><br><span class="line">    GlobalAvgPool2d() <span class="comment"># 1</span></span><br><span class="line">)</span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    b1, b2, b3, b4, b5,</span><br><span class="line">    FlattenLayer(), <span class="comment"># (N, 1024, 1, 1)转化成向量(N, 1024)</span></span><br><span class="line">    nn.Linear(<span class="number">1024</span>, <span class="number">10</span>) <span class="comment"># 全连接层输出类别，这里的1024是之前的通道数，与图像尺寸无关</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>加载数据时，这里的尺寸改成了96，也可以继续用之前的224，GoogLeNet因为使用了全局平均池化，所以对输入图片尺寸不敏感：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">96</span>)</span><br></pre></td></tr></table></figure><h2 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h2><p>在之前的例子里，我们对输入数据做了标准化处理：处理后的任意一个特征在数据集中所有样本上的均值为0、标准差为1。标准化处理输入数据使各个特征的分布相近：这往往更容易训练出有效的模型。<br>通常来说，数据标准化预处理对于浅层模型就足够有效了。随着模型训练的进行，当每层中参数更新时，靠近输出层的输出较难出现剧烈变化。但对深层神经网络来说，即使输入数据已做标准化，训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化。这种计算数值的不稳定性通常令我们难以训练出有效的深度模型。<br>批量归一化的提出正是为了应对深度模型训练的挑战。在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使整个神经网络在各层的中间输出的数值更稳定。<br>批量归一化和下一节将要介绍的残差网络为训练和设计深度模型提供了两类重要思路。<br>对全连接层和卷积层做批量归一化的方法稍有不同。<br>（1）对全连接层做批量归一化：将批量归一化层置于全连接层中的仿射变换和激活函数之间，批量归一化层引入了两个可以学习的模型参数，拉伸（scale）参数$\gamma$和偏移（shift）参数$\beta$。<br>（2）对卷积层做批量归一化：对卷积层来说，批量归一化发生在卷积计算之后、应用激活函数之前。如果卷积计算输出多个通道，我们需要对这些通道的输出分别做批量归一化，且每个通道都拥有独立的拉伸和偏移参数，并均为标量。<br>（3）预测时的批量归一化：使用批量归一化训练时，我们可以将批量大小设得大一点，从而使批量内样本的均值和方差的计算都较为准确。将训练好的模型用于预测时，我们希望模型对于任意输入都有确定的输出。因此，单个样本的输出不应取决于批量归一化所需要的随机小批量中的均值和方差。一种常用的方法是通过移动平均估算整个训练数据集的样本均值和方差，并在预测时使用它们得到确定的输出。可见，和丢弃层一样，批量归一化层在训练模式和预测模式下的计算结果也是不一样的。</p><p>Pytorch中nn模块定义的BatchNorm1d和BatchNorm2d类使用起来非常简单，二者分别用于全连接层和卷积层，都需要指定输入的num_features参数值，对于全连接层来说该值应为输出个数，对于卷积层来说则为输出通道数。</p><h2 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h2><p>让我们先思考一个问题：对神经网络模型添加新的层，充分训练后的模型是否只可能更有效地降低训练误差？理论上，原模型解的空间只是新模型解的空间的子空间。也就是说，如果我们能将新添加的层训练成恒等映射f(x)=x，新模型和原模型将同样有效。由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差。然而在实践中，添加过多的层后训练误差往往不降反升。即使利用批量归一化带来的数值稳定性使训练深层模型更加容易，该问题仍然存在。针对这一问题，何恺明等人提出了残差网络（ResNet）。它在2015年的ImageNet图像识别挑战赛夺魁，并深刻影响了后来的深度神经网络的设计。<br>残差块通过跨层的数据通道从而能够训练出有效的深度神经网络。</p><h3 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h3><p>在残差块中，输入可通过跨层的数据线路更快地向前传播。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 残差块可以设定输出通道数、是否使用额外的1×11×1卷积层来修改通道数以及卷积层的步幅，即可以改变输出大小。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Residual</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, use_1x1conv=<span class="literal">False</span>, stride=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># ResNet沿用了VGG全3×33×3卷积层的设计。</span></span><br><span class="line">        <span class="comment"># 残差块里首先有2个有相同输出通道数的3×33×3卷积层。</span></span><br><span class="line">        <span class="comment"># 每个卷积层后接一个批量归一化层和ReLU激活函数。</span></span><br><span class="line">        <span class="comment"># 然后将输入跳过这两个卷积运算后直接加在最后的ReLU激活函数前。</span></span><br><span class="line">        <span class="comment"># 这样的设计要求两个卷积层的输出与输入形状一样，从而可以相加。如果想改变通道数，就需要引入一个额外的1×1卷积层来将输入变换成需要的形状后再做相加运算。</span></span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=stride)</span><br><span class="line">        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=stride)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        <span class="keyword">return</span> F.relu(Y + X)</span><br></pre></td></tr></table></figure><h3 id="ResNet模型"><a href="#ResNet模型" class="headerlink" title="ResNet模型"></a>ResNet模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ResNet的前两层跟GoogLeNet中的一样：在输出通道数为64、步幅为2的7×7卷积层后接步幅为2的3×3的最大池化层。</span></span><br><span class="line"><span class="comment"># 不同之处在于ResNet每个卷积层后增加的批量归一化层。</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"><span class="comment"># GoogLeNet在后面接了4个由Inception块组成的模块。ResNet则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet_block</span>(<span class="params">in_channels, out_channels, num_residuals, first_block=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> first_block:</span><br><span class="line">        <span class="comment"># 第一个模块的通道数同输入通道数一致</span></span><br><span class="line">        <span class="keyword">assert</span> in_channels == out_channels</span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_residuals):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> first_block:</span><br><span class="line">            <span class="comment"># 后面的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。</span></span><br><span class="line">            blk.append(Residual(in_channels, out_channels, use_1x1conv=<span class="literal">True</span>, stride=<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 在第一个模块中，由于之前已经使用了步幅为2的最大池化层，所以无须减小高和宽。</span></span><br><span class="line">            blk.append(Residual(out_channels, out_channels))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*blk)</span><br><span class="line"><span class="comment"># 为ResNet加入所有残差块。这里每个模块使用两个残差块。</span></span><br><span class="line">net.add_module(<span class="string">&#x27;resnet_block1&#x27;</span>, resnet_block(<span class="number">64</span>, <span class="number">64</span>, <span class="number">2</span>, first_block=<span class="literal">True</span>))</span><br><span class="line">net.add_module(<span class="string">&#x27;resnet_block2&#x27;</span>, resnet_block(<span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>))</span><br><span class="line">net.add_module(<span class="string">&#x27;resnet_block3&#x27;</span>, resnet_block(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line">net.add_module(<span class="string">&#x27;resnet_block4&#x27;</span>, resnet_block(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 最后，与GoogLeNet一样，加入全局平均池化层后接上全连接层输出。</span></span><br><span class="line">net.add_module(<span class="string">&#x27;global_avg_pool&#x27;</span>, GlobalAvgPool2d()) <span class="comment"># GlobalAvgPool2d的输出: (Batch, 512, 1, 1)</span></span><br><span class="line">net.add_module(<span class="string">&#x27;fc&#x27;</span>, nn.Sequential(FlattenLayer(), nn.Linear(<span class="number">512</span>, <span class="number">10</span>)))</span><br><span class="line"><span class="comment"># 这里每个模块里有4个卷积层（不计算1×11×1卷积层），加上最开始的卷积层和最后的全连接层，共计18层。这个模型通常也被称为ResNet-18。</span></span><br><span class="line"><span class="comment"># 通过配置不同的通道数和模块里的残差块数可以得到不同的ResNet模型，例如更深的含152层的ResNet-152。</span></span><br><span class="line"><span class="comment"># 虽然ResNet的主体架构跟GoogLeNet的类似，但ResNet结构更简单，修改也更方便。这些因素都导致了ResNet迅速被广泛使用。</span></span><br></pre></td></tr></table></figure><p>拿个测试数据跑一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"><span class="keyword">for</span> name, layer <span class="keyword">in</span> net.named_children():</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(name, <span class="string">&#x27;output shape = &#x27;</span>, X.shape)</span><br></pre></td></tr></table></figure><p>最后，加载数据和训练模型都跟之前的一样。</p><h2 id="稠密连接网络（DenseNet）"><a href="#稠密连接网络（DenseNet）" class="headerlink" title="稠密连接网络（DenseNet）"></a>稠密连接网络（DenseNet）</h2><p>ResNet中的跨层连接设计引申出了数个后续工作，比如这里的稠密连接网络（DenseNet）。<br>假设将部分前后相邻的运算抽象为模块A和模块B。与ResNet的主要区别在于，DenseNet里模块B的输出不是像ResNet那样和模块A的输出相加，而是在通道维上连结。这样模块A的输出可以直接传入模块B后面的层。在这个设计里，模块A直接跟模块B后面的所有层连接在了一起。这也是它被称为“稠密连接”的原因。<br>DenseNet的主要构建模块是稠密块（dense block）和过渡层（transition layer）。前者定义了输入和输出是如何连结的，后者则用来控制通道数，使之不过大。</p><h3 id="稠密块"><a href="#稠密块" class="headerlink" title="稠密块"></a>稠密块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DenseNet使用了ResNet改良版的“批量归一化、激活和卷积”结构，首先在conv_block函数里实现这个结构。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_block</span>(<span class="params">in_channels, out_channels</span>):</span></span><br><span class="line">    blk = nn.Sequential(</span><br><span class="line">        nn.BatchNorm2d(in_channels),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line"><span class="comment"># 稠密块由多个conv_block组成，每块使用相同的输出通道数。</span></span><br><span class="line"><span class="comment"># 卷积块的通道数控制了输出通道数相对于输入通道数的增长，因此也被称为增长率（growth rate）</span></span><br><span class="line"><span class="comment"># 比如，定义一个有2个输出通道数为10的卷积块。使用通道数为3的输入时，我们会得到通道数为3+2×10=23的输出，增长率就是10</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DenseBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_convs, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        net = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">            in_c = in_channels + i* out_channels</span><br><span class="line">            net.append(conv_block(in_c, out_channels))</span><br><span class="line"></span><br><span class="line">        self.net = nn.ModuleList(net)</span><br><span class="line">        self.out_channels = in_channels + num_convs * out_channels <span class="comment"># 计算输出通道数</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> self.net:</span><br><span class="line">            Y = blk(X)</span><br><span class="line">            X = torch.cat((X, Y), dim=<span class="number">1</span>) <span class="comment"># 在通道维上将输入和输出连结</span></span><br><span class="line">        <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><h3 id="过渡层"><a href="#过渡层" class="headerlink" title="过渡层"></a>过渡层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于每个稠密块都会带来通道数的增加，使用过多则会带来过于复杂的模型。</span></span><br><span class="line"><span class="comment"># 过渡层用来控制模型复杂度。它通过1×11×1卷积层来减小通道数，并使用步幅为2的平均池化层减半高和宽，从而进一步降低模型复杂度。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transition_block</span>(<span class="params">in_channels, out_channels</span>):</span></span><br><span class="line">    blk = nn.Sequential(</span><br><span class="line">        nn.BatchNorm2d(in_channels),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> blk</span><br></pre></td></tr></table></figure><h3 id="DenseNet模型"><a href="#DenseNet模型" class="headerlink" title="DenseNet模型"></a>DenseNet模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DenseNet首先使用同ResNet一样的单卷积层和最大池化层。</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 类似于ResNet接下来使用的4个残差块，DenseNet使用的是4个稠密块。</span></span><br><span class="line"><span class="comment"># 同ResNet一样，可以设置每个稠密块使用多少个卷积层。这里我们设成4，从而与上一节的ResNet-18保持一致。</span></span><br><span class="line"><span class="comment"># 稠密块里的卷积层通道数（即增长率）设为32，所以每个稠密块将增加128个通道。</span></span><br><span class="line">num_channels, growth_rate = <span class="number">64</span>, <span class="number">32</span> <span class="comment"># num_channels为当前的通道数</span></span><br><span class="line">num_convs_in_dense_blocks = [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>] <span class="comment"># length为4，表明有4个稠密块，每个元素都是4，表明每个稠密块有4个卷积层</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, num_convs <span class="keyword">in</span> <span class="built_in">enumerate</span>(num_convs_in_dense_blocks):</span><br><span class="line">    DB = DenseBlock(num_convs, num_channels, growth_rate)</span><br><span class="line">    net.add_module(<span class="string">&#x27;DenseBlock_%d&#x27;</span> % i, DB)</span><br><span class="line">    <span class="comment"># 上一个稠密块的输出通道，这里用的是类.属性的用法</span></span><br><span class="line">    num_channels = DB.out_channels</span><br><span class="line">    <span class="comment"># 在稠密块之间加入通道数减半的过渡层</span></span><br><span class="line">    <span class="keyword">if</span> i != <span class="built_in">len</span>(num_convs_in_dense_blocks) - <span class="number">1</span>:</span><br><span class="line">        net.add_module(<span class="string">&#x27;transition_block_%d&#x27;</span> % i, transition_block(num_channels, num_channels // <span class="number">2</span>))</span><br><span class="line">        num_channels = num_channels // <span class="number">2</span></span><br><span class="line">net.add_module(<span class="string">&#x27;BN&#x27;</span>, nn.BatchNorm2d(num_channels))</span><br><span class="line">net.add_module(<span class="string">&#x27;relu&#x27;</span>, nn.ReLU())</span><br><span class="line"><span class="comment"># 与ResNet一样，最后加入全局平均池化层后接上全连接层输出。</span></span><br><span class="line">net.add_module(<span class="string">&#x27;global_avg_pool&#x27;</span>, GlobalAvgPool2d()) <span class="comment"># GlobalAvgPool2d的输出: (Batch, num_channels, 1, 1)</span></span><br><span class="line">net.add_module(<span class="string">&#x27;fc&#x27;</span>, nn.Sequential(FlattenLayer(), nn.Linear(num_channels, <span class="number">10</span>)))</span><br></pre></td></tr></table></figure><p>最后，加载数据和训练模型都跟之前的一样。</p><h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><p>本章先略过</p><h1 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h1><h2 id="优化与深度学习"><a href="#优化与深度学习" class="headerlink" title="优化与深度学习"></a>优化与深度学习</h2><p>虽然优化为深度学习提供了最小化损失函数的方法，但本质上，优化与深度学习的目标是有区别的。<br>由于优化算法的目标函数通常是一个基于训练数据集的损失函数，优化的目标在于降低训练误差。 而深度学习的目标在于降低泛化误差。为了降低泛化误差，除了使用优化算法降低训练误差以外，还需要注意应对过拟合。<br>在一个深度学习问题中，我们通常会预先定义一个损失函数。有了损失函数以后，我们就可以使用优化算法试图将其最小化。在优化中，这样的损失函数通常被称作优化问题的目标函数（objective function）。依据惯例，优化算法通常只考虑最小化目标函数。其实，任何最大化问题都可以很容易地转化为最小化问题，只需令目标函数的相反数为新的目标函数即可。<br>优化在深度学习中有很多挑战，比如局部最小值和鞍点。<br>（1）深度学习模型的目标函数可能有若干局部最优值。当一个优化问题的数值解在局部最优解附近时，由于目标函数有关解的梯度接近或变成零，最终迭代求得的数值解可能只令目标函数局部最小化而非全局最小化。<br>（2）梯度接近或变成零可能是由于当前解在局部最优解附近造成的。事实上，另一种可能性是当前解在鞍点（saddle point）附近。比如在鞍点位置，目标函数在x轴方向上是局部最小值，但在y轴方向上是局部最大值。<br>假设一个函数的输入为k维向量，输出为标量，那么它的海森矩阵（Hessian matrix）有k个特征值。该函数在梯度为0的位置上可能是局部最小值、局部最大值或者鞍点。<br>当函数的海森矩阵在梯度为零的位置上的特征值全为正时，该函数得到局部最小值。<br>当函数的海森矩阵在梯度为零的位置上的特征值全为负时，该函数得到局部最大值。<br>当函数的海森矩阵在梯度为零的位置上的特征值有正有负时，该函数得到鞍点。<br>随机矩阵理论告诉我们，对于一个大的高斯随机矩阵来说，任一特征值是正或者是负的概率都是0.5。那么，以上第一种情况的概率为 0.5的k次方。由于深度学习模型参数通常都是高维的（k很大），目标函数的鞍点通常比局部最小值更常见。</p><h2 id="梯度下降和随机梯度下降"><a href="#梯度下降和随机梯度下降" class="headerlink" title="梯度下降和随机梯度下降"></a>梯度下降和随机梯度下降</h2><p>下图中的公式清晰地解释了为什么梯度下降能降低目标函数的数值：<br><img src="https://user-images.githubusercontent.com/6218739/76134337-5bb1f800-6058-11ea-908d-a03ebaa1a44f.png" alt="image"><br>在深度学习里，目标函数通常是训练数据集中有关各个样本的损失函数的平均。当训练数据样本数很大时，梯度下降每次迭代的计算开销很高。<br>随机梯度下降（stochastic gradient descent，SGD）减少了每次迭代的计算开销。</p><h2 id="小批量随机梯度下降"><a href="#小批量随机梯度下降" class="headerlink" title="小批量随机梯度下降"></a>小批量随机梯度下降</h2><p>在每一次迭代中，梯度下降使用整个训练数据集来计算梯度，因此它有时也被称为批量梯度下降（batch gradient descent）。而随机梯度下降在每次迭代中只随机采样一个样本来计算梯度。我们还可以在每轮迭代中随机均匀采样多个样本来组成一个小批量，然后使用这个小批量来计算梯度。<br>在实际中，（小批量）随机梯度下降的学习率可以在迭代过程中自我衰减。<br>当批量大小为1时，小批量随机梯度下降算法即为随机梯度下降；当批量大小等于训练数据样本数时，该算法即为梯度下降。当批量较小时，每次迭代中使用的样本少，这会导致并行处理和内存使用效率变低。这使得在计算同样数目样本的情况下比使用更大批量时所花时间更多。当批量较大时，每个小批量梯度里可能含有更多的冗余信息。为了得到较好的解，批量较大时比批量较小时需要计算的样本数目可能更多，例如增大迭代周期数。</p><h2 id="动量法"><a href="#动量法" class="headerlink" title="动量法"></a>动量法</h2><p>目标函数有关自变量的梯度代表了目标函数在自变量当前位置下降最快的方向。因此，梯度下降也叫作最陡下降（steepest descent）。在每次迭代中，梯度下降根据自变量当前位置，沿着当前位置的梯度更新自变量。然而，如果自变量的迭代方向仅仅取决于自变量当前位置，这可能会带来一些问题。举个例子：同一位置上，假设目标函数在竖直方向比在水平方向的斜率的绝对值更大。因此，给定学习率，梯度下降迭代自变量时会使自变量在竖直方向比在水平方向移动幅度更大。那么，我们需要一个较小的学习率从而避免自变量在竖直方向上越过目标函数最优解。然而，这会造成自变量在水平方向上朝最优解移动变慢。<br>动量法的提出是为了解决梯度下降的上述问题。<br>（1）动量法使用了指数加权移动平均的思想。它将过去时间步的梯度做了加权平均，且权重按时间步指数衰减。<br>（2）动量法使得相邻时间步的自变量更新在方向上更加一致。<br>在PyTorch中，只需要通过参数momentum来指定动量超参数即可使用动量法。</p><h2 id="AdaGrad算法"><a href="#AdaGrad算法" class="headerlink" title="AdaGrad算法"></a>AdaGrad算法</h2><p>在之前介绍过的优化算法中，目标函数自变量的每一个元素在相同时间步都使用同一个学习率来自我迭代。<br>动量法依赖指数加权移动平均使得自变量的更新方向更加一致，从而降低发散的可能。而AdaGrad算法根据自变量在每个维度的梯度值的大小来调整各个维度上的学习率，从而避免统一的学习率难以适应所有维度的问题。<br>AdaGrad算法在迭代过程中不断调整学习率，并让目标函数自变量中每个元素都分别拥有自己的学习率。<br>使用AdaGrad算法时，自变量中每个元素的学习率在迭代过程中一直在降低（或不变）。<br>通过名称为Adagrad的优化器方法，我们便可使用PyTorch提供的AdaGrad算法来训练模型。</p><h2 id="RMSProp算法"><a href="#RMSProp算法" class="headerlink" title="RMSProp算法"></a>RMSProp算法</h2><p>RMSProp算法和AdaGrad算法的不同在于，RMSProp算法使用了小批量随机梯度按元素平方的指数加权移动平均来调整学习率。<br>通过名称为RMSprop的优化器方法，我们便可使用PyTorch提供的RMSProp算法来训练模型。注意，超参数$\gamma$通过alpha指定。</p><h2 id="AdaDelta算法"><a href="#AdaDelta算法" class="headerlink" title="AdaDelta算法"></a>AdaDelta算法</h2><p>除了RMSProp算法以外，另一个常用优化算法AdaDelta算法也针对AdaGrad算法在迭代后期可能较难找到有用解的问题做了改进。有意思的是，AdaDelta算法没有学习率这一超参数。AdaDelta算法没有学习率超参数，它通过使用有关自变量更新量平方的指数加权移动平均的项来替代RMSProp算法中的学习率。<br>通过名称为Adadelta的优化器方法，我们便可使用PyTorch提供的AdaDelta算法。它的超参数可以通过rho来指定。</p><h2 id="Adam算法"><a href="#Adam算法" class="headerlink" title="Adam算法"></a>Adam算法</h2><p>Adam算法在RMSProp算法基础上对小批量随机梯度也做了指数加权移动平均。所以Adam算法可以看做是RMSProp算法与动量法的结合。<br>Adam算法使用了偏差修正。<br>通过名称为“Adam”的优化器实例，我们便可使用PyTorch提供的Adam算法。</p><h1 id="计算性能"><a href="#计算性能" class="headerlink" title="计算性能"></a>计算性能</h1><h2 id="命令式编程和符号式编程"><a href="#命令式编程和符号式编程" class="headerlink" title="命令式编程和符号式编程"></a>命令式编程和符号式编程</h2><p>（1）命令式编程更方便。当我们在Python里使用命令式编程时，大部分代码编写起来都很直观。同时，命令式编程更容易调试。这是因为我们可以很方便地获取并打印所有的中间变量值，或者使用Python的调试工具。<br>（2）符号式编程更高效并更容易移植。一方面，在编译的时候系统容易做更多优化（因为在编译时系统能够完整地获取整个程序）；另一方面，符号式编程可以将程序变成一个与Python无关的格式，从而可以使程序在非Python环境下运行，以避开Python解释器的性能问题。<br>截止目前（2020年3月），PyTorch仅采用了命令式编程方式。</p><h2 id="异步计算"><a href="#异步计算" class="headerlink" title="异步计算"></a>异步计算</h2><p>以下一段是唐树森同学对PyTorch官网上的翻译。<br>默认情况下，PyTorch中的 GPU 操作是异步的。当调用一个使用 GPU 的函数时，这些操作会在特定的设备上排队但不一定会在稍后立即执行。这就使我们可以并行更多的计算，包括 CPU 或其他 GPU 上的操作。 一般情况下，异步计算的效果对调用者是不可见的，因为（1）每个设备按照它们排队的顺序执行操作，（2）在 CPU 和 GPU 之间或两个 GPU 之间复制数据时，PyTorch会自动执行必要的同步操作。因此，计算将按每个操作同步执行的方式进行。 可以通过设置环境变量CUDA_LAUNCH_BLOCKING = 1来强制进行同步计算。当 GPU 产生error时，这可能非常有用。（异步执行时，只有在实际执行操作之后才会报告此类错误，因此堆栈跟踪不会显示请求的位置。）</p><h2 id="自动并行计算"><a href="#自动并行计算" class="headerlink" title="自动并行计算"></a>自动并行计算</h2><p>PyTorch能有效地实现在不同设备上（比如两块GPU）自动并行计算。</p><h2 id="多GPU计算"><a href="#多GPU计算" class="headerlink" title="多GPU计算"></a>多GPU计算</h2><p>因为目前手头只有一块GPU，所以本节没法实战，故略过。<br>需要注意单主机多GPU计算与分布式计算的区别。</p><h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><h2 id="图像增广"><a href="#图像增广" class="headerlink" title="图像增广"></a>图像增广</h2><p>这个地方有几点提前注意：<br>（1）下面介绍的都是torchvision自带的函数，关于图像增广可以借助更专业的第三方库（比如可以将标注一块增广），比如：<br><a href="https://github.com/aleju/imgaug">Image augmentation for machine learning experiments</a><br>（2）为了在预测时得到确定的结果，我们通常只将图像增广应用在训练样本上，而不在预测时使用含随机操作的图像增广。此外，在实际PyTorch应用时，注意使用ToTensor将小批量图像转成PyTorch需要的格式，即形状为(批量大小, 通道数, 高, 宽)、值域在0到1之间且类型为32位浮点数。</p><p>图像增广（image augmentation）技术通过对训练图像做一系列随机改变，来产生相似但又不同的训练样本，从而扩大训练数据集的规模。图像增广的另一种解释是，随机改变训练样本可以降低模型对某些属性的依赖，从而提高模型的泛化能力。例如，我们可以对图像进行不同方式的裁剪，使感兴趣的物体出现在不同位置，从而减轻模型对物体出现位置的依赖性。我们也可以调整亮度、色彩等因素来降低模型对色彩的敏感度。可以说，在当年AlexNet的成功中，图像增广技术功不可没。</p><p>这部分涉及PIL、skimage、OpenCV、PyTorch Tensor，这四个有类似的地方，也有很多小区别，比如：<br>（1）PIL、skimage、OpenCV的图像通道都是h乘w乘c，即高乘宽乘通道，而PyTorch的ToTensor自己会转化为c乘h乘w，同时转为float后除以255（这里一定注意，如果ToTensor接收的是numpy的array，一定保证它是uint8格式，否则可能仅是通道顺序变化，而数值没有除以255）<br>（2）PIL的数据类型是Image对象，skimage和OpenCV都是numpy。</p><p>torchvision.transforms模块有大量现成的转换方法，不过需要注意的是有的方法输入的是PIL图像，如Resize；有的方法输入的是tensor，如Normalize；而还有的是用于二者转换，如ToTensor将PIL图像转换成tensor。一定要注意这点，使用时看清文档。</p><p>具体可以参考如下文章：<br><a href="https://zhuanlan.zhihu.com/p/52344534">OpenCV，PIL，Skimage你pick谁</a><br><a href="https://www.jianshu.com/p/dd08418c306f">opencv-PIL-matplotlib-Skimage-Pytorch图片读取区别与联系</a><br><a href="https://zhuanlan.zhihu.com/p/27382990">pytorch图像基本操作</a></p><h3 id="常用的图像增广方法"><a href="#常用的图像增广方法" class="headerlink" title="常用的图像增广方法"></a>常用的图像增广方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里使用PIL读取图像</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;drive/My Drive/cat1.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 翻转</span></span><br><span class="line"><span class="comment"># 左右翻转图像通常不改变物体的类别。它是最早也是最广泛使用的一种图像增广方法。</span></span><br><span class="line">horizon_flip = transforms.RandomHorizontalFlip()</span><br><span class="line"><span class="comment"># 上下翻转不如左右翻转通用。但是至少对于样例图像，上下翻转不会造成识别障碍。</span></span><br><span class="line">vertical_flip = transforms.RandomVerticalFlip()</span><br><span class="line"><span class="comment"># 裁剪</span></span><br><span class="line"><span class="comment"># 可以通过对图像随机裁剪来让物体以不同的比例出现在图像的不同位置</span></span><br><span class="line"><span class="comment"># 这同样能够降低模型对目标位置的敏感性。</span></span><br><span class="line"><span class="comment"># 每次随机裁剪出一块面积为原面积10%∼100%的区域，且该区域的宽和高之比随机取自0.5∼2，</span></span><br><span class="line"><span class="comment"># 然后再将该区域的宽和高分别缩放到200像素。</span></span><br><span class="line">shape_aug = transforms.RandomResizedCrop(<span class="number">200</span>, scale=(<span class="number">0.1</span>, <span class="number">1</span>), ratio=(<span class="number">0.5</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 变化颜色</span></span><br><span class="line"><span class="comment"># 可以从4个方面改变图像的颜色：亮度（brightness）、对比度（contrast）、饱和度（saturation）和色调（hue）。</span></span><br><span class="line"><span class="comment"># 将图像的亮度随机变化为原图亮度的50%（1−0.5）∼150%（1+0.5）</span></span><br><span class="line">brightness_change = transforms.ColorJitter(brightness=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 随机变化图像的色调</span></span><br><span class="line">hue_change = transforms.ColorJitter(hue=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 随机变化图像的对比度</span></span><br><span class="line">contrast_change = transforms.ColorJitter(contrast=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 综合设置颜色变化</span></span><br><span class="line">color_aug = transforms.ColorJitter(brightness=<span class="number">0.5</span>, contrast=<span class="number">0.5</span>, saturation=<span class="number">0.5</span>, hue=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 叠加多个图像增广方法</span></span><br><span class="line"><span class="comment"># 实际应用中我们会将多个图像增广方法叠加使用。</span></span><br><span class="line"><span class="comment"># 我们可以通过Compose实例将上面定义的多个图像增广方法叠加起来，再应用到每张图像之上。</span></span><br><span class="line">compose = transforms.Compose([</span><br><span class="line">                              transforms.RandomHorizontalFlip(),</span><br><span class="line">                              color_aug,</span><br><span class="line">                              shape_aug</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 大部分图像增广方法都有一定的随机性。</span></span><br><span class="line"><span class="comment"># 为了方便观察图像增广的效果，需要多次运行转换函数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    img_trans = horizon_flip(img)</span><br><span class="line">    img_trans = vertical_flip(img)</span><br><span class="line">    img_trans = shape_aug(img)</span><br><span class="line">    img_trans = brightness_change(img)</span><br><span class="line">    img_trans = hue_change(img)</span><br><span class="line">    img_trans = contrast_change(img)</span><br><span class="line">    img_trans = color_aug(img)</span><br><span class="line">    img_trans = compose(img)</span><br><span class="line">    <span class="comment"># 存储时使用skimage，借此看看skimage与PIL的转换</span></span><br><span class="line">    io.imsave(np.<span class="built_in">str</span>(i)+<span class="string">&#x27;.jpg&#x27;</span>, np.array(img_trans))</span><br></pre></td></tr></table></figure><h2 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h2><p>迁移学习是解决小数据集的一个有效方法。<br>本节介绍迁移学习中的一种常用技术：微调（fine tuning）。微调由以下4步构成。<br>在源数据集（如ImageNet数据集）上预训练一个神经网络模型，即源模型。<br>创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。我们还假设源模型的输出层跟源数据集的标签紧密相关，因此在目标模型中不予采用。<br>为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。<br>在目标数据集上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。<br>当目标数据集远小于源数据集时，微调有助于提升模型的泛化能力。</p><p>注: 在使用预训练模型时，一定要和预训练时作同样的预处理。 如果你使用的是torchvision的models，那就要求: All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. 如果你使用的是pretrained-models.pytorch仓库，请务必阅读其README，其中说明了如何预处理。</p><p>接下来我们来实践一个具体的例子：热狗识别。我们将基于一个小数据集对在ImageNet数据集上训练好的ResNet模型进行微调。该小数据集含有数千张包含热狗和不包含热狗的图像。我们将使用微调得到的模型来识别一张图像中是否包含热狗。<br>导入必要的包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> ImageFolder</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="获取数据集-1"><a href="#获取数据集-1" class="headerlink" title="获取数据集"></a>获取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载数据集</span></span><br><span class="line">!wget https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/hotdog.<span class="built_in">zip</span></span><br><span class="line"><span class="comment"># 解压，得到两个文件夹hotdog/train和hotdog/test。</span></span><br><span class="line"><span class="comment"># 这两个文件夹下面均有hotdog和not-hotdog两个类别文件夹，每个类别文件夹里面是图像文件。</span></span><br><span class="line">!unzip hotdog.<span class="built_in">zip</span></span><br><span class="line"><span class="comment"># 查看一下数据</span></span><br><span class="line"><span class="comment"># 关于ImageFolder的用法可以参考下面的链接：</span></span><br><span class="line"><span class="comment"># https://discuss.pytorch.org/t/questions-about-imagefolder/774/3</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/TH_NUM/article/details/80877435</span></span><br><span class="line"><span class="built_in">print</span>(train_imgs.classes) <span class="comment"># ImageFolder假设所有的文件按文件夹保存好，每个文件夹下面存贮同一类别的图片，文件夹的名字为分类的名字。</span></span><br><span class="line"><span class="built_in">print</span>(train_imgs.class_to_idx) <span class="comment"># 字符串类别所对应的数值类别</span></span><br><span class="line">train_imgs[<span class="number">0</span>][<span class="number">0</span>] <span class="comment"># 前面的是正类图像，即热狗</span></span><br><span class="line">train_imgs[-<span class="number">1</span>][<span class="number">0</span>] <span class="comment"># 后面的是负类图像，即非热狗</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定RGB三个通道的均值和方差来将图像通道归一化 (每个数值减去该通道所有数值的平均值，再除以该通道所有数值的标准差作为输出)</span></span><br><span class="line"><span class="comment"># 这个地方一定与预训练模型所做的处理保持一致！！</span></span><br><span class="line">normalize = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line"><span class="comment"># 训练集所做的预处理</span></span><br><span class="line">train_augs = transforms.Compose([</span><br><span class="line">                                 <span class="comment"># 先从图像中裁剪出随机大小和随机高宽比的一块随机区域，然后将该区域缩放为高和宽均为224像素的输入</span></span><br><span class="line">                                 transforms.RandomResizedCrop(size=<span class="number">224</span>),</span><br><span class="line">                                 <span class="comment"># 左右翻转</span></span><br><span class="line">                                 transforms.RandomHorizontalFlip(),</span><br><span class="line">                                 <span class="comment"># 转为PyTorch所需的形状为(批量大小, 通道数, 高, 宽)、值域在0到1之间且类型为32位浮点数的数据</span></span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 <span class="comment"># 归一化</span></span><br><span class="line">                                 normalize</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 测试集所做的预处理</span></span><br><span class="line">test_augs = transforms.Compose([</span><br><span class="line">                                <span class="comment"># 将图像的高和宽均缩放为256像素</span></span><br><span class="line">                                transforms.Resize(size=<span class="number">256</span>),</span><br><span class="line">                                <span class="comment"># 然后从中裁剪出高和宽均为224像素的中心区域作为输入</span></span><br><span class="line">                                transforms.CenterCrop(size=<span class="number">224</span>),</span><br><span class="line">                                transforms.ToTensor(),</span><br><span class="line">                                normalize</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h3 id="定义和初始化模型-1"><a href="#定义和初始化模型-1" class="headerlink" title="定义和初始化模型"></a>定义和初始化模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用在ImageNet数据集上预训练的ResNet-18作为源模型。</span></span><br><span class="line"><span class="comment"># 这里指定pretrained=True来自动下载并加载预训练的模型参数。在第一次使用时需要联网下载模型参数。</span></span><br><span class="line"><span class="comment"># 不管你是使用的torchvision的models还是pretrained-models.pytorch仓库，默认都会将预训练好的模型参数下载到你的home目录下.torch文件夹。</span></span><br><span class="line"><span class="comment"># 你可以通过修改环境变量$TORCH_MODEL_ZOO来更改下载目录。</span></span><br><span class="line"><span class="comment"># 另一个比较常用的方法是，在其源码中找到下载地址直接浏览器输入地址下载，下载好后将其放到环境变量$TORCH_MODEL_ZOO所指文件夹即可，这样比较快。</span></span><br><span class="line">pretrained_net = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面打印源模型的成员变量fc。</span></span><br><span class="line"><span class="comment"># 作为一个全连接层，它将ResNet最终的全局平均池化层输出变换成ImageNet数据集上1000类的输出。</span></span><br><span class="line"><span class="comment"># 如果你使用的是其他模型，那可能没有成员变量fc（比如models中的VGG预训练模型），</span></span><br><span class="line"><span class="comment"># 所以正确做法是查看对应模型源码中其定义部分，这样既不会出错也能加深我们对模型的理解。</span></span><br><span class="line"><span class="built_in">print</span>(pretrained_net.fc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里应该将最后的fc成修改我们需要的输出类别数:</span></span><br><span class="line">pretrained_net.fc = nn.Linear(<span class="number">512</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(pretrained_net.fc)</span><br><span class="line"><span class="comment"># 此时fc层中的参数已经被初始化了，但是其他层依然保存着预训练得到的参数。</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(pretrained_net.fc.parameters()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于是在很大的ImageNet数据集上预训练的，所以非fc层的参数已经足够好，因此一般只需使用较小的学习率来微调这些参数</span></span><br><span class="line"><span class="comment"># 而fc中的随机初始化参数一般需要更大的学习率从头训练。</span></span><br><span class="line"><span class="comment"># PyTorch可以方便的对模型的不同部分设置不同的学习参数</span></span><br><span class="line"><span class="comment"># 将fc层的参数的id取出</span></span><br><span class="line">output_params = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">id</span>, pretrained_net.fc.parameters()))</span><br><span class="line"><span class="comment"># 从整个net的所有参数中剔除fc的参数，保留非fc中的参数放入feature_params中</span></span><br><span class="line">feature_params = <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: <span class="built_in">id</span>(p) <span class="keyword">not</span> <span class="keyword">in</span> output_params, pretrained_net.parameters())</span><br><span class="line">lr = <span class="number">0.01</span> <span class="comment"># 默认的学习率设为0.01</span></span><br><span class="line">optimizer = optim.SGD([</span><br><span class="line">                       &#123;<span class="string">&#x27;params&#x27;</span>: feature_params&#125;, <span class="comment"># 非fc层的参数使用默认的学习率，即外层的学习率</span></span><br><span class="line">                       &#123;<span class="string">&#x27;params&#x27;</span>: pretrained_net.fc.parameters(), <span class="string">&#x27;lr&#x27;</span>: lr*<span class="number">10</span>&#125; <span class="comment"># fc层参数的学习率设为已训练过的部分的10倍</span></span><br><span class="line">                       ],</span><br><span class="line">                      lr=lr,</span><br><span class="line">                      weight_decay=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure><h3 id="微调模型"><a href="#微调模型" class="headerlink" title="微调模型"></a>微调模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先定义一个统一的训练过程函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">data_iter, net, device=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        <span class="comment"># 如果没指定device，则使用net的device</span></span><br><span class="line">        device = <span class="built_in">list</span>(net.parameters())[<span class="number">0</span>].device</span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">                net.<span class="built_in">eval</span>() <span class="comment"># 评估模式，这会关闭dropout</span></span><br><span class="line">                acc_sum += (net(X.to(device)).argmax(dim=<span class="number">1</span>)==y.to(device)).<span class="built_in">float</span>().<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">                net.train() <span class="comment"># 改回训练模式</span></span><br><span class="line"></span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> acc_sum / n</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">train_iter, test_iter, net, loss, optimizer, device, num_epochs</span>):</span></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;training on &quot;</span>, device)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            train_l_sum += l.cpu().item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().cpu().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&#x27;</span> </span><br><span class="line">              % (epoch+<span class="number">1</span>, train_l_sum/n, train_acc_sum/n, test_acc, time.time()-start))</span><br><span class="line"><span class="comment"># 再定义一个使用微调的训练函数train_fine_tuning以便多次调用</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fine_tuning</span>(<span class="params">net, optimizer, batch_size=<span class="number">128</span>, num_epochs=<span class="number">5</span></span>):</span></span><br><span class="line">    train_iter = DataLoader(ImageFolder(<span class="string">&#x27;hotdog/train&#x27;</span>, transform=train_augs), batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    test_iter = DataLoader(ImageFolder(<span class="string">&#x27;hotdog/test&#x27;</span>, transform=test_augs), batch_size)</span><br><span class="line">    loss = torch.nn.CrossEntropyLoss()</span><br><span class="line">    train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据前面的设置，我们将以10倍的学习率从头训练目标模型的输出层参数</span></span><br><span class="line">train_fine_tuning(pretrained_net, optimizer)</span><br></pre></td></tr></table></figure><h2 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h2><p>很多时候图像里有多个我们感兴趣的目标，我们不仅想知道它们的类别，还想得到它们在图像中的具体位置。在计算机视觉里，我们将这类任务称为目标检测（object detection）或物体检测。<br>在目标检测里，我们通常使用边界框（bounding box）来描述目标位置。边界框是一个矩形框，可以由矩形左上角的x和y轴坐标与右下角的x和y轴坐标确定。<br>目标检测相关知识暂时略过，包括下面的锚框、目标检测数据集、SSD、区域卷积神经网络R-CNN系列（R-CNN、Fast R-CNN、Faster R-CNN、Mask R-CNN）。<br>值得一提的是，Mask R-CNN在Faster R-CNN的基础上做了修改。Mask R-CNN将兴趣区域池化层替换成了兴趣区域对齐层，即通过双线性插值（bilinear interpolation）来保留特征图上的空间信息，从而更适于像素级预测。兴趣区域对齐层的输出包含了所有兴趣区域的形状相同的特征图。它们既用来预测兴趣区域的类别和边界框，又通过额外的全卷积网络预测目标的像素级位置。</p><h2 id="语义分割和数据集"><a href="#语义分割和数据集" class="headerlink" title="语义分割和数据集"></a>语义分割和数据集</h2><p>在目标检测问题中，我们一直使用方形边界框来标注和预测图像中的目标。而语义分割（semantic segmentation）问题，它关注如何将图像分割成属于不同语义类别的区域。值得一提的是，这些语义区域的标注和预测都是像素级的。与目标检测相比，语义分割标注的像素级的边框显然更加精细。</p><h3 id="图像分割和实例分割"><a href="#图像分割和实例分割" class="headerlink" title="图像分割和实例分割"></a>图像分割和实例分割</h3><p>计算机视觉领域还有2个与语义分割相似的重要问题，即图像分割（image segmentation）和实例分割（instance segmentation）。在这里将它们与语义分割简单区分一下。<br>（1）图像分割将图像分割成若干组成区域。这类问题的方法通常利用图像中像素之间的相关性。它在训练时不需要有关图像像素的标签信息，在预测时也无法保证分割出的区域具有我们希望得到的语义。比如，图像分割后不知道分割出来的东西是什么，并不知道哪个是狗，哪个是猫。<br>（2）实例分割又叫同时检测并分割（simultaneous detection and segmentation）。它研究如何识别图像中各个目标实例的像素级区域。与语义分割有所不同，实例分割不仅需要区分语义，还要区分不同的目标实例。如果图像中有两只狗，实例分割需要区分像素属于这两只狗中的哪一只。</p><h3 id="Pascal-VOC2012语义分割数据集"><a href="#Pascal-VOC2012语义分割数据集" class="headerlink" title="Pascal VOC2012语义分割数据集"></a>Pascal VOC2012语义分割数据集</h3><p>语义分割的一个重要数据集叫作Pascal VOC2012。<br>（1）下载并读取数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载数据集</span></span><br><span class="line">!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-<span class="number">2012.</span>tar</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_voc_images</span>(<span class="params">root=<span class="string">&quot;drive/My Drive/VOCdevkit/VOC2012&quot;</span>, is_train=<span class="literal">True</span>, max_num=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># ImageSets/Segmentation路径包含了指定训练和测试样本的文本文件</span></span><br><span class="line">    txt_fname = <span class="string">&#x27;%s/ImageSets/Segmentation/%s&#x27;</span> % (root, <span class="string">&#x27;train.txt&#x27;</span> <span class="keyword">if</span> is_train <span class="keyword">else</span> <span class="string">&#x27;val.txt&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_fname, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        images = f.read().split()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> max_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        images = images[:<span class="built_in">min</span>(max_num, <span class="built_in">len</span>(images))]</span><br><span class="line">    features, labels = [<span class="literal">None</span>]*<span class="built_in">len</span>(images), [<span class="literal">None</span>]*<span class="built_in">len</span>(images)</span><br><span class="line">    <span class="keyword">for</span> i, fname <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">        <span class="comment"># JPEGImages和SegmentationClass路径下分别包含了样本的输入图像和标签</span></span><br><span class="line">        features[i] = Image.<span class="built_in">open</span>(<span class="string">&#x27;%s/JPEGImages/%s.jpg&#x27;</span> % (root, fname)).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        <span class="comment"># 这里的标签也是图像格式，其尺寸和它所标注的输入图像的尺寸相同。标签中颜色相同的像素属于同一个语义类别。</span></span><br><span class="line">        labels[i] = Image.<span class="built_in">open</span>(<span class="string">&#x27;%s/SegmentationClass/%s.png&#x27;</span> % (root, fname)).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> features, labels</span><br><span class="line">voc_dir = <span class="string">&#x27;drive/My Drive/VOCdevkit/VOC2012&#x27;</span></span><br><span class="line">train_features, train_labels = read_voc_images(voc_dir, max_num=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在标签图像中，白色和黑色分别代表边框和背景，而其他不同的颜色则对应不同的类别。</span></span><br><span class="line"><span class="comment"># 接下来，我们列出标签中每个RGB颜色的值及其标注的类别。</span></span><br><span class="line">VOC_COLORMAP = [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">128</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">128</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">128</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">0</span>, <span class="number">128</span>, <span class="number">128</span>], [<span class="number">128</span>, <span class="number">128</span>, <span class="number">128</span>],</span><br><span class="line">                [<span class="number">64</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">192</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">64</span>, <span class="number">128</span>, <span class="number">0</span>], [<span class="number">192</span>, <span class="number">128</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">64</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">192</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">64</span>, <span class="number">128</span>, <span class="number">128</span>], [<span class="number">192</span>, <span class="number">128</span>, <span class="number">128</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">64</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">64</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">192</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">192</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">64</span>, <span class="number">128</span>]]</span><br><span class="line"></span><br><span class="line">VOC_CLASSES = [<span class="string">&#x27;background&#x27;</span>, <span class="string">&#x27;aeroplane&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;diningtable&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;motorbike&#x27;</span>, <span class="string">&#x27;person&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;potted plant&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;sofa&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;tv/monitor&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个256*256*256长度的tensor</span></span><br><span class="line">colormap2label = torch.zeros(<span class="number">256</span>**<span class="number">3</span>, dtype=torch.uint8)</span><br><span class="line"><span class="keyword">for</span> i, colormap <span class="keyword">in</span> <span class="built_in">enumerate</span>(VOC_COLORMAP):</span><br><span class="line">    <span class="comment"># 将颜色索引与类别索引一一对应起来</span></span><br><span class="line">    <span class="comment"># 注意colormap2label是一个一维向量，所以不同通道的颜色值传入后要乘以256</span></span><br><span class="line">    <span class="comment"># 具体的数值大小无意义，只要是不同类别能分辨开即可，同时与下面的</span></span><br><span class="line">    <span class="comment"># (colormap[:, :, 0]*256+colormap[:, :, 1])*256+colormap[:,:,2]要对应起来</span></span><br><span class="line">    colormap2label[(colormap[<span class="number">0</span>]*<span class="number">256</span>+colormap[<span class="number">1</span>])*<span class="number">256</span>+colormap[<span class="number">2</span>]] = i</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">voc_label_indices</span>(<span class="params">colormap, colormap2label</span>):</span></span><br><span class="line">    <span class="comment"># 将PIL Image转成numpy，然后数据类型改为int32位，colormap仍然是h*w*c的样式</span></span><br><span class="line">    colormap = np.array(colormap.convert(<span class="string">&#x27;RGB&#x27;</span>)).astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将不同的通道乘以256转化成索引值</span></span><br><span class="line">    <span class="comment"># 这样，idx的shape就是h*w</span></span><br><span class="line">    idx = ((colormap[:, :, <span class="number">0</span>]*<span class="number">256</span>+colormap[:, :, <span class="number">1</span>])*<span class="number">256</span>+colormap[:,:,<span class="number">2</span>])</span><br><span class="line">    <span class="comment"># 找到该索引矩阵所对应的标签类别</span></span><br><span class="line">    <span class="comment"># 因为idx是索引矩阵，其大小与图像大小相同，那么返回的也正是每个像素所对应的类别，即与图像同样大小的类别矩阵</span></span><br><span class="line">    <span class="keyword">return</span> colormap2label[idx]</span><br></pre></td></tr></table></figure><p>（2）预处理数据<br>在之前的章节中，我们通过缩放图像使其符合模型的输入形状。然而在语义分割里，这样做需要将预测的像素类别重新映射回原始尺寸的输入图像。这样的映射难以做到精确，尤其在不同语义的分割区域。为了避免这个问题，我们将图像裁剪成固定尺寸而不是缩放。具体来说，我们使用图像增广里的随机裁剪，并对输入图像和标签裁剪相同区域。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">voc_rand_crop</span>(<span class="params">feature, label, height, width</span>):</span></span><br><span class="line">    i, j, h, w = torchvision.transforms.RandomCrop.get_params(feature, output_size=(height, width))</span><br><span class="line">    feature = torchvision.transforms.functional.crop(feature, i, j, h, w)</span><br><span class="line">    label = torchvision.transforms.functional.crop(label, i, j, h, w)</span><br><span class="line">    <span class="keyword">return</span> feature, label</span><br><span class="line"></span><br><span class="line"><span class="comment"># 比如随机裁剪200*300大小的区域</span></span><br><span class="line">img = voc_rand_crop(train_features[<span class="number">0</span>], train_labels[<span class="number">0</span>], <span class="number">200</span>, <span class="number">300</span>)</span><br></pre></td></tr></table></figure><p>（3）自定义语义分割数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VOCSegDataset</span>(<span class="params">torch.utils.data.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, is_train, crop_size, voc_dir, colormap2label, max_num=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># 对输入图像的RGB三个通道的值分别做标准化</span></span><br><span class="line">        self.rgb_mean = np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">        self.rgb_std = np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">        self.tsf = torchvision.transforms.Compose([</span><br><span class="line">                                                   torchvision.transforms.ToTensor(),</span><br><span class="line">                                                   torchvision.transforms.Normalize(</span><br><span class="line">                                                       mean=self.rgb_mean,</span><br><span class="line">                                                       std=self.rgb_std)</span><br><span class="line">        ])</span><br><span class="line">        self.crop_size = crop_size</span><br><span class="line">        features, labels = read_voc_images(</span><br><span class="line">            root = voc_dir,</span><br><span class="line">            is_train = is_train,</span><br><span class="line">            max_num = max_num</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 由于数据集中有些图像的尺寸可能小于随机裁剪所指定的输出尺寸，这些样本需要通过自定义的filter函数所移除。</span></span><br><span class="line">        self.features = self.<span class="built_in">filter</span>(features)</span><br><span class="line">        self.labels = self.<span class="built_in">filter</span>(labels)</span><br><span class="line">        self.colormap2label = colormap2label</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;read &#x27;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(self.features)) + <span class="string">&#x27; valid samples&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这个地方需要特别注意，PIL.size返回的是(width, height)，即宽在前，高在后，而我们输入的参数是高在前</span></span><br><span class="line">    <span class="comment"># https://liam.page/2015/04/22/pil-tutorial-basic-usage/</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">filter</span>(<span class="params">self, imgs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [img <span class="keyword">for</span> img <span class="keyword">in</span> imgs <span class="keyword">if</span> (</span><br><span class="line">            img.size[<span class="number">1</span>] &gt;= self.crop_size[<span class="number">0</span>] <span class="keyword">and</span> </span><br><span class="line">            img.size[<span class="number">0</span>] &gt;= self.crop_size[<span class="number">1</span>]</span><br><span class="line">        )]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过实现__getitem__函数，我们可以任意访问数据集中索引为idx的输入图像及其每个像素的类别索引</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        feature, label = voc_rand_crop(self.features[idx], self.labels[idx], *self.crop_size)</span><br><span class="line">        <span class="keyword">return</span> (self.tsf(feature), <span class="comment"># feature是float32的tensor</span></span><br><span class="line">                voc_label_indices(label, self.colormap2label) <span class="comment"># label是uint8的tensor</span></span><br><span class="line">                )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.features)</span><br><span class="line"></span><br><span class="line">crop_size = (<span class="number">320</span>, <span class="number">480</span>)</span><br><span class="line">max_num = <span class="number">100</span></span><br><span class="line">voc_train = VOCSegDataset(<span class="literal">True</span>, crop_size, voc_dir, colormap2label, max_num)</span><br><span class="line">voc_test = VOCSegDataset(<span class="literal">False</span>, crop_size, voc_dir, colormap2label, max_num)</span><br><span class="line"><span class="comment"># 设批量大小为64，分别定义训练集和测试集的迭代器。</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">num_workers = <span class="number">4</span></span><br><span class="line">train_iter = torch.utils.data.DataLoader(voc_train, batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                              drop_last=<span class="literal">True</span>, num_workers=num_workers)</span><br><span class="line"></span><br><span class="line">test_iter = torch.utils.data.DataLoader(voc_test, batch_size, drop_last=<span class="literal">True</span>,</span><br><span class="line">                             num_workers=num_workers)</span><br></pre></td></tr></table></figure><h2 id="全卷积网络"><a href="#全卷积网络" class="headerlink" title="全卷积网络"></a>全卷积网络</h2><p>全卷积网络（fully convolutional network，FCN）采用卷积神经网络实现了从图像像素到像素类别的变换。与之前介绍的卷积神经网络有所不同，全卷积网络通过转置卷积（transposed convolution）层将中间层特征图的高和宽变换回输入图像的尺寸，从而令预测结果与输入图像在空间维（高和宽）上一一对应：给定空间维上的位置，通道维的输出即该位置对应像素的类别预测。<br>全卷积网络先使用卷积神经网络抽取图像特征，然后通过 1乘1 卷积层将通道数变换为类别个数，最后通过转置卷积层将特征图的高和宽变换为输入图像的尺寸，从而输出每个像素的类别。<br>在全卷积网络中，可以将转置卷积层初始化为双线性插值的上采样。</p><h1 id="自然语言处理"><a href="#自然语言处理" class="headerlink" title="自然语言处理"></a>自然语言处理</h1><p>暂时略过。</p>]]></content>
    
    
    <summary type="html">Attention预警！：
时刻铭记“Garbage in, garbage out!”，因此，涉及到data时，一定注意实际查看，确保计算时Input和Output的一致性和准确性。

原书MXNet版在这里。
PyTorch版在这里。

深度学习简介
目前的机器学习和深度学习应用共同的核心思想：用数据编程。
通俗来说，机器学习是一门讨论各式各样的适用于不同问题的函数形式，以及如何使用数据来有效地获取函数参数具体值的学科。
深度学习是具有多级表示的表征学习方法（表征学习关注如何自动找出表示数据的合适方式，以便更好地将输入变换为正确的输出）。在每一级（从原始数据开始），深度学习通过简单的函数将</summary>
    
    
    
    <category term="programming" scheme="http://qixinbo.github.io/categories/programming/"/>
    
    
    <category term="Machine Learning" scheme="http://qixinbo.github.io/tags/Machine-Learning/"/>
    
    <category term="PyTorch" scheme="http://qixinbo.github.io/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle细胞赛：基于PyTorch/UNet算法的细胞核识别</title>
    <link href="http://qixinbo.github.io/2020/02/29/kaggle-nuclei/"/>
    <id>http://qixinbo.github.io/2020/02/29/kaggle-nuclei/</id>
    <published>2020-02-28T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.701Z</updated>
    
    <content type="html"><![CDATA[<p>从2015年开始，Kaggle每年都举办一次Data Science Bowl，旨在召集众多力量开发算法，来解决当前某一特定领域的迫切问题。2018年的数据碗的任务是识别细胞的细胞核nuclei，从而使得更加方便地进行药物测试，使得新药的上市时间缩短。</p><p>Yun Chen分享了他的使用PyTorch/UNet算法的notebook，见<a href="https://www.kaggle.com/cloudfall/pytorch-tutorials-on-dsb2018">这里</a>，本文是对该notebook代码的详细解析和再现，并适当做了一些修改。</p><p>再分享一篇挺好的背景文章：<br><a href="https://www.zybuluo.com/Team/note/1205894">基于深度学习的图像语义分割算法综述</a></p><h1 id="数据集分析"><a href="#数据集分析" class="headerlink" title="数据集分析"></a>数据集分析</h1><h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!kaggle competitions download -c data-science-bowl-<span class="number">2018</span></span><br></pre></td></tr></table></figure><h2 id="解压并迁移数据"><a href="#解压并迁移数据" class="headerlink" title="解压并迁移数据"></a>解压并迁移数据</h2><p>解压数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">!unzip stage1_sample_submission.csv.<span class="built_in">zip</span></span><br><span class="line">!unzip stage1_solution.csv.<span class="built_in">zip</span></span><br><span class="line">!unzip stage1_train_labels.csv.<span class="built_in">zip</span></span><br><span class="line">!unzip stage2_sample_submission_final.csv.<span class="built_in">zip</span></span><br><span class="line"> </span><br><span class="line">!mkdir stage1_test</span><br><span class="line">!unzip stage1_test.<span class="built_in">zip</span> -d stage1_test</span><br><span class="line"></span><br><span class="line">!mkdir stage1_train</span><br><span class="line">!unzip stage1_train.<span class="built_in">zip</span> -d stage1_train</span><br><span class="line"></span><br><span class="line">!mkdir stage2_test_final</span><br><span class="line">!unzip stage2_test_final.<span class="built_in">zip</span> -d stage2_test_final</span><br></pre></td></tr></table></figure><p>迁移数据到Google Drive：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">!mkdir nuclei</span><br><span class="line">!mv stage1_test nuclei</span><br><span class="line">!mv stage1_train nuclei</span><br><span class="line">!mv stage2_test_final/ nuclei</span><br><span class="line">!mv *.csv nuclei</span><br><span class="line">!mv nuclei /content/drive/My\ Drive</span><br></pre></td></tr></table></figure><p>这样就做到了持久化，防止notebook重启时数据丢失。</p><h2 id="数据文件描述"><a href="#数据文件描述" class="headerlink" title="数据文件描述"></a>数据文件描述</h2><p>（1）/stage1_train/*：该文件夹是训练集，包含训练用的图像及其掩膜图像<br>（2）/stage1_test/*：该文件夹是测试集，仅包含图像<br>（3）/stage2_test/*：这是第二阶段的测试集，仅包含图像<br>（4）stage1_sample_submission.csv：在第一阶段需要提交的文件格式<br>（5）stage2_sample_submission.csv：在第二阶段需要提交的文件格式<br>（6）stage1_train_labels.csv：该文件是训练集中的掩膜图像的游程编码RLE</p><h1 id="加载必要的Python包"><a href="#加载必要的Python包" class="headerlink" title="加载必要的Python包"></a>加载必要的Python包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line">TRAIN_PATH = <span class="string">&#x27;./train.pth&#x27;</span></span><br><span class="line">TEST_PATH = <span class="string">&#x27;./test.tph&#x27;</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h1 id="数据集加载"><a href="#数据集加载" class="headerlink" title="数据集加载"></a>数据集加载</h1><p>数据集加载是至关重要的一步，也是非常繁琐的一步。因为这一步无法标准化，必须针对特定的数据集进行解析。</p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>下面是对该竞赛的数据集的处理方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span>(<span class="params">file_path, has_mask=<span class="literal">True</span></span>):</span></span><br><span class="line">  file_path = Path(file_path)</span><br><span class="line">  files = <span class="built_in">sorted</span>(<span class="built_in">list</span>(file_path.iterdir()))</span><br><span class="line">  datas = []</span><br><span class="line">  <span class="keyword">for</span> file <span class="keyword">in</span> tqdm(files):</span><br><span class="line">    item = &#123;&#125;</span><br><span class="line">    imgs = []</span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> (file/<span class="string">&#x27;images&#x27;</span>).iterdir():</span><br><span class="line">      img = io.imread(image)</span><br><span class="line">      imgs.append(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(imgs) == <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> img.shape[<span class="number">2</span>] &gt; <span class="number">3</span>:</span><br><span class="line">      <span class="keyword">assert</span> (img[:, :, <span class="number">3</span>]!=<span class="number">255</span>).<span class="built_in">sum</span>() == <span class="number">0</span></span><br><span class="line">    img = img[:, :, :<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> has_mask:</span><br><span class="line">      mask_files = <span class="built_in">list</span>((file/<span class="string">&#x27;masks&#x27;</span>).iterdir())</span><br><span class="line">      masks = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> i, mask <span class="keyword">in</span> <span class="built_in">enumerate</span>(mask_files):</span><br><span class="line">        mask = io.imread(mask)</span><br><span class="line">        <span class="keyword">assert</span> (mask[(mask!=<span class="number">0</span>)] == <span class="number">255</span>).<span class="built_in">all</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> masks <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">          H, W = mask.shape</span><br><span class="line">          masks = np.zeros((<span class="built_in">len</span>(mask_files), H, W))</span><br><span class="line">        masks[i] = mask</span><br><span class="line"></span><br><span class="line">      total_mask = masks.<span class="built_in">sum</span>(<span class="number">0</span>)</span><br><span class="line">           <span class="keyword">assert</span> (total_mask[(total_mask!=<span class="number">0</span>)] == <span class="number">255</span>).<span class="built_in">all</span>()</span><br><span class="line"></span><br><span class="line">      item[<span class="string">&#x27;mask&#x27;</span>] = torch.from_numpy(total_mask)</span><br><span class="line"></span><br><span class="line">    item[<span class="string">&#x27;name&#x27;</span>] = <span class="built_in">str</span>(file).split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">    item[<span class="string">&#x27;img&#x27;</span>] = torch.from_numpy(img)</span><br><span class="line">    datas.append(item)</span><br><span class="line">    <span class="keyword">return</span> datas</span><br><span class="line"> </span><br><span class="line">test = process(<span class="string">&quot;/content/drive/My Drive/nuclei/stage1_test&quot;</span>, <span class="literal">False</span>)</span><br><span class="line">torch.save(test, TEST_PATH)</span><br><span class="line">train = process(<span class="string">&quot;/content/drive/My Drive/nuclei/stage1_train&quot;</span>)</span><br><span class="line">torch.save(train, TRAIN_PATH)</span><br></pre></td></tr></table></figure><p>具体来看：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file_path = Path(file_path)</span><br><span class="line">files = <span class="built_in">sorted</span>(<span class="built_in">list</span>(file_path.iterdir()))</span><br></pre></td></tr></table></figure><p>这里用了Python3的pathlib库来读入文件夹路径，之前大家常用的是os.path，但现在普遍推荐使用pathlib库来替代os.path，因为其采用面向对象的方式，且用法更简单，参加资料如下：<br><a href="https://xin053.github.io/2016/07/03/pathlib%E8%B7%AF%E5%BE%84%E5%BA%93%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/">pathlib路径库使用详解</a></p><p>然后再用list转换一下，是为了下面使用tqdm库来可视化进度条。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> image <span class="keyword">in</span> (file/<span class="string">&#x27;images&#x27;</span>).iterdir():</span><br><span class="line">  img = io.imread(image)</span><br><span class="line">  imgs.append(img)</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(imgs) == <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> img.shape[<span class="number">2</span>] &gt; <span class="number">3</span>:</span><br><span class="line">  <span class="keyword">assert</span> (img[:, :, <span class="number">3</span>]!=<span class="number">255</span>).<span class="built_in">sum</span>() == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">img = img[:, :, :<span class="number">3</span>]</span><br></pre></td></tr></table></figure><p>这一部分是读取具体的图像，但这里注意两点：<br>（1）首先对每一子文件夹下的图像数量进行判断，确保只有一张图像；<br>（2）这个数据集中的图像有个特点，它是4通道的，最后一个通道的值都是255，所以这里会有shape的判断，并且使用了assert来确保最后一个通道值都是255。<br>最后取原图像的前三个通道存入新图像中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> has_mask:</span><br><span class="line">  mask_files = <span class="built_in">list</span>((file/<span class="string">&#x27;masks&#x27;</span>).iterdir())</span><br><span class="line">  masks = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i, mask <span class="keyword">in</span> <span class="built_in">enumerate</span>(mask_files):</span><br><span class="line">    mask = io.imread(mask)</span><br><span class="line">    <span class="keyword">assert</span> (mask[(mask!=<span class="number">0</span>)] == <span class="number">255</span>).<span class="built_in">all</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> masks <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">      H, W = mask.shape</span><br><span class="line">      masks = np.zeros((<span class="built_in">len</span>(mask_files), H, W))</span><br><span class="line"></span><br><span class="line">    masks[i] = mask</span><br></pre></td></tr></table></figure><p>这一步是逐个读取掩膜文件，其中的assert语句是保证mask确实是0和255二值的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmp_mask = masks.<span class="built_in">sum</span>(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">assert</span> (tmp_mask[(tmp_mask!=<span class="number">0</span>)] == <span class="number">255</span>).<span class="built_in">all</span>()</span><br></pre></td></tr></table></figure><p>这一步是将masks中的同一位置上的元素进行加和，然后通过assert语句保证加和后不为0的元素都是255，这一步是保证每个像素上都最多只有一个掩膜值，即两个掩膜没有重叠。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_mask = masks.<span class="built_in">sum</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>因为masks变量实际有多个通道，即多个掩膜，这一步是将每个通道上的掩膜值根据序号重新赋值，然后组合在一起，使得所有掩膜都在一张图像上。(这一步与原notebook不同，原notebook是不同的掩膜有不一样的值)</p><p>比如这张细胞核图像：<br><img src="https://user-images.githubusercontent.com/6218739/75554371-2b28f780-5a75-11ea-9357-928dde25f866.png" alt="1f84ac0d-1df9-42c9-b4ee-ca08102cd715"><br>它的掩膜就是：<br><img src="https://user-images.githubusercontent.com/6218739/75554405-3d0a9a80-5a75-11ea-9663-e85c11cf5df3.png" alt="012a8162-4eaa-489c-8f35-e196651a8071"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  item[<span class="string">&#x27;mask&#x27;</span>] = torch.from_numpy(total_mask)</span><br><span class="line"></span><br><span class="line">item[<span class="string">&#x27;name&#x27;</span>] = <span class="built_in">str</span>(file).split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">item[<span class="string">&#x27;img&#x27;</span>] = torch.from_numpy(img)</span><br><span class="line">datas.append(item)</span><br></pre></td></tr></table></figure><p>然后将图像img、文件名name和掩膜mask（如果有的话）以字典的形式存入datas这个列表中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test = process(<span class="string">&quot;/content/drive/My Drive/nuclei/stage1_test&quot;</span>, <span class="literal">False</span>)</span><br><span class="line">torch.save(test, TEST_PATH)</span><br><span class="line">train = process(<span class="string">&quot;/content/drive/My Drive/nuclei/stage1_train&quot;</span>)</span><br><span class="line">torch.save(train, TRAIN_PATH)</span><br></pre></td></tr></table></figure><p>最后，将这个列表用PyTorch存储模型的方式持久化存储下来。<br>这一步需要的时间很长，所以最好是将这个存储数据的列表持久化后，将其挪动到Google Drive中，防止下次重启丢失。<br>但实际操作下来，发现过程不是那么美好，首先是Google Colab给分配的RAM有点小，而训练集中的数据特别多，尤其是mask分开存储的方式，使得数据量巨多，后期直接把内存撑爆了，而且执行速度非常慢，于是将代码稍微改了以下，每隔5步就torch save一下，然后将datas清零，这样就能保证及时释放内存：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> k % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">  torch.save(datas, name + np.<span class="built_in">str</span>(k)+<span class="string">&quot;.pt&quot;</span>)</span><br><span class="line">  datas = []</span><br></pre></td></tr></table></figure><p>然后再把所有save的数据load以后串接起来就行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_catenate</span>(<span class="params">file_path</span>):</span></span><br><span class="line">    path = Path(file_path)</span><br><span class="line">    data = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(path.iterdir()):</span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        temp = torch.load(i)</span><br><span class="line">        data += temp</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure><h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><p>首先定义数据集格式，自定义的数据集格式需要继承torch.utils.data.Dataset，然后重载以下两个方法：<br>（1）__len__：这样len(dataset)就可以返回整个数据集的大小，<br>（2）__getitem__：这样就可以使用dataset[i]来对数据进行索引。<br>针对这里的具体训练数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainDataset</span>(<span class="params">data.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data, source_transform, target_transform</span>):</span></span><br><span class="line">        self.datas = data</span><br><span class="line">        self.s_transform = source_transform</span><br><span class="line">        self.t_transform = target_transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        data = self.datas[index]</span><br><span class="line">        img = data[<span class="string">&#x27;img&#x27;</span>].numpy()</span><br><span class="line">        mask = data[<span class="string">&#x27;mask&#x27;</span>][:, :, <span class="literal">None</span>].byte().numpy()</span><br><span class="line">        img = self.s_transform(img)</span><br><span class="line">        mask = self.t_transform(mask)</span><br><span class="line">        <span class="keyword">return</span> img, mask</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.datas)</span><br></pre></td></tr></table></figure><p>可以看出，对img和mask分别又做了一些变换。<br>对于这些变换操作来说，最佳实践是不要写函数，而是写可调用的类，这样参数就不必每次都要传递。因此，只需实现__call__方法和__init__方法（如有必要）。然后如下调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tsfm = Transform(params)</span><br><span class="line">transformed_sample = tsfm(sample)</span><br></pre></td></tr></table></figure><p>这里因为所有的变换在torchvision的transforms中是自带的，所以不需要自定义变换，只调用即可，而且使用了Compose将这些变换组合起来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> PIL</span><br><span class="line">s_trans = transforms.Compose([</span><br><span class="line">                              transforms.ToPILImage(),</span><br><span class="line">                              transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">                              transforms.ToTensor(),</span><br><span class="line">                              transforms.Normalize(mean=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], std=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">t_trans = transforms.Compose([</span><br><span class="line">                              transforms.ToPILImage(),</span><br><span class="line">                              transforms.Resize((<span class="number">128</span>, <span class="number">128</span>), interpolation=PIL.Image.NEAREST),</span><br><span class="line">                              transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>然后将变换规则传入数据集中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = TrainDataset(train, s_trans, t_trans)</span><br></pre></td></tr></table></figure><p>具体使用该数据集时，可以使用for循环来逐个读取数据，但这样势必会丧失一些功能：<br>（1）批量处理数据；<br>（2）打乱数据顺序；<br>（3）并行加载数据。<br>因此，PyTorch提供了torch.utils.data.DataLoader类作为迭代器，提供上述功能。<br>将数据集放入DataLoader中，并指定参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataloader = data.DataLoader(train_dataset, num_workers=<span class="number">2</span>, batch_size=<span class="number">4</span>)</span><br></pre></td></tr></table></figure><h1 id="UNet网络结构"><a href="#UNet网络结构" class="headerlink" title="UNet网络结构"></a>UNet网络结构</h1><p>崔家华的一篇博文对UNet的网络结构和代码实现讲得挺好，见<a href="https://cuijiahua.com/blog/2019/12/dl-15.html">这里</a>。<br>本部分是对崔同学的博文的摘抄学习，代码部分中的参数是结合上面的notebook中的参数进行了修改。</p><h2 id="网络结构原理"><a href="#网络结构原理" class="headerlink" title="网络结构原理"></a>网络结构原理</h2><blockquote><p>UNet最早发表在2015的MICCAI会议上，5年多的时间，论文引用量已经达到了接近12000次。<br>UNet成为了大多做医疗影像语义分割任务的baseline，同时也启发了大量研究者对于U型网络结构的研究，发表了一批基于UNet网络结构的改进方法的论文。<br>UNet网络结构，最主要的两个特点是：U型网络结构和Skip Connection跳层连接。</p></blockquote><p><img src="https://user-images.githubusercontent.com/6218739/75503501-bde37b00-5a10-11ea-99ac-9c9015aa1bb0.png" alt="image"></p><blockquote><p>UNet是一个对称的网络结构，左侧为下采样，右侧为上采样。<br>按照功能可以将左侧的一系列下采样操作称为encoder，将右侧的一系列上采样操作称为decoder。<br>Skip Connection中间四条灰色的平行线，Skip Connection就是在上采样的过程中，融合下采样过过程中的feature map。<br>Skip Connection用到的融合的操作也很简单，就是将feature map的通道进行叠加，俗称Concat。</p></blockquote><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>将整个UNet结构拆分为多个模块进行分析。（后面的文字依然是摘抄自崔家华博客，不再加引用标识，见谅）</p><h3 id="DoubleConv模块"><a href="#DoubleConv模块" class="headerlink" title="DoubleConv模块"></a>DoubleConv模块</h3><p>从UNet网络中可以看出，不管是下采样过程还是上采样过程，每一层都会连续进行两次卷积操作，这种操作在UNet网络中重复很多次，可以单独写一个DoubleConv模块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubleConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;(convolution =&gt; [BN] =&gt; ReLU) * 2&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.double_conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.double_conv(x)</span><br></pre></td></tr></table></figure><p>上述的Pytorch代码：torch.nn.Sequential是一个时序容器，Modules 会以它们传入的顺序被添加到容器中。比如上述代码的操作顺序：卷积-&gt;BN-&gt;ReLU-&gt;卷积-&gt;BN-&gt;ReLU。<br>DoubleConv模块的in_channels和out_channels可以灵活设定，以便扩展使用。<br>输出矩阵的高度和宽度（即输出的特征图feature map）这两个维度的尺寸由输入矩阵、卷积核、扫描方式所共同决定，计算公式为：<br><img src="https://user-images.githubusercontent.com/6218739/75505152-71e70500-5a15-11ea-9784-2b27b6731e80.png" alt="image"></p><h3 id="Down模块"><a href="#Down模块" class="headerlink" title="Down模块"></a>Down模块</h3><p>UNet网络一共有4次下采样过程，模块化代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Down</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Downscaling with maxpool then double conv&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool_conv = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            DoubleConv(in_channels, out_channels)</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.maxpool_conv(x)</span><br></pre></td></tr></table></figure><p>这里的代码很简单，就是一个maxpool池化层，进行下采样，然后接一个DoubleConv模块。<br>其中，池化层选的是2乘以2的窗口大小，那么默认获得的也是这样大小的填充步长，池化以后的feature map的大小计算方式跟上面卷积的相同。</p><p>至此，UNet网络的左半部分的下采样过程的代码都写好了，接下来是右半部分的上采样过程。</p><h3 id="Up模块"><a href="#Up模块" class="headerlink" title="Up模块"></a>Up模块</h3><p>上采样过程用到的最多的当然就是上采样了，除了常规的上采样操作，还有进行特征的融合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Up</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Upscaling then double conv&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, bilinear=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if bilinear, use the normal convolutions to reduce the number of channels</span></span><br><span class="line">        <span class="keyword">if</span> bilinear:</span><br><span class="line">            self.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.up = nn.ConvTranspose2d(in_channels, in_channels // <span class="number">2</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.conv = DoubleConv(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x1, x2</span>):</span></span><br><span class="line">        x1 = self.up(x1)</span><br><span class="line">        <span class="comment"># input is CHW</span></span><br><span class="line">        diffY = torch.tensor([x2.size()[<span class="number">2</span>] - x1.size()[<span class="number">2</span>]])</span><br><span class="line">        diffX = torch.tensor([x2.size()[<span class="number">3</span>] - x1.size()[<span class="number">3</span>]])</span><br><span class="line">        x1 = F.pad(x1, [diffX // <span class="number">2</span>, diffX - diffX // <span class="number">2</span>,</span><br><span class="line">                        diffY // <span class="number">2</span>, diffY - diffY // <span class="number">2</span>])</span><br><span class="line">        <span class="comment"># if you have padding issues, see</span></span><br><span class="line">        <span class="comment"># https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a</span></span><br><span class="line">        <span class="comment"># https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd</span></span><br><span class="line">        x = torch.cat([x2, x1], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure><p>代码复杂一些，我们可以分开来看。<br>首先是__init__初始化函数里定义的上采样方法以及卷积采用DoubleConv。<br>上采样，定义了两种方法：Upsample和ConvTranspose2d，也就是双线性插值和反卷积。<br>双线性插值很好理解，示意图：<br><img src="https://user-images.githubusercontent.com/6218739/75517269-49710200-5a39-11ea-8ae3-7316d43727cf.png" alt="image"></p><p>简单地讲：已知Q11、Q12、Q21、Q22四个点坐标，通过Q11和Q21求R1，再通过Q12和Q22求R2，最后通过R1和R2求P，这个过程就是双线性插值。对于一个feature map而言，其实就是在像素点中间补点，补的点的值是多少，是由相邻像素点的值决定的。<br>反卷积，顾名思义，就是反着卷积。卷积是让featuer map越来越小，反卷积就是让feature map越来越大，示意图：</p><p><img src="https://user-images.githubusercontent.com/6218739/75517361-76bdb000-5a39-11ea-85a2-a869f7443195.png" alt="image"></p><p>下面蓝色为原始图片，周围白色的虚线方块为padding结果，通常为0，上面绿色为卷积后的图片。 这个示意图，就是一个从2<em>2的feature map-&gt;4</em>4的feature map过程。<br>在forward前向传播函数中，x1接收的是上采样的数据，x2接收的是特征融合的数据。<br>如果两个feature map大小不同，那么特征融合方法可以有两种：<br>（1）将大的feature进行裁剪，再进行concat；<br>（2）将小的feature进行填充，再进行concat。</p><p>这里是使用的第二种，先对小的feature map进行padding，再进行concat。</p><h3 id="OutConv模块"><a href="#OutConv模块" class="headerlink" title="OutConv模块"></a>OutConv模块</h3><p>用上述的DoubleConv模块、Down模块、Up模块就可以拼出UNet的主体网络结构了。UNet网络的输出需要根据分割数量，整合输出通道。具体操作就是channel的变换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OutConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(OutConv, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure><p>需要注意的是原notebook中没有加入Sigmoid层，但实测加入后精度提高很多。这样得到的就是一个0到1的概率分布。</p><h3 id="UNet网络"><a href="#UNet网络" class="headerlink" title="UNet网络"></a>UNet网络</h3><p>这一部分是将上面的模块组合起来形成整个UNet网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; Full assembly of the parts to form the complete network &quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;Refer https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_model.py&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, bilinear=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(UNet, self).__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.bilinear = bilinear</span><br><span class="line">        self.inc = DoubleConv(n_channels, <span class="number">64</span>)</span><br><span class="line">        self.down1 = Down(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.down2 = Down(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.down3 = Down(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        self.down4 = Down(<span class="number">512</span>, <span class="number">1024</span>)</span><br><span class="line">        self.up1 = Up(<span class="number">1024</span>, <span class="number">512</span>, bilinear)</span><br><span class="line">        self.up2 = Up(<span class="number">512</span>, <span class="number">256</span>, bilinear)</span><br><span class="line">        self.up3 = Up(<span class="number">256</span>, <span class="number">128</span>, bilinear)</span><br><span class="line">        self.up4 = Up(<span class="number">128</span>, <span class="number">64</span>, bilinear)</span><br><span class="line">        self.outc = OutConv(<span class="number">64</span>, n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x1 = self.inc(x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)</span><br><span class="line">        x5 = self.down4(x4)</span><br><span class="line">        x = self.up1(x5, x4)</span><br><span class="line">        x = self.up2(x, x3)</span><br><span class="line">        x = self.up3(x, x2)</span><br><span class="line">        x = self.up4(x, x1)</span><br><span class="line">        logits = self.outc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">model = UNet(n_channels=<span class="number">1</span>, n_classes=<span class="number">1</span>).cuda()</span><br></pre></td></tr></table></figure><p>这里还有另外一位网友写的UNet网络进行辅助理解，<a href="https://github.com/JavisPeng/u_net_liver/blob/master/unet.py">点击这里</a>。</p><h1 id="定义损失函数和优化器"><a href="#定义损失函数和优化器" class="headerlink" title="定义损失函数和优化器"></a>定义损失函数和优化器</h1><p>这里使用Dice系数定义损失：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">soft_dice_loss</span>(<span class="params">inputs, targets</span>):</span></span><br><span class="line">        num = targets.size(<span class="number">0</span>)</span><br><span class="line">        m1  = inputs.view(num,-<span class="number">1</span>)</span><br><span class="line">        m2  = targets.view(num,-<span class="number">1</span>)</span><br><span class="line">        intersection = (m1 * m2)</span><br><span class="line">        score = <span class="number">2.</span> * (intersection.<span class="built_in">sum</span>(<span class="number">1</span>)+<span class="number">1</span>) / (m1.<span class="built_in">sum</span>(<span class="number">1</span>) + m2.<span class="built_in">sum</span>(<span class="number">1</span>)+<span class="number">1</span>)</span><br><span class="line">        score = <span class="number">1</span> - score.<span class="built_in">sum</span>()/num</span><br><span class="line">        <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure><p>具体的原理可以参见如下一篇博客：<br><a href="https://www.aiuai.cn/aifarm1159.html">医学图像分割之 Dice Loss</a></p><p>优化器选择Adam：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.Adam(model.parameters(),lr = <span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure><h1 id="训练和保存模型"><a href="#训练和保存模型" class="headerlink" title="训练和保存模型"></a>训练和保存模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader, <span class="number">0</span>):</span><br><span class="line">        x_train, y_train = data</span><br><span class="line">        x_train = x_train.cuda()</span><br><span class="line">        y_train = y_train.cuda()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        predict = model(x_train)</span><br><span class="line">        loss = soft_dice_loss(predict, y_train)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">19</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">20</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Finish training&quot;</span>)</span><br></pre></td></tr></table></figure><p>这里在GPU上进行训练。<br>训练完后及时地将模型保存下来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MODEL_PATH = <span class="string">&#x27;model.pth&#x27;</span></span><br><span class="line">torch.save(model.state_dict(), MODEL_PATH)</span><br></pre></td></tr></table></figure><p>#测试</p><h2 id="创建测试数据集和加载器"><a href="#创建测试数据集和加载器" class="headerlink" title="创建测试数据集和加载器"></a>创建测试数据集和加载器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestDataset</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, path, source_transform</span>):</span></span><br><span class="line">        self.datas = torch.load(path)</span><br><span class="line">        self.s_transform = source_transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        data = self.datas[index]</span><br><span class="line">        img = data[<span class="string">&#x27;img&#x27;</span>].numpy()</span><br><span class="line">        img = self.s_transform(img)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.datas)</span><br><span class="line"></span><br><span class="line">test_dataset = TestDataset(TEST_PATH, s_trans)</span><br><span class="line">test_dataloader = data.DataLoader(test_dataset,num_workers=<span class="number">2</span>,batch_size=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h2 id="查看一下测试集"><a href="#查看一下测试集" class="headerlink" title="查看一下测试集"></a>查看一下测试集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataiter = <span class="built_in">iter</span>(test_dataloader)</span><br><span class="line">imgs = dataiter.<span class="built_in">next</span>()</span><br></pre></td></tr></table></figure><p>注意上面的imgs的size()是这样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">2</span>, <span class="number">1</span>, <span class="number">128</span>, <span class="number">128</span>])</span><br></pre></td></tr></table></figure><p>最前面的2是batch size，说明dataloader中一个元素包含两张图像，所以保存时需要这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">io.imsave(<span class="string">&quot;1.png&quot;</span>, imgs[<span class="number">0</span>][<span class="number">0</span>].data.numpy())</span><br></pre></td></tr></table></figure><h2 id="加载模型（可选）"><a href="#加载模型（可选）" class="headerlink" title="加载模型（可选）"></a>加载模型（可选）</h2><p>如有必要的话，先从模型文件中加载模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = UNet(<span class="number">1</span>, <span class="number">1</span>).cuda()</span><br><span class="line">model.load_state_dict(torch.load(MODEL_PATH))</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">output = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">        data = data.cuda()</span><br><span class="line">        <span class="comment"># io.imsave(&quot;train.png&quot;, data[1][0].data.cpu().numpy())</span></span><br><span class="line">        predict = model(data)</span><br><span class="line">        <span class="comment"># io.imsave(&quot;test.png&quot;, o[1][0].data.cpu().numpy())</span></span><br><span class="line">        output.append(predict)</span><br><span class="line"></span><br><span class="line">    result = torch.cat(output, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>然后得到的result可以通过设置阈值来二值化显示最终结果，比如第i张图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pred = result[i][<span class="number">0</span>].data.cpu().numpy()</span><br><span class="line">pred[pred&gt;<span class="number">0.7</span>] = <span class="number">255</span></span><br><span class="line">pred[pred&lt;=<span class="number">0.7</span>] = <span class="number">0</span></span><br><span class="line">io.imsave(<span class="string">&quot;i.png&quot;</span>, pred)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">从2015年开始，Kaggle每年都举办一次Data Science Bowl，旨在召集众多力量开发算法，来解决当前某一特定领域的迫切问题。2018年的数据碗的任务是识别细胞的细胞核nuclei，从而使得更加方便地进行药物测试，使得新药的上市时间缩短。

Yun Chen分享了他的使用PyTorch/UNet算法的notebook，见这里，本文是对该notebook代码的详细解析和再现，并适当做了一些修改。

再分享一篇挺好的背景文章：
基于深度学习的图像语义分割算法综述

数据集分析
下载数据集
1


!kaggle competitions download -c data-scienc</summary>
    
    
    
    <category term="programming" scheme="http://qixinbo.github.io/categories/programming/"/>
    
    
    <category term="kaggle" scheme="http://qixinbo.github.io/tags/kaggle/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析：17 -- 重构版ImagePy解析</title>
    <link href="http://qixinbo.github.io/2020/02/26/ImagePy_17/"/>
    <id>http://qixinbo.github.io/2020/02/26/ImagePy_17/</id>
    <published>2020-02-25T16:00:00.000Z</published>
    <updated>2021-03-25T07:20:30.369Z</updated>
    
    <content type="html"><![CDATA[<p>%%%%%%%%<br>2021.2.14更新:增加了sciapp和sciwx的介绍<br>%%%%%%%%</p><p>新版ImagePy有如下特点：<br>（1）将原版ImagePy非常特色的可视化组件完全解耦，比如画布、表格、对话框等组件，将其重构为sciwx库，这样第三方开发人员就可以更加方便地使用这些组件而构建自己的特定应用；<br>（2）创建了一套适用于图像处理的接口标准sciapp，其中定义了图像类Image、表格类Table、几何矢量类Shape，并实现了对这些类的常用操作，即sciapp作为后端支持；<br>（2）新版ImagePy在sciwx库和sciapp库的基础上进行再集成开发，即底层符合sciapp标准、前端使用sciwx显示，然后提供一整套完善的管理系统和丰富的插件库，从而实现复杂的图像处理功能。</p><p>因此，sciwx等价于napari等库，着重于可视化；sciapp等价于ImageJ等库，着重于通用数据接口，ImagePy则是基于两者的插件库。新版ImagePy架构思路清晰，集成更加自然契合，因此，ImagePy/sciapp/sciwx无论是对底层开发人员还是图像处理小白都有着无可比拟的优势：小到开发一个图像处理小工具，大到作为一个大型软件“开箱即用”，都可以轻松应对。</p><p>多说一句题外话，多谢龙哥的精辟的总结：对于图像处理问题，图像+矢量+图论三条腿走路。</p><h1 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h1><p>特别地，对sciapp和sciwx包进行一个更为详细的介绍。<br>如上所述，sciapp负责后端数据操作，sciwx负责前端组件。</p><h2 id="sciapp"><a href="#sciapp" class="headerlink" title="sciapp"></a>sciapp</h2><p>sciapp包的介绍主要引用了<a href="https://github.com/Image-Py/imagepy/blob/master/sciapp/doc/cn_readme.md">官方的介绍</a>。<br>sciapp包主要有三个重要的模块：Object模块、App模块和Action模块。</p><h3 id="Object模块"><a href="#Object模块" class="headerlink" title="Object模块"></a>Object模块</h3><p>Object模块定义了科学计算中常用的基础数据结构封装类，当然，如果仅仅为了计算，绝大多数时候，Numpy，Pandas等数据类型已经可以胜任，这里的封装，主要是面向交互与展示的，例如Image对象是图像数据，里面带了一个lut成员，用于在展示时映射成伪彩色。<br>（1）Image：多维图像，基于Numpy<br>（2）Table：表格，基于DataFrame<br>（3）Shape: 点线面，任意多边形，可与GeoJson，Shapely互转<br>（4）Surface：三维表面</p><h3 id="App模块"><a href="#App模块" class="headerlink" title="App模块"></a>App模块</h3><p>App模块是一个科学容器，里面包含若干管理器managers，用于管理App所持有的上面各类对象object，这里的管理功能包括增加、删除、查询等，即对象object的生命周期都在App管理器中。以图像对象Image为例，App管理器有如下功能：<br>（1）show_img(self, img, title=None): 展示一个Image对象，并添加到app.img_manager管理器中；<br>（2）get_img(self, title=None): 根据title获取Image，如果缺省则返回管理器中的第一个Image；<br>（3）img_names(self): 返回当前app持有的Image对象名称列表；<br>（4）active_img(self, title=None): 将指定名称的Image对象置顶，以便于get_img可以优先获得；<br>（5）close_img(self, title=None): 关闭指定图像，并从app.img_manager管理器中移除。</p><p>除了这些特定于某种对象的功能，还有一些与用户交互的功能，比如：<br>（1）alert(self, info, title=’sciapp’): 弹出一个提示框，需要用户确认；<br>（2）yes_no(self, info, title=’sciapp’): 要求用户输入True/False；<br>（3）show_txt(self, cont, title=’sciapp’): 对用户进行文字提示；<br>（4）show_md(self, cont, title=’sciapp’): 以MarkDown语法书写，向用户弹出格式化文档；<br>（5）show_para(self, title, para, view, on_handle=None, on_ok=None, on_cancel=None, on_help=None, preview=False, modal=True): 展示交互对话框，para是参数字典，view指定了交互方式。</p><p>但是，需要特别注意的是，这里的App中的这些交互功能，都只是在命令行中print信息，具体使用时需要在子类中用UI框架（比如sciwx）重载这些方法。</p><h3 id="Action模块"><a href="#Action模块" class="headerlink" title="Action模块"></a>Action模块</h3><p>Action模块是对App所管理的对象的操作，比如对图像做滤波等。因此，该模块也是后面自定义开发时打交道最多的模块。<br>该模块与App的交互只需通过它的start函数即可，即将App类的实例app传入即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SciAction</span>:</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;base action, just has a start method, alert a hello&#x27;&#x27;&#x27;</span></span><br><span class="line">    name = <span class="string">&#x27;SciAction&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">self, app, para=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.app = app</span><br><span class="line">        app.alert(<span class="string">&#x27;Hello, I am SciAction!\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">app = App()</span><br><span class="line">SciAction().start(app)</span><br></pre></td></tr></table></figure><p>SciAction是所有Action的基类，它定义了最基本的功能，同时，sciapp提供了更高级的模板，供开发者的自定义action用于继承，比如：<br>（1）ImgAction：用于处理图像，自动获取当前图像，需要重载para、view进行交互，重载run进行图像处理；<br>（2）Tool：工具，用于在某种控件上的鼠标交互，同时其派生出了图像工具ImageTool、表格工具TableTool、矢量编辑工具ShapeTool（如点线面绘制）。</p><p>另外，Advanced目录下有一些高级模板（如支持图像多通道、批量操作、多线程支持等），供扩展插件时使用；Plugins目录下也有一些带有具体功能的、开箱即用的Action。</p><h2 id="sciwx"><a href="#sciwx" class="headerlink" title="sciwx"></a>sciwx</h2><p>sciwx提供了一系列基于wxPython的前端可视化组件，其中最重要的就是可视化2D图像的画布功能。</p><h3 id="Canvas画布"><a href="#Canvas画布" class="headerlink" title="Canvas画布"></a>Canvas画布</h3><p>Canvas画布是定制化的wxPython的Panel，其详细解析可见<a href="https://qixinbo.info/2019/10/29/imagepy_12/">该文</a>。</p><h3 id="ICanvas画布、MCanvas组件、CanvasNoteBook组件、CanvasFrame应用和CanvasNoteFrame应用"><a href="#ICanvas画布、MCanvas组件、CanvasNoteBook组件、CanvasFrame应用和CanvasNoteFrame应用" class="headerlink" title="ICanvas画布、MCanvas组件、CanvasNoteBook组件、CanvasFrame应用和CanvasNoteFrame应用"></a>ICanvas画布、MCanvas组件、CanvasNoteBook组件、CanvasFrame应用和CanvasNoteFrame应用</h3><p>ICanvas是在Canvas基础上对于位图的展示提供进一步的接口支持，比如默认绑定ImageTool这种Action，提供set_img设置图像、set_rg设置数值范围、set_lut设置快速查找表、set_cn设置通道、set_tool设置工具等接口。<br>MCanvas是对ICanvas的进一步包装，比如在顶部添加显示图像信息的信息条、在底部增加可以切换某一通道、某一slice的滑动条。<br>CanvasNoteBook组件是对MCanvas的多标签页管理，即每一个标签页都可以添加一个MCanvas。<br>以上几个组件实际都是深度定制的前端组件，而接下来的CanvasFrame和CanvasNoteFrame是同时拥有前端和后端的功能，它们的父类同时是wx.Frame和上面的sciapp的App类，应该可以说这两个是可以独立运行的开箱即用的应用。<br>CanvasFrame是对MCanvas的封装，可以使用上面MCanvas的设置接口，同时还可以增加菜单栏、工具栏以及显示对话框等。<br>CanvasNoteFrame是对CanvasNoteBook的封装，即增加了标签页管理。</p><h3 id="VCanvas画布、SCanvas组件、VectorNoteBook组件、VectorFrame应用和VectorNoteFrame应用"><a href="#VCanvas画布、SCanvas组件、VectorNoteBook组件、VectorFrame应用和VectorNoteFrame应用" class="headerlink" title="VCanvas画布、SCanvas组件、VectorNoteBook组件、VectorFrame应用和VectorNoteFrame应用"></a>VCanvas画布、SCanvas组件、VectorNoteBook组件、VectorFrame应用和VectorNoteFrame应用</h3><p>VCanvas是在Canvas基础上对于矢量形状的展示提供进一步的接口支持，比如默认绑定ShapeTool这种Action，提供set_shp设置形状、set_tool设置工具等接口。<br>Scanvas是对VCanvas的进一步包装，比如在顶部添加显示形状信息的信息条。<br>VectorNoteBook组件时对VCanvas的多标签页管理。<br>同上，VectorFrame和VectorNoteFrame也都是兼具后端和前端功能的应用。</p><h2 id="前端和后端耦合"><a href="#前端和后端耦合" class="headerlink" title="前端和后端耦合"></a>前端和后端耦合</h2><p>如上所述，sciapp负责后端，sciwx负责前端，两者联动的机理如下：<br>（1）通过sciapp的dataio模块来控制输入输出，将图像等对象添加进App管理器；<br>（2）将App管理器传入其他action模块的start()入口函数，即可实现对图像等对象的操作；<br>（3）sciwx前端组件通过set_img()等接口接收App管理器，并将之可视化。<br>其中，第二步可以通过代码执行，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Gaussian().start(app)</span><br></pre></td></tr></table></figure><p>但也可以通过前端交互，比如通过菜单命令和工具栏的鼠标操作。那么菜单栏和工具栏又是怎样识别这些命令的呢？<br>对于菜单栏：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MenuBar</span>(<span class="params">wx.MenuBar</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, app</span>):</span></span><br><span class="line">        wx.MenuBar.__init__(self)</span><br><span class="line">        self.app = app</span><br><span class="line">        app.SetMenuBar(self)</span><br><span class="line">....</span><br><span class="line">....</span><br><span class="line">            f = <span class="keyword">lambda</span> e, p=vs: p().start(self.app)</span><br><span class="line">            self.Bind(wx.EVT_MENU, f, item)</span><br></pre></td></tr></table></figure><p>注意两个地方：<br>一个是MenuBar的初始化函数，需要传入app实例；第二是在添加菜单项时，其功能通过lambda函数调用了命令的start()函数。<br>对于工具栏：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToolBar</span>(<span class="params">wx.Panel</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent, vertical=<span class="literal">False</span></span>):</span></span><br><span class="line">        self.app = parent</span><br><span class="line"></span><br><span class="line">        btn.Bind( wx.EVT_LEFT_DOWN, <span class="keyword">lambda</span> e, obj=obj: self.on_tool(e, obj))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_tool</span>(<span class="params">self, evt, tol</span>):</span></span><br><span class="line">        tol.start(self.app)</span><br></pre></td></tr></table></figure><p>仍然是两个地方：ToolBar的初始化函数也传入parent了，它实际也是app实例；第二也是鼠标按下操作绑定了工具命令的start()函数。</p><p>这个作为后端服务的app实例可以额外创建，但是通常做法是将前端和后端联合起来，创建一个组合体，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImageApp</span>(<span class="params">wx.Frame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"> self, parent </span>):</span></span><br><span class="line">        wx.Frame.__init__ ( self, parent, <span class="built_in">id</span> = wx.ID_ANY, title = <span class="string">&#x27;ImageApp&#x27;</span>,</span><br><span class="line">                            size = wx.Size(<span class="number">800</span>,<span class="number">600</span>), pos = wx.DefaultPosition,</span><br><span class="line">                            style = wx.RESIZE_BORDER|wx.DEFAULT_FRAME_STYLE|wx.TAB_TRAVERSAL )</span><br><span class="line">        App.__init__(self)</span><br></pre></td></tr></table></figure><p>因此，添加菜单栏和工具栏时，传入的都是self，即自身，因为其自身就有App管理器的能力。</p><p>下面是对ImagePy所基于的sciwx库各个组件的demo进行逐步解析（最好是直接运行一下，以获得直观感受）。</p><h1 id="画布"><a href="#画布" class="headerlink" title="画布"></a>画布</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> Canvas</span><br><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">frame = wx.Frame(<span class="literal">None</span>, title=<span class="string">&#x27;gray test&#x27;</span>)</span><br><span class="line">canvas = Canvas(frame, autofit=<span class="literal">True</span>)</span><br><span class="line">canvas.set_img(camera())</span><br><span class="line">frame.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>ImagePy/sciwx展示一张图像所使用的是Canvas类，它是对wxPython的面板Panel类的深度定制，可以实现对图像的区域缩放、拖动、标注等。之前写过一篇对该类的详细解释，见<a href="http://qixinbo.info/2019/10/29/ImagePy_12/">这里</a>。</p><h1 id="通道、图像序列展示"><a href="#通道、图像序列展示" class="headerlink" title="通道、图像序列展示"></a>通道、图像序列展示</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> astronaut</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> MCanvas</span><br><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">frame = wx.Frame(<span class="literal">None</span>, title=<span class="string">&#x27;gray test&#x27;</span>)</span><br><span class="line">canvas = MCanvas(frame, autofit=<span class="literal">True</span>)</span><br><span class="line">canvas.set_imgs([astronaut(), <span class="number">255</span>-astronaut()])</span><br><span class="line">canvas.set_cn(<span class="number">0</span>)</span><br><span class="line">frame.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>上面的Canvas类仅能展示一张图像，这里的MCanvas类则是用于展示图像序列和多通道：<br>（1）图像序列：将多个图像组合成列表list，然后传入set_imgs()方法中；<br>（2）通道：对于多通道图像，可以传入单个通道，如0或1或2，这时是单通道灰度显示，也可以组合成(0, 1, 2)，即RGB彩色显示，甚至可以任意按不同顺序组合通道，比如(1, 0, 2)，即将原来的通道1变成现在的通道0，再彩色显示。对于灰度图，则只有通道0。</p><h1 id="内部图像类Image"><a href="#内部图像类Image" class="headerlink" title="内部图像类Image"></a>内部图像类Image</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> Canvas, Image</span><br><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">obj = Image()</span><br><span class="line">obj.img = camera()</span><br><span class="line">obj.cn = <span class="number">0</span></span><br><span class="line">frame = wx.Frame(<span class="literal">None</span>, title=<span class="string">&#x27;gray test&#x27;</span>)</span><br><span class="line">canvas = Canvas(frame, autofit=<span class="literal">True</span>)</span><br><span class="line">canvas.set_img(obj)</span><br><span class="line">frame.Show()   </span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>这个例子是测试ImagePy的内部图像类Image，该类是源图像的一个包装，同时提供多种属性供调用，比如图像名称title、源图像img、通道数channels、整个图像序列中包含图像个数slices、图像尺寸shape、色彩范围range、快照snapshot等。</p><p>这里是先构造一个Image对象，然后将camera这张图像传给该对象的img属性，然后再传给Canvas。<br>之前例子中Canvas是直接接收camera，这两种方式都可以，因为Canvas类中对类型做了判断和处理。</p><h1 id="自定义鼠标事件"><a href="#自定义鼠标事件" class="headerlink" title="自定义鼠标事件"></a>自定义鼠标事件</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> Canvas</span><br><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestTool</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, image, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;x:%d y:%d btn:%d ctrl:%s alt:%s shift:%s&#x27;</span>%</span><br><span class="line">              (x, y, btn, key[<span class="string">&#x27;ctrl&#x27;</span>], key[<span class="string">&#x27;alt&#x27;</span>], key[<span class="string">&#x27;shift&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, image, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, image, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, image, x, y, d, **key</span>):</span></span><br><span class="line">        image.img[:] = image.img + d</span><br><span class="line">        key[<span class="string">&#x27;canvas&#x27;</span>].update()</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">frame = wx.Frame(<span class="literal">None</span>)</span><br><span class="line">canvas = Canvas(frame, autofit=<span class="literal">True</span>)</span><br><span class="line">canvas.set_img(camera())</span><br><span class="line">canvas.set_tool(TestTool())</span><br><span class="line">frame.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>这一步实际是将画布中的默认绑定的DefaultTool改成了自定义的TestTool，然后再将动作反馈给画布。<br>从中也可以看出自定义工具中可以调用的接口：<br>（1）image：即画布承载的Image对象，具体的源图像则是image.img<br>（2）x和y：当前鼠标所在的图像像素坐标，水平方向是x方向，垂直方向是y方向，这两个坐标是与图像的Numpy数据存储一一对应的：因为Numpy的元素获取是先row后column，所以这里的y对应row，x对应column。另外因为这两个坐标有可能因为缩放、移动而产生负值，此时如果要做画笔这类的应用的话，就需要clip一下，保证画笔始终在图像中；不过另一方面，这样的设置也使得可以draw出超出图像的更大的ROI。还有下面一种坐标，是代表鼠标在面板中的像素坐标。btn是鼠标按键，1为左键按下，2为中键按下，3为右键按下，key是字典，里面有多个字段，key[‘alt’]代表是否按下alt键，key[‘ctrl’]代表是否按下ctrl键，key[‘shift’]代表是否按下shift键，key[‘px’]返回鼠标当前的画布x坐标，key[‘py’]返回画布y坐标，key[‘canvas’]返回该画布自身。</p><h1 id="工具栏"><a href="#工具栏" class="headerlink" title="工具栏"></a>工具栏</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"><span class="keyword">from</span> sciwx.widgets <span class="keyword">import</span> ToolBar</span><br><span class="line"><span class="keyword">from</span> sciwx.action <span class="keyword">import</span> Tool</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestTool</span>(<span class="params">Tool</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">self, app</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;i am a tool&quot;</span>)</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">frame = wx.Frame(<span class="literal">None</span>)</span><br><span class="line">tool = ToolBar(frame)</span><br><span class="line">tool.add_tool(<span class="string">&#x27;A&#x27;</span>, TestTool)</span><br><span class="line">tool.add_tools(<span class="string">&#x27;B&#x27;</span>, [(<span class="string">&#x27;A&#x27;</span>, TestTool), (<span class="string">&#x27;C&#x27;</span>, <span class="literal">None</span>)])</span><br><span class="line">tool.Layout()</span><br><span class="line">frame.Fit()</span><br><span class="line">frame.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>上面的自定义鼠标事件是在后台将默认的鼠标事件进行了重载，无法显示成一个工具。且如果多个工具，每个工具点击后的鼠标事件都不同，是需要将这些事件分开来写的。<br>这个例子是用来显示工具栏，里面的TestTool纯粹是为了该例子的完整运行，没有任何的实际意义，正规的自定义工具是要重载各种鼠标动作。<br>实际上的工具栏的鼠标动作是与具体的Canvas相绑定的，所以在没有添加canvas的情况下是无法执行具体工具的。<br>可以看出：<br>（1）sciwx现在不仅支持使用icon作为工具图标，也支持使用单个英文字母作为图标，更加方便易用；<br>（2）sciwx支持一次性添加多个工具。<br>后面的例子会展示将画布与工具进行绑定。</p><h1 id="集成面板"><a href="#集成面板" class="headerlink" title="集成面板"></a>集成面板</h1><p>CanvasFrame是将画布与菜单栏、工具栏集成显示（实际无法与菜单栏集成，因为菜单栏需要传入app实例，下方具体解释，且后面有具体的集成菜单栏的方法），CanvasNoteFrame进一步地提供标签页功能。<br>不过这一步仅是测试这两个类能否正确使用，还没有加上特定的菜单栏和工具栏，下面的例子中将具体展示。<br>同时注意，这一步调用时不再需要像之前的例子那样事先生成一个wxPython的Frame，因为这两个类本身就是Frame，所以省了这一步，相当于定制化了wxPython的frame。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> astronaut, camera</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasFrame, CanvasNoteFrame</span><br><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">canvas_frame_test</span>():</span></span><br><span class="line">    cf = CanvasFrame(<span class="literal">None</span>, autofit=<span class="literal">True</span>)</span><br><span class="line">    cf.set_imgs([camera(), <span class="number">255</span>-camera()])</span><br><span class="line">    cf.Show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">canvas_note_test</span>():</span></span><br><span class="line">    cnf = CanvasNoteFrame(<span class="literal">None</span>)</span><br><span class="line">    cv1 = cnf.add_canvas()</span><br><span class="line">    cv1.set_img(camera())</span><br><span class="line">    cv2 = cnf.add_canvas()</span><br><span class="line">    cv2.set_img(astronaut())</span><br><span class="line">    cv2.set_cn((<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))</span><br><span class="line">    cnf.Show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = wx.App()</span><br><span class="line">    canvas_frame_test()</span><br><span class="line">    canvas_note_test()</span><br><span class="line">    app.MainLoop()</span><br></pre></td></tr></table></figure><p>CanvasFrame和CanvasNoteFrame归根结底都是调用了Canvas类，且将Canvas一系列的设定方法传递给了它们。</p><h1 id="画布集成工具栏"><a href="#画布集成工具栏" class="headerlink" title="画布集成工具栏"></a>画布集成工具栏</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.draw <span class="keyword">import</span> line</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasFrame</span><br><span class="line"><span class="keyword">from</span> sciwx.action <span class="keyword">import</span> Tool, DefaultTool</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pencil</span>(<span class="params">Tool</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Pencil&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.status = <span class="literal">False</span></span><br><span class="line">        self.oldp = (<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        self.status = <span class="literal">True</span></span><br><span class="line">        self.oldp = (y, x)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        self.status = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.status:<span class="keyword">return</span></span><br><span class="line">        se = self.oldp + (y,x)</span><br><span class="line">        rs,cs = line(*[<span class="built_in">int</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> se])</span><br><span class="line">        rs.clip(<span class="number">0</span>, ips.shape[<span class="number">1</span>], out=rs)</span><br><span class="line">        cs.clip(<span class="number">0</span>, ips.shape[<span class="number">0</span>], out=cs)</span><br><span class="line">        ips.img[rs,cs] = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        self.oldp = (y, x)</span><br><span class="line">        key[<span class="string">&#x27;canvas&#x27;</span>].update()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, ips, x, y, d, **key</span>):</span><span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera, astronaut</span><br><span class="line">    <span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread</span><br><span class="line"></span><br><span class="line">    app = wx.App()</span><br><span class="line">    cf = CanvasFrame(<span class="literal">None</span>, autofit=<span class="literal">False</span>)</span><br><span class="line">    cf.set_imgs([astronaut(), <span class="number">255</span>-astronaut()])</span><br><span class="line">    cf.set_cn((<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">    bar = cf.add_toolbar()</span><br><span class="line">    bar.add_tool(<span class="string">&#x27;M&#x27;</span>, DefaultTool)</span><br><span class="line">    bar.add_tool(<span class="string">&#x27;P&#x27;</span>, Pencil)</span><br><span class="line">    cf.Show()</span><br><span class="line">    app.MainLoop()</span><br></pre></td></tr></table></figure><p>这个例子就是将画布与默认工具和画笔工具集成起来。<br>由于这里是两个工具，那么这个画布是怎样知道该响应哪个工具了吗？原理如下：<br>（1）ToolBar类中将具体工具绑定了鼠标单击事件，当某一工具被点击后，就会触发它继承自父类Tool的start()方法，将该工具自身传给Tool.default；<br>（2）Canvas画布类会时刻监听鼠标事件，其中会调用Tool.default，于是，两者就关联了起来。此处Tool.default是种类似“多态”的用法，即直接调用父类，无需知道其具体的子类类型，具体调用则是看运行时类型决定。</p><h1 id="菜单栏"><a href="#菜单栏" class="headerlink" title="菜单栏"></a>菜单栏</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wx</span><br><span class="line"><span class="keyword">from</span> sciwx.widgets <span class="keyword">import</span> MenuBar</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">P</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">self, app</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(self.name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">data = (<span class="string">&#x27;menu&#x27;</span>, [</span><br><span class="line">        (<span class="string">&#x27;File&#x27;</span>, [(<span class="string">&#x27;Open&#x27;</span>, P(<span class="string">&#x27;O&#x27;</span>)),</span><br><span class="line">                  <span class="string">&#x27;-&#x27;</span>,</span><br><span class="line">                  (<span class="string">&#x27;Close&#x27;</span>, P(<span class="string">&#x27;C&#x27;</span>))]),</span><br><span class="line">        (<span class="string">&#x27;Edit&#x27;</span>, [(<span class="string">&#x27;Copy&#x27;</span>, P(<span class="string">&#x27;C&#x27;</span>)),</span><br><span class="line">                  (<span class="string">&#x27;A&#x27;</span>, [(<span class="string">&#x27;B&#x27;</span>, P(<span class="string">&#x27;B&#x27;</span>)),</span><br><span class="line">                         (<span class="string">&#x27;C&#x27;</span>, P(<span class="string">&#x27;C&#x27;</span>))]),</span><br><span class="line">                  (<span class="string">&#x27;Paste&#x27;</span>, P(<span class="string">&#x27;P&#x27;</span>))])])</span><br><span class="line"></span><br><span class="line">app = wx.App()</span><br><span class="line">frame = wx.Frame(<span class="literal">None</span>)</span><br><span class="line">menubar = MenuBar(frame)</span><br><span class="line">menubar.load(data)</span><br><span class="line">frame.SetMenuBar(menubar)</span><br><span class="line">frame.Show()</span><br><span class="line">app.MainLoop()</span><br></pre></td></tr></table></figure><p>该例有两个特点：<br>（1）菜单项是以元组的形式传入MenuBar中，且能多级解析，这就提供了非常大的灵活性，后面ImagePy的丰富的插件系统也能顺利地加载进来；<br>（2）类P实际就是一个最小的可运行的插件，其重要的一个成员函数就是start()方法，注意到其需要传入一个app参数（这里因为没有用到图像，所以app没有实际用处）。</p><p>从菜单栏开始，相比于以前的ImagePy的管理机制，新解耦的sciwx拥有了一个新的管理方式，即App类，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">App</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.img_manager = Manager()</span><br><span class="line">        self.wimg_manager = Manager()</span><br><span class="line">        self.tab_manager = Manager()</span><br><span class="line">        self.wtab_manager = Manager()</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_img</span>(<span class="params">self, img</span>):</span> <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_table</span>(<span class="params">self, img</span>):</span> <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_md</span>(<span class="params">self, img, title=<span class="string">&#x27;&#x27;</span></span>):</span> <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_txt</span>(<span class="params">self, img, title=<span class="string">&#x27;&#x27;</span></span>):</span> <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot</span>(<span class="params">self</span>):</span> <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot3d</span>(<span class="params">self</span>):</span> <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_img</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;add&#x27;</span>, img.name)</span><br><span class="line">        self.img_manager.add(img)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remove_img</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;remove&#x27;</span>, img.name)</span><br><span class="line">        self.img_manager.remove(img)</span><br><span class="line">…</span><br><span class="line">…</span><br></pre></td></tr></table></figure><p>图像、表格属于基础元素，其管理和展示，归为app自身的功能（以前是通过管理器），创建app实例就可以维护基础元素的信息。这样可以有如下优点：<br>（1）实现了UI定制，元素的操作与具体的Desktop端、Web端或Headless样式进行解耦。比如sciwx自带一个sciapp模块，它就是一个具体的wxPython的前端实现，同理，也可以自己创建一个web的前端或headless的接口调用；对于headless形式的接口，可以ssh远程登录调用它处理图像，也可以将使用GUI前端形成的处理流程转成headless形式的流程，然后放到服务器上进行运行，这就适用于需要长时间处理图像的大型任务；<br>（2）创建某个插件时，可以将app对象传入进去，相当于拿着app对象，就可以获取当前打开的各种元素，以显示各种信息。换句话说，插件所需要干的三件事：获取数据、处理数据和展示数据，处理数据时插件自身的功能，而第一个和第三个都是通过与app交互来实现的。与之前相比，不再需要全局的处理函数IPy。</p><p>下面就是实际对app的应用实例。</p><h1 id="集成菜单栏"><a href="#集成菜单栏" class="headerlink" title="集成菜单栏"></a>集成菜单栏</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.ndimage <span class="keyword">import</span> gaussian_filter</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasFrame</span><br><span class="line"><span class="keyword">from</span> sciwx.action <span class="keyword">import</span> ImgAction</span><br><span class="line"><span class="keyword">from</span> sciwx.app.manager <span class="keyword">import</span> App</span><br><span class="line"><span class="keyword">from</span> sciwx.widgets <span class="keyword">import</span> MenuBar</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Gaussian</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Gaussian&#x27;</span></span><br><span class="line">    note = [<span class="string">&#x27;auto_snap&#x27;</span>, <span class="string">&#x27;preview&#x27;</span>]</span><br><span class="line">    para = &#123;<span class="string">&#x27;sigma&#x27;</span>:<span class="number">2</span>&#125;</span><br><span class="line">    view = [(<span class="built_in">float</span>, <span class="string">&#x27;sigma&#x27;</span>, (<span class="number">0</span>, <span class="number">30</span>), <span class="number">1</span>, <span class="string">&#x27;sigma&#x27;</span>, <span class="string">&#x27;pix&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, img, snap, para</span>):</span></span><br><span class="line">        gaussian_filter(snap, para[<span class="string">&#x27;sigma&#x27;</span>], output=img)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Undo</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Undo&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, img, snap, para</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(ips.img.mean(), ips.snap.mean())</span><br><span class="line">        ips.swap()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestFrame</span>(<span class="params">CanvasFrame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span> (<span class="params">self, parent</span>):</span></span><br><span class="line">        CanvasFrame.__init__(self, parent)</span><br><span class="line">        App.__init__(self)</span><br><span class="line"></span><br><span class="line">        self.Bind(wx.EVT_ACTIVATE, self.init_image)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_image</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        self.add_img(self.canvas.image)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_menubar</span>(<span class="params">self</span>):</span></span><br><span class="line">        menubar = MenuBar(self)</span><br><span class="line">        self.SetMenuBar(menubar)</span><br><span class="line">        <span class="keyword">return</span> menubar</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera, astronaut</span><br><span class="line">    <span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread</span><br><span class="line"></span><br><span class="line">    app = wx.App()</span><br><span class="line">    cf = TestFrame(<span class="literal">None</span>)</span><br><span class="line">    cf.set_img(camera())</span><br><span class="line">    cf.set_cn(<span class="number">0</span>)</span><br><span class="line">    bar = cf.add_menubar()</span><br><span class="line">    bar.load((<span class="string">&#x27;menu&#x27;</span>,[(<span class="string">&#x27;Filter&#x27;</span>,[(<span class="string">&#x27;Gaussian&#x27;</span>, Gaussian),</span><br><span class="line">                                 (<span class="string">&#x27;Unto&#x27;</span>, Undo)]),</span><br><span class="line">                      ]))</span><br><span class="line">    cf.Show()</span><br><span class="line">    app.MainLoop()</span><br></pre></td></tr></table></figure><p>一个最小可用的例子如上。<br>需要说明的是：<br>（1）CanvasFrame定位是带窗口的画布，但因为它默认添加了菜单栏，而菜单栏是插件的组合，所以需要传入app，但当前的CanvasFrame没有提供app接口，所以这里新定义了一个类TestFrame，它继承自原始的CanvasFrame和App，然后将原生的CanvasFrame中的add_menu()方法直接复制并粘贴到新的TestFrame下。<br>（2）此处的TestFrame是与sciapp等价的，只是TestFrame是最小可用的一个前端实现，而sciapp是大型框架ImagePy的实现。</p><h1 id="集成工具栏和菜单栏"><a href="#集成工具栏和菜单栏" class="headerlink" title="集成工具栏和菜单栏"></a>集成工具栏和菜单栏</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.ndimage <span class="keyword">import</span> gaussian_filter</span><br><span class="line"><span class="keyword">from</span> skimage.draw <span class="keyword">import</span> line</span><br><span class="line"><span class="keyword">from</span> sciwx.canvas <span class="keyword">import</span> CanvasFrame</span><br><span class="line"><span class="keyword">from</span> sciwx.action <span class="keyword">import</span> ImgAction, Tool, DefaultTool</span><br><span class="line"><span class="keyword">from</span> sciwx.app <span class="keyword">import</span> App</span><br><span class="line"><span class="keyword">from</span> sciwx.widgets <span class="keyword">import</span> MenuBar</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Gaussian</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Gaussian&#x27;</span></span><br><span class="line">    note = [<span class="string">&#x27;auto_snap&#x27;</span>, <span class="string">&#x27;preview&#x27;</span>]</span><br><span class="line">    para = &#123;<span class="string">&#x27;sigma&#x27;</span>:<span class="number">2</span>&#125;</span><br><span class="line">    view = [(<span class="built_in">float</span>, <span class="string">&#x27;sigma&#x27;</span>, (<span class="number">0</span>, <span class="number">30</span>), <span class="number">1</span>, <span class="string">&#x27;sigma&#x27;</span>, <span class="string">&#x27;pix&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, img, snap, para</span>):</span></span><br><span class="line">        gaussian_filter(snap, para[<span class="string">&#x27;sigma&#x27;</span>], output=img)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Undo</span>(<span class="params">ImgAction</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Undo&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, img, snap, para</span>):</span> ips.swap()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pencil</span>(<span class="params">Tool</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;Pencil&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.status = <span class="literal">False</span></span><br><span class="line">        self.oldp = (<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        self.status = <span class="literal">True</span></span><br><span class="line">        self.oldp = (y, x)</span><br><span class="line">        ips.snapshot()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        self.status = <span class="literal">False</span></span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.status:<span class="keyword">return</span></span><br><span class="line">        se = self.oldp + (y,x)</span><br><span class="line">        rs,cs = line(*[<span class="built_in">int</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> se])</span><br><span class="line">        rs.clip(<span class="number">0</span>, ips.shape[<span class="number">1</span>], out=rs)</span><br><span class="line">        cs.clip(<span class="number">0</span>, ips.shape[<span class="number">0</span>], out=cs)</span><br><span class="line">        ips.img[rs,cs] = <span class="number">255</span></span><br><span class="line">        self.oldp = (y, x)</span><br><span class="line">        key[<span class="string">&#x27;canvas&#x27;</span>].update()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, ips, x, y, d, **key</span>):</span><span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestFrame</span>(<span class="params">CanvasFrame, App</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span> (<span class="params">self, parent</span>):</span></span><br><span class="line">        CanvasFrame.__init__(self, parent)</span><br><span class="line">        App.__init__(self)</span><br><span class="line"> </span><br><span class="line">        self.Bind(wx.EVT_ACTIVATE, self.init_image)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_image</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        self.add_img(self.canvas.image)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_menubar</span>(<span class="params">self</span>):</span></span><br><span class="line">        menubar = MenuBar(self)</span><br><span class="line">        self.SetMenuBar(menubar)</span><br><span class="line">        <span class="keyword">return</span> menubar</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera, astronaut</span><br><span class="line">    <span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread</span><br><span class="line"></span><br><span class="line">    app = wx.App()</span><br><span class="line">    cf = TestFrame(<span class="literal">None</span>)</span><br><span class="line">    cf.set_img(camera())</span><br><span class="line">    cf.set_cn(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    bar = cf.add_menubar()</span><br><span class="line">    bar.load((<span class="string">&#x27;menu&#x27;</span>,[(<span class="string">&#x27;Filter&#x27;</span>,[(<span class="string">&#x27;Gaussian&#x27;</span>, Gaussian),</span><br><span class="line">                                 (<span class="string">&#x27;Unto&#x27;</span>, Undo)]),]))</span><br><span class="line"></span><br><span class="line">    bar = cf.add_toolbar()</span><br><span class="line">    bar.add_tool(<span class="string">&#x27;M&#x27;</span>, DefaultTool)</span><br><span class="line">    bar.add_tool(<span class="string">&#x27;P&#x27;</span>, Pencil)</span><br><span class="line">    cf.Show()</span><br><span class="line">    app.MainLoop()</span><br></pre></td></tr></table></figure><p>这个例子又在上面例子的基础上加了工具栏。</p><h1 id="全组件集合版"><a href="#全组件集合版" class="headerlink" title="全组件集合版"></a>全组件集合版</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sciwx.app <span class="keyword">import</span> SciApp</span><br><span class="line"><span class="keyword">from</span> sciwx.action <span class="keyword">import</span> ImgAction, Tool, DefaultTool</span><br><span class="line"><span class="keyword">from</span> sciwx.plugins.curve <span class="keyword">import</span> Curve</span><br><span class="line"><span class="keyword">from</span> sciwx.plugins.channels <span class="keyword">import</span> Channels</span><br><span class="line"><span class="keyword">from</span> sciwx.plugins.histogram <span class="keyword">import</span> Histogram</span><br><span class="line"><span class="keyword">from</span> sciwx.plugins.viewport <span class="keyword">import</span> ViewPort</span><br><span class="line"><span class="keyword">from</span> sciwx.plugins.filters <span class="keyword">import</span> Gaussian, Undo</span><br><span class="line"><span class="keyword">from</span> sciwx.plugins.pencil <span class="keyword">import</span> Pencil</span><br><span class="line"><span class="keyword">from</span> sciwx.plugins.io <span class="keyword">import</span> Open, Save</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera</span><br><span class="line">   </span><br><span class="line">    app = wx.App(<span class="literal">False</span>)</span><br><span class="line">    frame = SciApp(<span class="literal">None</span>)</span><br><span class="line">   </span><br><span class="line">    frame.load_menu((<span class="string">&#x27;menu&#x27;</span>,[(<span class="string">&#x27;File&#x27;</span>,[(<span class="string">&#x27;Open&#x27;</span>, Open),</span><br><span class="line">                                      (<span class="string">&#x27;Save&#x27;</span>, Save)]),</span><br><span class="line">                             (<span class="string">&#x27;Filters&#x27;</span>, [(<span class="string">&#x27;Gaussian&#x27;</span>, Gaussian),</span><br><span class="line">                                          (<span class="string">&#x27;Undo&#x27;</span>, Undo)])]))</span><br><span class="line"></span><br><span class="line">    frame.load_tool((<span class="string">&#x27;tools&#x27;</span>,[(<span class="string">&#x27;standard&#x27;</span>, [(<span class="string">&#x27;P&#x27;</span>, Pencil),</span><br><span class="line">                                            (<span class="string">&#x27;D&#x27;</span>, DefaultTool)]),</span><br><span class="line">                              (<span class="string">&#x27;draw&#x27;</span>, [(<span class="string">&#x27;X&#x27;</span>, Pencil),</span><br><span class="line">                                        (<span class="string">&#x27;X&#x27;</span>, Pencil)])]), <span class="string">&#x27;draw&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    frame.load_widget((<span class="string">&#x27;widgets&#x27;</span>, [(<span class="string">&#x27;Histogram&#x27;</span>, [(<span class="string">&#x27;Histogram&#x27;</span>, Histogram),</span><br><span class="line">                                                  (<span class="string">&#x27;Curve&#x27;</span>, Curve),</span><br><span class="line">                                                  (<span class="string">&#x27;Channels&#x27;</span>, Channels)]),</span><br><span class="line">                                   (<span class="string">&#x27;Navigator&#x27;</span>, [(<span class="string">&#x27;Viewport&#x27;</span>, ViewPort)])]))</span><br><span class="line"></span><br><span class="line">    frame.show_img(camera())</span><br><span class="line">    frame.show_img(camera())</span><br><span class="line">    frame.Show()</span><br><span class="line">    app.MainLoop()</span><br></pre></td></tr></table></figure><p>该例子可以说是基于sciwx的重构版ImagePy的雏形了，面板、菜单栏、工具栏、直方图、鹰眼灯组件悉数登场，可以说非常完善了。</p>]]></content>
    
    
    <summary type="html">%%%%%%%%
2021.2.14更新:增加了sciapp和sciwx的介绍
%%%%%%%%

新版ImagePy有如下特点：
（1）将原版ImagePy非常特色的可视化组件完全解耦，比如画布、表格、对话框等组件，将其重构为sciwx库，这样第三方开发人员就可以更加方便地使用这些组件而构建自己的特定应用；
（2）创建了一套适用于图像处理的接口标准sciapp，其中定义了图像类Image、表格类Table、几何矢量类Shape，并实现了对这些类的常用操作，即sciapp作为后端支持；
（2）新版ImagePy在sciwx库和sciapp库的基础上进行再集成开发，即底层符合sciapp标准、前</summary>
    
    
    
    <category term="computational material science" scheme="http://qixinbo.github.io/categories/computational-material-science/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
</feed>
