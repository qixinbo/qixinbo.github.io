<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>数字旗手</title>
  
  <subtitle>电气化、自动化、数字化、智能化、智慧化</subtitle>
  <link href="http://qixinbo.github.io/atom.xml" rel="self"/>
  
  <link href="http://qixinbo.github.io/"/>
  <updated>2021-11-18T08:22:51.670Z</updated>
  <id>http://qixinbo.github.io/</id>
  
  <author>
    <name>Xin-Bo Qi(亓欣波)</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ImagePy解析： 28 -- 三维可视化</title>
    <link href="http://qixinbo.github.io/2021/11/18/ImagePy_28/"/>
    <id>http://qixinbo.github.io/2021/11/18/ImagePy_28/</id>
    <published>2021-11-17T16:00:00.000Z</published>
    <updated>2021-11-18T08:22:51.670Z</updated>
    
    <content type="html"><![CDATA[<p>本文解析一下ImagePy的三维画布。<br>以如下例子入手：<br><img src="https://user-images.githubusercontent.com/6218739/141955577-f4a7c5c5-0a9a-409b-9fde-399a92f0c1d8.png" alt="demo"><br>首先，原始图像是一个5乘5的方形图像，其中间是4乘4的白色，周围是一圈黑色。<br>由这张原始图根据距离变换得到右上角的高程图，继而对该高程图做三维可视化。</p><h1 id="渲染插件"><a href="#渲染插件" class="headerlink" title="渲染插件"></a>渲染插件</h1><p>二维平面的三维可视化插件是这样写的：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Surface2D</span>(<span class="params">Simple</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;2D Surface&#x27;</span></span><br><span class="line">    note = [<span class="string">&#x27;8-bit&#x27;</span>, <span class="string">&#x27;16-bit&#x27;</span>, <span class="string">&#x27;float&#x27;</span>]</span><br><span class="line">    para = &#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;undifine&#x27;</span>, <span class="string">&#x27;sample&#x27;</span>:<span class="number">2</span>, <span class="string">&#x27;sigma&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;h&#x27;</span>:<span class="number">0.3</span>, <span class="string">&#x27;cm&#x27;</span>:<span class="string">&#x27;gray&#x27;</span>&#125;</span><br><span class="line">    view = [(<span class="built_in">str</span>, <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">            (<span class="built_in">int</span>, <span class="string">&#x27;sample&#x27;</span>, (<span class="number">1</span>,<span class="number">10</span>), <span class="number">0</span>, <span class="string">&#x27;down sample&#x27;</span>, <span class="string">&#x27;pix&#x27;</span>),</span><br><span class="line">            (<span class="built_in">int</span>, <span class="string">&#x27;sigma&#x27;</span>, (<span class="number">0</span>,<span class="number">30</span>), <span class="number">0</span>, <span class="string">&#x27;sigma&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">            (<span class="built_in">float</span>, <span class="string">&#x27;h&#x27;</span>, (<span class="number">0.1</span>,<span class="number">10</span>), <span class="number">1</span>, <span class="string">&#x27;scale z&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">            (<span class="string">&#x27;cmap&#x27;</span>, <span class="string">&#x27;cm&#x27;</span>, <span class="string">&#x27;color map&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, imgs, para = <span class="literal">None</span></span>):</span></span><br><span class="line">        ds, sigma, cm = para[<span class="string">&#x27;sample&#x27;</span>], para[<span class="string">&#x27;sigma&#x27;</span>], ColorManager.get(para[<span class="string">&#x27;cm&#x27;</span>])</span><br><span class="line">        mesh = Surface2d(ips.img, sample=ds, sigma=sigma, k=para[<span class="string">&#x27;h&#x27;</span>], cmap=cm)</span><br><span class="line">        self.app.show_mesh(mesh, para[<span class="string">&#x27;name&#x27;</span>])</span><br></pre></td></tr></table></figure><br>其界面为：<br><img src="https://user-images.githubusercontent.com/6218739/141955719-7c81041c-9c56-4f10-ba0c-1d5d68643f20.png" alt="interface"><br>即设定名字、下采样率、平滑率和z轴伸缩率，以及渲染所用的colormap。(在该demo中，就按如图中的参数进行设置)<br>然后将这些参数传给Surface2d这个ImagePy定义的Mesh对象。<br>最后调用show_mesh方法将其呈现出来。<br>下面是一步步分析这个Mesh对象及其绘制方法。</p><h1 id="Mesh对象"><a href="#Mesh对象" class="headerlink" title="Mesh对象"></a>Mesh对象</h1><p>如前所述，二维高程图传给了Surface2d这一类，具体看一下其代码实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Surface2d</span>(<span class="params">Mesh</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, img=<span class="literal">None</span>, sample=<span class="number">1</span>, sigma=<span class="number">0</span>, k=<span class="number">0.3</span>, **key</span>):</span></span><br><span class="line">self.img, self.sample, self.sigma, self.k = img, sample, sigma, k</span><br><span class="line">Mesh.__init__(self, **key)</span><br><span class="line">self.set_data(img, sample, sigma, k)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_data</span>(<span class="params">self, img=<span class="literal">None</span>, sample=<span class="literal">None</span>, sigma=<span class="literal">None</span>, k=<span class="literal">None</span>, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> img <span class="keyword">is</span> <span class="literal">None</span>: self.img = img</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> sample <span class="keyword">is</span> <span class="literal">None</span>: self.sample = sample</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> sigma <span class="keyword">is</span> <span class="literal">None</span>: self.sigma = sigma</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> k <span class="keyword">is</span> <span class="literal">None</span>: self.k = k</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">sum</span>([<span class="keyword">not</span> i <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> (img, sample, sigma, k)])&gt;<span class="number">0</span>:</span><br><span class="line"><span class="keyword">from</span> ..util <span class="keyword">import</span> meshutil</span><br><span class="line">vert, fs = meshutil.create_surface2d(self.img, self.sample, self.sigma, self.k)</span><br><span class="line">Mesh.set_data(self, verts=vert, faces=fs.astype(np.uint32), colors=vert[:,<span class="number">2</span>], **key)</span><br><span class="line"><span class="keyword">else</span>: Mesh.set_data(self, **key)</span><br></pre></td></tr></table></figure><br>可以看到，在它的初始化函数中调用了set_data方法。进一步地，在该方法中有两个核心方法：将图像转化为顶点和面，然后再转为Mesh对象。</p><h2 id="位图提取格点坐标和像素值"><a href="#位图提取格点坐标和像素值" class="headerlink" title="位图提取格点坐标和像素值"></a>位图提取格点坐标和像素值</h2><p>即如下方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vert, fs = meshutil.create_surface2d(self.img, self.sample, self.sigma, self.k)</span><br></pre></td></tr></table></figure><br>源码及注释为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_surface2d</span>(<span class="params">img, sample=<span class="number">1</span>, sigma=<span class="number">0</span>, k=<span class="number">0.3</span></span>):</span></span><br><span class="line">    <span class="keyword">from</span> scipy.ndimage <span class="keyword">import</span> gaussian_filter</span><br><span class="line">    <span class="comment">#start = time()</span></span><br><span class="line">    <span class="comment"># 以采样率为步长进行图像的重新提取</span></span><br><span class="line">    img = img[::sample, ::sample].astype(np.float32)</span><br><span class="line">    <span class="comment"># 如果指定了平滑率，则使用高斯滤波进行平滑</span></span><br><span class="line">    <span class="keyword">if</span> sigma&gt;<span class="number">0</span>: img = gaussian_filter(img, sigma)</span><br><span class="line">    <span class="comment"># 根据采样后的图像形状生成网格格点</span></span><br><span class="line">    xs, ys = np.mgrid[:img.shape[<span class="number">0</span>],:img.shape[<span class="number">1</span>]]</span><br><span class="line">    <span class="comment"># 根据采样率，将格点范围伸缩到之前的大小</span></span><br><span class="line">    xs *= sample; ys *= sample</span><br><span class="line">    <span class="comment"># 将图像像素值乘以伸缩大小，作为z轴的值，与格点坐标xy传入下面的方法</span></span><br><span class="line">    <span class="keyword">return</span> create_grid_mesh(xs, ys, img*k)</span><br></pre></td></tr></table></figure><br>在此例中，依照上面的参数，来看一下各个中间结果：<br>首先高程图在降采样后，图像矩阵为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">2.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]]</span><br></pre></td></tr></table></figure><br>然后在$\sigma=1$的高斯滤波后，图像矩阵为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.17534617</span> <span class="number">0.2415005</span>  <span class="number">0.17534617</span>]</span><br><span class="line"> [<span class="number">0.2415005</span>  <span class="number">0.3326134</span>  <span class="number">0.2415005</span> ]</span><br><span class="line"> [<span class="number">0.17534617</span> <span class="number">0.2415005</span>  <span class="number">0.17534617</span>]]</span><br></pre></td></tr></table></figure><br>其再经过k倍的伸缩，变为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.8767308</span> <span class="number">1.2075025</span> <span class="number">0.8767308</span>]</span><br><span class="line"> [<span class="number">1.2075025</span> <span class="number">1.6630671</span> <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">0.8767308</span> <span class="number">1.2075025</span> <span class="number">0.8767308</span>]]</span><br></pre></td></tr></table></figure><br>同时xs和ys即网格格点坐标，也经过了降采样，以及范围伸缩，变为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">4</span> <span class="number">4</span>]]</span><br></pre></td></tr></table></figure></p><h2 id="获取格点和面的信息"><a href="#获取格点和面的信息" class="headerlink" title="获取格点和面的信息"></a>获取格点和面的信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_grid_mesh</span>(<span class="params">xs, ys, zs</span>):</span></span><br><span class="line">    h, w = xs.shape</span><br><span class="line">    <span class="comment"># 将xy坐标位置和z值合并起来</span></span><br><span class="line">    vts = np.array([xs, ys, zs], dtype=np.float32)</span><br><span class="line">    <span class="comment"># 这一步是定义以某格点为参考点的坐标系下它与哪些点形成面</span></span><br><span class="line">    <span class="comment"># 在局部坐标系下，参考点索引为0，那么它所构成的面有两个</span></span><br><span class="line">    <span class="comment"># 分别与(1, 1+w)这两个点构成一个面，与(1+w, w)这两个点构成一个面</span></span><br><span class="line">    <span class="comment"># 比如在此例下，did的值就是[[0 1 4 0 4 3]]</span></span><br><span class="line">    did = np.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>+w, <span class="number">0</span>, <span class="number">1</span>+w, w]], dtype=np.uint32)</span><br><span class="line">    <span class="comment"># rcs由两部分构成</span></span><br><span class="line">    <span class="comment"># 第一部分是获取全局坐标系下每一排的第一个元素的索引，所以是以w为步长</span></span><br><span class="line">    <span class="comment"># 注意排除最后一排，即是w*h还要减去w，因为最后一排元素所参与的面可以通过倒数第二排来获得</span></span><br><span class="line">    <span class="comment"># 对于此例，就是[[0], [3]]，注意这里使用None来增加一个维度</span></span><br><span class="line">    <span class="comment"># 第二部分是获取全局坐标系下每一列的索引，所以是以1为步长</span></span><br><span class="line">    <span class="comment"># 注意是排除最后一列，即w要减去1，这也是因为最后一列参与的面可以通过前一列得到</span></span><br><span class="line">    <span class="comment"># 对于此例，就是[0, 1]</span></span><br><span class="line">    <span class="comment"># 最终rcs就是numpy数组的[[0],[3]]+[0, 1]</span></span><br><span class="line">    <span class="comment"># 这里用到了numpy的广播： https://qixinbo.info/2019/10/20/python-indexing/</span></span><br><span class="line">    <span class="comment"># [[0, 0],[3, 3]] + [[0, 1], [0, 1]] = [[0, 1], [3, 4]]</span></span><br><span class="line">    <span class="comment"># 代表的意思就是在全局坐标系中，第一排取索引为0和1的格点，在第二排取索引为3和4的格点</span></span><br><span class="line">    rcs = np.arange(<span class="number">0</span>,w*h-w,w)[:,<span class="literal">None</span>] + np.arange(<span class="number">0</span>,w-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 接下来就是根据上面取得的格点，得到每个格点上所形成的面</span></span><br><span class="line">    <span class="comment"># 首先第一部分是将rcs拉直为[[0], [1], [3], [4]]，即这四个格点索引拉平到一个维度上</span></span><br><span class="line">    <span class="comment"># 然后加上上面的局部坐标系下形成面的格点索引[[0 1 4 0 4 3]]</span></span><br><span class="line">    <span class="comment"># 同样根据广播原则，就得到了每个格点与相邻点所形成的面</span></span><br><span class="line">    <span class="comment"># 结果为：[[0 1 4 0 4 3], [1 2 5 1 5 4], [3 4 7 3 7 6], [4 5 8 4 8 7]] </span></span><br><span class="line">    <span class="comment"># 即每个格点上都参与形成两个面，具体每一个面的格点组成看上面的序列</span></span><br><span class="line">    faces = rcs.reshape(-<span class="number">1</span>,<span class="number">1</span>) + did</span><br><span class="line">    <span class="comment"># 返回值是两个</span></span><br><span class="line">    <span class="comment"># 第一个就是格点坐标及其上面的值，并按这三个值合并起来算一个重新改变形状</span></span><br><span class="line">    <span class="comment"># 第二个就是由格点所形成的面的信息</span></span><br><span class="line">    <span class="keyword">return</span> vts.reshape(<span class="number">3</span>,-<span class="number">1</span>).T.copy(), faces.reshape(-<span class="number">1</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>具体的解析过程见上面源码。<br>最后说一下最终返回的格点信息和面信息，分别是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.</span>        <span class="number">0.</span>        <span class="number">0.8767308</span>]</span><br><span class="line"> [<span class="number">0.</span>        <span class="number">2.</span>        <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">0.</span>        <span class="number">4.</span>        <span class="number">0.8767308</span>]</span><br><span class="line"> [<span class="number">2.</span>        <span class="number">0.</span>        <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">2.</span>        <span class="number">2.</span>        <span class="number">1.6630671</span>]</span><br><span class="line"> [<span class="number">2.</span>        <span class="number">4.</span>        <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">4.</span>        <span class="number">0.</span>        <span class="number">0.8767308</span>]</span><br><span class="line"> [<span class="number">4.</span>        <span class="number">2.</span>        <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">4.</span>        <span class="number">4.</span>        <span class="number">0.8767308</span>]]</span><br></pre></td></tr></table></figure><br>以第一个格点为例，它是在(0, 0)坐标，同时上面的值是0.8767308。<br>以及面信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">1</span> <span class="number">4</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">4</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">2</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">5</span> <span class="number">4</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">7</span> <span class="number">6</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span> <span class="number">8</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">8</span> <span class="number">7</span>]]</span><br></pre></td></tr></table></figure><br>以第一个面为例，它由(0, 1, 4)号格点组成。</p><h2 id="构建Mesh对象"><a href="#构建Mesh对象" class="headerlink" title="构建Mesh对象"></a>构建Mesh对象</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传入上面的格点、面、颜色（这里取的是格点上的z值）以及cmap</span></span><br><span class="line">Mesh.set_data(self, verts=vert, faces=fs.astype(np.uint32), colors=vert[:,<span class="number">2</span>], **key)</span><br></pre></td></tr></table></figure><p>上述代码是调用了Mesh对象的set_data方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mesh</span>:</span></span><br><span class="line"><span class="comment"># 在初始化函数中传入一个Mesh对象所需要的信息</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, verts=<span class="literal">None</span>, faces=<span class="literal">None</span>, colors=<span class="literal">None</span>, cmap=<span class="literal">None</span>, **key</span>):</span></span><br><span class="line"><span class="comment"># 如果有格点信息，但没有面信息</span></span><br><span class="line"><span class="keyword">if</span> faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> verts <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line"><span class="comment"># 则直接按格点个数-1生成面，即两个相邻格点相连，就成为面</span></span><br><span class="line">faces = np.arange(<span class="built_in">len</span>(verts), dtype=np.uint32)</span><br><span class="line"><span class="comment"># 传入格点信息</span></span><br><span class="line">self.verts = verts.astype(np.float32, copy=<span class="literal">False</span>) <span class="keyword">if</span> <span class="keyword">not</span> verts <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="comment"># 传入面信息</span></span><br><span class="line">self.faces = faces.astype(np.uint32, copy=<span class="literal">False</span>) <span class="keyword">if</span> <span class="keyword">not</span> faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="comment"># 传入颜色信息</span></span><br><span class="line">self.colors = colors</span><br><span class="line"><span class="comment"># 设置模式、可见性和dirty属性等</span></span><br><span class="line">self.mode, self.visible, self.dirty = <span class="string">&#x27;mesh&#x27;</span>, <span class="literal">True</span>, <span class="string">&#x27;geom&#x27;</span></span><br><span class="line"><span class="comment"># 设置alpha透明度和边信息</span></span><br><span class="line">self.alpha = <span class="number">1</span>; self.edges = <span class="literal">None</span></span><br><span class="line"><span class="comment"># 设置高光、colormap</span></span><br><span class="line">self.high_light = <span class="literal">False</span>; self.cmap = <span class="string">&#x27;gray&#x27;</span> <span class="keyword">if</span> cmap <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> cmap</span><br><span class="line"><span class="comment"># 调用set_data方法</span></span><br><span class="line">self.set_data(**key)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_data</span>(<span class="params">self, verts=<span class="literal">None</span>, faces=<span class="literal">None</span>, colors=<span class="literal">None</span>, **key</span>):</span></span><br><span class="line"><span class="comment"># 同上面的初始化功能近似，区别是可以直接调用它来配置信息</span></span><br><span class="line"><span class="keyword">if</span> faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> verts <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">faces = np.arange(<span class="built_in">len</span>(verts), dtype=np.uint32)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> verts <span class="keyword">is</span> <span class="literal">None</span>: self.verts = verts.astype(np.float32, copy=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> faces <span class="keyword">is</span> <span class="literal">None</span>: self.faces = faces.astype(np.uint32, copy=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> colors <span class="keyword">is</span> <span class="literal">None</span>: self.colors = colors</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> faces <span class="keyword">is</span> <span class="literal">None</span>: self.edge = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">sum</span>([i <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> [verts, faces, colors]])&lt;<span class="number">3</span>: self.dirty = <span class="string">&#x27;geom&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> self.faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> self.faces.ndim==<span class="number">1</span>: key[<span class="string">&#x27;mode&#x27;</span>] = <span class="string">&#x27;points&#x27;</span></span><br><span class="line"><span class="keyword">elif</span> <span class="keyword">not</span> self.faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> self.faces.shape[<span class="number">1</span>]==<span class="number">2</span>: </span><br><span class="line"><span class="keyword">if</span> key.get(<span class="string">&#x27;mode&#x27;</span>, self.mode)==<span class="string">&#x27;mesh&#x27;</span>: key[<span class="string">&#x27;mode&#x27;</span>] = <span class="string">&#x27;grid&#x27;</span></span><br><span class="line"><span class="keyword">if</span> key.get(<span class="string">&#x27;mode&#x27;</span>, self.mode) != self.mode: self.dirty = <span class="string">&#x27;geom&#x27;</span></span><br><span class="line">self.mode = key.get(<span class="string">&#x27;mode&#x27;</span>, self.mode)</span><br><span class="line">self.visible = key.get(<span class="string">&#x27;visible&#x27;</span>, self.visible)</span><br><span class="line">self.alpha = key.get(<span class="string">&#x27;alpha&#x27;</span>, self.alpha)</span><br><span class="line">self.high_light = key.get(<span class="string">&#x27;high_light&#x27;</span>, <span class="literal">False</span>)</span><br><span class="line">self.cmap = key.get(<span class="string">&#x27;cmap&#x27;</span>, self.cmap)</span><br><span class="line">self.dirty = self.dirty <span class="keyword">or</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure></p><h1 id="可视化Mesh"><a href="#可视化Mesh" class="headerlink" title="可视化Mesh"></a>可视化Mesh</h1><p>即将Mesh对象通过三维画布展示出来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.app.show_mesh(mesh, para[<span class="string">&#x27;name&#x27;</span>])</span><br></pre></td></tr></table></figure><br>这里就是调用了app的show_mesh方法。<br>ImagePy的三维画布是基于VisPy的，同时又进行了封装，最底层的是如下这个类：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Canvas3D</span>(<span class="params">scene.SceneCanvas</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>(<span class="params">cls, parent, scene3d=<span class="literal">None</span></span>):</span></span><br><span class="line">        self = <span class="built_in">super</span>().__new__(cls)</span><br><span class="line">        scene.SceneCanvas.__init__(self, app=<span class="string">&quot;wx&quot;</span>, parent=parent, keys=<span class="string">&#x27;interactive&#x27;</span>, show=<span class="literal">True</span>, dpi=<span class="number">150</span>)</span><br><span class="line">        canvas = parent.GetChildren()[-<span class="number">1</span>]</span><br><span class="line">        self.unfreeze()</span><br><span class="line">        self.canvas = weakref.ref(canvas)</span><br><span class="line">        self.view = self.central_widget.add_view()</span><br><span class="line">        self.set_scene(scene3d <span class="keyword">or</span> Scene())</span><br><span class="line">        self.visuals = &#123;&#125;</span><br><span class="line">        self.curobj = <span class="literal">None</span></span><br><span class="line">        self.freeze()</span><br><span class="line">        canvas.Bind(wx.EVT_IDLE, self.on_idle)</span><br><span class="line">        canvas.tool = <span class="literal">None</span></span><br><span class="line">        canvas.camera = scene.cameras.TurntableCamera(parent=self.view.scene, fov=<span class="number">45</span>, name=<span class="string">&#x27;Turntable&#x27;</span>)</span><br><span class="line">        canvas.set_camera = self.set_camera</span><br><span class="line">        canvas.fit = <span class="keyword">lambda</span> : self.set_camera(auto=<span class="literal">True</span>)</span><br><span class="line">        canvas.at = self.at</span><br><span class="line">        self.view.camera = canvas.camera</span><br><span class="line">        <span class="keyword">return</span> canvas</span><br></pre></td></tr></table></figure><br>VisPy的教程略微有点少，留坑待填。</p>]]></content>
    
    
    <summary type="html">本文解析一下ImagePy的三维画布。
以如下例子入手：

首先，原始图像是一个5乘5的方形图像，其中间是4乘4的白色，周围是一圈黑色。
由这张原始图根据距离变换得到右上角的高程图，继而对该高程图做三维可视化。

渲染插件
二维平面的三维可视化插件是这样写的：
1
2
3
4
5
6
7
8
9
10
11
12
13
14


class Surface2D(Simple):
    title = &#39;2D Surface&#39;
    note = [&#39;8-bit&#39;, &#39;16-bit&#39;, &#39;float&#39;]
    para = {&#39;name&#39;:&#39;undifine&#39;, &#39;sample&#39;:2, &#39;</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>Electron初探：基于Web的跨平台桌面应用开发</title>
    <link href="http://qixinbo.github.io/2021/11/15/electron/"/>
    <id>http://qixinbo.github.io/2021/11/15/electron/</id>
    <published>2021-11-14T16:00:00.000Z</published>
    <updated>2021-11-15T06:37:55.565Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://juejin.cn/post/6844904055236460558">你能分得清楚 Chromium, V8, Blink, Gecko, WebKit 之间的区别吗？</a><br><a href="https://msyfls123.github.io/blog/2020/11/02/%E4%B8%9D%E8%88%AC%E9%A1%BA%E6%BB%91%E7%9A%84Electron%E8%B7%A8%E7%AB%AF%E5%BC%80%E5%8F%91%E4%BD%93%E9%AA%8C/">丝般顺滑的 Electron 跨端开发体验</a><br><a href="https://jspang.com/detailed?id=62#toc34">Electron 免费视频教程-用前端技术开发桌面应用</a><br><a href="https://weishuai.gitbooks.io/electron-/content/tutorial/quick-start.html">Electron 快速入门</a></p><h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><h2 id="引擎"><a href="#引擎" class="headerlink" title="引擎"></a>引擎</h2><p>JavaScript引擎的作用是解释和编译JavaScript代码。<br>而浏览器引擎不仅负责管理网页的布局，同时其包括JavaScript引擎。<br>当前市场上只有 3 个主要的浏览器引擎：Mozilla 的 Gecko、Google 的 Blink、还有苹果的的 WebKit（Blink 的近亲）。<br>Blink 是 Google Chrome浏览器及Chromium开源浏览器（可以理解为：Chromium + 集成 Google 产品 = Google Chrome）的渲染引擎，V8 是 Blink 内置的 JavaScript 引擎。具体来说，V8 对 DOM（文档对象模型）一无所知，因为它仅用于处理 JavaScript；而Blink 内置的布局引擎负责处理网页布局和展示。</p><h2 id="后端"><a href="#后端" class="headerlink" title="后端"></a>后端</h2><p>Node.js 就是运行在服务端的 JavaScript，类比Java后端、Python后端等。<br>因为 Node.js 不需要使用 DOM，所以 Node.js 只使用了 V8 引擎，而没有把整个 Blink 引擎都搬过来用。</p><h2 id="Electron"><a href="#Electron" class="headerlink" title="Electron"></a>Electron</h2><p>Electron = Chromium + Node.js + Native API<br>（1）Chromium : 为Electron提供了强大的UI能力，可以不考虑兼容性的情况下，利用强大的Web生态来开发界面。<br>（2）Node.js ：让Electron有了底层的操作能力，比如文件的读写，甚至是集成C++等等操作，并可以使用大量开源的npm包来完成开发需求。<br>（3）Native API ： Native API让Electron有了跨平台和桌面端的原生能力，比如说它有统一的原生界面，窗口、托盘这些。</p><p>Electron作用是用Web前端技术来开发桌面应用。</p><p>具体原理：<br>Electron 就是 Chromium（Chrome 内核）、Node.js 和系统原生 API 的结合。它做的事情很简单，整个应用跑在一个 main process（主进程） 上，需要提供 GUI 界面时则创建一个 renderer process（渲染进程）去开启一个 Chromium 里的 BrowserWindow/BrowserView，实际就像是 Chrome 的一个窗口或者 Tab 页一样，而其中展示的既可以是本地网页也可以是线上网页，主进程和渲染进程间通过 IPC 进行通讯，主进程可以自由地调用 Electron 提供的系统 API 以及 Node.js 模块，可以控制其所辖渲染进程的生命周期。</p><h3 id="主进程"><a href="#主进程" class="headerlink" title="主进程"></a>主进程</h3><p>在 Electron 里，运行 package.json 里 main 脚本的进程被称为主进程。在主进程运行的脚本可以以创建 web 页面的形式展示 GUI。</p><h3 id="渲染进程"><a href="#渲染进程" class="headerlink" title="渲染进程"></a>渲染进程</h3><p>由于 Electron 使用 Chromium 来展示页面，所以 Chromium 的多进程结构也被充分利用。每个 Electron 的页面都在运行着自己的进程，这样的进程我们称之为渲染进程。<br>在一般浏览器中，网页通常会在沙盒环境下运行，并且不允许访问原生资源。然而，Electron 用户拥有在网页中调用 Node.js 的 APIs 的能力，可以与底层操作系统直接交互。</p><h3 id="主进程与渲染进程的区别"><a href="#主进程与渲染进程的区别" class="headerlink" title="主进程与渲染进程的区别"></a>主进程与渲染进程的区别</h3><p>主进程使用 BrowserWindow 实例创建页面。每个 BrowserWindow 实例都在自己的渲染进程里运行页面。当一个 BrowserWindow 实例被销毁后，相应的渲染进程也会被终止。<br>主进程管理所有页面和与之对应的渲染进程。每个渲染进程都是相互独立的，并且只关心他们自己的页面。<br>由于在页面里管理原生 GUI 资源是非常危险而且容易造成资源泄露，所以在页面调用 GUI 相关的 APIs 是不被允许的。如果你想在网页里使用 GUI 操作，其对应的渲染进程必须与主进程进行通讯，请求主进程进行相关的 GUI 操作。<br>在 Electron，我们提供几种方法用于主进程和渲染进程之间的通讯。像 ipcRenderer 和 ipcMain 模块用于发送消息， remote 模块用于 RPC 方式通讯。</p><h1 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h1><h2 id="安装Electron"><a href="#安装Electron" class="headerlink" title="安装Electron"></a>安装Electron</h2><p>可以全局安装：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g electron</span><br></pre></td></tr></table></figure><br>或者仅项目安装：新建一个文件夹，然后，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install electron --save-dev</span><br></pre></td></tr></table></figure><br>然后使用以下命令查看是否安装成功：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npx electron -v</span><br><span class="line">或</span><br><span class="line">./node_modules/.<span class="built_in">bin</span>/electron -v</span><br></pre></td></tr></table></figure></p><h1 id="Electron的Hello-World"><a href="#Electron的Hello-World" class="headerlink" title="Electron的Hello World"></a>Electron的Hello World</h1><h2 id="新建index-html文件"><a href="#新建index-html文件" class="headerlink" title="新建index.html文件"></a>新建index.html文件</h2><p>在项目的根目录中新建一个index.html文件，相当于UI都写在html中（可以在sublimetext输入html自动生成）：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=<span class="string">&quot;utf-8&quot;</span>&gt;</span><br><span class="line">    &lt;meta name=<span class="string">&quot;viewport&quot;</span> content=<span class="string">&quot;width=device-width, initial-scale=1&quot;</span>&gt;</span><br><span class="line">    &lt;title&gt;Hello World&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">    hello World</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p><h2 id="新建main-js文件"><a href="#新建main-js文件" class="headerlink" title="新建main.js文件"></a>新建main.js文件</h2><p>在根目录下新建一个main.js文件，这个就是Electron的主进程文件。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">var electron = require(<span class="string">&#x27;electron&#x27;</span>)  //引入electron模块</span><br><span class="line"></span><br><span class="line">var app = electron.app   // 创建electron引用</span><br><span class="line"></span><br><span class="line">var BrowserWindow = electron.BrowserWindow;  //创建窗口引用</span><br><span class="line"></span><br><span class="line">var mainWindow = null ;  //声明要打开的主窗口</span><br><span class="line">app.on(&#x27;ready&#x27;,()=&gt;&#123;</span><br><span class="line">    mainWindow = new BrowserWindow(&#123;width:<span class="number">400</span>,height:<span class="number">400</span>&#125;)   //设置打开的窗口大小</span><br><span class="line"></span><br><span class="line">    mainWindow.loadFile(<span class="string">&#x27;index.html&#x27;</span>)  //加载那个页面</span><br><span class="line"></span><br><span class="line">    //监听关闭事件，把主窗口设置为null</span><br><span class="line">    mainWindow.on(&#x27;closed&#x27;,()=&gt;&#123;</span><br><span class="line">        mainWindow = null</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p><h2 id="创建package-json文件"><a href="#创建package-json文件" class="headerlink" title="创建package.json文件"></a>创建package.json文件</h2><p>在终端使用命令：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm init --yes</span><br></pre></td></tr></table></figure><br>这时候main的值为main.js就正确了。</p><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>终端下运行：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\node_modules\.<span class="built_in">bin</span>\electron .</span><br></pre></td></tr></table></figure></p><p>然后结果为：<br><img src="https://user-images.githubusercontent.com/6218739/141733207-8ae86b3e-95ab-4c5d-8e49-6f11c5721fd7.png" alt="hello"></p><p>试了这个最小例子，感觉使用electron来开发桌面应用的话，既能跨平台，比如Windows、Linux、MacOS，一处水源供全球，还能直接转化成Web应用，即不让用户安装软件，给他一个链接直接访问。<br>这样就可进可退，一次开发，到处使用，但前提是得熟悉JS开发，这个坑待填。。</p>]]></content>
    
    
    <summary type="html">参考文献
你能分得清楚 Chromium, V8, Blink, Gecko, WebKit 之间的区别吗？
丝般顺滑的 Electron 跨端开发体验
Electron 免费视频教程-用前端技术开发桌面应用
Electron 快速入门

基础概念
引擎
JavaScript引擎的作用是解释和编译JavaScript代码。
而浏览器引擎不仅负责管理网页的布局，同时其包括JavaScript引擎。
当前市场上只有 3 个主要的浏览器引擎：Mozilla 的 Gecko、Google 的 Blink、还有苹果的的 WebKit（Blink 的近亲）。
Blink 是 Google Chrome浏览</summary>
    
    
    
    <category term="digitalization" scheme="http://qixinbo.github.io/categories/digitalization/"/>
    
    
    <category term="GUI" scheme="http://qixinbo.github.io/tags/GUI/"/>
    
  </entry>
  
  <entry>
    <title>NLP霸主Transformer及CV新秀Vision Transformer解析</title>
    <link href="http://qixinbo.github.io/2021/11/09/transformer/"/>
    <id>http://qixinbo.github.io/2021/11/09/transformer/</id>
    <published>2021-11-08T16:00:00.000Z</published>
    <updated>2021-11-09T07:58:46.805Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://cuijiahua.com/blog/2021/01/dl-basics-3.html">保姆级教程：图解Transformer</a><br><a href="https://terrifyzhao.github.io/2019/01/11/Transformer%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.html">Transformer模型详解</a><br><a href="https://wmathor.com/index.php/archives/1438/">Transformer 详解</a><br><a href="https://picture.iczhiku.com/weixin/message1610942723056.html">盘点 | 2021年paper大热的Transformer (ViT)</a><br><a href="https://zhuanlan.zhihu.com/p/356155277">“未来”的经典之作ViT：transformer is all you need!</a><br><a href="https://paddlepedia.readthedocs.io/en/latest/tutorials/computer_vision/classification/ViT.html">ViT( Vision Transformer)</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention Is All You Need</a>是一篇Google于2017年提出的将Attention思想发挥到极致的论文。这篇论文中提出一个全新的模型，叫 Transformer，抛弃了以往深度学习任务里面使用到的 CNN 和 RNN ，目前大热的Bert、GPT和DALL-E就是基于Transformer构建的，这个模型广泛应用于NLP领域，例如机器翻译，问答系统，文本摘要和语音识别等等方向。<br><img src="https://user-images.githubusercontent.com/6218739/140851930-34149770-8d8b-4fed-bdf2-43cce255f0b1.png" alt="1"></p><p>相比于NLP领域，在CV领域中，卷积神经网络CNN却是绝对的霸主。对于图像问题，CNN具有天然的先天优势（inductive bias）：平移不变性（translation equivariance）和局部性（locality）。而transformer虽然不并具备这些优势，但是transformer的核心self-attention的优势不像卷积那样有固定且有限的感受野，self-attention操作可以获得long-range信息（相比之下CNN要通过不断堆积Conv layers来获取更大的感受野），但训练的难度就比CNN要稍大一些。<br>仍然是Google，<a href="https://arxiv.org/pdf/2010.11929.pdf">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a>这篇2020年的论文将Transformer引入了CV中，形成了Vision Transformer，简称为ViT。<br>本文尝试理解一下原始Transformer及其衍生品ViT。</p><h1 id="Transformer架构"><a href="#Transformer架构" class="headerlink" title="Transformer架构"></a>Transformer架构</h1><p>Transformer 的内部，在本质上是一个 Encoder-Decoder 的结构，即 编码器-解码器。<br><img src="https://user-images.githubusercontent.com/6218739/140852001-0fbc70ae-83f7-40c7-b784-4ed205ac30a9.png" alt="2"><br>Transformer 中抛弃了传统的 CNN 和 RNN，整个网络结构完全由 Attention 机制组成，并且采用了 6 层 Encoder-Decoder 结构。<br><img src="https://user-images.githubusercontent.com/6218739/140852095-d48c5aaa-d167-4169-8b56-5451a8db4416.png" alt="3"><br>显然，Transformer 主要分为两大部分，分别是编码器和解码器。<br>整个 Transformer 是由 6 个这样的结构组成，为了方便理解，我们只看其中一个Encoder-Decoder 结构。<br>以一个简单的例子进行说明：<br><img src="https://user-images.githubusercontent.com/6218739/140852188-a8f1dee3-5b59-489b-ba4e-df8d6664f6da.png" alt="4"></p><p>Why do we work?，我们为什么工作？<br>左侧红框是编码器，右侧红框是解码器，<br>编码器负责把自然语言序列映射成为隐藏层（上图第2步），即含有自然语言序列的数学表达。<br>解码器把隐藏层再映射为自然语言序列，从而使我们可以解决各种问题，如情感分析、机器翻译、摘要生成、语义关系抽取等。<br>简单说下，上图每一步都做了什么：<br>（1）输入自然语言序列到编码器: Why do we work?；<br>（2）编码器输出的隐藏层，再输入到解码器；<br>（3）输入 $&lt;𝑠𝑡𝑎𝑟𝑡&gt;$符号到解码器；<br>（4）解码器得到第一个字”为”；<br>（5）将得到的第一个字”为”落下来再输入到解码器；<br>（6）解码器得到第二个字”什”；<br>（7）将得到的第二字再落下来，直到解码器输出 $&lt;𝑒𝑛𝑑&gt;$，即序列生成完成。</p><h2 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h2><p>编码器即是把自然语言序列映射为隐藏层的数学表达的过程。<br>为了方便学习，编码器可以分为 4 个部分：<br><img src="https://user-images.githubusercontent.com/6218739/140853558-6b30feb1-7ca3-495b-8c6f-a1456d67be8d.png" alt="5"></p><h3 id="位置嵌入（𝑝𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝑎𝑙-𝑒𝑛𝑐𝑜𝑑𝑖𝑛𝑔）"><a href="#位置嵌入（𝑝𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝑎𝑙-𝑒𝑛𝑐𝑜𝑑𝑖𝑛𝑔）" class="headerlink" title="位置嵌入（𝑝𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝑎𝑙 𝑒𝑛𝑐𝑜𝑑𝑖𝑛𝑔）"></a>位置嵌入（𝑝𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝑎𝑙 𝑒𝑛𝑐𝑜𝑑𝑖𝑛𝑔）</h3><p>我们输入数据 X 维度为[batch size, sequence length]的数据，比如我们为什么工作。<br>batch size 就是 batch 的大小，这里只有一句话，所以 batch size 为 1，sequence length 是句子的长度，一共 7 个字，所以输入的数据维度是 [1, 7]。<br>我们不能直接将这句话输入到编码器中，因为 Tranformer 不认识，我们需要先进行字嵌入，即得到图中的$X_{embedding}$。</p><p>简单点说，就是文字到字向量的转换，这种转换是将文字转换为计算机认识的数学表示，用到的方法就是Word2Vec，Word2Vec的具体细节，对于初学者暂且不用了解，这个是可以直接使用的。</p><p>得到的$X{embedding}$的维度是[batch size, sequence length, embedding dimension]，embedding dimension 的大小由 Word2Vec 算法决定，Tranformer 采用 512 长度的字向量。所以$X_{embedding}$的维度是[1, 7, 512]。</p><p>至此，输入的我们为什么工作，可以用一个矩阵来简化表示。<br><img src="https://user-images.githubusercontent.com/6218739/140853602-a6f68d15-8308-4b0d-b067-abb5d9a7e098.png" alt="6"><br>我们知道，文字的先后顺序，很重要。<br>比如吃饭没、没吃饭、没饭吃、饭吃没、饭没吃，同样三个字，顺序颠倒，所表达的含义就不同了。<br>文字的位置信息很重要，Tranformer 没有类似 RNN 的循环结构，没有捕捉顺序序列的能力。<br>为了保留这种位置信息交给 Tranformer 学习，我们需要用到位置嵌入。<br>加入位置信息的方式非常多，最简单的可以是直接将绝对坐标 0,1,2 编码。<br>Tranformer 采用的是 sin-cos 规则，使用了 sin 和 cos 函数的线性变换来提供给模型位置信息：</p><script type="math/tex; mode=display">\begin{aligned} P E_{(p o s, 2 i)} &=\sin \left(p o s / 10000^{2 i / d_{\text {model }}}\right) \\ P E_{(\text {pos }, 2 i+1)} &=\cos \left(\text { pos } / 10000^{2 i / d_{\text {model }}}\right) \end{aligned}</script><p>上式中 pos 指的是句中字的位置，取值范围是 [0, 𝑚𝑎𝑥 𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 𝑙𝑒𝑛𝑔𝑡ℎ)，i 指的是字嵌入的维度, 取值范围是 [0, 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑑𝑖𝑚𝑒𝑛𝑠𝑖𝑜𝑛)。<br>上面有 sin 和 cos 一组公式，也就是对应着 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑑𝑖𝑚𝑒𝑛𝑠𝑖𝑜𝑛 维度的一组奇数和偶数的序号的维度，从而产生不同的周期性变化。<br>可以用代码，简单看下效果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入依赖库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_positional_encoding</span>(<span class="params">max_seq_len, embed_dim</span>):</span></span><br><span class="line">    <span class="comment"># 初始化一个positional encoding</span></span><br><span class="line">    <span class="comment"># embed_dim: 字嵌入的维度</span></span><br><span class="line">    <span class="comment"># max_seq_len: 最大的序列长度</span></span><br><span class="line">    positional_encoding = np.array([</span><br><span class="line">        [pos / np.power(<span class="number">10000</span>, <span class="number">2</span> * i / embed_dim) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(embed_dim)]</span><br><span class="line">        <span class="keyword">if</span> pos != <span class="number">0</span> <span class="keyword">else</span> np.zeros(embed_dim) <span class="keyword">for</span> pos <span class="keyword">in</span> <span class="built_in">range</span>(max_seq_len)])</span><br><span class="line">    positional_encoding[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(positional_encoding[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>])  <span class="comment"># dim 2i 偶数</span></span><br><span class="line">    positional_encoding[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(positional_encoding[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>])  <span class="comment"># dim 2i+1 奇数</span></span><br><span class="line">    <span class="comment"># 归一化, 用位置嵌入的每一行除以它的模长</span></span><br><span class="line">    <span class="comment"># denominator = np.sqrt(np.sum(position_enc**2, axis=1, keepdims=True))</span></span><br><span class="line">    <span class="comment"># position_enc = position_enc / (denominator + 1e-8)</span></span><br><span class="line">    <span class="keyword">return</span> positional_encoding</span><br><span class="line">    </span><br><span class="line">positional_encoding = get_positional_encoding(max_seq_len=<span class="number">100</span>, embed_dim=<span class="number">16</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">sns.heatmap(positional_encoding)</span><br><span class="line">plt.title(<span class="string">&quot;Sinusoidal Function&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;hidden dimension&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;sequence length&quot;</span>)</span><br></pre></td></tr></table></figure><br>可以看到，位置嵌入在 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑑𝑖𝑚𝑒𝑛𝑠𝑖𝑜𝑛 （也是hidden dimension ）维度上随着维度序号增大，周期变化会越来越慢，而产生一种包含位置信息的纹理。<br><img src="https://user-images.githubusercontent.com/6218739/140854019-3e363d94-cefe-4772-a7f2-fa87de1eb41b.png" alt="embed"><br>就这样，产生独一的纹理位置信息，模型从而学到位置之间的依赖关系和自然语言的时序特性。<br>最后，将$X_{\text {embedding }}$和 位置嵌入 相加（维度相同，可以直接相加），得到该字真正的向量表示，然后送给下一层。</p><h3 id="自注意力层（𝑠𝑒𝑙𝑓-𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛-𝑚𝑒𝑐ℎ𝑎𝑛𝑖𝑠𝑚）"><a href="#自注意力层（𝑠𝑒𝑙𝑓-𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛-𝑚𝑒𝑐ℎ𝑎𝑛𝑖𝑠𝑚）" class="headerlink" title="自注意力层（𝑠𝑒𝑙𝑓 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 𝑚𝑒𝑐ℎ𝑎𝑛𝑖𝑠𝑚）"></a>自注意力层（𝑠𝑒𝑙𝑓 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 𝑚𝑒𝑐ℎ𝑎𝑛𝑖𝑠𝑚）</h3><p>这部分介绍来自于<a href="https://terrifyzhao.github.io/2019/01/11/Transformer%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.html">这篇博客</a><br>self-attention，其思想和attention类似，但是self-attention是Transformer用来将其他相关单词的“理解”转换成我们正在处理的单词的一种思路，我们看个例子： The animal didn’t cross the street because it was too tired 这里的it到底代表的是animal还是street呢，对于我们来说能很简单的判断出来，但是对于机器来说，是很难判断的，self-attention就能够让机器把it和animal联系起来，接下来我们看下详细的处理过程。<br>（1）首先，self-attention会计算出三个新的向量，在论文中，向量的维度是512维，我们把这三个向量分别称为Query、Key、Value，这三个向量是用embedding向量与一个矩阵相乘得到的结果，这个矩阵是随机初始化的，维度为（64，512），注意第二个维度需要和embedding的维度一样，其值在BP的过程中会一直进行更新，得到的这三个向量的维度是64低于embedding维度的。<br><img src="https://user-images.githubusercontent.com/6218739/140857139-71ca395e-ec3a-40c4-8c0d-4c815ceb9e09.png" alt="qkv"><br>那么Query、Key、Value这三个向量又是什么呢？这三个向量对于attention来说很重要，当你理解了下文后，你将会明白这三个向量扮演者什么的角色。<br>（2）计算self-attention的分数值，该分数值决定了当我们在某个位置encode一个词时，对输入句子的其他部分的关注程度。这个分数值的计算方法是Query与Key做点乘，以下图为例，首先我们需要针对Thinking这个词，计算出其他词对于该词的一个分数值，首先是针对于自己本身即$q1·k1$，然后是针对于第二个词即$q1·k2$。<br><img src="https://user-images.githubusercontent.com/6218739/140857357-91caf198-e459-471b-a800-8ae705ef1434.png" alt="score"><br>（3）接下来，把点乘的结果除以一个常数，这里我们除以8，这个值一般是采用上文提到的矩阵的第一个维度的开方即64的开方8，当然也可以选择其他的值，然后把得到的结果做一个softmax的计算。得到的结果即是每个词对于当前位置的词的相关性大小，当然，当前位置的词相关性肯定会很大。<br><img src="https://user-images.githubusercontent.com/6218739/140857512-c22f2546-25e5-449d-8632-6cdffd1dc4fe.png" alt="score2"><br>（4）下一步就是把Value和softmax得到的值进行相乘，并相加，得到的结果即是self-attention在当前节点的值。<br><img src="https://user-images.githubusercontent.com/6218739/140857653-468ca02a-3dfb-4d33-a8b9-36f8596f9f15.png" alt="score3"><br>在实际的应用场景，为了提高计算速度，我们采用的是矩阵的方式，直接计算出Query, Key, Value的矩阵，然后把embedding的值与三个矩阵直接相乘，把得到的新矩阵Q与K相乘，乘以一个常数，做softmax操作，最后乘上V矩阵：<br><img src="https://user-images.githubusercontent.com/6218739/140857883-d06b029d-99ec-4a28-8711-35b0d4425f53.png" alt="attention"><br><img src="https://user-images.githubusercontent.com/6218739/140857941-c6f16054-2104-4205-850b-d15bc96a6659.png" alt="attention2"><br>这种通过 query 和 key 的相似性程度来确定 value 的权重分布的方法被称为scaled dot-product attention。</p><h4 id="Multi-Headed-Attention"><a href="#Multi-Headed-Attention" class="headerlink" title="Multi-Headed Attention"></a>Multi-Headed Attention</h4><p>这篇论文更牛的地方是给self-attention加入了另外一个机制，被称为“multi-headed” attention，该机制理解起来很简单，就是说不仅仅只初始化一组Q、K、V的矩阵，而是初始化多组，tranformer是使用了8组，所以最后得到的结果是8个矩阵。<br><img src="https://user-images.githubusercontent.com/6218739/140868505-278beff7-e9dc-440d-87ad-b2a021310a59.png" alt="multihead1"><br><img src="https://user-images.githubusercontent.com/6218739/140868544-311c039e-252c-425f-b957-3d1f2eece542.png" alt="multihead2"><br>这给我们留下了一个小的挑战，前馈神经网络没法输入8个矩阵呀，这该怎么办呢？所以我们需要一种方式，把8个矩阵降为1个，首先，我们把8个矩阵连在一起，这样会得到一个大的矩阵，再随机初始化一个矩阵和这个组合好的矩阵相乘，最后得到一个最终的矩阵。<br><img src="https://user-images.githubusercontent.com/6218739/140868642-638e7a9f-6543-4068-b569-12984bc7b5be.png" alt="multihead3"><br>这就是multi-headed attention的全部流程了，这里其实已经有很多矩阵了，我们把所有的矩阵放到一张图内看一下总体的流程。<br><img src="https://user-images.githubusercontent.com/6218739/140868817-3f900670-e211-4395-bb5a-2e9625ed3644.png" alt="multihead4"></p><h3 id="残差链接和层归一化"><a href="#残差链接和层归一化" class="headerlink" title="残差链接和层归一化"></a>残差链接和层归一化</h3><p>加入了残差设计和层归一化操作，目的是为了防止梯度消失，加快收敛。</p><h4 id="残差设计"><a href="#残差设计" class="headerlink" title="残差设计"></a>残差设计</h4><p>我们在上一步得到了经过注意力矩阵加权之后的 $𝑉$， 也就是$𝐴𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛(𝑄, 𝐾, 𝑉)$，我们对它进行一下转置，使其和$X_{\text {embedding }}$ 的维度一致, 也就是 [𝑏𝑎𝑡𝑐ℎ 𝑠𝑖𝑧𝑒, 𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 𝑙𝑒𝑛𝑔𝑡ℎ, 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑑𝑖𝑚𝑒𝑛𝑠𝑖𝑜𝑛]，然后把他们加起来做残差连接，直接进行元素相加，因为他们的维度一致:</p><script type="math/tex; mode=display">X_{embedding} + Attention(Q, \ K, \ V)</script><p>在之后的运算里，每经过一个模块的运算，都要把运算之前的值和运算之后的值相加，从而得到残差连接，训练的时候可以使梯度直接走捷径反传到最初始层：</p><script type="math/tex; mode=display">X + SubLayer(X)</script><h4 id="层归一化"><a href="#层归一化" class="headerlink" title="层归一化"></a>层归一化</h4><p>Normalization有很多种，但是它们都有一个共同的目的，那就是把输入转化成均值为0方差为1的数据。我们在把数据送入激活函数之前进行normalization（归一化），因为我们不希望输入数据落在激活函数的饱和区。<br>说到 normalization，那就肯定得提到 Batch Normalization。BN的主要思想就是：在每一层的每一批数据上进行归一化。我们可能会对输入数据进行归一化，但是经过该网络层的作用后，我们的数据已经不再是归一化的了。随着这种情况的发展，数据的偏差越来越大，我的反向传播需要考虑到这些大的偏差，这就迫使我们只能使用较小的学习率来防止梯度消失或者梯度爆炸。<br>BN的具体做法就是对每一小批数据，在批这个方向上做归一化。如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/140869917-059093b6-d8c7-462e-9926-ecdb6101f898.png" alt="BN"><br>可以看到，右半边求均值是沿着数据 batch_size的方向进行的，其计算公式如下：</p><script type="math/tex; mode=display">BN(x_i)=\alpha × \frac{x_i-\mu_b}{\sqrt{\sigma^2_B+\epsilon}}+\beta</script><p>那么什么是 Layer normalization 呢？它也是归一化数据的一种方式，不过 LN 是在每一个样本上计算均值和方差，而不是BN那种在批方向计算均值和方差！<br><img src="https://user-images.githubusercontent.com/6218739/140870020-f7fb5f4e-d6de-4838-9dbb-e809e0f2fdec.png" alt="LN"><br>LN的公式为：</p><script type="math/tex; mode=display">LN(x_i)=\alpha × \frac{x_i-\mu_L}{\sqrt{\sigma^2_L+\epsilon}}+\beta</script><h3 id="前馈网络"><a href="#前馈网络" class="headerlink" title="前馈网络"></a>前馈网络</h3><p>前馈网络FeedForward，其实就是两层线性映射并用激活函数激活。<br>然后经过这个网络激活后，再经过一个残差连接和层归一化，即可输出。<br>直接看代码可能更直观：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionwiseFeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; A two-feed-forward-layer module &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_in, d_hid, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 两个fc层，对最后的512维度进行变换</span></span><br><span class="line">        self.w_1 = nn.Linear(d_in, d_hid) <span class="comment"># position-wise</span></span><br><span class="line">        self.w_2 = nn.Linear(d_hid, d_in) <span class="comment"># position-wise</span></span><br><span class="line">        self.layer_norm = nn.LayerNorm(d_in, eps=<span class="number">1e-6</span>)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        residual = x</span><br><span class="line"></span><br><span class="line">        x = self.w_2(F.relu(self.w_1(x)))</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x += residual</span><br><span class="line"></span><br><span class="line">        x = self.layer_norm(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p><h3 id="编码器总结"><a href="#编码器总结" class="headerlink" title="编码器总结"></a>编码器总结</h3><p>经过上面 3 个步骤，我们已经基本了解了 Encoder 的主要构成部分。<br>用一个更直观的图表示如下：<br><img src="https://user-images.githubusercontent.com/6218739/140872426-955ab9c0-842e-444c-947b-b6d9292a4fe1.png" alt="encoder"><br>文字描述为：<br>输入$x_1,x_2$经 self-attention 层之后变成$z_1,z_2$ ，然后和输入$x_1,x_2$进行残差连接，经过 LayerNorm 后输出给全连接层。全连接层也有一个残差连接和一个 LayerNorm，最后再输出给下一个 Encoder（每个 Encoder Block 中的 FeedForward 层权重都是共享的）<br>公式描述为：<br>（1）字向量与位置编码</p><script type="math/tex; mode=display">X = \text{Embedding-Lookup}(X) + \text{Positional-Encoding}</script><p>（2）自注意力机制</p><script type="math/tex; mode=display">\begin{align}Q &= \text{Linear}_q(X) = XW_{Q}\\K &= \text{Linear}_k(X) = XW_{K}\\V &= \text{Linear}_v(X) = XW_{V}\\X_{attention} &= \text{Self-Attention}(Q,K,V)\end{align}</script><p>（3）self-attention 残差连接与 Layer Normalization</p><script type="math/tex; mode=display">\begin{align}X_{attention} &= X + X_{attention}\\X_{attention} &= \text{LayerNorm}(X_{attention})\end{align}</script><p>（4）前馈网络FeedForward</p><script type="math/tex; mode=display">X_{hidden} = \text{Linear}(\text{ReLU}(\text{Linear}(X_{attention})))</script><p>（5）FeedForward 残差连接与 Layer Normalization</p><script type="math/tex; mode=display">\begin{align}X_{hidden} &= X_{attention} + X_{hidden}\\X_{hidden} &= \text{LayerNorm}(X_{hidden})\end{align}</script><p>其中：</p><script type="math/tex; mode=display">X_{hidden} \in \mathbb{R}^{batch\_size  \ * \  seq\_len. \  * \  embed\_dim}</script><h2 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h2><p>见<a href="https://wmathor.com/index.php/archives/1438/">原文</a>。<br>Decoder架构如下：<br><img src="https://user-images.githubusercontent.com/6218739/140873135-92be1693-5efe-4998-9c6b-9071a3c96fae.png" alt="decoder"><br>我们先从 HighLevel 的角度观察一下 Decoder 结构，从下到上依次是：<br>（1）Masked Multi-Head Self-Attention<br>（2）Multi-Head Encoder-Decoder Attention<br>（3）FeedForward Network<br>和 Encoder 一样，上面三个部分的每一个部分，都有一个残差连接，后接一个 Layer Normalization。Decoder 的中间部件并不复杂，大部分在前面 Encoder 里我们已经介绍过了，但是 Decoder 由于其特殊的功能，因此在训练时会涉及到一些细节。</p><h3 id="Masked-Self-Attention"><a href="#Masked-Self-Attention" class="headerlink" title="Masked Self-Attention"></a>Masked Self-Attention</h3><p>具体来说，传统 Seq2Seq 中 Decoder 使用的是 RNN 模型，因此在训练过程中输入$t$时刻的词，模型无论如何也看不到未来时刻的词，因为循环神经网络是时间驱动的，只有当$t$时刻运算结束了，才能看到$t+1$时刻的词。而 Transformer Decoder 抛弃了 RNN，改为 Self-Attention，由此就产生了一个问题，在训练过程中，整个 ground truth 都暴露在 Decoder 中，这显然是不对的，我们需要对 Decoder 的输入进行一些处理，该处理被称为 Mask。<br>举个例子，Decoder 的 ground truth 为 “start起始符号 I am fine”，我们将这个句子输入到 Decoder 中，经过 WordEmbedding 和 Positional Encoding 之后，将得到的矩阵做三次线性变换$W_Q,W_K,W_V$。然后进行 self-attention 操作，首先通过$\frac {Q\times K^T}{\sqrt {d_k}}$得到 Scaled Scores，接下来非常关键，我们要对 Scaled Scores 进行 Mask，举个例子，当我们输入 “I” 时，模型目前仅知道包括 “I” 在内之前所有字的信息，即 “start起始符号” 和 “I” 的信息，不应该让其知道 “I” 之后词的信息。道理很简单，我们做预测的时候是按照顺序一个字一个字的预测，怎么能这个字都没预测完，就已经知道后面字的信息了呢？Mask 非常简单，首先生成一个下三角全 0，上三角全为负无穷的矩阵，然后将其与 Scaled Scores 相加即可：<br><img src="https://user-images.githubusercontent.com/6218739/140873707-8ab175f3-df87-40bc-901f-62305d01b2cd.png" alt="mask"><br>之后再做 softmax，就能将 - inf 变为 0，得到的这个矩阵即为每个字之间的权重：<br><img src="https://user-images.githubusercontent.com/6218739/140873785-a14ea99e-09c5-4610-a97f-39039bd99ad6.png" alt="unmask"><br>Multi-Head Self-Attention 无非就是并行的对上述步骤多做几次，前面 Encoder 也介绍了，这里就不多赘述了。</p><h3 id="Masked-Encoder-Decoder-Attention"><a href="#Masked-Encoder-Decoder-Attention" class="headerlink" title="Masked Encoder-Decoder Attention"></a>Masked Encoder-Decoder Attention</h3><p>其实这一部分的计算流程和前面 Masked Self-Attention 很相似，结构也一摸一样，唯一不同的是这里的$K,V$为 Encoder 的输出（不然Encoder辛辛苦苦做的输出就没用了），$Q$为 Decoder 中 Masked Self-Attention 的输出。<br><img src="https://user-images.githubusercontent.com/6218739/140874351-f075901e-7869-4f2d-8c03-c94b12116938.png" alt="e-d"></p><h1 id="Vision-Transformer"><a href="#Vision-Transformer" class="headerlink" title="Vision Transformer"></a>Vision Transformer</h1><p>使用Transformer进行视觉任务的研究已经成了一个新的热点，大家为了更低的模型复杂度以及训练的效率，都在研究如何将这一技术应用在视觉任务上。<br>通常来说，在所有的关于Transformer的论文以及工作中，有两个比较大的架构，其中一个就是传统的CNNs加Transformer组合而成的结构，另一种是纯粹的Transformers。<br>ViT使用的就是纯粹的Transformer去完成视觉任务，也就是说，它没有使用任何的CNNs。这也是它的价值所在，谷歌大脑团队在几乎没有修改任何基于NLP的Transformer的结构基础之上，只是将输入进行了一个适配，将图片切分成许多的小格，然后将这些作为序列输入到模型，最终完成了分类任务，并且效果可以直追基于CNNs的SOTA。<br>ViT的思路很简单：直接把图像分成固定大小的patchs，然后通过线性变换得到patch embedding，这就类比NLP的words和word embedding，由于transformer的输入就是a sequence of token embeddings，所以将图像的patch embeddings送入transformer后就能够进行特征提取从而分类了。ViT模型原理如下图所示，其实ViT模型只是用了transformer的Encoder来提取特征（原始的transformer还有decoder部分，用于实现sequence to sequence，比如机器翻译）。<br><img src="https://user-images.githubusercontent.com/6218739/140877989-64b07f86-fe4f-45df-8f4c-a30a11391cb0.png" alt="ViT"></p><p>ViT架构相对于原始Transformer，有一些特殊处理：</p><h2 id="图像分块嵌入"><a href="#图像分块嵌入" class="headerlink" title="图像分块嵌入"></a>图像分块嵌入</h2><p>考虑到在Transformer结构中，输入是一个二维的矩阵，矩阵的形状可以表示为$(N,D)$，其中$N$是sequence的长度，而$D$是sequence中每个向量的维度。因此，在ViT算法中，首先需要设法将$H \times W \times C$的三维图像转化为$(N,D)$的二维输入。<br>ViT中的具体实现方式为：将$H \times W \times C$的图像，变为一个$N \times (P^2 \times C)$的序列。这个序列可以看作是一系列展平的图像块，也就是将图像切分成小块后，再将其展平。该序列中一共包含了$N=HW/P^2$个图像块，每个图像块的维度则是$(P^2\times C)$。其中$P$是图像块的大小，$C$是通道数量。经过如上变换，就可以将$N$视为sequence的长度了。但是，此时每个图像块的维度是$(P^2\times C)$，而我们实际需要的向量维度是$D$，因此我们还需要对图像块进行 Embedding。这里 Embedding 的方式非常简单，只需要对每个$(P^2 \times C)$的图像块做一个线性变换，将维度压缩为$D$即可。</p><h2 id="Class-Token"><a href="#Class-Token" class="headerlink" title="Class Token"></a>Class Token</h2><p>ViT借鉴BERT增加了一个特殊的class token。transformer的encoder输入是a sequence patch embeddings，输出也是同样长度的a sequence patch features，但图像分类最后需要获取image feature，简单的策略是采用pooling，比如求patch features的平均来获取image feature，但是ViT并没有采用类似的pooling策略，而是直接增加一个特殊的class token，其最后输出的特征加一个linear classifier就可以实现对图像的分类（ViT的pre-training时是接一个MLP head），所以输入ViT的sequence长度是$N+1$。<br>class token对应的embedding在训练时随机初始化，然后通过训练得到。</p><h2 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h2><p>按照 Transformer 结构中的位置编码习惯，这个工作也使用了位置编码。不同的是，ViT 中的位置编码没有采用原版 Transformer 中的 sin-cos编码，而是直接设置为可学习的 Positional Encoding。对训练好的 Positional Encoding 进行可视化，可以看到，位置越接近，往往具有更相似的位置编码。此外，出现了行列结构，同一行/列中的 patch 具有相似的位置编码。<br><img src="https://user-images.githubusercontent.com/6218739/140884681-87fb368e-87a6-4e6a-a9df-3ea19a31012b.png" alt="vit-pos"></p>]]></content>
    
    
    <summary type="html">参考文献
保姆级教程：图解Transformer
Transformer模型详解
Transformer 详解
盘点 | 2021年paper大热的Transformer (ViT)
“未来”的经典之作ViT：transformer is all you need!
ViT( Vision Transformer)

简介
Attention Is All You Need是一篇Google于2017年提出的将Attention思想发挥到极致的论文。这篇论文中提出一个全新的模型，叫 Transformer，抛弃了以往深度学习任务里面使用到的 CNN 和 RNN ，目前大热的Bert、GPT和D</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="Transformer" scheme="http://qixinbo.github.io/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>Python爱浏览器，但浏览器不爱它：如何让Python运行在浏览器上</title>
    <link href="http://qixinbo.github.io/2021/11/05/python-on-web/"/>
    <id>http://qixinbo.github.io/2021/11/05/python-on-web/</id>
    <published>2021-11-04T16:00:00.000Z</published>
    <updated>2021-11-05T08:37:11.546Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>一直以来，网页浏览器编程所用的编程语言主力就是JavaScript，浏览器就是一个JavaScript的原生解释器。<br>那么Python能不能直接运行在浏览器上呢，或者说Python能不能作为浏览器开发的编程语言？<br>本文对这一问题做了详细的调研，结果可以用一句话总结：可以，但很鸡肋。</p><h1 id="可用方案"><a href="#可用方案" class="headerlink" title="可用方案"></a>可用方案</h1><p>调研过程中，发现了很多有趣的解决方案，总结起来可以有两类：<br>（1）将Python语言编译成JavaScript<br>即将现成的Python语言翻译成JavaScript，然后在浏览器网页中运行，比如：<br><a href="https://brython.info/index.html">Brython</a><br><a href="https://skulpt.org/">Skulpt</a><br><a href="https://www.transcrypt.org/">Transcrypt</a><br>（2）在浏览器中内置Python解释器<br>即将Python解释器放在浏览器中，这样就能直接运行Python代码，比如：<br><a href="https://pyodide.org/en/stable/">Pyodide</a><br><a href="https://pypyjs.org/">PyPy.js</a></p><p>我觉得这两类各自的重点不一样：<br>第一种是为了用Python来代替JavaScript，即用Python操作网页DOM（Document Object Model）元素，让不熟悉JS的编程人员也能用Python来做一个简单的动态交互网页；<br>第二种，比如Pyodide，它的野心很大，即将Python的科学计算生态搬到浏览器中，比如numpy、scipy、matplotlib等科学计算常用的函数库直接放进浏览器中，而不是常见的比如作为浏览器服务器后端来调用。这样实现的效果就是不需要部署服务器，直接在浏览器中做复杂的函数计算，并反映到网页上。<br>下面详细介绍一下两类实现中的代表：Brython和Pyodide。</p><h1 id="Brython"><a href="#Brython" class="headerlink" title="Brython"></a>Brython</h1><p>先看一下用Brython写的Hello World：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;meta name=<span class="string">&quot;description&quot;</span> content=<span class="string">&quot;Hello world demo written in Brython www.brython.info&quot;</span>&gt;</span><br><span class="line">&lt;meta name=<span class="string">&quot;keywords&quot;</span> content=<span class="string">&quot;Python,Brython&quot;</span>&gt;</span><br><span class="line">&lt;meta charset=<span class="string">&quot;iso-8859-1&quot;</span>&gt;</span><br><span class="line">&lt;title&gt;Hello world&lt;/title&gt;</span><br><span class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;/src/brython.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">&lt;script type=&quot;text/python&quot; src=&quot;show_source.py&quot;&gt;&lt;/script&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line"></span><br><span class="line">// ------------注意看这一块-------------</span><br><span class="line">&lt;body onload=<span class="string">&quot;brython(1)&quot;</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">&quot;text/python&quot;</span>&gt;</span><br><span class="line"><span class="keyword">from</span> browser <span class="keyword">import</span> document, alert</span><br><span class="line"><span class="keyword">from</span> browser.widgets.dialog <span class="keyword">import</span> InfoDialog</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">echo</span>(<span class="params">ev</span>):</span></span><br><span class="line">    InfoDialog(<span class="string">&quot;Hello&quot;</span>, <span class="string">f&quot;Hello <span class="subst">&#123;document[<span class="string">&#x27;zone&#x27;</span>].value&#125;</span> !&quot;</span>)</span><br><span class="line"></span><br><span class="line">document[<span class="string">&quot;test&quot;</span>].bind(<span class="string">&quot;click&quot;</span>, echo)</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">// ------------注意看结束-------------</span><br><span class="line"></span><br><span class="line">&lt;p&gt;Your name <span class="keyword">is</span> : &lt;<span class="built_in">input</span> <span class="built_in">id</span>=<span class="string">&quot;zone&quot;</span> autocomplete=<span class="string">&quot;off&quot;</span>&gt;</span><br><span class="line">&lt;button id=&quot;test&quot;&gt;click !&lt;/button&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line"></span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><br>从上面片段很显而易见，Brython就是用Python来替代JavaScript的写法，比如获取网页上的元素并改变其值。<br>如果想快速开发一个动态网页，同时不懂JavaScript，可以使用Brython来写。<br>但注意Brython没法使用Python的整个生态，只能使用部分标准库，比如sys。</p><h1 id="Pyodide"><a href="#Pyodide" class="headerlink" title="Pyodide"></a>Pyodide</h1><p>简言之，Pyodide就是在浏览器中运行Python，且能调用Python的数值计算库。<br>Pyodide解决的痛点是无法在浏览器中进行科学计算：<br>（1）一方面，现在越来越多的软件都Web化、浏览器化。而浏览器的通用编程语言是JavaScript，但其没有成熟的数据科学处理库，也缺乏一些数值计算很有用的功能和数据结构。<br>（2）另一方面，Python具有成熟且活跃的科学计算生态，比如基本上所有函数库都依赖的numpy数据结构，但其无法在浏览器运行。<br>Pyodide 项目则是通过将现有的 CPython 解释器编译为 WebAssembly 并在浏览器的 JavaScript 环境中运行这个编译出来的二进制文件，这提供了一种在浏览器中运行 Python 的方法。</p><p>Pyodide有一些非常炫的功能点：</p><h2 id="在Python和JavaScript之间进行交互"><a href="#在Python和JavaScript之间进行交互" class="headerlink" title="在Python和JavaScript之间进行交互"></a>在Python和JavaScript之间进行交互</h2><p>如果所有Pyodide能做的就只是运行Python代码并写出到标准输出上，它将会增长成为一个不错的很酷的技巧，但是不会成为一个用于实际工作的实用工具。真正的力量源于它与浏览器API以及其它运行在浏览器中的JavaScript库交互的能力。由于我们已经将Python解释器编译为了WebAssembly，它也与JavaScript端具有深度的交互。<br>Pyodide会在许多Python与JavaScript之间的内建数据类型之间进行隐式转换。其中一些转换时很直接明显的，但如往常一样，那就是很有趣的极端情况。<br><img src="https://user-images.githubusercontent.com/6218739/140268286-c89f066f-72fc-4cc9-8709-c95fc6d98096.png" alt="data"></p><h2 id="访问Web-API和DOM"><a href="#访问Web-API和DOM" class="headerlink" title="访问Web API和DOM"></a>访问Web API和DOM</h2><p>可以通过以下方式获得Web页面上的文档对象模型DOM：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> js <span class="keyword">import</span> document</span><br></pre></td></tr></table></figure><br>这会将document对象作为一个代理从JavaScript端导入到Python端。你可以开始从Python中对其调用方法:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">document.getElementById(<span class="string">&quot;myElement&quot;</span>)</span><br></pre></td></tr></table></figure></p><h2 id="多维数组"><a href="#多维数组" class="headerlink" title="多维数组"></a>多维数组</h2><p>在Python中， NumPy 数组是最常用的多维数组的实现。JavaScript具有TypedArrays，其仅含有一个单一的数值类型，但是是一维的，因此需要在其之上构建多维索引。<br>由于实际上这些数组可能会非常大，我们不想在语言运行时间拷贝它们。那不仅仅会花相当长的时间，而且在内存中同时保留两个拷贝将会加重浏览器所具有的被限制的内存的负担。<br>幸运的是，我们可以不用拷贝来共享数据。多维数组通常是用少量用于描述值类型和数组形状及内存分布的元数据来实现的。数据本身是从元数据中通过指针访问的另一个内存区域。该内存处于一个叫作“WebAssembly堆”的区域，这带来一个优势，因为其可以从JavaScript和Python中同时访问。我们可以简单地在语言之间拷贝元数据(其本身非常小)，并保持指针指向WebAssembly堆中的数据。<br><img src="https://user-images.githubusercontent.com/6218739/140268781-ab70c08a-1821-4a06-b7de-d65633d54b31.png" alt="numpy"></p><h2 id="实时交互可视化"><a href="#实时交互可视化" class="headerlink" title="实时交互可视化"></a>实时交互可视化</h2><p>在浏览器中进行数据科学计算相比于如Jupyter一样在远程内核中进行计算的一大优势就是，交互式可视化不用通过网络来传输数据并重新处理和展示这些数据。这很大程度地减少了延迟—用户移动鼠标的时刻与屏幕更新并显示图案的时刻之间的间隔时间。</p><p>要使得其能工作需要上面描述到的所有的技术片段能够很好地协同工作。我们使用matplotlib来看一下用于展示正态分布如何工作的交互性示例。首先，通过Python的Numpy产生随机数据。接下来，Matplotlib接管该数据，并使用内建的软件渲染器来将其绘出。它使用Pyodide对零拷贝共享数组的支持来将像素回馈给JavaScript端，在这里数据最终被渲染为HTML的画布。然后浏览器接管工作，将像素显示到屏幕上。用来支持交互性操作的鼠标和键盘事件通过从Web浏览器到Python的回调函数的调用来处理。<br><img src="https://user-images.githubusercontent.com/6218739/140269007-b21d4a82-4def-4581-8631-331f570917e4.gif" alt="matplotlib-interacting-with-plots"></p><p>但需要注意的是Pyodide有两个缺点：<br>（1）包体积巨大，在浏览器中第一次访问内含Pyodide的网页时，会下载相应的python包，最基础的pyodide也有22MB大小，更不用说如果有额外的包，比如matplotlib，会更加巨大，导致长时间加载不出来页面；<br>（2）对于Python日渐火热的深度学习生态，Pyodide也没法直接利用，毕竟那些函数库会更大。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>JavaScript作为浏览器的原住民，其在基于网页的应用开发中的地位不可撼动，虽然Python能通过各种方式部分取代它的功能，但目前还很不成熟，开发简易功能尚可，但重度和高阶应用则基本不可能。期待以后的技术发展能将浏览器和Python结合得更加紧密。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://python.freelycode.com/contribution/detail/1567">在浏览器中用Python做数据科学：Pyodide</a><br><a href="https://jishuin.proginn.com/p/763bfbd5bd1e">LWN: Pyodide - 浏览器中的Python！</a><br><a href="https://hacks.mozilla.org/2019/04/pyodide-bringing-the-scientific-python-stack-to-the-browser/">Pyodide: Bringing the scientific Python stack to the browser</a><br><a href="https://www.bilibili.com/video/BV1X541187XK">把python装进浏览器，需要几个步骤？</a><br><a href="https://www.youtube.com/watch?v=iUqVgykaF-k&amp;t=91s">Iodide and Pyodide: Bringing Data Science Computation to the Web Browser - Michael Droettboom</a></p>]]></content>
    
    
    <summary type="html">简介
一直以来，网页浏览器编程所用的编程语言主力就是JavaScript，浏览器就是一个JavaScript的原生解释器。
那么Python能不能直接运行在浏览器上呢，或者说Python能不能作为浏览器开发的编程语言？
本文对这一问题做了详细的调研，结果可以用一句话总结：可以，但很鸡肋。

可用方案
调研过程中，发现了很多有趣的解决方案，总结起来可以有两类：
（1）将Python语言编译成JavaScript
即将现成的Python语言翻译成JavaScript，然后在浏览器网页中运行，比如：
Brython
Skulpt
Transcrypt
（2）在浏览器中内置Python解释器
即将Py</summary>
    
    
    
    <category term="digitalization" scheme="http://qixinbo.github.io/categories/digitalization/"/>
    
    
    <category term="GUI" scheme="http://qixinbo.github.io/tags/GUI/"/>
    
  </entry>
  
  <entry>
    <title>经典图像特征点提取SIFT算法详解</title>
    <link href="http://qixinbo.github.io/2021/10/26/sift/"/>
    <id>http://qixinbo.github.io/2021/10/26/sift/</id>
    <published>2021-10-25T16:00:00.000Z</published>
    <updated>2021-10-29T02:32:54.361Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://liuchang.men/2020/02/24/SIFT%E7%AE%97%E6%B3%95%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/">SIFT算法深入理解</a><br><a href="https://blog.csdn.net/lhanchao/article/details/52345845">特征点匹配——SIFT算法详解</a><br><a href="https://www.cnblogs.com/wj-1314/p/11981974.html">图像金字塔（高斯金字塔，拉普拉斯金字塔，图像缩放resize函数）</a><br><a href="https://blog.csdn.net/zddblog/article/details/7521424">SIFT算法详解</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>SIFT（Scale Invariant Feature Transform），尺度不变特征变换匹配算法，是由David G. Lowe在1999年（《Object Recognition from Local Scale-Invariant Features》）提出的高效区域检测算法，在2004年（《Distinctive Image Features from Scale-Invariant Keypoints》）得以完善。<br>SIFT算子是把图像中检测到的特征点用一个128维的特征向量进行描述，因此一幅图像经过SIFT算法后表示为一个128维的特征向量集。<br>SIFT算法的实质是在不同的尺度空间上查找关键点(特征点)，并计算出关键点的方向。SIFT所查找到的关键点是一些十分突出，不会因光照、仿射变换和噪音等因素而变化的点，如角点、边缘点、暗区的亮点及亮区的暗点等。<br>SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，对于光照、仿射和投影变换也有一定的不变性，是非常稳定的局部特征，现在应用很广泛。</p><p>Lowe将SIFT算法分解为如下四步：</p><ol><li>尺度空间极值检测：搜索所有尺度上的图像位置。通过高斯微分函数来识别潜在的对于尺度和旋转不变的兴趣点。</li><li>特征点精确定位：在每个候选的位置上，通过一个拟合精细的模型来确定位置和尺度。特征点的选择依据于它们的稳定程度。</li><li>方向确定：基于图像局部的梯度方向，分配给每个特征点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而提供对于这些变换的不变性。</li><li>特征点描述：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变化。</li></ol><h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h1><h2 id="尺度空间极值检测"><a href="#尺度空间极值检测" class="headerlink" title="尺度空间极值检测"></a>尺度空间极值检测</h2><h3 id="尺度空间理论"><a href="#尺度空间理论" class="headerlink" title="尺度空间理论"></a>尺度空间理论</h3><p>尺度越大图像越模糊。<br>用机器视觉系统分析未知场景时，计算机并不预先知道图像中物体的尺度。我们需要同时考虑图像在多尺度下的描述，获知感兴趣物体的最佳尺度。另外如果不同的尺度下都有同样的关键点，那么在不同的尺度的输入图像下就都可以检测出来关键点匹配，也就是尺度不变性。 图像的尺度空间表达就是图像在所有尺度下的描述。</p><h3 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h3><p>高斯核是唯一可以产生多尺度空间的核。<br>一个图像的尺度空间$L(x,y,\sigma)$，定义为原始图像$I(x,y)$与一个可变尺度的2维高斯函数$G(x,y,\sigma)$的卷积运算。<br>二维空间高斯函数：</p><script type="math/tex; mode=display">G(x_i,y_i,\sigma)=\frac{1}{2\pi\sigma^2}exp\lgroup-\frac{(x-x_i)^2+(y-y_i)^2}{2\sigma^2}\rgroup</script><p>那么尺度空间就是：</p><script type="math/tex; mode=display">L(x,y,\sigma)=G(x,y,\sigma)*I(x,y)</script><p>在二维空间中，这个公式生成的曲面的等高线是从中心开始呈正态分布的同心圆。分布不为零的像素组成的卷积矩阵与原始图像做变换。每个像素的值都是周围相邻像素值的高斯加权平均。中心像素的值有最大的高斯分布值，所以有最大的权重，相邻像素随着距离中心像素越来越远，其权重也越来越小。这样进行模糊处理比其它的均衡模糊滤波器更高地保留了边缘效果。$\sigma$越大，中心像素的权重与周围像素就会相对越小，加权平均后就会越模糊；反之，$\sigma$越小，中心像素权重相对越大，当$\sigma=0$时，就是原图的样子，相当于周围像素对新图没有贡献。换句话说，大尺度对应于图像的概貌特征，小尺度对应于图像的细节特征。<br>理论上来讲，图像中每点的分布都不为零，这也就是说每个像素的计算都需要包含整幅图像。在实际应用中，在计算高斯函数的离散近似时，在大概$3\sigma$距离之外的像素都可以看作不起作用，这些像素的计算也就可以忽略。通常，图像处理程序只需要计算$(6\sigma+1)\cdot(6\sigma+1)$的矩阵就可以保证相关像素影响。</p><h3 id="金字塔多分辨率"><a href="#金字塔多分辨率" class="headerlink" title="金字塔多分辨率"></a>金字塔多分辨率</h3><p>与多尺度空间相对的，金字塔是早期图像多尺度的表示方式。图像金字塔化一般两个步骤：<br>(1) 使用低通滤波器（LPF）平滑图像；<br>(2) 平滑图像降采样（通常$\frac{1}{2}$）<br>该方式能得到系列尺寸缩小的图片。</p><p>尺度空间表达和金字塔分辨率表达的明显区别有：<br>（1）尺度空间表达是由不同高斯核平滑卷积得到的，在所有尺度上分辨率相同；<br>（2）金字塔多分辨率表达每层分辨率减少固定比率。<br>因此，金字塔多分辨率生成快，空间少，但局部特征描述单一；多尺度空间的图片局部特征可以在不同尺度描述，但随尺度参数增加会增加冗余信息。</p><h3 id="高斯金字塔"><a href="#高斯金字塔" class="headerlink" title="高斯金字塔"></a>高斯金字塔</h3><p>高斯金字塔是最基本的图像塔。原理：首先将原图像作为最底层图像 level0（高斯金字塔的第0层），利用高斯核（$5*5$）对其进行卷积，然后对卷积后的图像进行下采样（去除偶数行和列）得到上一层图像G1，将此图像作为输入，重复卷积和下采样操作得到更上一层的图像，反复迭代多次，形成一个金字塔形的图像数据结构，即高斯金字塔。<br>高斯金字塔是在sift算子中提出来的概念，首先高斯金字塔并不是一个金字塔，而是由很多组（Octave）金字塔构成，并且每组金字塔都包含若干层（Interval），即在同一组的金字塔中，使用不同$\sigma$进行高斯模糊，然后再不同组的金字塔中，使用下采样，获得不同分辨率的图像。<br>高斯金字塔的构建过程：<br>（1）先将原图像扩大一倍之后作为高斯金字塔的第1组第1层，将第1组第1层图像经高斯卷积（高斯平滑或称高斯滤波）之后作为第1组金字塔的第2层。对于参数$\sigma$，在SIFT算子中取的是固定值 1.6；<br>（2）将$\sigma$乘以一个比例系数k，等到一个新的平滑因子$\sigma = k *\sigma$，用它来平滑第1组第2层图像，结果图像作为第3层。<br>（3）如此重复，最后得到L层图像，在同一组中，每一层图像的尺寸都是一样的，只是平滑系数不一样。它们对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。<br>（4）将第1组倒数第三层图像作为比例因子为2的降采样，得到的图像作为第2组的第1层，然后对第2组的第1层图像作平滑因子为 $\sigma$的高斯平滑，得到第2组的第2层，就像步骤2中一样，如此得到第2组的L层图像，同组内它们的尺寸是一样的，对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。但是在尺寸方面第2组是第1组图像的一半。<br>这样反复执行，就可以得到一共O组，每组L层，共计$O*L$个图像，这些图像一起就构成了高斯金字塔。<br>在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子$\sigma$是前一层图像平滑因子的$k$倍；<br>在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半。</p><h3 id="高斯拉普拉斯金字塔"><a href="#高斯拉普拉斯金字塔" class="headerlink" title="高斯拉普拉斯金字塔"></a>高斯拉普拉斯金字塔</h3><p>LoG（Laplace of Gaussian）是对高斯函数进行拉普拉斯变换：</p><script type="math/tex; mode=display">L(x,y,\sigma)=\frac{\partial^2G}{\partial x^2} + \frac{\partial^2G}{\partial y^2}</script><p>拉普拉斯金字塔用于重建图形，也就是预测残差，对图像进行最大程度的还原。比如一幅小图像重建为一幅大图。原理：用高斯金字塔的每一层图像减去其上一层图像上采样并高斯卷积之后的预测图像，得到一系列的差值图像，即为Laplacian分解图像。<br>LoG第$i$层的数学定义：</p><script type="math/tex; mode=display">\begin{align}L_i &= G_i-Up(G_{i+1})\otimes g \\&=G_i - PyrUp(G_{i+1}) \\\end{align}</script><p>式中，$G_i$表示高斯金字塔中第$i$层图像。也就是说，拉普拉斯金字塔是通过高斯金字塔图像减去先缩小（即上一层图像）后再放大（即上采样操作）并高斯卷积后的图像的一系列图像构成的。</p><h3 id="高斯差分金字塔"><a href="#高斯差分金字塔" class="headerlink" title="高斯差分金字塔"></a>高斯差分金字塔</h3><p>LoG的主要缺点是需要求二阶导，计算较复杂，因此我们就想用别的算子去近似它。DoG（Difference of Gaussian），相当于对LoG的近似计算，SIFT算法中建议某一尺度的特征检测，可以通过两个相邻高斯尺度空间的图像相减，得到DoG的响应值图像。DoG和LoG的关系如下述所示： </p><script type="math/tex; mode=display">\sigma\nabla^2G = \frac{\partial G}{\partial\sigma} \approx \frac{G(x,y,k\sigma) - G(x,y,\sigma)}{k\sigma - \sigma}</script><p>因此，有：</p><script type="math/tex; mode=display">G(x,y,k\sigma) - G(x,y,y\sigma) \approx (k-1)\sigma^2\nabla^2G</script><p>而$\sigma^2\nabla^2G$正是尺度归一化算子的表达形式。在所有的尺度中$k-1$是一个常数，当$k$趋近于1的时候误差趋近于0，但实际上这种误差对于极值的位置检测并没有什么影响（不过前人的实验证明LoG提取的特征稳定性最强）。<br><img src="https://user-images.githubusercontent.com/6218739/138830197-52b6d1f1-ffb1-474e-abfa-d204cace5c57.png" alt="dog"></p><h3 id="空间极值点检测（关键点的初步探查）"><a href="#空间极值点检测（关键点的初步探查）" class="headerlink" title="空间极值点检测（关键点的初步探查）"></a>空间极值点检测（关键点的初步探查）</h3><p>SIFT关键点是由DOG空间的局部极值点组成的，关键点的初步探查是通过同一组内各DoG相邻两层图像之间比较完成的。<br>极值点定义：每一个像素点与它所有相邻点比较，当其大于（或小于）它的图像域和尺度域的所有相邻点时，即为极值点。<br>为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。<br><img src="https://user-images.githubusercontent.com/6218739/138831439-2566a884-59cf-45df-a11a-7aa319584b64.png" alt="peak-detect"><br>由于要在相邻尺度进行比较，那么对于高斯差分金子塔中的每一组的所有层，只能在中间两层中进行两个尺度的极值点检测，其它尺度则只能在不同组中进行。为了在每组中检测$S$个尺度的极值点，则DOG金字塔每组需$S+2$层图像，而DOG金字塔由高斯金字塔相邻两层相减得到，则高斯金字塔每组需$S+3$层图像，实际计算时S在3到5之间。<br>当然这样产生的极值点并不全都是稳定的特征点，因为某些极值点响应较弱，而且DOG算子会产生较强的边缘响应。</p><p>到这里，总结一下，构建DOG尺度空间金字塔的三个重要参数是：尺度$\sigma$、组(octave)数$O$和组内层数$S$。</p><h2 id="特征点点精确定位"><a href="#特征点点精确定位" class="headerlink" title="特征点点精确定位"></a>特征点点精确定位</h2><p>计算机中存储的图像数据是离散的，而我们之前找到的极值点也就是离散空间中的极值点，但是离散空间中的极值点并不是真实的连续空间中的极值点。所以需要对DoG空间进行拟合处理，以找到极值点的精确位置和尺度。另外，我们还需要去除那些在边缘位置的极值点，以提高关键点的稳定性。</p><h3 id="精确定位"><a href="#精确定位" class="headerlink" title="精确定位"></a>精确定位</h3><p><img src="https://user-images.githubusercontent.com/6218739/138843995-feea3390-c7fd-4f40-8fb1-88660ed06b1d.png" alt="fit"><br>利用已知的离散空间点插值得到连续空间极值点的方法叫做子像元插值。<br>在Lowe的论文中，使用的是泰勒展开式作为拟合函数。<br>通过上步的极值点检测，我们得到的极值点是一个三维向量，包括它所在的尺度$\sigma$以及所在尺度图像中的位置坐标$(x, y)$。<br>设$X_0 = (x_0,y_0,\sigma_0)$，则泰勒展开的矩阵表示为：</p><script type="math/tex; mode=display">f(\left[\begin{matrix}x\\y\\\sigma\end{matrix}\right]) \approx f(\left[\begin{matrix}x_0\\y_0\\\sigma_0\end{matrix}\right]) + [\frac{\partial f}{\partial x}    \frac{\partial f}{\partial y} \frac{\partial f}{\partial \sigma}]\left(\left[\begin{matrix}x\\y\\\sigma\end{matrix}\right]-\left[\begin{matrix}x_0\\y_0\\\sigma_0\end{matrix}\right]\right) + \\\frac{1}{2}\left(\left[x \quad y \quad \sigma\right] - \left[x_0 \quad y_0 \quad \sigma_0\right]\right)\left[\begin{matrix}\frac{\partial^2 f}{\partial x \partial x} & \frac{\partial^2 f}{\partial x \partial y} & \frac{\partial^2 f}{\partial x \partial \sigma} \\ \frac{\partial^2 f}{\partial x \partial y}&\frac{\partial^2 f}{\partial y \partial y}&\frac{\partial^2 f}{\partial y \partial \sigma}\\\frac{\partial^2 f}{\partial x \partial \sigma}&\frac{\partial^2 f}{\partial y \partial \sigma}&\frac{\partial^2 f}{\partial \sigma \partial \sigma}\end{matrix}\right]\left(\left[\begin{matrix}x\\y\\\sigma\end{matrix}\right]-\left[\begin{matrix}x_0\\y_0\\\sigma_0\end{matrix}\right]\right)</script><p>若写成矢量形式，则为 ：</p><script type="math/tex; mode=display">f(X) = f(X_0）+\frac{\partial f^T}{\partial X}(X- X_0)+\frac{1}{2}(X-X_0)^T\frac{\partial^2 f}{\partial X^2}(X-X_0)</script><p>在这里$X_0$表示离散的插值中心，$X$表示拟合后连续空间的插值点坐标，则设$\hat{X} = X - X_0$，表示偏移量，带入上式，另求得的导数为0（求一阶导等于0得到的点就是极值点），则有 </p><script type="math/tex; mode=display">\hat{X} = -\frac{\partial^2 f^{-1}}{\partial X^2}\frac{\partial f}{\partial X}</script><p>只要上式中得到的偏移量大于0.5，则认为偏移量过大，需要把位置移动到拟合后的新位置，继续进行迭代求偏移量，若迭代过一定次数后偏移量仍然大于0.5，则抛弃该点。如果迭代过程中有偏移量小于0.5，则停止迭代。 </p><p>把该极值点带入到原公式中，则得到极值点所在的函数值：</p><script type="math/tex; mode=display">f(\hat{X}) = f(X_0) + \frac{1}{2}\frac{\partial f^T}{\partial X} \hat{X}</script><p>如果上式中得到的$f(\hat{X})$过小，即其响应值过小，这样的点易受噪声的干扰而变得不稳定，所以也要被删除，Lowe论文中阈值为0.03（设灰度值为0~1）。</p><h3 id="消除边缘响应"><a href="#消除边缘响应" class="headerlink" title="消除边缘响应"></a>消除边缘响应</h3><p>有些极值点的位置是在图像的边缘位置的，因为图像的边缘点很难定位，同时也容易受到噪声的干扰，我们把这些点看做是不稳定的极值点，需要进行去除。<br>由于图像中的物体的边缘位置的点的主曲率一般会比较高，因此我们可以通过主曲率来判断该点是否在物体的边缘位置。<br>某像素点位置处的主曲率可以由二维的Hessian矩阵计算得到：</p><script type="math/tex; mode=display">H = \left[\begin{matrix}D_{xx}(x,y)&D_{xy}(x,y)\\D_{xy}(x,y)&D_{yy}(x,y)\end{matrix}\right]</script><p>设该矩阵的两个特征值分别为$\alpha$和$\beta$，其中$\alpha = \gamma\beta$，有如下公式：</p><script type="math/tex; mode=display">Tr(H) = \alpha +\beta</script><p>和</p><script type="math/tex; mode=display">Det(H) = \alpha\beta</script><p>其中$Tr(H)$表示矩阵的迹，$Det(H)$表示的矩阵的行列式。<br>首先需要去除行列式为负的点。接下来需要去掉主曲率比较大的点，Lowe中使用如下判断规则：</p><script type="math/tex; mode=display">\frac{Tr(H)^2}{Det(H)} = \frac{(\gamma\beta+\beta)^2}{\gamma\beta^2} = \frac{(\gamma+1)^2}{\gamma}</script><p>这里$\gamma$越大，则表示该点越有可能在边缘，因此要检查主曲率是否超过一定的阈值$\gamma_0$，只需要判断：</p><script type="math/tex; mode=display">\frac{Tr(H)^2}{Det(H)} < \frac{(\gamma_0+1)^2}{\gamma_0}</script><p>Lowe论文中阈值为10。 </p><h2 id="特征点方向确定"><a href="#特征点方向确定" class="headerlink" title="特征点方向确定"></a>特征点方向确定</h2><p>上面我们已经找到了特征点。为了实现图像旋转不变性，需要根据检测到的特征点局部图像结构为特征点方向赋值。我们使用图像的梯度直方图法求特征点局部结构的稳定方向。</p><h3 id="梯度方向和幅值"><a href="#梯度方向和幅值" class="headerlink" title="梯度方向和幅值"></a>梯度方向和幅值</h3><p>在前文中，精确定位关键点后也找到特征点的尺度值$\sigma$，根据这一尺度值，得到最接近这一尺度值的高斯图像： </p><script type="math/tex; mode=display">L(x,y) = G(x,y,\sigma)\otimes I(x,y)</script><p>使用有限差分，计算以特征点为中心，以$3\times1.5\sigma$为半径的区域内图像梯度的幅值$m(x,y)$和幅角$\theta(x,y)$，公式如下： </p><script type="math/tex; mode=display">\begin{align}m(x,y) &= \sqrt{(L(x+1, y) - L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2} \\\theta(x,y)&=arctan(\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)})\end{align}</script><h3 id="梯度直方图"><a href="#梯度直方图" class="headerlink" title="梯度直方图"></a>梯度直方图</h3><p>在完成特征点邻域内高斯图像梯度计算后，使用直方图统计邻域内像素对应的梯度方向和幅值。<br>梯度方向直方图的横轴是梯度方向角，纵轴是梯度方向角对应的梯度幅值累加值（(为简化，图中只画了八个方向的直方图)）。梯度方向直方图将0°~360°的范围分为36个柱，每10°为一个柱。可看作一定区域内的图像像素点对特征点方向生成所作的贡献。<br><img src="https://user-images.githubusercontent.com/6218739/138852341-c6e124e1-3cad-43e6-9b1d-af995d9a7bb6.png" alt="hist"><br>在计算直方图时，每个加入直方图的采样点都使用圆形高斯函数函数进行了加权处理，也就是进行高斯平滑。Lowe建议子区域的像素的梯度大小$\sigma=0.5d$的高斯加权计算。这主要是因为SIFT算法只考虑了尺度和旋转不变形，没有考虑仿射不变性。通过高斯平滑，可以使关键点附近的梯度幅值有较大权重，从而部分弥补没考虑仿射不变形产生的特征点不稳定。<br>通常离散的梯度直方图要进行插值拟合处理，以求取更精确的方向角度值。</p><h3 id="特征点方向"><a href="#特征点方向" class="headerlink" title="特征点方向"></a>特征点方向</h3><p>直方图峰值代表该特征点处邻域内图像梯度的主方向，也就是该特征点的主方向。在梯度方向直方图中，当存在另一个相当于主峰值$80\%$能量的峰值时，则将这个方向认为是该特征点的辅方向。<br>所以一个特征点可能检测得到多个方向，这可以增强匹配的鲁棒性。Lowe的论文指出大概有$15\%$特征点具有多方向，但这些点对匹配的稳定性至为关键。<br>获得图像特征点主方向后，每个特征点有三个信息$(x,y,\sigma,\theta)$：位置、尺度、方向。<br>由此我们可以确定一个SIFT特征区域。通常使用一个带箭头的圆或直接使用箭头表示SIFT区域的三个值：中心表示特征点位置，半径表示特征点尺度（$r=2.5\sigma$），箭头表示主方向。<br>具有多个方向的特征点可以复制成多份，然后将方向值分别赋给复制后的特征点。如下图：<br><img src="https://user-images.githubusercontent.com/6218739/138855713-27783685-f694-4aca-a641-9bef8c823c56.png" alt="fea1"></p><h2 id="特征点描述"><a href="#特征点描述" class="headerlink" title="特征点描述"></a>特征点描述</h2><p>上文找到的SIFT特征点包含位置、尺度和方向的信息。接下来的步骤是特征点描述，即用一组向量将这个特征点描述出来，这个描述子不但包括特征点，也包括特征点周围对其有贡献的像素点，用来作为目标匹配的依据（所以描述子应该有较高的独特性，以保证匹配率），也可使特征点具有更多的不变特性，如光照变化、3D视点变化等。<br>SIFT描述子$h(x,y,\theta)$是对特征点附近邻域内高斯图像梯度统计的结果，是一个三维矩阵，但通常用一个矢量来表示。特征向量通过对三维矩阵按一定规律排列得到。</p><h3 id="描述子采样区域"><a href="#描述子采样区域" class="headerlink" title="描述子采样区域"></a>描述子采样区域</h3><p>特征描述子与特征点所在尺度有关，因此对梯度的求取应在特征点对应的高斯图像上进行。<br>将特征点附近划分成$d\times d$个子区域，每个子区域尺寸为$m\sigma$个像元（$d=4$，$m=3$，$\sigma$为特征点的尺度值）。考虑到实际计算时需要双线性插值，故计算的图像区域为$m\sigma(d+1)$，再考虑旋转，则实际计算的图像区域为$\frac{\sqrt{2}}{2}m\sigma(d+1)$，如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/138855575-3dc7b05b-90af-4bc7-82b5-6228406161df.png" alt="area"></p><h3 id="区域坐标轴旋转"><a href="#区域坐标轴旋转" class="headerlink" title="区域坐标轴旋转"></a>区域坐标轴旋转</h3><p>为了保证特征矢量具有旋转不变性，要以特征点为中心，在附近邻域内旋转$\theta$角，即旋转为特征点的方向。<br><img src="https://user-images.githubusercontent.com/6218739/138855946-d33c2c3c-7d7e-4f73-b441-24184c7d2ed1.png" alt="rotate"><br>旋转后区域内采样点新的坐标为： </p><script type="math/tex; mode=display">\begin{pmatrix} x' \\ y'\end{pmatrix} = \begin{pmatrix} cos\theta & -sin\theta \\ sin\theta & cos\theta\end{pmatrix} \begin{pmatrix} x \\ y\end{pmatrix}</script><h3 id="计算采样区域梯度直方图"><a href="#计算采样区域梯度直方图" class="headerlink" title="计算采样区域梯度直方图"></a>计算采样区域梯度直方图</h3><p>将旋转后区域划分为$d\times d$个子区域（每个区域间隔为$m\sigma$像元），在子区域内计算8个方向的梯度直方图，绘制每个方向梯度方向的累加值，形成一个种子点。 与求主方向不同的是，此时，每个子区域梯度方向直方图将0°~360°划分为8个方向区间，每个区间为45°。即每个种子点有8个方向区间的梯度强度信息。由于存在$d\times d$，即$4\times 4$个子区域，所以最终共有$4\times 4 \times 8 = 128$个数据（Lowe建议的数据），形成128维SIFT特征矢量。<br><img src="https://user-images.githubusercontent.com/6218739/138856347-869aa2f0-2669-4e70-9251-52b34f034439.png" alt="final"><br>对特征矢量需要加权处理，加权采用$\frac{m\sigma d}{2}$的标准高斯函数。为了除去光照变化影响，还有进一步归一化处理。</p><p>至此SIFT描述子生成，SIFT算法也基本完成了。</p>]]></content>
    
    
    <summary type="html">参考文献
SIFT算法深入理解
特征点匹配——SIFT算法详解
图像金字塔（高斯金字塔，拉普拉斯金字塔，图像缩放resize函数）
SIFT算法详解

简介
SIFT（Scale Invariant Feature Transform），尺度不变特征变换匹配算法，是由David G. Lowe在1999年（《Object Recognition from Local Scale-Invariant Features》）提出的高效区域检测算法，在2004年（《Distinctive Image Features from Scale-Invariant Keypoints》）得以完善。
SIFT</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="Image" scheme="http://qixinbo.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>GAN系列算法原理及极简代码解析</title>
    <link href="http://qixinbo.github.io/2021/10/21/gan/"/>
    <id>http://qixinbo.github.io/2021/10/21/gan/</id>
    <published>2021-10-20T16:00:00.000Z</published>
    <updated>2021-10-21T08:38:46.620Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h1><p><a href="https://alberthg.github.io/2018/05/05/introduction-gan/">生成对抗网络——原理解释和数学推导</a><br>首先有一个“生成器(Generator)”：其实就是一个神经网络，或者是更简单的理解，他就是一个函数(Function)。输入一组向量，经由生成器，产生一组目标矩阵（如果你要生成图片，那么矩阵就是图片的像素集合，具体的输出视你的任务而定）。它的目的就是使得自己造样本的能力尽可能强，强到什么程度呢，强到你判别网络没法判断我是真样本还是假样本。<br>同时还有一个“判别器(Discriminator)”：判别器的目的就是能判别出来一张图它是来自真实样本集还是假样本集。假如输入的是真样本，网络输出就接近 1，输入的是假样本，网络输出接近 0，那么很完美，达到了很好判别的目的。<br>那为什么需要这两个组件呢？GAN在结构上受博弈论中的二人零和博弈 （即二人的利益之和为零，一方的所得正是另一方的所失）的启发，系统由一个生成模型（G）和一个判别模型（D）构成。G 捕捉真实数据样本的潜在分布，并生成新的数据样本；D 是一个二分类器，判别输入是真实数据还是生成的样本。生成器和判别器均可以采用深度神经网络。GAN的优化过程是一个极小极大博弈(Minimax game)问题，优化目标是达到纳什均衡。</p><h1 id="原始GAN"><a href="#原始GAN" class="headerlink" title="原始GAN"></a>原始GAN</h1><p>这里用的网络非常简单，仅有二层，且还不是卷积神经网络，而是全连接层。后面的GAN变种会使用更加强大的深度网络。<br>首先先看一下判别器和生成器的分别的损失函数：<br><img src="https://user-images.githubusercontent.com/6218739/136900996-05cfa37c-96f4-48cf-9f5b-7f7aa6a074b8.png" alt="loss-d"><br><img src="https://user-images.githubusercontent.com/6218739/136901466-4f4a85d8-92db-4eaf-9e05-6b8b206df7d7.png" alt="loss-g"></p><p>最终实现的效果就是：生成器能够凭空（也不是完全凭空，它的输入是一个具有隐参量维度的噪声图像）生成一张与训练图片极为类似的虚假图片。</p><p>代码在：<br><a href="https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/GANs">Machine-Learning-Collection/ML/Pytorch/GANs</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter  <span class="comment"># to print to tensorboard</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 判别器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_features</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 非常小的网络</span></span><br><span class="line">        self.disc = nn.Sequential(</span><br><span class="line">            nn.Linear(in_features, <span class="number">128</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.01</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.disc(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># z是隐空间参量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, z_dim, img_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.gen = nn.Sequential(</span><br><span class="line">            nn.Linear(z_dim, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.01</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, img_dim),</span><br><span class="line">            <span class="comment"># 输入会标准化为[-1, 1]，所以这里的输出也要标准化到[-1, 1]</span></span><br><span class="line">            nn.Tanh(), </span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.gen(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 超参数设置</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">lr = <span class="number">3e-4</span> <span class="comment"># 学习率</span></span><br><span class="line">z_dim = <span class="number">64</span> <span class="comment"># 隐参量的维度</span></span><br><span class="line">image_dim = <span class="number">28</span> * <span class="number">28</span> * <span class="number">1</span>  <span class="comment"># 784，MNIST</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">num_epochs = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">disc = Discriminator(image_dim).to(device)</span><br><span class="line">gen = Generator(z_dim, image_dim).to(device)</span><br><span class="line"><span class="comment"># 这里加入噪声是为了看出在迭代过程中的变化</span></span><br><span class="line">fixed_noise = torch.randn((batch_size, z_dim)).to(device)</span><br><span class="line">transforms = transforms.Compose(</span><br><span class="line">    <span class="comment"># 按道理应该采用与MNist相同的均值和标准差(0.1307, 0.3081)</span></span><br><span class="line">    <span class="comment"># 但上面的超参数的设置是作者用(0.5, 0.5)时调出来的，所以这里如果改了就会发散</span></span><br><span class="line">    <span class="comment"># 这也说明GAN对参数非常敏感，非常难以训练</span></span><br><span class="line">    [transforms.ToTensor(), transforms.Normalize((<span class="number">0.5</span>,), (<span class="number">0.5</span>,)),]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">dataset = datasets.MNIST(root=<span class="string">&quot;dataset/&quot;</span>, transform=transforms, download=<span class="literal">True</span>)</span><br><span class="line">loader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 判别器的优化算法</span></span><br><span class="line">opt_disc = optim.Adam(disc.parameters(), lr=lr)</span><br><span class="line"><span class="comment"># 生成器的优化算法</span></span><br><span class="line">opt_gen = optim.Adam(gen.parameters(), lr=lr)</span><br><span class="line"><span class="comment"># 损失函数设为Binary Cross Entropy</span></span><br><span class="line"><span class="comment"># 公式为-[y*logx + (1-y)log(1-x)]</span></span><br><span class="line"><span class="comment"># 注意公式前面的负号，后面计算损失时该负号将最大化改为了最小化</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line">writer_fake = SummaryWriter(<span class="string">f&quot;logs/fake&quot;</span>)</span><br><span class="line">writer_real = SummaryWriter(<span class="string">f&quot;logs/real&quot;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># 从加载器里取出的是real图像</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (real, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        real = real.view(-<span class="number">1</span>, <span class="number">784</span>).to(device)</span><br><span class="line">        batch_size = real.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">########## 训练判别器：最大化log(D(x)) + log(1 - D(G(z))) ###############</span></span><br><span class="line">        <span class="comment">## 即：log(D(real)) + log(1 - D(G(latent_noise)))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 事先准备隐空间的噪声数据</span></span><br><span class="line">        noise = torch.randn(batch_size, z_dim).to(device)</span><br><span class="line">        <span class="comment"># 将噪声数据传给生成器，生成假的图像</span></span><br><span class="line">        fake = gen(noise)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#### 计算log(D(x))损失 ####</span></span><br><span class="line">        <span class="comment"># 将真实图像传给判别器，即计算D(x)</span></span><br><span class="line">        disc_real = disc(real).view(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将D(x)与1分别作为预测值和目标值放到BCE中进行计算</span></span><br><span class="line">        <span class="comment"># 根据BCE的公式-[y*logx + (1-y)log(1-x)]，这里y为1，因此此处计算的就是-log(D(x))</span></span><br><span class="line">        <span class="comment"># 也可以这样理解，此处的损失就是看看判别器对于真实图像的预测是不是接近1，即判别器对于真实图像的性能怎么样</span></span><br><span class="line">        lossD_real = criterion(disc_real, torch.ones_like(disc_real))</span><br><span class="line"></span><br><span class="line">        <span class="comment">#### 计算log(1-D(G(z)))损失</span></span><br><span class="line">        <span class="comment"># 将生成器生成的虚假图像传给判别器，即计算D(G(z))</span></span><br><span class="line">        disc_fake = disc(fake).view(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将D(G(z))与0分别作为预测值和目标值放到BCE中进行计算</span></span><br><span class="line">        <span class="comment"># 根据BCE的公式-[y*logx + (1-y)log(1-x)]，这里y为0，因此此处计算的就是-log(1-D(G(z)))</span></span><br><span class="line">        <span class="comment"># 也可以这样理解，此处的损失就是看看判别器对于虚假图像的预测是不是接近0，即判别器对于虚假图像的性能怎么样</span></span><br><span class="line">        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 总损失</span></span><br><span class="line">        lossD = (lossD_real + lossD_fake) / <span class="number">2</span></span><br><span class="line">        <span class="comment"># 判别器的反向传播</span></span><br><span class="line">        disc.zero_grad()</span><br><span class="line">        <span class="comment"># 注意，这里将retain_graph设为True，是为了保留该过程中计算的梯度，后续生成器网络更新时使用</span></span><br><span class="line">        <span class="comment"># 否则这里判别器网络构建了正向计算图后，反向传播结束后就将其销毁</span></span><br><span class="line">        lossD.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line">        opt_disc.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">########## 训练生成器：最小化log(1 - D(G(z)))，等价于最大化log(D(G(z)) ###############</span></span><br><span class="line">        <span class="comment">## 第二种损失不会遇到梯度饱和的问题</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将生成器生成的虚假图像传给判别器，即计算D(G(z))</span></span><br><span class="line">        <span class="comment"># 这里的disc是经过了升级后的判别器，所以与第99行的D(G(z))计算不同</span></span><br><span class="line">        <span class="comment"># 但fake这个量还是上面的fake = gen(noise)</span></span><br><span class="line">        output = disc(fake).view(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将D(G(z))与1分别作为预测值和目标值放到BCE中进行计算</span></span><br><span class="line">        <span class="comment"># 根据BCE的公式-[y*logx + (1-y)log(1-x)]，这里y为1，因此此处计算的就是-log(D(G(z)))</span></span><br><span class="line">        <span class="comment"># 也可以这样理解，此处的损失就是看看判别器对于生成器生成的虚假图像的预测是不是接近1，即生成器有没有骗过判别器</span></span><br><span class="line">        <span class="comment"># 这里log(D(G(z))的计算与上面的log(D(G(z))的计算不重复，是因为生成器和判别器是分开训练的，两者都要有各自的损失函数</span></span><br><span class="line">        lossG = criterion(output, torch.ones_like(output))</span><br><span class="line">        <span class="comment"># 生成器的反向传播</span></span><br><span class="line">        gen.zero_grad()</span><br><span class="line">        lossG.backward()</span><br><span class="line">        opt_gen.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下面就是用于tenshorboard的可视化</span></span><br><span class="line">        <span class="keyword">if</span> batch_idx == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(</span><br><span class="line">                <span class="string">f&quot;Epoch [<span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>] Batch <span class="subst">&#123;batch_idx&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(loader)&#125;</span> \</span></span><br><span class="line"><span class="string">                      Loss D: <span class="subst">&#123;lossD:<span class="number">.4</span>f&#125;</span>, loss G: <span class="subst">&#123;lossG:<span class="number">.4</span>f&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                fake = gen(fixed_noise).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">                data = real.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">                img_grid_fake = torchvision.utils.make_grid(fake, normalize=<span class="literal">True</span>)</span><br><span class="line">                img_grid_real = torchvision.utils.make_grid(data, normalize=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">                writer_fake.add_image(</span><br><span class="line">                    <span class="string">&quot;Mnist Fake Images&quot;</span>, img_grid_fake, global_step=step</span><br><span class="line">                )</span><br><span class="line">                writer_real.add_image(</span><br><span class="line">                    <span class="string">&quot;Mnist Real Images&quot;</span>, img_grid_real, global_step=step</span><br><span class="line">                )</span><br><span class="line">                step += <span class="number">1</span></span><br></pre></td></tr></table></figure></p><h1 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h1><p>DCGAN，深度卷积生成对抗网络，全名“Deep Convolutional Generative Adversarial Networks”。<br>DCGAN的生成器和判别器的网络架构如下：<br><img src="https://user-images.githubusercontent.com/6218739/136920307-cfbf4981-6576-4bad-9a31-866b8465ece4.png" alt="dcgan"><br>与上面的原生的GAN类似，DCGAN是将网络架构换成了深度卷积网络，其参数也要小心调节。</p><h1 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h1><p><a href="https://zhuanlan.zhihu.com/p/25071913">令人拍案叫绝的Wasserstein GAN</a><br>（该文章下面的评论也很有见解）<br>自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进DCGAN依靠的是对判别器和生成器的架构进行实验枚举，最终找到一组比较好的网络架构设置，但是实际上是治标不治本，没有彻底解决问题。而Wasserstein GAN（下面简称WGAN）成功地做到了以下爆炸性的几点：<br>（1）彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度<br>（2）基本解决了collapse mode的问题，确保了生成样本的多样性（collapse mode就是模式倒塌。比如我们知道人民币有好几个面额的纸币。假钞制造团伙发现如果他们将全部精力都放在制造一种面值的货币时最容易获得成功。而这时候，模式倒塌也就发生了。虽然这个假钞制造团伙能够制造出十分真实的货币，但却只有一种，而这有时并不是我们希望的。我们希望假钞制造团伙能生成所有的币值人民币。）<br>（3）训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高<br>（4）以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到。<br>那以上好处来自哪里？这就是令人拍案叫绝的部分了——实际上作者整整花了两篇论文，在第一篇《Towards Principled Methods for Training Generative Adversarial Networks》里面推了一堆公式定理，从理论上分析了原始GAN的问题所在，从而针对性地给出了改进要点；在这第二篇《Wasserstein GAN》里面，又再从这个改进点出发推了一堆公式定理，最终给出了改进的算法实现流程，而改进后相比原始GAN的算法实现流程却只改了四点：<br>（1）判别器最后一层去掉sigmoid<br>（2）生成器和判别器的loss不取log<br>（3）每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c<br>（4）不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行。</p><p>上述是工程上的改进，但为什么这样改进，需要非常深厚的数学知识推导。从宏观上理解就是如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/137093439-169e8c77-debc-46cb-982f-d91502574eb4.png" alt="distance"><br>GAN的目的是使得生成图像的样本分布与真实图像的样本分布尽可能相近，即数学上怎样表达这两种分布的距离。原始GAN使用了JS散度来衡量该距离（更新loss后的GAN使用的是KL散度），WGAN则使用的是Wasserstein距离。<br>因为对于JS散度，无论真实样本分布跟生成样本分布是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数$log 2$，而这对于梯度下降方法意味着——梯度为0！此时对于最优判别器来说，生成器肯定是得不到一丁点梯度信息的；即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。 原始GAN不稳定的原因是：判别器训练得太好，生成器梯度消失，生成器loss降不下去；判别器训练得不好，生成器梯度不准，四处乱跑。只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样，所以GAN才那么难训练。<br>Ian Goodfellow提出的原始GAN两种形式有各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。<br>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。<br>其具体定义如下：<br><img src="https://user-images.githubusercontent.com/6218739/137243663-49a15547-9972-4daf-95ea-5a78751e10af.png" alt="em"><br>（注意，Wasserstein距离本身是一个距离的概念，上式中的下界意思是从这两个分布中采样时取得的最小距离，就是Wasserstein距离）<br>在实际使用Wasserstein距离时，无法直接应用，作者将其通过某一定理改变成了如下条件：<br><img src="https://user-images.githubusercontent.com/6218739/137256384-4c8ed599-a4e0-46b3-9b1f-d8546bfc53fb.png" alt="wgan-1"><br><img src="https://user-images.githubusercontent.com/6218739/137256914-76caca0f-c705-4973-aa5e-b492ba1910f6.png" alt="wgan-2"><br>即这里不知道函数f的具体形式，用一组参数w来定义这些f，这里就是深度学习中的常用套路，“什么东西如果不知道，就用神经网络来学到”，因此f就是参数为w的一套网络，这里原作者命名为Critic。（至于上式中K施加的限制，是通过对权重参数w的裁剪来实现的。）<br>注意上式中是尽可能最大化才能获得Wasserstein距离，因此网络f的作用是一个测距网络，它的最大化max的过程就是为了找到Wasserstein距离，即该网络逐步优化成为一个准确的Wasserstein距离测量尺。<br>因此，最好不把它称为判别网络，而是称为测距网络。它的训练过程就是最小化下面的损失（因为它是为了近似拟合Wasserstein距离，属于回归任务，所以要把最后一层的sigmoid拿掉）：<br><img src="https://user-images.githubusercontent.com/6218739/137257689-06b20ed0-fd71-411e-b3c2-17798a574b3d.png" alt="wgan-loss-1"><br>那么接下来，因为测距网络已经将Wasserstein距离计算了出来，下一步就是将该距离尽可能地减小，从而使得生成图像的分布尽可能地与真实图像的分布类似，这就是生成器网络要干的事情。<br>回到公式14中Wasserstein距离的定义，该距离由两部分构成，第一项是真实图像分布的贡献，第二项是生成图像分布的贡献，而第一项与生成器网络无关，因此要使得Wasserstein距离变得小一些（注意不要受式中的max影响，max是为了计算Wasserstein距离），就要使第二项（注意带前面的负号）变小，即：<br><img src="https://user-images.githubusercontent.com/6218739/137263288-aa414595-7a8d-4b78-97ed-83c134835975.png" alt="wgan-loss-2"><br>至于代码实现，大部分都可以复用之前的，只是针对上面说的四点改动一下即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测距网络，看着跟原始GAN的判别网络类似，但核心意义不同，这里仍然沿用那个网络架构，但改个名字以示区别</span></span><br><span class="line">critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    <span class="comment"># Target labels not needed! &lt;3 unsupervised</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        data = data.to(device)</span><br><span class="line">        cur_batch_size = data.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">### 训练测距网络，最大化E[critic(real)] - E[critic(fake)]</span></span><br><span class="line">        <span class="comment">### 即最小化-(E[critic(real)] - E[critic(fake)])</span></span><br><span class="line">        <span class="comment"># Critic训练得越好，对Generator的提升更有利，因此多训练几轮Critic。</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(CRITIC_ITERATIONS):</span><br><span class="line">            noise = torch.randn(cur_batch_size, Z_DIM, <span class="number">1</span>, <span class="number">1</span>).to(device)</span><br><span class="line">            fake = gen(noise)</span><br><span class="line">            critic_real = critic(data).reshape(-<span class="number">1</span>)</span><br><span class="line">            critic_fake = critic(fake).reshape(-<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 测距网络的损失函数</span></span><br><span class="line">            <span class="comment"># 两个期望值相减</span></span><br><span class="line">            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))</span><br><span class="line">            critic.zero_grad()</span><br><span class="line">            loss_critic.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line">            opt_critic.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 裁剪网络权重</span></span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> critic.parameters():</span><br><span class="line">                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)</span><br><span class="line"></span><br><span class="line">        <span class="comment">########## 训练生成器网络 ################</span></span><br><span class="line">        <span class="comment">## 最大化E[critic(gen_fake)]</span></span><br><span class="line">        <span class="comment">## 即最小化-E[critic(gen_fake)]</span></span><br><span class="line">        gen_fake = critic(fake).reshape(-<span class="number">1</span>)</span><br><span class="line">        loss_gen = -torch.mean(gen_fake)</span><br><span class="line">        gen.zero_grad()</span><br><span class="line">        loss_gen.backward()</span><br><span class="line">        opt_gen.step()</span><br></pre></td></tr></table></figure></p><h2 id="WGAN-GP"><a href="#WGAN-GP" class="headerlink" title="WGAN-GP"></a>WGAN-GP</h2><p><a href="https://zhuanlan.zhihu.com/p/58260684">WGAN的来龙去脉</a><br>作者们发现WGAN有时候也会伴随样本质量低、难以收敛等问题。WGAN为了保证Lipschitz限制，采用了weight clipping的方法，然而这样的方式可能过于简单粗暴了，因此他们认为这是上述问题的罪魁祸首。<br>具体而言，他们通过简单的实验，发现weight clipping会导致两大问题：模型建模能力弱化，以及梯度爆炸或消失。<br>他们提出的替代方案是给Critic loss加入gradient penalty (GP)，这样，新的网络模型就叫WGAN-GP。<br>新的Loss为：<br><img src="https://user-images.githubusercontent.com/6218739/137277767-786bce8c-7f5c-4c2a-aca2-41cb80fcde85.png" alt="wgan-gp-loss"><br>另一个值得注意的地方是，用于计算GP的样本是生成样本和真实样本的线性插值。<br>GP部分的代码为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_penalty</span>(<span class="params">critic, real, fake, device=<span class="string">&quot;cpu&quot;</span></span>):</span></span><br><span class="line">    BATCH_SIZE, C, H, W = real.shape</span><br><span class="line">    alpha = torch.rand((BATCH_SIZE, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)).repeat(<span class="number">1</span>, C, H, W).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 线性插值</span></span><br><span class="line">    interpolated_images = real * alpha + fake * (<span class="number">1</span> - alpha)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算判别网络（测距网络）得分</span></span><br><span class="line">    mixed_scores = critic(interpolated_images)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算梯度</span></span><br><span class="line">    gradient = torch.autograd.grad(</span><br><span class="line">        inputs=interpolated_images,</span><br><span class="line">        outputs=mixed_scores,</span><br><span class="line">        grad_outputs=torch.ones_like(mixed_scores),</span><br><span class="line">        create_graph=<span class="literal">True</span>,</span><br><span class="line">        retain_graph=<span class="literal">True</span>,</span><br><span class="line">    )[<span class="number">0</span>]</span><br><span class="line">    gradient = gradient.view(gradient.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 2范数</span></span><br><span class="line">    gradient_norm = gradient.norm(<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">    gradient_penalty = torch.mean((gradient_norm - <span class="number">1</span>) ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> gradient_penalty</span><br></pre></td></tr></table></figure></p><h1 id="CGAN"><a href="#CGAN" class="headerlink" title="CGAN"></a>CGAN</h1><p><a href="https://zhuanlan.zhihu.com/p/61464846">李宏毅GAN2018笔记 Conditional GAN</a><br>Conditional，意思是条件，所以 Conditional GAN 的意思就是有条件的GAN。Conditional GAN 可以让 GAN 产生的结果符合一定的条件，即可以通过人为改变输入的向量（记不记得我们让生成器生成结果需要输入一个低维向量），控制最终输出的结果。<br>这种网络与普通 GAN 的区别在于输入加入了一个额外的 condition（比如在 text-to-image 任务中的描述文本），并且在训练的时候使得输出的结果拟合这个 condition。<br>所以现在判别器不仅要对生成结果的质量打分，还要对结果与输入 condition 的符合程度打分。<br>Conditional GAN 的判别器有两种常见架构，前者更为常用，但李宏毅老师认为后者更加合理，它用两个神经网络分别对输出结果的质量以及条件符合程度独立进行判别。<br><img src="https://user-images.githubusercontent.com/6218739/137661146-99fb337c-9d64-4740-ab9a-5b232a1aafdb.png" alt="cgan"></p><h1 id="Pix2Pix"><a href="#Pix2Pix" class="headerlink" title="Pix2Pix"></a>Pix2Pix</h1><p><a href="https://blog.csdn.net/u014380165/article/details/98453672">pix2pix算法笔记</a><br><a href="https://zhuanlan.zhihu.com/p/90300175">Pix2Pix图图转换网络原理分析与pytorch实现</a><br>自动图图转换任务被定义为：在给定充足的数据下，从一种场景转换到另一种场景。从功能实现上来看，网络需要学会“根据像素预测像素”（predict pixels from pixels）。<br>CNNs的研究已经给图图转换问题提供了一种简便的思路，比如设计一个编码解码网络AE，AE的输入 是白天的图像，AE的期望输出是黑夜的图像。那么可以使用MSE损失，来最小化网络输出的黑夜图像和真实黑夜图像之间的差异，实现白天到黑夜的图图转换。<br>然而，CNN需要我们去设计特定的损失函数，比如使用欧氏距离会导致预测的图像出现模糊。所以，需要去设计一种网络，这种网络不需要精心选择损失函数。<br>更确切地说，是用一种通用的损失函数形式来自动学习特定任务的损失函数，即GAN架构里判别器和生成器的损失函数是通用形式，它可以用来作为所有图图转换任务的统一损失，而具体任务的损失则是在训练过程中自动学习到的，这样就不用手动准确设定损失函数。</p><p>论文Image-to-Image Translation with Conditional Adversarial Networks发表在CVPR2017，简称pix2pix，是将GAN应用于有监督的“图像到图像”翻译的经典论文，有监督表示训练数据是成对的。图像到图像翻译（image-to-image translation）是GAN很重要的一个应用方向，什么叫图像到图像翻译呢？其实就是基于一张输入图像得到想要的输出图像的过程，可以看做是图像和图像之间的一种映射（mapping），我们常见的图像修复、超分辨率其实都是图像到图像翻译的例子。（节选为CSDN博主「AI之路」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明）<br>pix2pix基于GAN实现图像翻译，更准确地讲是基于cGAN（conditional GAN，也叫条件GAN），因为cGAN可以通过添加条件信息来指导图像生成，因此在图像翻译中就可以将输入图像作为条件，学习从输入图像到输出图像之间的映射，从而得到指定的输出图像。而其他基于GAN来做图像翻译的，因为GAN算法的生成器是基于一个随机噪声生成图像，难以控制输出，因此基本上都是通过其他约束条件来指导图像生成，而不是利用cGAN，这是pix2pix和其他基于GAN做图像翻译的差异。</p><p>生成器采用U-Net，这是在图像分割领域应用非常广泛的网络结构，能够充分融合特征；而原本GAN中常用的生成器结构是encoder-decoder类型。<br>判别器采用PatchGAN。通常判断都是对生成样本整体进行判断，比如对一张图片来说，就是直接看整张照片是否真实。而且Image-to-Image Translation中很多评价是像素对像素的，所以在这里提出了分块判断的算法，在图像的每个块上去判断是否为真，最终平均给出结果。PatchGAN的差别主要是在于Discriminator上，一般的GAN是只需要输出一个true or fasle 的矢量，这是代表对整张图像的评价；但是PatchGAN输出的是一个N x N的矩阵，这个N x N的矩阵的每一个元素，比如a(i,j) 只有True or False 这两个选择（label 是 N x N的矩阵，每一个元素是True 或者 False），这样的结果往往是通过卷积层来达到的，因为逐次叠加的卷积层最终输出的这个N x N 的矩阵，其中的每一个元素，实际上代表着原图中的一个比较大的感受野，也就是说对应着原图中的一个Patch，因此具有这样结构以及这样输出的GAN被称之为Patch GAN。这么设计的原因是依靠L1项来保证低频的准确性。为了对高频信息建模（即细节），关注对局部图像块（patches）就已经足够了。</p><p>损失函数沿用了最原始的GAN的损失，即有log作用：<br><img src="https://user-images.githubusercontent.com/6218739/137694646-69faa7ab-913e-4cdc-9f6f-6e97faf30da7.png" alt="pix2pix-loss-1"><br>同时加入了一个L1损失，使生成图像不仅要像真实图片，也要更接近于输入的条件图片：<br><img src="https://user-images.githubusercontent.com/6218739/137695208-19578014-4dcf-448d-8781-35a33a519441.png" alt="pix2pix-loss-2"><br>将对抗损失和L1损失相加，就得到了最终的整体损失函数：<br><img src="https://user-images.githubusercontent.com/6218739/137695374-7ee625bb-6593-4391-8d0b-10a407d1642d.png" alt="pix2pix-loss"></p><p>pix2pix的代码实现与之前的GAN大同小异，不同的地方就是上面的模型架构和损失函数，不再赘述。</p><h1 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h1><p><a href="https://zhuanlan.zhihu.com/p/26332365">异父异母的三胞胎：CycleGAN, DiscoGAN, DualGAN</a><br><a href="https://zhuanlan.zhihu.com/p/26995910">CycleGAN</a></p><p>pix2pix的模型是在成对的数据上训练的，也就是说，对于线条到猫的应用，我们训练的时候就需要提供一对一对的数据：一个线条画，和对应的真实的猫图片。<br>然而在很多情况下，我们并没有这样完美的成对的训练数据。比如说如果你想把马变成斑马，并没有这样对应的一个马对应一个斑马。然而，马的图片和斑马的图片却很多。所以这篇论文就是希望，能够通过不成对的训练数据，来学到变换。<br>一个普通的GAN只有一个生成器和一个判别器。而在CycleGAN里，分别有两个生成器和判别器。如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/138195026-c3033357-122f-4448-90b8-bd4814cf2e9c.png" alt="cyclegan"><br>一个生成器将X域的图片转换成Y域的图片（用G表示），而另一个生成器做相反的事情，用F表示。而两个判别器$D_x$和$D_y$试图分辨两个域中真假图片。（这里假图片指的是从真照片transform来的）<br>看上图，X通过G生成Y，Y再通过F生成X，构成了一个循环，所以叫CycleGAN。整个cycle可以看成是一个autoencoder，两个generator看成是encoder和decoder。而两个discriminator则是准则。<br>损失函数分为两部分：<br>（1）对抗损失Adversarial Loss：<br>从X到Y的对抗损失为：<br><img src="https://user-images.githubusercontent.com/6218739/138197675-43f6916f-3730-4836-b962-dce030489cfe.png" alt="cyclegan-loss-1"><br>从Y到X的对抗损失反之亦然。<br>（2）Cycle Consistency 损失<br>Cycle consistency是为了使得transform能成功。讲道理，如果你能从X转换到Y，然后再从Y转换到X，最后的结果应该和输入相似。这里他们用最后输出和输入的L1距离来作为另外的惩罚项。<br>这个惩罚项防止了mode collapse的问题。如果没有这个cycle consistency项，网络会输出更真实的图片，但是无论什么输入，都会是一样的输出。而如果加了cycle consistency，一样的输出会导致cycle consistency的直接失败。所以这规定了在经过了变换之后的图片不仅需要真实，且包含原本图片的信息。<br><img src="https://user-images.githubusercontent.com/6218739/138223001-01e048e8-1f0d-4ae0-aa39-5cb518809809.png" alt="cyclegan-loss-2"></p><p>制作数据集时，比如想把马和斑马进行转换，那么就准备马的数据集X，斑马的数据集Y，两者不需要数量相等，也不需要一一对应。训练时，上面的损失会保证马转换成相同体型和姿态的斑马。</p><h1 id="ProGAN"><a href="#ProGAN" class="headerlink" title="ProGAN"></a>ProGAN</h1><p><a href="https://zhuanlan.zhihu.com/p/93748098">ProGAN：Step by step, better than better</a><br>ProGAN 中的 Pro 并非 Professional，而是 Progressive，即逐渐的意思，这篇 paper 主要想解决的问题是高清图像难以生成的问题，图像生成主要的技术路线有：（1）Autoregressive Model: PixelRNN，（2）VAEs，（3）GANs。<br>GAN最大的好处在于生成的图像十分Sharp，而弱点则在于训练麻烦，容易崩，而且生成的数据分布只是训练集数据分布的一个子集，即多样性不足。ProGAN 最大的贡献在于提出了一种新的训练方式，即，我们不要一上来就学那么难的高清图像生成，这样会让 Generator 直接崩掉，而是从低清开始学起，学好了再提升分辨率学更高分辨率下的图片生成。从4x4到8x8一直提升到1024x1024，循序渐进，即能有效且稳定地训练出一个高质量的高分辨率生成器模型。<br>这样做的好处主要有二：<br>（1）毫无疑问，比直接学生成 1024x1024 的图像稳定多了。<br>（2）另外，节省时间，训练低分辨率阶段下的生成器快得不知道哪里去了，大大节省整体训练时间。</p><h1 id="SRGAN"><a href="#SRGAN" class="headerlink" title="SRGAN"></a>SRGAN</h1><p><a href="https://perper.site/2019/03/01/SRGAN-%E8%AF%A6%E8%A7%A3/">SRGAN 详解</a><br>SRGAN目标从一个低分辨率的图片中生成它的高分辨率版本。<br>传统CNN方法：基于深度学习的高分辨率图像重建已经取得了很好的效果，其方法是通过一系列低分辨率图像和与之对应的高分辨率图像作为训练数据，学习一个从低分辨率图像到高分辨率图像的映射函数。但是当图像的放大倍数在4以上时，很容易使得到的结果显得过于平滑，而缺少一些细节上的真实感。这是因为传统的方法使用的代价函数一般是最小均方差（MSE），使得生成的图像有较高的信噪比，但是缺少了高频信息，出现过度平滑的纹理。作者还做了实验，证明并不是信噪比越高超分辨率效果越好。<br>本文的做法：应当使重建的高分辨率图像与真实的高分辨率图像无论是低层次的像素值上，还是高层次的抽象特征上，和整体概念和风格上，都应当接近。因此在loss部分，SRGAN加上了feature map部分的MSE loss。<br>网络结构有：<br>生成网络部分：SRResnet，输入是低分辨率图像（注意与原始GAN输入是噪声进行对比），由残差结构，BN，PReLU组成，用于实现高分辨率的生成。<br>判别器部分：由大量卷积层，Leaky ReLU,BN等结构组成，用于判别图像的真实性。<br>损失函数由两部分组成：（1）content loss：传统算法使用的是还原图像与GT图像之间的MSE损失，作者为了避免放大后特征过于平滑，认为高层次（features map）也应当相似。因此定义了VGG feature map loss。（2）adversarial loss：对抗网络部分的loss为判别器判别loss，即当生成器生成的图片，判别器认为为真实的图片时，该loss取得最小。<br>因此，SRGAN是一个监督式算法，它需要Ground Truth的输入。</p><h2 id="ESRGAN"><a href="#ESRGAN" class="headerlink" title="ESRGAN"></a>ESRGAN</h2><p><a href="https://zhuanlan.zhihu.com/p/338646051">ESRGAN超分辨网络</a><br>ESRGAN就是Enhanced Super-Resolution Generative Adversarial Networks，作者主要从三个方面对SRGAN进行改进：网络结构、对抗损失、感知损失。<br>（1）网络结构：引入了 Residual-in-Residual Dense Block (RRDB)来代替SRGAN中的resblock；移除了网络单元的BN层；增加了residual scaling，来消除部分因移除BN层对深度网络训练稳定性的影响。<br>（2）对抗损失：SRGAN的对抗损失的目的是为了让真实图像的判决概率更接近1，让生成图像的判决概率更接近0。而改进的ESRGAN的目标是，让生成图像和真实图像之间的距离保持尽可能大，这是引入了真实图像和生成图像间的相对距离（Relativistic average GAN简称RaGAN），而不是SRGAN中的衡量和0或1间的绝对距离。（具体说来，ESRGAN目的是：让真实图像的判决分布减去生成图像的平均分布，再对上述结果做sigmoid处理，使得结果更接近于1；让生成图像的判决分布减去真实图像的平均分布，再对上述结果做sigmoid处理，使得结果更接近于0。）<br>（3）感知损失：（基于特征空间的计算，而非像素空间）使用VGG网络激活层前的特征图，而不像SRGAN中使用激活层后的特征图。因为激活层后的特征图有更稀疏的特征，而激活前的特征图有更详细的细节，因此可以带来更强的监督。并且，通过使用激活后的特征图作为感知损失的计算，可以带来更加锐化的边缘和更好视觉体验。</p>]]></content>
    
    
    <summary type="html">基本思想
生成对抗网络——原理解释和数学推导
首先有一个“生成器(Generator)”：其实就是一个神经网络，或者是更简单的理解，他就是一个函数(Function)。输入一组向量，经由生成器，产生一组目标矩阵（如果你要生成图片，那么矩阵就是图片的像素集合，具体的输出视你的任务而定）。它的目的就是使得自己造样本的能力尽可能强，强到什么程度呢，强到你判别网络没法判断我是真样本还是假样本。
同时还有一个“判别器(Discriminator)”：判别器的目的就是能判别出来一张图它是来自真实样本集还是假样本集。假如输入的是真样本，网络输出就接近 1，输入的是假样本，网络输出接近 0，那么很完美，达到了</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="GAN" scheme="http://qixinbo.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>YOLO系列算法原理及极简代码解析</title>
    <link href="http://qixinbo.github.io/2021/09/25/yolo3/"/>
    <id>http://qixinbo.github.io/2021/09/25/yolo3/</id>
    <published>2021-09-24T16:00:00.000Z</published>
    <updated>2021-09-25T15:15:16.864Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>物体检测的两个步骤可以概括为：<br>步骤一：检测目标位置（生成矩形框）<br>步骤二：对目标物体进行分类<br>物体检测主流的算法框架大致分为one-stage与two-stage。two-stage算法代表有R-CNN系列，one-stage算法代表有Yolo系列。two-stage算法将步骤一与步骤二分开执行，输入图像先经过候选框生成网络（例如faster rcnn中的RPN网络），再经过分类网络；one-stage算法将步骤一与步骤二同时执行，输入图像只经过一个网络，生成的结果中同时包含位置与类别信息。two-stage与one-stage相比，精度高，但是计算量更大，所以运算较慢。</p><h1 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h1><h2 id="YOLOv1"><a href="#YOLOv1" class="headerlink" title="YOLOv1"></a>YOLOv1</h2><p><a href="https://zhuanlan.zhihu.com/p/70387154">【论文解读】Yolo三部曲解读——Yolov1</a><br>YOLOv1的网络架构如下图：<br><img src="https://user-images.githubusercontent.com/6218739/133874079-e9c89d7b-f8f3-4078-8d9a-30e9f0451df3.png" alt="yolov1"><br>直接上结构图，输入图像大小为448乘448，经过若干个卷积层与池化层，变为7乘7乘1024张量（图一中倒数第三个立方体），最后经过两层全连接层，输出张量维度为7乘7乘30，这就是Yolo v1的整个神经网络结构，和一般的卷积物体分类网络没有太多区别，最大的不同就是：分类网络最后的全连接层，一般连接于一个一维向量，向量的不同位代表不同类别，而这里的输出向量是一个三维的张量（7乘7乘30）。上图中Yolo的backbone网络结构，受启发于GoogLeNet，也是v2、v3中Darknet的先锋。本质上来说没有什么特别，没有使用BN层，用了一层Dropout。除了最后一层的输出使用了线性激活函数，其他层全部使用Leaky Relu激活函数。网络结构没有特别的东西，不再赘述。</p><p>输出张量维度的意义：<br>（1）7乘7的含义<br>7乘7是指图片被分成了7乘7个格子，如下图：<br><img src="https://user-images.githubusercontent.com/6218739/133877539-5d2fe916-a712-4676-9a5e-06a3657a27cf.png" alt="grid-yolov1"><br>在Yolo中，如果一个物体的中心点，落在了某个格子中，那么这个格子将负责预测这个物体。而那些没有物体中心点落进来的格子，则不负责预测任何物体。这个设定就好比该网络在一开始，就将整个图片上的预测任务进行了分工，一共设定7乘7个按照方阵列队的检测人员，每个人员负责检测一个物体，大家的分工界线，就是看被检测物体的中心点落在谁的格子里。当然，是7乘7还是9乘9，是上图中的参数S，可以自己修改，精度和性能会随之有些变化。<br>（2）30的含义<br>刚才设定了49个检测人员，那么每个人员负责检测的内容，就是这里的30（注意，30是张量最后一维的长度）。在Yolo v1论文中，30是由$(4+1) \times 2 +20$得到的。其中$4+1$是矩形框的中心点坐标(x,y)、长宽(w,h)以及是否属于被检测物体的置信度c；2是一个格子共回归两个矩形框，每个矩形框分别产生5个预测值（每个格子预测矩形框个数，是可调超参数；论文中选择了2个框，当然也可以只预测1个框，具体预测几个矩形框，无非是在计算量和精度之间取一个权衡。如果只预测一个矩形框，计算量会小很多，但是如果训练数据都是小物体，那么网络学习到的框，也会普遍比较小，测试时如果物体较大，那么预测效果就会不理想；如果每个格子多预测几个矩形框，如上文中讲到的，每个矩形框的学习目标会有所分工，有些学习小物体特征，有些学习大物体特征等；在Yolov2、v3中，这个数目都有一定的调整。）；20代表预测20个类别。这里有几点需要注意：1. 每个方格（grid） 产生2个预测框，2也是参数，可以调，但是一旦设定为2以后，那么每个方格只产生两个矩形框，最后选定置信度更大的矩形框作为输出，也就是最终每个方格只输出一个预测矩形框。2. 每个方格只能预测一个物体。虽然可以通过调整参数，产生不同的矩形框，但这只能提高矩形框的精度。所以当有很多个物体的中心点落在了同一个格子里，该格子只能预测一个物体。也就是格子数为7乘7时，该网络最多预测49个物体。<br>如上述原文中提及，在强行施加了格点限制以后，每个格点只能输出一个预测结果，所以该算法最大的不足，就是对一些邻近小物体的识别效果不是太好，例如成群结队的小鸟。</p><p>损失函数：<br><img src="https://user-images.githubusercontent.com/6218739/133877787-e073a763-b371-4908-8456-60f6329974b7.png" alt="loss-yolov1"><br>论文中Loss函数，密密麻麻的公式初看可能比较难懂。其实论文中给出了比较详细的解释。所有的损失都是使用平方和误差公式。<br>（1）预测框的中心点(x,y)。造成的损失是上图中的第一行。其中$\mathbb{I}_{ij}^{obj}$为控制函数，在标签中包含物体的那些格点处，该值为 1 ；若格点不含有物体，该值为 0。也就是只对那些有真实物体所属的格点进行损失计算，若该格点不包含物体，那么预测数值不对损失函数造成影响。（x,y）数值与标签用简单的平方和误差。<br>（2）预测框的宽高。造成的损失是上图的第二行。$\mathbb{I}_{ij}^{obj}$的含义一样，也是使得只有真实物体所属的格点才会造成损失。这里对在损失函数中的处理分别取了根号，原因在于，如果不取根号，损失函数往往更倾向于调整尺寸比较大的预测框。例如，20个像素点的偏差，对于800乘600的预测框几乎没有影响，此时的IOU数值还是很大，但是对于30乘40的预测框影响就很大。取根号是为了尽可能的消除大尺寸框与小尺寸框之间的差异。<br>（3）第三行与第四行，都是预测框的置信度C。当该格点不含有物体时，该置信度的标签为0；若含有物体时，该置信度的标签为预测框与真实物体框的IOU数值（IOU计算公式为：两个框交集的面积除以并集的面积）。<br>（4）第五行为物体类别概率P，对应的类别位置，该标签数值为1，其余位置为0，与分类网络相同。<br>此时再来看$\lambda_{coord}$与$\lambda_{noobj}$，Yolo面临的物体检测问题，是一个典型的类别数目不均衡的问题。其中49个格点，含有物体的格点往往只有3、4个，其余全是不含有物体的格点。此时如果不采取点措施，那么物体检测的mAP不会太高，因为模型更倾向于不含有物体的格点。$\lambda_{coord}$与$\lambda_{noobj}$的作用，就是让含有物体的格点，在损失函数中的权重更大，让模型更加“重视”含有物体的格点所造成的损失。在论文中， 取值分别为5与0.5。</p><p>一些技巧：<br>（1）回归offset代替直接回归坐标<br>不直接回归中心点坐标数值，而是回归相对于格点左上角坐标的位移值。例如，第一个格点中物体坐标为$(2.3, 3.6)$，另一个格点中的物体坐标为$(5.4, 6.3)$，这四个数值让神经网络暴力回归，有一定难度。所以这里的offset是指，既然格点已知，那么物体中心点的坐标一定在格点正方形里，相对于格点左上角的位移值一定在区间$[0, 1)$中。让神经网络去预测$(0.3, 0.6)$与$(0.4, 0.3)$会更加容易，在使用时，加上格点左上角坐标$(2, 3)$、$(5, 6)$即可。</p><p>（2）同一格点的不同预测框有不同作用<br>前文中提到，每个格点预测两个或多个矩形框。此时假设每个格点预测两个矩形框。那么在训练时，见到一个真实物体，我们是希望两个框都去逼近这个物体的真实矩形框，还是只用一个去逼近？或许通常来想，让两个人一起去做同一件事，比一个人做一件事成功率要高，所以可能会让两个框都去逼近这个真实物体。但是作者没有这样做，在损失函数计算中，只对和真实物体最接近的框计算损失，其余框不进行修正。这样操作之后作者发现，一个格点的两个框在尺寸、长宽比、或者某些类别上逐渐有所分工，总体的召回率有所提升<br>（3）使用非极大抑制生成预测框<br>通常来说，在预测的时候，格点与格点并不会冲突，但是在预测一些大物体或者邻近物体时，会有多个格点预测了同一个物体。此时采用非极大抑制技巧，过滤掉一些重叠的矩形框。不过此时mAP提升并没有像在RCNN或DPM中那样显著提升。<br>（4）推理时将类别预测最大值乘以预测框最大值作为输出置信度<br>在推理时，使用物体的类别预测最大值p乘以预测框的最大值c，作为输出预测物体的置信度。这样也可以过滤掉一些大部分重叠的矩形框。输出检测物体的置信度，同时考虑了矩形框与类别，满足阈值的输出更加可信。</p><h2 id="YOLOv2"><a href="#YOLOv2" class="headerlink" title="YOLOv2"></a>YOLOv2</h2><p><a href="https://zhuanlan.zhihu.com/p/74540100">【论文解读】Yolo三部曲解读——Yolov2</a><br>Yolov2论文标题就是更好，更快，更强。Yolov1发表之后，计算机视觉领域出现了很多trick，例如批归一化、多尺度训练，v2也尝试借鉴了R-CNN体系中的anchor box，所有的改进提升，下面逐一介绍。</p><ol><li>Batch Normalization（批归一化）<br>检测系列的网络结构中，BN逐渐变成了标配。在Yolo的每个卷积层中加入BN之后，mAP提升了2%，并且去除了Dropout。</li><li>High Resolution Classifier（分类网络高分辨率预训练）<br>在Yolov1中，网络的backbone部分会在ImageNet数据集上进行预训练，训练时网络输入图像的分辨率为224乘224。在v2中，将分类网络在输入图片分辨率为448乘448的ImageNet数据集上训练10个epoch，再使用检测数据集（例如coco）进行微调。高分辨率预训练使mAP提高了大约4%。</li><li>Convolutional With Anchor Boxes（Anchor Box替换全连接层）<br>第一篇解读v1时提到，每个格点预测两个矩形框，在计算loss时，只让与ground truth最接近的框产生loss数值，而另一个框不做修正。这样规定之后，作者发现两个框在物体的大小、长宽比、类别上逐渐有了分工。在v2中，神经网络不对预测矩形框的宽高的绝对值进行预测，而是预测与Anchor框的偏差（offset），每个格点指定n个Anchor框。在训练时，最接近ground truth的框产生loss，其余框不产生loss。在引入Anchor Box操作后，mAP由69.5下降至69.2，原因在于，每个格点预测的物体变多之后，召回率大幅上升，准确率有所下降，总体mAP略有下降。<br>v2中移除了v1最后的两层全连接层，全连接层计算量大，耗时久。文中没有详细描述全连接层的替换方案，这里笔者猜测是利用1乘1的卷积层代替（欢迎指正），具体的网络结构原文中没有提及，官方代码也被yolo v3替代了。v2主要是各种trick引入后的效果验证，建议不必纠结于v2的网络结构。</li><li>Dimension Clusters（Anchor Box的宽高由聚类产生）<br>这里算是作者的一个创新点。Faster R-CNN中的九个Anchor Box的宽高是事先设定好的比例大小，一共设定三个面积大小的矩形框，每个矩形框有三个宽高比：1:1，2:1，1:2，总共九个框。而在v2中，Anchor Box的宽高不经过人为获得，而是将训练数据集中的矩形框全部拿出来，用kmeans聚类得到先验框的宽和高。例如使用5个Anchor Box, 那么kmeans聚类的类别中心个数设置为5。<br>加入了聚类操作之后，引入Anchor Box之后，mAP上升。<br>需要强调的是，聚类必须要定义聚类点（矩形框）之间的距离函数，文中使用（1-IOU）数值作为两个矩形框的的距离函数，这里的运用也是非常的巧妙。</li><li>Direct location prediction（绝对位置预测）<br>Yolo中的位置预测方法很清晰，就是相对于左上角的格点坐标预测偏移量。这里的Direct具体含义，应该是和其他算法框架对比后得到的。比如其他流行的位置预测公式是先预测一个系数，系数又需要与先验框的宽高相乘才能得到相较于参考点的位置偏移，而在yolov2中，系数通过一个激活函数直接产生偏移位置数值，与矩形框的宽高独立开，变得更加直接。</li><li>Fine-Grained Features（细粒度特征）<br>在26乘26的特征图，经过卷积层等，变为13乘13的特征图后，作者认为损失了很多细粒度的特征，导致小尺寸物体的识别效果不佳，所以在此加入了passthrough层。passthrough层就是将26乘26乘1的特征图，变成13乘13乘4的特征图，在这一次操作中不损失细粒度特征。</li><li>Multi-Scale Training（多尺寸训练）<br>很关键的一点是，Yolo v2中只有卷积层与池化层，所以对于网络的输入大小，并没有限制，整个网络的降采样倍数为32，只要输入的特征图尺寸为32的倍数即可，如果网络中有全连接层，就不是这样了。所以Yolo v2可以使用不同尺寸的输入图片训练。<br>作者使用的训练方法是，在每10个batch之后，就将图片resize成{320, 352, …, 608}中的一种。不同的输入，最后产生的格点数不同，比如输入图片是320乘320，那么输出格点是10乘10，如果每个格点的先验框个数设置为5，那么总共输出500个预测结果；如果输入图片大小是608乘608，输出格点就是19乘19，共1805个预测结果。<br>在引入了多尺寸训练方法后，迫使卷积核学习不同比例大小尺寸的特征。当输入设置为544乘544甚至更大，Yolo v2的mAP已经超过了其他的物体检测算法。</li></ol><h2 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h2><p><a href="https://zhuanlan.zhihu.com/p/76802514">【论文解读】Yolo三部曲解读——Yolov3</a><br><img src="https://user-images.githubusercontent.com/6218739/133880395-2f580763-b4fc-4aea-b36e-2d745834a1da.png" alt="yolov3"><br>Yolov3使用Darknet-53作为整个网络的分类骨干部分（见上图虚线部分）。<br>Darknet-53的架构如下图：<br><img src="https://user-images.githubusercontent.com/6218739/133880487-984b7259-6b63-42e4-8d6a-7ae420fb4591.png" alt="darknet53"><br>backbone部分由Yolov2时期的Darknet-19进化至Darknet-53，加深了网络层数，引入了Resnet中的跨层加和操作。Darknet-53处理速度每秒78张图，比Darknet-19慢不少，但是比同精度的ResNet快很多。Yolov3依然保持了高性能。</p><p>网络结构解析：</p><ol><li>Yolov3中，只有卷积层，通过调节卷积步长控制输出特征图的尺寸。所以对于输入图片尺寸没有特别限制。</li><li>Yolov3借鉴了金字塔特征图思想，小尺寸特征图用于检测大尺寸物体，而大尺寸特征图检测小尺寸物体。特征图的输出维度为$N \times N \times [3 \times (4+1+80)]$， $N \times N$为输出特征图格点数，一共3个Anchor框，每个框有4维预测框数值和1维预测框置信度，80维物体类别数。</li><li>Yolov3总共输出3个特征图，第一个特征图下采样32倍，第二个特征图下采样16倍，第三个下采样8倍。输入图像经过Darknet-53（无全连接层），再经过Yoloblock生成的特征图被当作两用，第一用为经过3乘3卷积层、1乘1卷积之后生成特征图一，第二用为经过1乘1卷积层加上采样层，与Darnet-53网络的中间层输出结果进行拼接，产生特征图二。同样的循环之后产生特征图三。</li><li>concat操作与加和操作的区别：加和操作来源于ResNet思想，将输入的特征图，与输出特征图对应维度进行相加，即$y=f(x)+x$；而concat操作源于DenseNet网络的设计思路，将特征图按照通道维度直接进行拼接，例如8乘8乘16的特征图与8乘8乘16的特征图拼接后生成8乘8乘32的特征图。</li><li>上采样层(upsample)：作用是将小尺寸特征图通过插值等方法，生成大尺寸图像。例如使用最近邻插值算法，将8乘8的图像变换为16乘16。上采样层不改变特征图的通道数。</li></ol><p>Yolo的整个网络，吸取了Resnet、Densenet、FPN的精髓，可以说是融合了目标检测当前业界最有效的全部技巧。</p><p>YOLOv3与YOLOv2和YOLOv1相比最大的改善就是对boundingbox进行了跨尺度预测(Prediction Across Scales)，提高YOLO模型对不同尺度对象的预测精度。<br><img src="https://user-images.githubusercontent.com/6218739/133882919-4d3ede76-ff3d-4435-a4c0-a577c181bd2d.png" alt="yolov3-output"><br><a href="https://zhuanlan.zhihu.com/p/75811997">YOLO_v3论文解读</a></p><p>结合上图看，卷积网络在79层后，经过下方几个黄色的卷积层得到一种尺度的检测结果。相比输入图像，这里用于检测的特征图有32倍的下采样。比如输入是416乘416的话，这里的特征图就是13乘13了。由于下采样倍数高，这里特征图的感受野比较大，因此适合检测图像中尺寸比较大的对象。<br>为了实现细粒度的检测，第79层的特征图又开始作上采样（从79层往右开始上采样卷积），然后与第61层特征图拼接（Concatenation），这样得到第91层较细粒度的特征图，同样经过几个卷积层后得到相对输入图像16倍下采样的特征图。它具有中等尺度的感受野，适合检测中等尺度的对象。<br>最后，第91层特征图再次上采样，并与第36层特征图拼接（Concatenation），最后得到相对输入图像8倍下采样的特征图。它的感受野最小，适合检测小尺寸的对象。<br>随着输出的特征图的数量和尺度的变化，先验框的尺寸也需要相应的调整。YOLO2已经开始采用K-means聚类得到先验框的尺寸，YOLO3延续了这种方法，为每种下采样尺度设定3种先验框，总共聚类出9种尺寸的先验框。在COCO数据集这9个先验框是：</p><script type="math/tex; mode=display">(10 \times 13)，(16 \times 30)，(33 \times 23)，(30 \times 61)，(62 \times 45)，(59 \times 119)，(116 \times 90)，(156 \times 198)，(373 \times 326)</script><p>分配上，在最小的13乘13特征图上（有最大的感受野）应用较大的先验框$(116 \times 90)，(156 \times 198)，(373 \times 326)$，适合检测较大的对象。中等的26乘26特征图上（中等感受野）应用中等的先验框$(30 \times 61)，(62 \times 45)，(59 \times 119)$，适合检测中等大小的对象。较大的52乘52特征图上（较小的感受野）应用较小的先验框$(10 \times 13)，(16 \times 30)，(33 \times 23)$，适合检测较小的对象。</p><p>YOLOv3前向解码过程：<br>根据不同的输入尺寸，会得到不同大小的输出特征图，以图二中输入图片$256 \times 256 \times 3$为例，输出的特征图为$8 \times 8 \times 255$、$16 \times 16 \times 255$、$32 \times 32 \times 255$。在Yolov3的设计中，每个特征图的每个格子中，都配置3个不同的先验框（就是下面的锚框），所以最后三个特征图，这里暂且reshape为$8 \times 8 \times 3 \times 85$、$16 \times 16 \times 3 \times 85$、$32 \times 32 \times 3 \times 85$，这样更容易理解，在代码中也是reshape成这样之后更容易操作。<br>三张特征图就是整个Yolo输出的检测结果，检测框位置（4维）、检测置信度（1维）、类别（80维）都在其中，加起来正好是85维。特征图最后的维度85，代表的就是这些信息，而特征图其他维度$N \times N \times 3$，$N \times N$代表了检测框的参考位置信息，3是3个不同尺度的先验框。</p><p>三个特征图一共可以解码出 $8 × 8 × 3 + 16 × 16 × 3 + 32 × 32 × 3 = 4032$ 个box以及相应的类别、置信度。这4032个box，在训练和推理时，使用方法不一样：</p><ol><li>训练时4032个box全部送入打标签函数，进行后一步的标签以及损失函数的计算。</li><li>推理时，选取一个置信度阈值，过滤掉低阈值box，再经过nms（非极大值抑制），就可以输出整个网络的预测结果了。</li></ol><p>YOLOv3训练策略（反向过程）：</p><ol><li>预测框一共分为三种情况：正例（positive）、负例（negative）、忽略样例（ignore）。</li><li>正例：任取一个ground truth，与4032个框全部计算IOU，IOU最大的预测框，即为正例。并且一个预测框，只能分配给一个ground truth。例如第一个ground truth已经匹配了一个正例检测框，那么下一个ground truth，就在余下的4031个检测框中，寻找IOU最大的检测框作为正例。ground truth的先后顺序可忽略。正例产生置信度loss、检测框loss、类别loss。预测框为对应的ground truth box标签；类别标签对应类别为1，其余为0；置信度标签为1。</li><li>忽略样例：正例除外，与任意一个ground truth的IOU大于阈值（论文中使用0.5），则为忽略样例。忽略样例不产生任何loss。</li><li>负例：正例除外（与ground truth计算后IOU最大的检测框，但是IOU小于阈值，仍为正例），与全部ground truth的IOU都小于阈值（0.5），则为负例。负例只有置信度产生loss，置信度标签为0。</li></ol><h1 id="YOLOv3源码"><a href="#YOLOv3源码" class="headerlink" title="YOLOv3源码"></a>YOLOv3源码</h1><p>从头实现YOLOv3的源码见：<br><a href="https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/object_detection/YOLOv3">YOLOv3 in PyTorch</a><br>该源码的视频讲解见：<br><a href="https://www.bilibili.com/video/BV1bo4y1X78v?spm_id_from=333.999.0.0">YOLOv3 from Scratch</a></p><h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><p>整个YOLOv3的模型架构如下配置：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于里面的元素</span></span><br><span class="line"><span class="comment"># 如果是元组，代表：(输出通道, 卷积核尺寸, 步长)</span></span><br><span class="line"><span class="comment"># YOLOv3中所有的卷积块（注意是卷积块，它由卷积层+批标准化层+LeakyReLU层构成）都是相同的，在下面的代码中用CNNBlock类实现</span></span><br><span class="line"><span class="comment"># 如果是列表，&quot;B&quot;代表残差块Residual Block，后面的次数代表重复次数，在下面用ResidualBlock类实现</span></span><br><span class="line"><span class="comment"># 如果是字符，那么&quot;S&quot;代表Scale不同尺度预测块，在此处计算损失，在下面用ScalePrediction类实现</span></span><br><span class="line"><span class="comment"># &quot;U&quot;代表Upsampling上采样，且与上一层进行连接，生成新的尺度预测</span></span><br><span class="line">config = [</span><br><span class="line">    (<span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">64</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">1</span>],</span><br><span class="line">    (<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">2</span>],</span><br><span class="line">    (<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">8</span>],</span><br><span class="line">    (<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">8</span>],</span><br><span class="line">    (<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">4</span>],  <span class="comment"># 到这里就是Darknet-53 backbone，53是全部卷积层的个数，它会在imagenet上进行预训练</span></span><br><span class="line">    (<span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;S&quot;</span>,</span><br><span class="line">    (<span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;U&quot;</span>,</span><br><span class="line">    (<span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;S&quot;</span>,</span><br><span class="line">    (<span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;U&quot;</span>,</span><br><span class="line">    (<span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;S&quot;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><br>首先看一下CNN卷积块的实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNNBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 此处会加上一个BN层的开关，如果关了BN层，就相当于是只有卷积层，而不是卷积块</span></span><br><span class="line">   <span class="comment"># 不加BN和ReLU层的纯卷积层是会在尺度预测的地方用到，即网络末端的卷积是纯卷积层</span></span><br><span class="line">   <span class="comment"># 同时使用kwargs参数接收其他参数，比如kerneal size，stride，padding等参数</span></span><br><span class="line">   <span class="comment"># 在整个网络中图像的宽高变化即维度压缩，是通过卷积块的stride参数来实现的</span></span><br><span class="line">   <span class="comment"># 由下面的分析可知，在残差块中图像宽高不变，但两个残差块中间的卷积块的stride为2，此时会对图像的宽高进行压缩减半</span></span><br><span class="line">   <span class="comment"># 整个网络中压缩最厉害的分支是一共压缩了5次，即压缩了32倍，另外两支分别压缩了16倍和8倍</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, bn_act=<span class="literal">True</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">       <span class="comment"># 如果使用了BN，那么偏置这个参数就没必要了，所以此处会根据BN层的有无进行偏置bias参数的开关</span></span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, bias=<span class="keyword">not</span> bn_act, **kwargs)</span><br><span class="line">        self.bn = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.leaky = nn.LeakyReLU(<span class="number">0.1</span>)</span><br><span class="line">        self.use_bn_act = bn_act</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.use_bn_act:</span><br><span class="line">            <span class="keyword">return</span> self.leaky(self.bn(self.conv(x)))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure><br>再看一下残差块的实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResidualBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 这里给出了是否使用残差连接的开关，在darknet-53部分都是打开残差连接，但到了尺度预测部分，该残差块是关闭了残差连接</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, channels, use_residual=<span class="literal">True</span>, num_repeats=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 整个残差块是一个ModuleList</span></span><br><span class="line">        self.layers = nn.ModuleList()</span><br><span class="line">       <span class="comment"># 根据重复次数进行循环</span></span><br><span class="line">        <span class="keyword">for</span> repeat <span class="keyword">in</span> <span class="built_in">range</span>(num_repeats):</span><br><span class="line">            self.layers += [</span><br><span class="line">                <span class="comment"># 每个残差块中的第一个卷积块都是通道数减半，卷积核尺寸为1，步长是默认的1，填充是默认的0，因此图像的输入和输出宽高不变</span></span><br><span class="line">            <span class="comment"># 第二个卷积块通道数变为两倍，卷积核尺寸为3，填充为1，步长仍是默认的1，因此图像的输入和输出宽高不变</span></span><br><span class="line">            <span class="comment"># 所以，总的来说，经过一个残差块后，图像的通道数、宽和高都不会变</span></span><br><span class="line">                nn.Sequential(</span><br><span class="line">                    CNNBlock(channels, channels // <span class="number">2</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">                    CNNBlock(channels // <span class="number">2</span>, channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                )</span><br><span class="line">            ]</span><br><span class="line"></span><br><span class="line">        self.use_residual = use_residual</span><br><span class="line">        self.num_repeats = num_repeats</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            <span class="comment"># 如果启用残差连接，那么就直接将x和经过处理后的x相加</span></span><br><span class="line">            <span class="keyword">if</span> self.use_residual:</span><br><span class="line">                x = x + layer(x)</span><br><span class="line">            <span class="comment"># 如果没有启用残差连接，那么就直接处理x，不管作为输入的x</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x = layer(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p><p>再来看不同尺度预测的类实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScalePrediction</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.pred = nn.Sequential(</span><br><span class="line">            <span class="comment"># 在每个尺度预测块中，先用一个卷积块将通道数加倍，同时通过设置卷积核尺寸为3，填充为1，步长是默认的1，来保持宽高不变</span></span><br><span class="line">            CNNBlock(in_channels, <span class="number">2</span> * in_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            <span class="comment"># 然后将得到的特征图通过一个卷积块转化为最终想要的向量的模样</span></span><br><span class="line">         <span class="comment"># 3指的是对于对于每一个grid cell，都有3个anchor boxes</span></span><br><span class="line">         <span class="comment"># 对于每一个anchor box，都需要有num_classes+5个元素，前面是类别数目，比如20，5是包含了x, y, w, h和置信度</span></span><br><span class="line">         <span class="comment"># 注意这里不使用BN层，同时卷积核为1，步长是默认的1，填充是默认的0，因此宽高不变</span></span><br><span class="line">            CNNBlock(</span><br><span class="line">                <span class="number">2</span> * in_channels, (num_classes + <span class="number">5</span>) * <span class="number">3</span>, bn_act=<span class="literal">False</span>, kernel_size=<span class="number">1</span></span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            self.pred(x)</span><br><span class="line">            <span class="comment"># 对x进行预测后，需要对结果进行reshape，形状依次为batch size、3、类别数+5、特征图宽度、特征图高度</span></span><br><span class="line">            .reshape(x.shape[<span class="number">0</span>], <span class="number">3</span>, self.num_classes + <span class="number">5</span>, x.shape[<span class="number">2</span>], x.shape[<span class="number">3</span>])</span><br><span class="line">            <span class="comment"># 再交换一下维度，把宽、高提到(类别数+5)的前面</span></span><br><span class="line">         <span class="comment"># 比如某一个尺度预测后，得到的向量形状为N x 3 x 13 x 13 x (5+num_classes)，grid cell就是13x13大小</span></span><br><span class="line">            .permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line">        )</span><br></pre></td></tr></table></figure></p><p>最后看整个模型的架构，即将上面的组件组合起来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YOLOv3</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 输入通道默认为3， 类别数默认为80</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, num_classes=<span class="number">80</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.layers = self._create_conv_layers()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_conv_layers</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 将所有模型组件都放在ModuleList中</span></span><br><span class="line">        layers = nn.ModuleList()</span><br><span class="line">        in_channels = self.in_channels</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 开始解析上面的config配置</span></span><br><span class="line">        <span class="keyword">for</span> module <span class="keyword">in</span> config:</span><br><span class="line">            <span class="comment"># 如果元素是个元组，代表它是个卷积块</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(module, <span class="built_in">tuple</span>):</span><br><span class="line">                <span class="comment"># 取出卷积块的相应配置</span></span><br><span class="line">                out_channels, kernel_size, stride = module</span><br><span class="line">                <span class="comment"># 往整个网络里添加卷积块</span></span><br><span class="line">                layers.append(</span><br><span class="line">                    CNNBlock(</span><br><span class="line">                        in_channels,</span><br><span class="line">                        out_channels,</span><br><span class="line">                        kernel_size=kernel_size,</span><br><span class="line">                        stride=stride,</span><br><span class="line">                        <span class="comment"># 如果卷积核为3，则填充为1，否则就填充为0，这样是为了当卷积核为3、步长为2时，填充设为1，此时宽高减半</span></span><br><span class="line">                  <span class="comment"># Pytorch默认卷积层的尺寸计算是向下取整，即(k+2*1-3)/2+1=k/2+floor(-0.5)+1=k/2-1+1=k/2</span></span><br><span class="line">                        padding=<span class="number">1</span> <span class="keyword">if</span> kernel_size == <span class="number">3</span> <span class="keyword">else</span> <span class="number">0</span>,</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line">                <span class="comment"># 更新通道数</span></span><br><span class="line">                in_channels = out_channels</span><br><span class="line"></span><br><span class="line">         <span class="comment"># 如果元素是个列表，代表是残差块</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(module, <span class="built_in">list</span>):</span><br><span class="line">                <span class="comment"># 取出残差块的相应配置</span></span><br><span class="line">                num_repeats = module[<span class="number">1</span>]</span><br><span class="line">                <span class="comment"># 往整个网络里添加残差块</span></span><br><span class="line">                layers.append(ResidualBlock(in_channels, num_repeats=num_repeats,))</span><br><span class="line"></span><br><span class="line">         <span class="comment"># 如果元素是个字符，那么就进入尺度预测模块</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(module, <span class="built_in">str</span>):</span><br><span class="line">                <span class="comment"># 如果是S，代表要进行在某一尺度上的预测了</span></span><br><span class="line">                <span class="keyword">if</span> module == <span class="string">&quot;S&quot;</span>:</span><br><span class="line">                    layers += [</span><br><span class="line">                        <span class="comment"># 下面这三块的网络架构参考下面那张YOLOv3的架构图</span></span><br><span class="line">                  <span class="comment"># 原码中残差块只重复了1次，为了与下面架构图中的YoloBlock相对应，这里改为重复2次，影响不大，因为在残差块中不改变图像大小</span></span><br><span class="line">                  <span class="comment"># 同时注意此时残差块关闭了残差连接</span></span><br><span class="line">                        ResidualBlock(in_channels, use_residual=<span class="literal">False</span>, num_repeats=<span class="number">2</span>),</span><br><span class="line">                        CNNBlock(in_channels, in_channels // <span class="number">2</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">                        ScalePrediction(in_channels // <span class="number">2</span>, num_classes=self.num_classes),</span><br><span class="line">                    ]</span><br><span class="line">                    <span class="comment"># 更新一下通道数</span></span><br><span class="line">                    in_channels = in_channels // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">             <span class="comment"># 如果是U，则进入上采样</span></span><br><span class="line">                <span class="keyword">elif</span> module == <span class="string">&quot;U&quot;</span>:</span><br><span class="line">                    layers.append(nn.Upsample(scale_factor=<span class="number">2</span>),)</span><br><span class="line">                    <span class="comment"># 通道数变为3倍，原因是这个地方进行了通道连接concatenation操作</span></span><br><span class="line">               <span class="comment"># 特别注意的是，不要在这个地方推导图像在整个模型中的处理过程，因为此时会发现前后通道数是不符的，因为通道一下从256跳到了768</span></span><br><span class="line">               <span class="comment"># 这个地方不是forward函数，并不是真正的数据处理过程，可以理解成这个地方仅是模型架构定义</span></span><br><span class="line">                    in_channels = in_channels * <span class="number">3</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 每一个尺度下都有一个output，这里用一个列表来承载三个output</span></span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="comment"># 存放进入不同预测分支的中间计算结果</span></span><br><span class="line">        route_connections = []</span><br><span class="line">        <span class="comment"># 对网络中的每一层进行遍历</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            <span class="comment"># 如果是尺度预测层，表示进入某一尺度的预测阶段，即进入某一个预测分支</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer, ScalePrediction):</span><br><span class="line">                <span class="comment"># 将预测结果添加进outputs中，注意这个地方是对x的一个分叉计算</span></span><br><span class="line">            <span class="comment"># 即x在这里走了两条路，一条路是进入尺度预测模块进行计算，另一条路是继续呆在主分支中，用于后续计算</span></span><br><span class="line">                outputs.append(layer(x))</span><br><span class="line">                <span class="comment"># 返回到主分支中</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">         <span class="comment"># 对常规的网络层进行计算，包含卷积块和重复次数不为8的残差块</span></span><br><span class="line">            x = layer(x)</span><br><span class="line"></span><br><span class="line">         <span class="comment"># 对于重复次数为8的残差块，由架构图可知，都是在这里进入不同的尺度预测分支</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer, ResidualBlock) <span class="keyword">and</span> layer.num_repeats == <span class="number">8</span>:</span><br><span class="line">                <span class="comment"># 将需要进入某分支的结果存放起来</span></span><br><span class="line">                route_connections.append(x)</span><br><span class="line"></span><br><span class="line">         <span class="comment"># 如果是遇到上采样模块</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(layer, nn.Upsample):</span><br><span class="line">                <span class="comment"># 就会将当前x与存放中间结果的route中的最后一个中间结果进行连接concatenation</span></span><br><span class="line">            <span class="comment"># 这个地方会将通道数变为3倍，因为上采样后的图像为n_channel，原主分支中的图像为2*n_channel，连接后就变为3*n_channel</span></span><br><span class="line">                x = torch.cat([x, route_connections[-<span class="number">1</span>]], dim=<span class="number">1</span>)</span><br><span class="line">                <span class="comment"># 用完最后一个元素就把它丢了，这样就能在下一次取到上一个存储的中间结果</span></span><br><span class="line">                route_connections.pop()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 最终outputs里是存放了三个尺度的预测模型</span></span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><br>YOLOv3架构图重新贴一下：<br><img src="https://user-images.githubusercontent.com/6218739/133880395-2f580763-b4fc-4aea-b36e-2d745834a1da.png" alt="yolov3"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>作者提供了YOLO格式的PASCAL VOC和MS COCO数据集的下载，分别在下面链接：<br><a href="https://www.kaggle.com/aladdinpersson/pascal-voc-dataset-used-in-yolov3-video">Pascal voc dataset used in YOLOv3 video</a><br><a href="https://www.kaggle.com/dataset/79abcc2659dc745fddfba1864438afb2fac3fabaa5f37daa8a51e36466db101e">MS-COCO-YOLOv3</a><br>关于数据集的格式可以参见下面的介绍：<br><a href="https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data">Train Custom Data</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YOLODataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">        self,</span></span></span><br><span class="line"><span class="function"><span class="params">        csv_file, <span class="comment"># csv文件路径</span></span></span></span><br><span class="line"><span class="function"><span class="params">        img_dir, <span class="comment"># 图像文件路径</span></span></span></span><br><span class="line"><span class="function"><span class="params">        label_dir, <span class="comment"># 标签文件路径</span></span></span></span><br><span class="line"><span class="function"><span class="params">        anchors, <span class="comment"># 九个锚框</span></span></span></span><br><span class="line"><span class="function"><span class="params">        image_size=<span class="number">416</span>, <span class="comment"># 图像尺寸</span></span></span></span><br><span class="line"><span class="function"><span class="params">        S=[<span class="number">13</span>, <span class="number">26</span>, <span class="number">52</span>], <span class="comment"># 三个特征图大小</span></span></span></span><br><span class="line"><span class="function"><span class="params">        C=<span class="number">20</span>, <span class="comment"># 类别数</span></span></span></span><br><span class="line"><span class="function"><span class="params">        transform=<span class="literal">None</span>, <span class="comment"># 图像变换</span></span></span></span><br><span class="line"><span class="function"><span class="params">    </span>):</span></span><br><span class="line">        self.annotations = pd.read_csv(csv_file) <span class="comment"># 图像和标签成对出现</span></span><br><span class="line">        self.img_dir = img_dir</span><br><span class="line">        self.label_dir = label_dir</span><br><span class="line">        self.image_size = image_size</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.S = S</span><br><span class="line">        self.anchors = torch.tensor(anchors[<span class="number">0</span>] + anchors[<span class="number">1</span>] + anchors[<span class="number">2</span>])  <span class="comment"># 将三个尺度下的三个锚框连起来，注意两个list相加就是join的效果</span></span><br><span class="line">        self.num_anchors = self.anchors.shape[<span class="number">0</span>]</span><br><span class="line">        self.num_anchors_per_scale = self.num_anchors // <span class="number">3</span></span><br><span class="line">        self.C = C</span><br><span class="line">        self.ignore_iou_thresh = <span class="number">0.5</span> <span class="comment"># 这个阈值用来区分忽略样例和负例，详见上面的解析</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.annotations)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        label_path = os.path.join(self.label_dir, self.annotations.iloc[index, <span class="number">1</span>]) <span class="comment"># 1就是代表第二列，即标签列</span></span><br><span class="line">        bboxes = np.roll(np.loadtxt(fname=label_path, delimiter=<span class="string">&quot; &quot;</span>, ndmin=<span class="number">2</span>), <span class="number">4</span>, axis=<span class="number">1</span>).tolist() <span class="comment"># 得到的边界框格式为(x, y, w, h, 类别)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读入图像文件</span></span><br><span class="line">        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, <span class="number">0</span>])</span><br><span class="line">        image = np.array(Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&quot;RGB&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 图像增强变换</span></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            augmentations = self.transform(image=image, bboxes=bboxes)</span><br><span class="line">            image = augmentations[<span class="string">&quot;image&quot;</span>]</span><br><span class="line">            bboxes = augmentations[<span class="string">&quot;bboxes&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最终目标是在三个特征图尺度上，每个尺度的每个格点上都有(self.num_anchors // 3)个预测框，每个预测框上都有6个分量，即[置信度标签, x, y, w, h, 类别]</span></span><br><span class="line">        <span class="comment"># 置信度标签为1，代表正例；标签为-1，代表忽略样例；标签为0，代表负例。</span></span><br><span class="line">        targets = [torch.zeros((self.num_anchors // <span class="number">3</span>, S, S, <span class="number">6</span>)) <span class="keyword">for</span> S <span class="keyword">in</span> self.S]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对该图像中的所有的边界框进行循环，目的是为了确定哪个锚框、哪个格点与其对应</span></span><br><span class="line">        <span class="keyword">for</span> box <span class="keyword">in</span> bboxes: </span><br><span class="line">            <span class="comment"># 确定与边界框对应的锚框是通过计算两者之间的IoU</span></span><br><span class="line">            <span class="comment"># box的第2、3元素就是宽度和高度</span></span><br><span class="line">            <span class="comment"># 这里的IoU计算相当于将锚框和边界框的中心放在一块，然后根据它们的宽高来计算</span></span><br><span class="line">            <span class="comment"># 即为了确定哪一种形状的锚框与该边界框最相近</span></span><br><span class="line">            iou_anchors = iou(torch.tensor(box[<span class="number">2</span>:<span class="number">4</span>]), self.anchors)</span><br><span class="line">            <span class="comment"># 找出重合度最大的即最好的锚框</span></span><br><span class="line">            anchor_indices = iou_anchors.argsort(descending=<span class="literal">True</span>, dim=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 取出该边界框的x, y, w, h</span></span><br><span class="line">            x, y, width, height, class_label = box</span><br><span class="line">            <span class="comment"># 下面这个列表初始化为False，但最终目的是变为True，即保证在每个尺度下该边界框都有对应的锚框</span></span><br><span class="line">            has_anchor = [<span class="literal">False</span>] * <span class="number">3</span>  <span class="comment"># each scale should have one anchor</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 因为一共有9个锚框，但分布在3个尺度下，下面就是将具体的锚框与它所属的尺度对应起来，即找到在每个尺度下的最好的锚框是哪个，将其判断为正例，其他不好的锚框进一步判断为负例还是忽略样例</span></span><br><span class="line">            <span class="comment"># 即对所有的锚框都会做判断，正例的锚框就会计算置信度loss、检测框loss、类别loss，负例只会计算置信度loss，忽略样例则什么loss都不计算</span></span><br><span class="line">            <span class="comment"># 先从9个锚框中重合度最大的锚框开始进行循环</span></span><br><span class="line">            <span class="keyword">for</span> anchor_idx <span class="keyword">in</span> anchor_indices:</span><br><span class="line">                <span class="comment"># 根据锚框的索引和每个尺度下拥有的锚框数量，就可以确定锚框所在的尺度</span></span><br><span class="line">                <span class="comment"># 比如如果锚框索引为8，且每个尺度下有3个锚框，那么scale_idx就是2，即第3个尺度，因此scale_idx就是该锚框所属的尺度的索引</span></span><br><span class="line">                scale_idx = anchor_idx // self.num_anchors_per_scale</span><br><span class="line">                <span class="comment"># 上述锚框索引为8，指的是该锚框在所有锚框中的索引，下面就是计算该锚框在该尺度下的索引，即anchor_on_scale就是2，也就是该尺度下该锚框是第3个</span></span><br><span class="line">                anchor_on_scale = anchor_idx % self.num_anchors_per_scale</span><br><span class="line">                <span class="comment"># 获取该尺度下的grid cell的个数，即格点个数</span></span><br><span class="line">                S = self.S[scale_idx]</span><br><span class="line">                <span class="comment"># 提醒一下：边界框的x和y坐标是其中心相对于整张图像的位置</span></span><br><span class="line">                <span class="comment"># 下面就是计算边界框属于图像中的哪个格点</span></span><br><span class="line">                <span class="comment"># 比如假设整个图像宽为W，那么边界框绝对位置就在W*x，而每个格点的宽度为W/S，那么在哪个格点就是W*x/(W/S)=S*x</span></span><br><span class="line">                <span class="comment"># 这里需要注意的是x是宽，但在矩阵中是列，即j,</span></span><br><span class="line">                <span class="comment"># 而y是高，在矩阵中是行，即i</span></span><br><span class="line">                i, j = <span class="built_in">int</span>(S * y), <span class="built_in">int</span>(S * x)  <span class="comment"># which cell</span></span><br><span class="line">                <span class="comment"># 下面这一行就是对于这一边界框，取出某一尺度下的锚框、格点及置信度（0元素就是代表是一个物体的可能性即置信度）</span></span><br><span class="line">                <span class="comment"># 刚开始anchor_taken都是0，表明在该尺度的该锚框没有被取走或说没有被判断，非0的话又有两种，1是代表是正例，-1代表是忽略样例</span></span><br><span class="line">                anchor_taken = targets[scale_idx][anchor_on_scale, i, j, <span class="number">0</span>]</span><br><span class="line">                <span class="comment"># 如果该尺度下（或称该格点）的该锚框没有被判断，且该尺度上之前没有确定锚框（即还没有出现正例）</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> anchor_taken <span class="keyword">and</span> <span class="keyword">not</span> has_anchor[scale_idx]:</span><br><span class="line">                    <span class="comment"># 就把第0个元素，即是一个物体的置信度置为1</span></span><br><span class="line">                    targets[scale_idx][anchor_on_scale, i, j, <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">                    <span class="comment"># 计算边界框的中心在格点中的相对位置</span></span><br><span class="line">                    x_cell, y_cell = S * x - j, S * y - i  <span class="comment"># both between [0,1]</span></span><br><span class="line">                    <span class="comment"># 计算边界框的宽高相对于格点的大小</span></span><br><span class="line">                    <span class="comment"># 仍然假设整张图像宽为W，边界框的绝对宽度就是W*width，那么它相对于格点的大小就是W*width/(W/S)=width*S</span></span><br><span class="line">                    width_cell, height_cell = (</span><br><span class="line">                        width * S,</span><br><span class="line">                        height * S,</span><br><span class="line">                    )  <span class="comment"># can be greater than 1 since it&#x27;s relative to cell</span></span><br><span class="line">                    box_coordinates = torch.tensor(</span><br><span class="line">                        [x_cell, y_cell, width_cell, height_cell]</span><br><span class="line">                    )</span><br><span class="line">                    <span class="comment"># 然后把上面的边界框相对于格点的相对位置和相对大小信息都存储到targets相应元素中，与具体的尺度、锚框和格点进行匹配。</span></span><br><span class="line">                    targets[scale_idx][anchor_on_scale, i, j, <span class="number">1</span>:<span class="number">5</span>] = box_coordinates</span><br><span class="line">                    <span class="comment"># 将物体类别也存储到相应元素</span></span><br><span class="line">                    targets[scale_idx][anchor_on_scale, i, j, <span class="number">5</span>] = <span class="built_in">int</span>(class_label)</span><br><span class="line">                    <span class="comment"># 将该尺度下是否确定了锚框置为True，即该锚框为正例</span></span><br><span class="line">                    has_anchor[scale_idx] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 如果已经出现了正例，但该锚框还没有被判断，即anchor_taken=0</span></span><br><span class="line">                <span class="comment"># 此时再判断该锚框与边界框的IoU是否大于阈值，如果大于阈值，且因为其不是正例，那么就将其置信度标签置为-1，即它为忽略样例，不参与损失计算</span></span><br><span class="line">                <span class="comment"># 这种情况出现在在该尺度上（或称在该格点上），有多个锚框都能与边界框吻合较好，但只取最好的那个</span></span><br><span class="line">                <span class="comment"># 但如果IoU小于阈值，那么其置信度标签仍为0，代表负例，会产生置信度loss，但不会产生其他类型的损失</span></span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> anchor_taken <span class="keyword">and</span> iou_anchors[anchor_idx] &gt; self.ignore_iou_thresh:</span><br><span class="line">                    targets[scale_idx][anchor_on_scale, i, j, <span class="number">0</span>] = -<span class="number">1</span>  <span class="comment"># ignore prediction</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image, <span class="built_in">tuple</span>(targets)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="损失计算"><a href="#损失计算" class="headerlink" title="损失计算"></a>损失计算</h2><p>YOLOv3中的损失有三种，一种是xywh带来的误差，即检测框loss；一种是置信度带来的误差，即是否是个物体obj带来的loss，称为置信度loss；一种是类别带来的误差，称为类别loss。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YoloLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.mse = nn.MSELoss() <span class="comment"># 均方差损失计算</span></span><br><span class="line">        self.bce = nn.BCEWithLogitsLoss() <span class="comment"># 加了Sigmoid的二进制交叉熵损失</span></span><br><span class="line">        self.entropy = nn.CrossEntropyLoss() <span class="comment"># 交叉熵损失</span></span><br><span class="line">        self.sigmoid = nn.Sigmoid() </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 确定损失函数中的各个权重常数，用来控制不同loss之间的比例</span></span><br><span class="line">        self.lambda_class = <span class="number">1</span> <span class="comment"># 类别损失权重常数</span></span><br><span class="line">        self.lambda_noobj = <span class="number">10</span> <span class="comment"># 负例损失权重常数</span></span><br><span class="line">        self.lambda_obj = <span class="number">1</span> <span class="comment"># 正例损失权重常数</span></span><br><span class="line">        self.lambda_box = <span class="number">10</span> <span class="comment"># 检测框损失权重常数</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, predictions, target, anchors</span>):</span></span><br><span class="line">        <span class="comment"># 判断每个尺度上的格点上是否是物体，即正例还是负例</span></span><br><span class="line">        <span class="comment"># 1为正例，0为负例，-1则为忽略样例</span></span><br><span class="line">        obj = target[..., <span class="number">0</span>] == <span class="number">1</span>  <span class="comment"># in paper this is Iobj_i</span></span><br><span class="line">        noobj = target[..., <span class="number">0</span>] == <span class="number">0</span>  <span class="comment"># in paper this is Inoobj_i</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ======================= #</span></span><br><span class="line">        <span class="comment">#   负例造成的置信度损失    #</span></span><br><span class="line">        <span class="comment"># ======================= #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用二进制交叉熵计算损失</span></span><br><span class="line">        no_object_loss = self.bce(</span><br><span class="line">            <span class="comment"># 取出置信度数值，即第0个元素</span></span><br><span class="line">            <span class="comment"># 这里使用0:1的形式，而不是直接使用0来取得元素，是为了保持维度不变</span></span><br><span class="line">            <span class="comment"># [noobj] 是使用了numpy的布尔索引，从而取出那些负例</span></span><br><span class="line">            (predictions[..., <span class="number">0</span>:<span class="number">1</span>][noobj]), (target[..., <span class="number">0</span>:<span class="number">1</span>][noobj]),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ==================== #</span></span><br><span class="line">        <span class="comment">#   正例造成的置信度损失 #</span></span><br><span class="line">        <span class="comment"># ==================== #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这个地方正例损失按上面的解析应该使用一个简单的bce即可，同时置信度标签在yolov3中是1和0二分类，而这里原作者使用的是IoU来作为置信度标签，即如下形式：</span></span><br><span class="line">        object_loss = self.bce(</span><br><span class="line">            (predictions[..., <span class="number">0</span>:<span class="number">1</span>][obj]), (target[..., <span class="number">0</span>:<span class="number">1</span>][obj]),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># # 原来的代码中是如下形式，这里先不仔细研究异同了</span></span><br><span class="line">        <span class="comment"># anchors = anchors.reshape(1, 3, 1, 1, 2)</span></span><br><span class="line">        <span class="comment"># box_preds = torch.cat([self.sigmoid(predictions[..., 1:3]), torch.exp(predictions[..., 3:5]) * anchors], dim=-1)</span></span><br><span class="line">        <span class="comment"># ious = intersection_over_union(box_preds[obj], target[..., 1:5][obj]).detach()</span></span><br><span class="line">        <span class="comment"># object_loss = self.mse(self.sigmoid(predictions[..., 0:1][obj]), ious * target[..., 0:1][obj])</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ======================== #</span></span><br><span class="line">        <span class="comment">#  检测框损失               #</span></span><br><span class="line">        <span class="comment"># ======================== #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这个地方涉及检测框的解码部分</span></span><br><span class="line">        <span class="comment"># 注意只取出正例造成的损失</span></span><br><span class="line">        predictions[..., <span class="number">1</span>:<span class="number">3</span>] = self.sigmoid(predictions[..., <span class="number">1</span>:<span class="number">3</span>])  <span class="comment"># x, y坐标</span></span><br><span class="line">        target[..., <span class="number">3</span>:<span class="number">5</span>] = torch.log(</span><br><span class="line">            (<span class="number">1e-16</span> + target[..., <span class="number">3</span>:<span class="number">5</span>] / anchors)</span><br><span class="line">        )  <span class="comment"># width, height coordinates</span></span><br><span class="line">        box_loss = self.mse(predictions[..., <span class="number">1</span>:<span class="number">5</span>][obj], target[..., <span class="number">1</span>:<span class="number">5</span>][obj])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ================== #</span></span><br><span class="line">        <span class="comment">#   类别损失   #</span></span><br><span class="line">        <span class="comment"># ================== #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算交叉熵损失，注意只取出正例造成的损失</span></span><br><span class="line">        class_loss = self.entropy(</span><br><span class="line">            (predictions[..., <span class="number">5</span>:][obj]), (target[..., <span class="number">5</span>][obj].long()),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment">#print(&quot;__________________________________&quot;)</span></span><br><span class="line">        <span class="comment">#print(self.lambda_box * box_loss)</span></span><br><span class="line">        <span class="comment">#print(self.lambda_obj * object_loss)</span></span><br><span class="line">        <span class="comment">#print(self.lambda_noobj * no_object_loss)</span></span><br><span class="line">        <span class="comment">#print(self.lambda_class * class_loss)</span></span><br><span class="line">        <span class="comment">#print(&quot;\n&quot;)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            self.lambda_box * box_loss</span><br><span class="line">            + self.lambda_obj * object_loss</span><br><span class="line">            + self.lambda_noobj * no_object_loss</span><br><span class="line">            + self.lambda_class * class_loss</span><br><span class="line">        )</span><br></pre></td></tr></table></figure></p><h2 id="超参数配置文件"><a href="#超参数配置文件" class="headerlink" title="超参数配置文件"></a>超参数配置文件</h2><p>此处就是将超参数配置都摘出来放在一个统一的配置文件中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">DATASET = <span class="string">&#x27;PASCAL_VOC&#x27;</span></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="comment"># seed_everything()  # If you want deterministic behavior</span></span><br><span class="line">NUM_WORKERS = <span class="number">4</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">IMAGE_SIZE = <span class="number">416</span></span><br><span class="line">NUM_CLASSES = <span class="number">20</span> <span class="comment">#类别数</span></span><br><span class="line">LEARNING_RATE = <span class="number">1e-5</span></span><br><span class="line">WEIGHT_DECAY = <span class="number">1e-4</span></span><br><span class="line">NUM_EPOCHS = <span class="number">100</span></span><br><span class="line">CONF_THRESHOLD = <span class="number">0.05</span></span><br><span class="line">MAP_IOU_THRESH = <span class="number">0.5</span></span><br><span class="line">NMS_IOU_THRESH = <span class="number">0.45</span></span><br><span class="line">S = [IMAGE_SIZE // <span class="number">32</span>, IMAGE_SIZE // <span class="number">16</span>, IMAGE_SIZE // <span class="number">8</span>]</span><br><span class="line">PIN_MEMORY = <span class="literal">True</span></span><br><span class="line">LOAD_MODEL = <span class="literal">True</span></span><br><span class="line">SAVE_MODEL = <span class="literal">True</span></span><br><span class="line">CHECKPOINT_FILE = <span class="string">&quot;checkpoint.pth.tar&quot;</span></span><br><span class="line">IMG_DIR = DATASET + <span class="string">&quot;/images/&quot;</span></span><br><span class="line">LABEL_DIR = DATASET + <span class="string">&quot;/labels/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过在训练集上kmeans聚类得到的锚框的大小</span></span><br><span class="line">ANCHORS = [</span><br><span class="line">    [(<span class="number">0.28</span>, <span class="number">0.22</span>), (<span class="number">0.38</span>, <span class="number">0.48</span>), (<span class="number">0.9</span>, <span class="number">0.78</span>)],</span><br><span class="line">    [(<span class="number">0.07</span>, <span class="number">0.15</span>), (<span class="number">0.15</span>, <span class="number">0.11</span>), (<span class="number">0.14</span>, <span class="number">0.29</span>)],</span><br><span class="line">    [(<span class="number">0.02</span>, <span class="number">0.03</span>), (<span class="number">0.04</span>, <span class="number">0.07</span>), (<span class="number">0.08</span>, <span class="number">0.06</span>)],</span><br><span class="line">]  <span class="comment"># Note these have been rescaled to be between [0, 1]</span></span><br></pre></td></tr></table></figure></p><h2 id="训练函数"><a href="#训练函数" class="headerlink" title="训练函数"></a>训练函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fn</span>(<span class="params">train_loader, model, optimizer, loss_fn, scaler, scaled_anchors</span>):</span></span><br><span class="line">    <span class="comment"># 显示进度条</span></span><br><span class="line">    loop = tqdm(train_loader, leave=<span class="literal">True</span>)</span><br><span class="line">    losses = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loop):</span><br><span class="line">        x = x.to(config.DEVICE)</span><br><span class="line">        <span class="comment"># 三个不同尺度下的目标</span></span><br><span class="line">        y0, y1, y2 = (</span><br><span class="line">            y[<span class="number">0</span>].to(config.DEVICE),</span><br><span class="line">            y[<span class="number">1</span>].to(config.DEVICE),</span><br><span class="line">            y[<span class="number">2</span>].to(config.DEVICE),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.cuda.amp.autocast():</span><br><span class="line">            out = model(x)</span><br><span class="line">            <span class="comment"># 前面的损失函数需要在三个尺度下都要计算一遍</span></span><br><span class="line">            loss = (</span><br><span class="line">                loss_fn(out[<span class="number">0</span>], y0, scaled_anchors[<span class="number">0</span>])</span><br><span class="line">                + loss_fn(out[<span class="number">1</span>], y1, scaled_anchors[<span class="number">1</span>])</span><br><span class="line">                + loss_fn(out[<span class="number">2</span>], y2, scaled_anchors[<span class="number">2</span>])</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        losses.append(loss.item())</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        scaler.scale(loss).backward()</span><br><span class="line">        scaler.step(optimizer)</span><br><span class="line">        scaler.update()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update progress bar</span></span><br><span class="line">        mean_loss = <span class="built_in">sum</span>(losses) / <span class="built_in">len</span>(losses)</span><br><span class="line">        loop.set_postfix(loss=mean_loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># 定义模型</span></span><br><span class="line">    model = YOLOv3(num_classes=config.NUM_CLASSES).to(config.DEVICE)</span><br><span class="line">    <span class="comment"># 优化器</span></span><br><span class="line">    optimizer = optim.Adam(</span><br><span class="line">        model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 损失函数</span></span><br><span class="line">    loss_fn = YoloLoss()</span><br><span class="line">    scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据加载器</span></span><br><span class="line">    train_loader, test_loader, train_eval_loader = get_loaders(</span><br><span class="line">        train_csv_path=config.DATASET + <span class="string">&quot;/train.csv&quot;</span>, test_csv_path=config.DATASET + <span class="string">&quot;/test.csv&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可以加载已训练好的模型</span></span><br><span class="line">    <span class="keyword">if</span> config.LOAD_MODEL:</span><br><span class="line">        load_checkpoint(</span><br><span class="line">            config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    scaled_anchors = (</span><br><span class="line">        torch.tensor(config.ANCHORS)</span><br><span class="line">        * torch.tensor(config.S).unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">    ).to(config.DEVICE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始迭代训练</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config.NUM_EPOCHS):</span><br><span class="line">        <span class="comment">#plot_couple_examples(model, test_loader, 0.6, 0.5, scaled_anchors)</span></span><br><span class="line">        train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#if config.SAVE_MODEL:</span></span><br><span class="line">        <span class="comment">#    save_checkpoint(model, optimizer, filename=f&quot;checkpoint.pth.tar&quot;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#print(f&quot;Currently epoch &#123;epoch&#125;&quot;)</span></span><br><span class="line">        <span class="comment">#print(&quot;On Train Eval loader:&quot;)</span></span><br><span class="line">        <span class="comment">#print(&quot;On Train loader:&quot;)</span></span><br><span class="line">        <span class="comment">#check_class_accuracy(model, train_loader, threshold=config.CONF_THRESHOLD)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch &gt; <span class="number">0</span> <span class="keyword">and</span> epoch % <span class="number">3</span> == <span class="number">0</span>:</span><br><span class="line">            check_class_accuracy(model, test_loader, threshold=config.CONF_THRESHOLD)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 得到预测框和真实的边界框的对比</span></span><br><span class="line">            <span class="comment"># 因为对于一张图像，在三个尺度上会有多个预测框与之吻合挺好，这里使用了NMS非极大值抑制来选择出最好的一个预测框</span></span><br><span class="line">            pred_boxes, true_boxes = get_evaluation_bboxes(</span><br><span class="line">                test_loader,</span><br><span class="line">                model,</span><br><span class="line">                iou_threshold=config.NMS_IOU_THRESH,</span><br><span class="line">                anchors=config.ANCHORS,</span><br><span class="line">                threshold=config.CONF_THRESHOLD,</span><br><span class="line">            )</span><br><span class="line">            <span class="comment"># 计算mAP</span></span><br><span class="line">            mapval = mean_average_precision(</span><br><span class="line">                pred_boxes,</span><br><span class="line">                true_boxes,</span><br><span class="line">                iou_threshold=config.MAP_IOU_THRESH,</span><br><span class="line">                box_format=<span class="string">&quot;midpoint&quot;</span>,</span><br><span class="line">                num_classes=config.NUM_CLASSES,</span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;MAP: <span class="subst">&#123;mapval.item()&#125;</span>&quot;</span>)</span><br><span class="line">            model.train()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">介绍
物体检测的两个步骤可以概括为：
步骤一：检测目标位置（生成矩形框）
步骤二：对目标物体进行分类
物体检测主流的算法框架大致分为one-stage与two-stage。two-stage算法代表有R-CNN系列，one-stage算法代表有Yolo系列。two-stage算法将步骤一与步骤二分开执行，输入图像先经过候选框生成网络（例如faster rcnn中的RPN网络），再经过分类网络；one-stage算法将步骤一与步骤二同时执行，输入图像只经过一个网络，生成的结果中同时包含位置与类别信息。two-stage与one-stage相比，精度高，但是计算量更大，所以运算较慢。

YOLO
</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="YOLO" scheme="http://qixinbo.github.io/tags/YOLO/"/>
    
  </entry>
  
  <entry>
    <title>顶级开源商业智能BI开发软件Superset————开发篇</title>
    <link href="http://qixinbo.github.io/2021/09/06/superset_dev/"/>
    <id>http://qixinbo.github.io/2021/09/06/superset_dev/</id>
    <published>2021-09-05T16:00:00.000Z</published>
    <updated>2021-09-13T07:11:36.495Z</updated>
    
    <content type="html"><![CDATA[<p>%%%%% 2021-9-13 update %%%%%<br>更新了地图部分和行业模板<br>%%%%%%%%%%%%%%%%%%%%%%%%%%%%%=</p><p><a href="https://qixinbo.info/2021/08/28/superset/">上一篇</a>介绍了怎样搭建和运行superset，这一篇着重于怎样对superset进行特殊配置和二次开发。</p><h1 id="更新并重新编译前端代码"><a href="#更新并重新编译前端代码" class="headerlink" title="更新并重新编译前端代码"></a>更新并重新编译前端代码</h1><p>前面已经说到，使用pip安装的是已经编译好的superset，无法修改前端源码，所以这里如果想对前端源码做改动，需要使用docker方式安装。<br>参考资料：<br><a href="https://github.com/apache/superset/blob/master/CONTRIBUTING.md">superset/CONTRIBUTING.md</a></p><h2 id="使用docker安装superset"><a href="#使用docker安装superset" class="headerlink" title="使用docker安装superset"></a>使用docker安装superset</h2><p>这一部分可以参考<a href="https://qixinbo.info/2021/08/28/superset/">入门篇</a>的docker安装部分。<br>但是需要万分注意的是，第一步拉取的docker镜像需要是dev分支，比如latest-dev，而不能是不带dev的分支，这里具体原理不清楚，但是我尝试时选择不带dev的分支，编译好多次都编译不成功。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull apache/superset:latest-dev</span><br></pre></td></tr></table></figure></p><h2 id="安装nodejs和npm"><a href="#安装nodejs和npm" class="headerlink" title="安装nodejs和npm"></a>安装nodejs和npm</h2><p>有两种方式，一种是使用nvm来管理：<br>（这个地方遇到一个坑，第一次使用了root账户安装了nvm，结果后面在使用npm时报“拒绝权限”错误，换用普通用户安装nvm后解决了）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0<span class="number">.37</span><span class="number">.0</span>/install.sh | bash</span><br><span class="line">cd superset-frontend</span><br><span class="line">nvm install --lts</span><br><span class="line">nvm use --lts</span><br><span class="line"></span><br><span class="line">npm install -g npm@<span class="number">7</span></span><br></pre></td></tr></table></figure><br>另一种是手动安装nodejs和npm：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wget https://nodejs.org/dist/v10<span class="number">.9</span><span class="number">.0</span>/node-v10<span class="number">.9</span><span class="number">.0</span>-linux-x64.tar.xz    // 下载，如果下载慢，就去nodejs.cn上找国内链接</span><br><span class="line">tar xf  node-v10<span class="number">.9</span><span class="number">.0</span>-linux-x64.tar.xz       // 解压</span><br><span class="line">cd node-v10<span class="number">.9</span><span class="number">.0</span>-linux-x64/                  // 进入解压目录</span><br><span class="line">./<span class="built_in">bin</span>/node -v                               // 执行node命令 查看版本</span><br><span class="line"></span><br><span class="line"><span class="comment">## 解压文件的 bin 目录底下包含了 node、npm 等命令，我们可以使用 ln 命令来设置软连接：</span></span><br><span class="line">ln -s /usr/software/nodejs/<span class="built_in">bin</span>/npm   /usr/local/<span class="built_in">bin</span>/ </span><br><span class="line">ln -s /usr/software/nodejs/<span class="built_in">bin</span>/node   /usr/local/<span class="built_in">bin</span>/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置npm镜像为国内的淘宝源</span></span><br><span class="line"><span class="comment"># 不过有时会显示该源里没有一些库，此时可以再切回官方源</span></span><br><span class="line"><span class="comment"># npm config set registry https://registry.npmjs.org/</span></span><br><span class="line">npm config <span class="built_in">set</span> registry http://registry.npm.taobao.org</span><br></pre></td></tr></table></figure></p><h2 id="安装相关依赖"><a href="#安装相关依赖" class="headerlink" title="安装相关依赖"></a>安装相关依赖</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确保安装的时npm 7</span></span><br><span class="line">npm install -g npm@<span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入前端文件夹</span></span><br><span class="line">cd superset-frontend</span><br><span class="line"><span class="comment"># 从package-lock.json安装依赖</span></span><br><span class="line">npm ci</span><br></pre></td></tr></table></figure><h2 id="编译资源文件"><a href="#编译资源文件" class="headerlink" title="编译资源文件"></a>编译资源文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm run build</span><br></pre></td></tr></table></figure><p>编译时遇到了如下问题：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: EPIPE: broken pipe</span><br></pre></td></tr></table></figure><br>多试几次。</p><h2 id="需要注意的问题"><a href="#需要注意的问题" class="headerlink" title="需要注意的问题"></a>需要注意的问题</h2><p>（1）再强调一遍，拉取docker镜像时选择dev分支。<br>（2）superset有很多种编译的方式，上面用到的是编译成生产环境所需的资源，还有其他，比如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">npm run build: the production assets, CSS/JSS minified <span class="keyword">and</span> optimized</span><br><span class="line">npm run dev-server: local development assets, <span class="keyword">with</span> sourcemaps <span class="keyword">and</span> hot refresh support</span><br><span class="line">npm run build-instrumented: instrumented application code <span class="keyword">for</span> collecting code coverage <span class="keyword">from</span> Cypress tests</span><br><span class="line">npm run build-dev: build assets <span class="keyword">in</span> development mode.</span><br><span class="line">npm run dev: built dev assets <span class="keyword">in</span> watch mode, will automatically rebuild when a file changes</span><br></pre></td></tr></table></figure><br>然而只尝试成功了第一个。。<br>（3）编译完后，要注意重启docker容器、强制刷新（不适用缓存）页面来使得修改生效。</p><h1 id="开启Prophet时间序列预测算法"><a href="#开启Prophet时间序列预测算法" class="headerlink" title="开启Prophet时间序列预测算法"></a>开启Prophet时间序列预测算法</h1><p><a href="https://www.modb.pro/db/50442">Facebook 在2017年开源了一个叫fbprophet的时间序列预测的算法该算法支持自定义季节和节假日，解决了像春节、618和双十一这种周期性节假日的指标预测难题</a>。prophet不仅可以处理时间序列存在一些异常值的情况，也可以处理部分缺失值的情形，还能够几乎全自动地预测时间序列未来的走势。而且Prophet包提供了直观易调的参数，即使是对缺乏模型知识的人来说，也可以据此对各种商业问题做出有意义的预测。<br>新版Superset（比如1.3版本）中对Time series这类图表（包括Line Chart、Area Chart、Bar Chart、Scatter plot）已经支持了prophet的调用，但是默认prophet包是不自动安装的，所以需要另外将prophet安装一下即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install pystan==<span class="number">2.19</span><span class="number">.1</span><span class="number">.1</span></span><br><span class="line">pip install prophet</span><br></pre></td></tr></table></figure><br>然后在上面这些图表的explore中的Predictive Analytics进行开启。</p><h1 id="配置PostgreSQL远程访问"><a href="#配置PostgreSQL远程访问" class="headerlink" title="配置PostgreSQL远程访问"></a>配置PostgreSQL远程访问</h1><p>（1）修改postgresql.conf<br>确保数据库可以接受来自任意IP的连接：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listen_addresses = <span class="string">&#x27;*&#x27;</span></span><br></pre></td></tr></table></figure><br>（2）修改pg_hba.conf<br>默认pg只允许本机通过密码认证登录，修改为以下内容后即可以对任意IP访问进行密码验证：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">host  <span class="built_in">all</span>  <span class="built_in">all</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span> md5</span><br></pre></td></tr></table></figure><br>（3）配置防火墙端口<br>在防火墙的入站规则里添加一条规则，使外部能够访问数据库端口。<br>（如果通过路由器的话，还要在路由器中设置一下端口规则）<br>（4）重启PostgreSQL服务<br>在windows的services中重启服务。</p><h1 id="权限控制"><a href="#权限控制" class="headerlink" title="权限控制"></a>权限控制</h1><p>Superset初始化权限之后，会创建5个角色，分别为Admin、Alpha、Gamma、sql_lab以及Public（现在又新增了一个granter角色）。Admin，Alpha和Gamma角色，分配了很多的菜单/视图权限，如果手工去修改，改错的可能性很大，加之Superset并没有说明每一项权限的完整文档，所以不建议去修改这些角色的定义。灵活使用预置的角色，可以快速满足业务上安全控制需求。<br>角色权限介绍：<br>（1）Admin：拥有所有权限，包括授予或取消其他用户的权限，以及更改其他用户的切片和仪表板。<br>（2）Alpha：能访问所有数据源，增加或者更改数据源，但不能更改其他用户权限。<br>（3）Gamma：只能使用来自数据源的数据，这些数据源是通过另一个补充角色授予他们访问权限的。只能查看由他们有权访问的数据源生成的切片和仪表板，无法更改或添加数据源。还要注意，当Gamma用户查看仪表板和切片列表视图时，他们将只看到他们有权访问的对象。<br>（4）sql_lab：能访问SQL Lab菜单。请注意，虽然默认情况下管理员用户可以访问所有数据库，但Alpha和Gamma用户都需要根据每个数据库授予访问权限。<br>（5）Public：默认没有任何权限。允许已注销的用户访问某些Superset功能是可能的。</p><h2 id="公开看板"><a href="#公开看板" class="headerlink" title="公开看板"></a>公开看板</h2><p>目前分享看板时都是需要登录某个用户，而对权限控制进行更改后就能使得匿名用户或未登录用户也能正常查看看板。<br>首先在superset的配置文件config.py中更改Public角色的权限：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUBLIC_ROLE_LIKE = <span class="string">&quot;Gamma&quot;</span></span><br></pre></td></tr></table></figure><br>即向Public角色授予与Gamma角色相同的权限。<br>然后：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">superset init</span><br></pre></td></tr></table></figure><br>重新初始化角色和权限，使上述更改生效。<br>此时在后台可以看到public角色拥有了与Gamma相同的权限集。<br>然后对public权限手动新增如下权限：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">all</span> datasource access on all_datasource_access</span><br></pre></td></tr></table></figure><br>才能正常公开查看看板。</p><p>参考文献：<br><a href="https://superset.apache.org/docs/security">Security</a><br><a href="https://cloud.tencent.com/developer/article/1031496">Superset权限使用场景</a></p><h1 id="多个数据源"><a href="#多个数据源" class="headerlink" title="多个数据源"></a>多个数据源</h1><h2 id="在多个数据源中查询"><a href="#在多个数据源中查询" class="headerlink" title="在多个数据源中查询"></a>在多个数据源中查询</h2><p>默认superset只能在一张表中进行数据可视化。<br>可以通过superset的SQL Lab工具箱进行连接查询（JOIN关键字）、合并查询（UNION关键字）和多表查询（注意这种多表查询又称笛卡尔查询，使用时要非常小心，因为结果集是目标表的行数乘积）等。（但是仍然需要所有的tables都在同一个数据库的同一个schema中）<br>然后将查询到的结果explore存储为虚拟virtual数据集。该数据集能和physical的数据集一样地进行explore。<br>这个地方需要注意的是需要对database进行额外设置，编辑database，然后勾选“Allow DML”。<br>（在SQL Lab调试时注意查看报错信息）</p><p>可参考preset上的教程：<br><a href="https://docs.preset.io/docs/sql-editor">https://docs.preset.io/docs/sql-editor</a><br><a href="https://docs.preset.io/docs/table-joins">https://docs.preset.io/docs/table-joins</a></p><h2 id="合并图表"><a href="#合并图表" class="headerlink" title="合并图表"></a>合并图表</h2><p>如果想在一张图表内制作多张图表，比如将拥有相同x坐标轴的折线图和柱状图放在一块，可以使用Mixed Time-Series。</p><h1 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h1><p>可以通过添加过滤器Filter Box对数据进行筛选，比如对特定时间、特定数值、特定字段等。<br>方式就是从图表中选择Filter Box，并对其进行配置即可。<br>配置时，会对过滤器指定具体的Column。默认情况下，过滤器会作用在有该Column的所有数据源上（即使是来自于多种数据库、多张数据表，只要该Column相同就可被过滤。当然某个数据集的该Column需要设定为filterable）。<br>默认情况下过滤器也会作用在dashboard中的所有图表上，可以配置哪些图表使用这些过滤器，有两种方式设置：<br>一种是图形化设置，在Edit Dashboard的Set Filter Mapping中就可以对具体哪个过滤器作用在哪个图表上进行配置，推荐这种方式，简单方便；<br>另一种是通过参数设置，在dashboard的JSON元数据配置中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;filter_immune_slices&quot;</span>: [<span class="number">324</span>, <span class="number">65</span>, <span class="number">92</span>],</span><br><span class="line">    <span class="string">&quot;filter_immune_slice_fields&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;177&quot;</span>: [<span class="string">&quot;country_name&quot;</span>, <span class="string">&quot;__time_range&quot;</span>],</span><br><span class="line">        <span class="string">&quot;32&quot;</span>: [<span class="string">&quot;__time_range&quot;</span>]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;timed_refresh_immune_slices&quot;</span>: [<span class="number">324</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>那些数字就是图表在该看板中的slice id，这些id可以通过Export Dashboard（回到总的dashboards页面）形成的json文件中查看。</p><h1 id="实时数据更新"><a href="#实时数据更新" class="headerlink" title="实时数据更新"></a>实时数据更新</h1><p>Superset可以设置以多长时间刷新看板，在”Set Auto Refresh Interval”中，默认有10s、30s、1min等，此处最小间隔为10s，最大间隔为24hours。<br>虽然从该入口处可选择的时间间隔种类有限，但可以在此处随意选择一个间隔，然后再在该看板的JSON元数据中进行更加细致的设置：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;timed_refresh_immune_slices&quot;</span>: [<span class="number">86</span>, <span class="number">89</span>, <span class="number">165</span>, <span class="number">166</span>, <span class="number">172</span>, <span class="number">191</span>],</span><br><span class="line">  <span class="string">&quot;refresh_frequency&quot;</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>比如上面将刷新频率设置为1s，同时设置哪些slices可以不刷新（默认是所有图表都刷新）。<br>但是需要注意的是，目前版本的superset（1.3.0）中每刷新一次，都会在界面上显示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">This dashboard <span class="keyword">is</span> currently force refreshing ....</span><br></pre></td></tr></table></figure><br>这样的弹窗，非常影响观感。<br>目前github上也有一个issue提到了该问题，开发人员正在修改该部分的设计：<br><a href="https://github.com/apache/superset/issues/13242">Make possible to disable the annoying “This dashboard is currently force refreshing” message #13242</a><br>如果等不到新的版本，可以手动修改如下地方的源码：<br><a href="https://github.com/apache/superset/blob/master/superset-frontend/src/dashboard/components/Header/index.jsx">superset/superset-frontend/src/dashboard/components/Header/index.jsx</a></p><p>以下是Youtube上一个演讲，使用Kafaka消息队列+Druid数据存储+Superset可视化的方案：<br><a href="https://www.youtube.com/watch?v=HOk7WtxBMzM">Interactive real-time dashboards on data streams using Kafka, Druid, and Superset</a></p><h1 id="查看stl模型文件"><a href="#查看stl模型文件" class="headerlink" title="查看stl模型文件"></a>查看stl模型文件</h1><p>stl文件是一种常用的描述三维物体的文件格式。superset没法直接展示这种文件格式，不过这里可以采用iframe的方式嵌入外部的stl阅读器来实现。<br>找了一圈后，发现viewstl这个网站提供优雅的渲染stl文件的功能，同时能免费嵌入其他网页中。网址见：<br><a href="https://www.viewstl.com/">View 3D STL files directly in your browser - no software installation is required</a><br>具体的嵌入功能见：<br><a href="https://www.viewstl.com/embed/">https://www.viewstl.com/embed/</a><br>进行一番配置后，复制其产生的代码即可，比如：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;iframe id=&quot;vs_iframe&quot; src=&quot;https://www.viewstl.com/?embedded&quot; style=&quot;border:0;margin:0;width:100%;height:100%;&quot;&gt;&lt;/iframe&gt;</span><br></pre></td></tr></table></figure><br>其中的stl文件可以由本地手动选择、本地服务托管、外部文件加载等多种方式。<br>本地服务托管就是本地建一个服务器放置stl文件，然后把内网地址作为参数传入即可，这样可以解决有时文件不能传到外网上这种问题。<br>外部文件加载需要提供文件URL地址，测试了几个网盘，比如google drive、百度网盘等，都有这样那样的问题无法解析，这里推荐使用阿里云的OSS存储服务。</p><h1 id="地图"><a href="#地图" class="headerlink" title="地图"></a>地图</h1><h2 id="deck-gl"><a href="#deck-gl" class="headerlink" title="deck.gl"></a>deck.gl</h2><p>deck.gl是由uber开发并开源出来的基于WebGL的大数据可视化框架。它具有提供不同类型可视化图层、GPU渲染的高性能，集成Mapbox展示地理信息数据（GIS）等特点。</p><h2 id="Mapbox"><a href="#Mapbox" class="headerlink" title="Mapbox"></a>Mapbox</h2><p>Mapbox是一个开源的地图制作系统，superset也与其进行了良好的集成，只需一个token，就可在superset中进行地图相关的操作。<br>获取token只需在Mapbox官网上注册一个账号，然后在superset的配置文件中设置环境变量即可（或者自己export或set该环境变量）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAPBOX_API_KEY = <span class="string">&quot;your token&quot;</span></span><br></pre></td></tr></table></figure></p><h2 id="GeoJson"><a href="#GeoJson" class="headerlink" title="GeoJson"></a>GeoJson</h2><p>deck.gl中的polygon图形需要使用某个区域的经纬度信息，它接收的可以是JSON格式的多边形数据，这种数据就是GeoJson数据。<br>获取GeoJson数据，可以使用在线的地图编辑器来获取，比如：<br><a href="http://geojson.io">http://geojson.io</a></p><p>关于GeoJson，其他有用的一些资源如下：<br><a href="https://echarts-maps.github.io/echarts-geomapping-book-zh/">地图工匠秘籍，其中的实战部分非常有用</a><br><a href="https://github.com/echarts-maps/echarts-geomapping-book-zh">上面这个网站的github</a><br><a href="https://github.com/echarts-maps">echarts-maps，上面这个网站的资源所在</a><br><a href="https://asmcn.icopy.site/awesome/awesome-geojson/">awesome geojson</a><br><a href="https://datav.aliyun.com/tools/atlas/index.html">高德的地图选择器，可以到区县级别</a></p><h2 id="内置地图"><a href="#内置地图" class="headerlink" title="内置地图"></a>内置地图</h2><p>superset也内置了两种地图：<br>（1）World Map：可以显示各个国家相关数据，国家代码可以有四种形式，比如Full name、code International Olympics Committee、code ISO 3166-1 alpha-2和code ISO 3166-1 alpha-3；<br>（2）Country Map：可以显示某个具体国家的省市的相关数据，具体省市的代码需要遵循ISO 3166-2标准。</p><h1 id="CSS模板"><a href="#CSS模板" class="headerlink" title="CSS模板"></a>CSS模板</h1><p>superset可以通过CSS方便地改变整个dashboard的样式。<br>CSS的语法可以通过如下教程快速上手：<br><a href="https://www.runoob.com/css/css-tutorial.html">菜鸟CSS教程</a><br>具体改变哪个元素或哪个类的样式，可以通过浏览器的Inspect检查功能，定位到想改变的元素上，然后通过临时修改其css查看效果，再在superset中添加css模板配置。</p><h1 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h1><p>Markdown组件可以允许添加Markdown语法的资源，以及html格式的资源。<br>比如可以加入图片、超链接、文本等。</p><h1 id="最大化看板"><a href="#最大化看板" class="headerlink" title="最大化看板"></a>最大化看板</h1><p>可以通过”Enter Fullscreen”来使看板最大化，但这种方式仍然会存在看板的标题栏。<br>通过在看板链接中配置standalone这个参数等于2，则可以将标题栏也给去掉，即：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;localhost:5000&#x2F;superset&#x2F;dashboard&#x2F;al-lca&#x2F;?standalone&#x3D;2</span><br></pre></td></tr></table></figure></p><h1 id="行业模板"><a href="#行业模板" class="headerlink" title="行业模板"></a>行业模板</h1><p>做看板是一门艺术，怎样提供数据洞察的同时又能做得好看，就是一门手艺活。<br>可以通过观摩和学习其他人的作品来提高自己的制作水平。<br>BAT三家互联网大厂都提供了自己的数据可视化低代码制作服务，里面也有很多的行业模板可供参考，是一个不错的学习地方：<br><a href="https://cn.aliyun.com/product/bigdata/datav">阿里云——DataV数据可视化</a><br><a href="https://cloud.baidu.com/product/sugar.html">百度云——数据可视化Sugar</a><br><a href="https://cloud.tencent.com/product/tcv">腾讯云——腾讯云图</a></p>]]></content>
    
    
    <summary type="html">%%%%% 2021-9-13 update %%%%%
更新了地图部分和行业模板
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%=

上一篇介绍了怎样搭建和运行superset，这一篇着重于怎样对superset进行特殊配置和二次开发。

更新并重新编译前端代码
前面已经说到，使用pip安装的是已经编译好的superset，无法修改前端源码，所以这里如果想对前端源码做改动，需要使用docker方式安装。
参考资料：
superset/CONTRIBUTING.md

使用docker安装superset
这一部分可以参考入门篇的docker安装部分。
但是需要万分注意的是，第一步</summary>
    
    
    
    <category term="digitalization" scheme="http://qixinbo.github.io/categories/digitalization/"/>
    
    
    <category term="Visualization" scheme="http://qixinbo.github.io/tags/Visualization/"/>
    
  </entry>
  
  <entry>
    <title>顶级开源商业智能BI开发软件Superset————入门篇</title>
    <link href="http://qixinbo.github.io/2021/08/28/superset/"/>
    <id>http://qixinbo.github.io/2021/08/28/superset/</id>
    <published>2021-08-27T16:00:00.000Z</published>
    <updated>2021-09-02T07:47:35.160Z</updated>
    
    <content type="html"><![CDATA[<p>%%%%%2021-9-2更新%%%%%%<br>更新使用docker安装连接宿主机的数据库</p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Apache Superset是一个现代的、企业级的商业智能（Business Intelligence）网络应用程序，它使得用户可以使用无代码可视化构建器和SQL编辑器来轻松探索和可视化自己的数据。<br>其最初由Airbnb开源，后来由Apache进行孵化，并且于今年（2021年）1 月 21 日宣布毕业并成为 Apache 软件基金会（ASF）的顶级项目（Top-Level Project），截止到现在（2021年8月25日）已经在GitHub上收获了超过4万颗star。<br>官网地址在<a href="https://superset.apache.org/">这里</a>。<br>示例看板在<a href="https://superset.apache.org/gallery">这里</a>。<br>有一句评价非常中肯：<a href="https://xie.infoq.cn/article/ff7e60ae303e0de531f0b4bf5">对开发人员最大的吸引力在于：支持的数据源足够多，界面足够花里胡哨！</a>。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>有多种方式安装superset，比如使用docker、使用pip安装等方式。<br>使用docker安装是最简单的一种方式，因为它已经将相关依赖都做成了一个镜像，同时其包含了github上的源码，有最大的自由度可供开发。<br>使用pip安装也较为方便，但是pip包本质上是一个已经编译好的包，没法修改源码，尤其是没法修改前端ui相关的代码。<br>下面介绍两种安装方式。</p><h2 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h2><h3 id="安装docker软件"><a href="#安装docker软件" class="headerlink" title="安装docker软件"></a>安装docker软件</h3><p>可以参考此处的<a href="https://www.runoob.com/docker/windows-docker-install.html">教程</a>。</p><h3 id="拉取superset镜像"><a href="#拉取superset镜像" class="headerlink" title="拉取superset镜像"></a>拉取superset镜像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull apache/superset</span><br></pre></td></tr></table></figure><h3 id="使用镜像"><a href="#使用镜像" class="headerlink" title="使用镜像"></a>使用镜像</h3><p>（1）开启一个superset实例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p <span class="number">8080</span>:<span class="number">8088</span> --name superset apache/superset</span><br></pre></td></tr></table></figure><br>（2）初始化实例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置管理员账号</span></span><br><span class="line">docker <span class="built_in">exec</span> -it superset superset fab create-admin \</span><br><span class="line">               --username admin \</span><br><span class="line">               --firstname Superset \</span><br><span class="line">               --lastname Admin \</span><br><span class="line">               --email admin@superset.com \</span><br><span class="line">               --password admin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迁移数据库</span></span><br><span class="line">docker <span class="built_in">exec</span> -it superset superset db upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载实例</span></span><br><span class="line">docker <span class="built_in">exec</span> -it superset superset load_examples</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">docker <span class="built_in">exec</span> -it superset superset init</span><br></pre></td></tr></table></figure><br>（3）登录：<br>在浏览器中的地址为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:<span class="number">8080</span>/login/ </span><br></pre></td></tr></table></figure></p><h3 id="连接宿主机的数据库"><a href="#连接宿主机的数据库" class="headerlink" title="连接宿主机的数据库"></a>连接宿主机的数据库</h3><p>（具体怎样连接数据库是在下面一节，但是因为docker安装方式会有一点不同，这里先说明一下，后面具体连接时注意这点即可）<br>如果数据库也是安装在同一个docker容器中，就没有如下特殊操作；<br>而如果数据库是在本地宿主机中，而superset安装在docker容器中，这样直接使用localhost是不能连接到宿主机的。还需要进行如下配置才可以。<br>（1）设置宿主机的数据库可外部访问<br>（1.1）修改postgresql.conf<br>确保数据库可以接受来自任意IP的连接：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listen_addresses = <span class="string">&#x27;*&#x27;</span></span><br></pre></td></tr></table></figure><br>（1.2）修改pg_hba.conf<br>默认pg只允许本机通过密码认证登录，修改为以下内容后即可以对任意IP访问进行密码验证：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">host  <span class="built_in">all</span>  <span class="built_in">all</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span> md5</span><br></pre></td></tr></table></figure><br>（1.3）重启PostgreSQL服务<br>在windows的services中重启服务。</p><p>（2）连接数据库时主机名更改<br>如上所述，连接数据库时主机名不能使用localhost，而需要使用特定名称。<br>对于Mac和Windows系统，docker有一个自动的解析，使用：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">host.docker.internal</span><br></pre></td></tr></table></figure><br>作为主机名即可。<br>对于Linux，可以先尝试：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">172.18</span><span class="number">.0</span><span class="number">.1</span></span><br></pre></td></tr></table></figure><br>作为主机名。如果这个不行，可以用以下命令：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect &lt;container-<span class="built_in">id</span>-<span class="keyword">or</span>-name&gt; | grep Gateway</span><br></pre></td></tr></table></figure><br>查看一下docker容器指向的宿主机的ip地址。</p><h2 id="pip安装"><a href="#pip安装" class="headerlink" title="pip安装"></a>pip安装</h2><h3 id="创建虚拟环境"><a href="#创建虚拟环境" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h3><p>使用virtualenv或Conda。<br>使用虚拟环境主要是为了安装环境的独立性，防止里面的库的版本混乱。这一步不详述了。</p><h3 id="安装必要的包"><a href="#安装必要的包" class="headerlink" title="安装必要的包"></a>安装必要的包</h3><p>大部分的包都能自动下载，但是下面这两个有可能会在自动安装时出现错误，导致整个安装出错（我在windows平台上安装时遇到了这两个问题）。<br>建议是自动安装，如果出错，再手动安装一下看看是不是这两个出现的问题。<br>（1）安装Sasl:<br>下载Sasl的wheel文件:<br><a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#sasl">https://www.lfd.uci.edu/~gohlke/pythonlibs/#sasl</a><br>然后：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install</span><br></pre></td></tr></table></figure><br>（2）安装python-geohash package:<br>下载wheel包，然后pip install。<br><a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-geohash">https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-geohash</a></p><h3 id="安装Superset"><a href="#安装Superset" class="headerlink" title="安装Superset"></a>安装Superset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最好确保一下superset是最新版</span></span><br><span class="line"><span class="comment"># 第一次安装时1.1.0版本有个注释层的bug</span></span><br><span class="line"><span class="comment"># 更新到1.3.0版本后就好了</span></span><br><span class="line">pip install apache-superset</span><br></pre></td></tr></table></figure><h3 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">superset db upgrade</span><br></pre></td></tr></table></figure><h3 id="配置superset"><a href="#配置superset" class="headerlink" title="配置superset"></a>配置superset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将Flask默认的app设置为superset，这样flask就能找到它</span></span><br><span class="line">export FLASK_APP=superset <span class="comment"># 在windows上就是set命令</span></span><br><span class="line"><span class="comment"># 创建管理员账户</span></span><br><span class="line">superset fab create-admin</span><br><span class="line"><span class="comment"># 加载一些示例看板</span></span><br><span class="line">superset load_examples</span><br><span class="line"><span class="comment"># 初始化superset</span></span><br><span class="line">superset init</span><br></pre></td></tr></table></figure><h3 id="启动superset"><a href="#启动superset" class="headerlink" title="启动superset"></a>启动superset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">superset run -p <span class="number">8088</span> --<span class="keyword">with</span>-threads --reload --debugger</span><br></pre></td></tr></table></figure><h1 id="连接数据库"><a href="#连接数据库" class="headerlink" title="连接数据库"></a>连接数据库</h1><p>Superset本身不提供数据库，其需要连接已有的数据库来作为数据存储的容器。<br>Superset支持各种数据库，包括MySQL，Presto，Hive，Postgres，Dremio，Snowflake，Teradata和其他数PB级的。由于Superset后端是用Python编写的，因此本质上是Python后端的Flask应用程序……在Python中，所有数据库都有很多驱动程序支持。<br>这里我们选用PostgreSQL数据库作为后端。</p><h2 id="安装PostgreSQL"><a href="#安装PostgreSQL" class="headerlink" title="安装PostgreSQL"></a>安装PostgreSQL</h2><p>可以通过下面的链接进行下载安装：<br><a href="https://www.enterprisedb.com/downloads/postgres-postgresql-downloads">PostgreSQL Database Download</a><br>里面自带了pgAdmin图形管理工具来操作PostgreSQL数据库。</p><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><p>安装好pgAdmin后，再通过它来手动创建一个自己的数据库，用于后续存储数据。<br>具体可以参考如下教程：<br><a href="https://www.runoob.com/postgresql/postgresql-create-database.html">PostgreSQL 创建数据库</a><br>特别注意的是该数据库的用户名username、密码password、主机地址host（本机就是localhost）、端口号port（默认是5432）和名称database。</p><p>初次创建后该数据库就直接跑起来后，但后面电脑关机后，有可能出现明明信息都正确，但是启动不起来的问题，比如出现下面这个问题：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Is the server running on host &quot;localhost&quot; (::1) and accepting TCP/IP connections on port 5432?</span><br></pre></td></tr></table></figure><br>这是因为后台的数据库服务没有启动。解决方法是在windows的Services中找到postgresql-x64-13这个服务，然后启动它。</p><h2 id="安装数据库驱动"><a href="#安装数据库驱动" class="headerlink" title="安装数据库驱动"></a>安装数据库驱动</h2><p>首先需要安装一个额外的库：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install psycopg2</span><br></pre></td></tr></table></figure></p><h2 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h2><p>在上面的启动的superset的web页面中，选择添加一个数据库，然后根据PostgreSQL的连接语法与前面创建的数据库进行连接，语法格式为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">postgresql://&#123;username&#125;:&#123;password&#125;@&#123;host&#125;:&#123;port&#125;/&#123;database&#125;</span><br></pre></td></tr></table></figure><br>然后点击“测试连接”，连接成功后即表明可以正确添加该数据库。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>有了底层数据库，还需要提取里面的数据。<br>对于本来就存在数据的数据库，可以在superset的“数据集”中进行添加选择，按照提示进行相关操作就行。<br>对于初次创建的数据库，里面是空的，没有任何的数据。此时可以通过上传csv文件进行添加，这样既在superset中添加了数据集，也在底层PostgreSQL数据库中添加了数据。<br>开启上传csv功能需要首先在数据库中进行设置，在superset的某个数据库的Extra/扩展选项卡中勾选“Allow Data Upload”/“允许数据上传”。<br>然后再在“数据”菜单中选择“上传CSV文件”。</p><p>额外福利：如果手头没有可玩的数据，可以通过下面三个链接获取一些示例数据（第三个时superset教程中的示例数据）：<br><a href="https://github.com/plotly/datasets">https://github.com/plotly/datasets</a><br><a href="https://github.com/fivethirtyeight/data">https://github.com/fivethirtyeight/data</a><br><a href="https://github.com/apache-superset/examples-data">https://github.com/apache-superset/examples-data</a></p><p>导入数据集后，可以对数据集的属性进行配置，比如哪一列是时间条件、是否可被过滤等。<br>需要注意的是superset对数据集加了一个语义层semantic layer，它存储了两种类型的计算数据：<br>（1）虚拟指标：对应Metrics这一标签页，可以编写不同列之间的聚合SQL查询，然后使得结果作为“列”来使用。这里可以使用并且鼓励使用SQL的聚合函数，如COUNT、SUM等；<br>（2）虚拟计算列：对应Calculated Columns这一标签页，可以对某一特定的列编写SQL语句来定制它的行为。在这里不能使用SQL的聚合函数。 </p><h1 id="可视化数据"><a href="#可视化数据" class="headerlink" title="可视化数据"></a>可视化数据</h1><p>Superset有两种探索数据的方式：<br>（1）Explore：零代码可视化编辑器，只需选择数据集，选定相应图表，配置一些外观属性，然后就可以创建可视化图表；只需点击相应的数据集，就可以进入Explore模式；Save Chart时可以选择添加到新看板或者某一个已存在的看板。<br>（2）SQL Lab：SQL工具箱，可以提供强大的SQL语言编辑功能，用于清洗、联合和准备数据，可以用于下一步的Explore流程。</p><p>superset的官方教程中给出了一个详细地Explore模式的使用教程，其使用的示例数据来自以下链接：<br><a href="https://github.com/apache-superset/examples-data/blob/master/tutorial_flights.csv">flights</a><br>强烈建议根据官方教程一步步走一遍，教程在<a href="https://superset.apache.org/docs/creating-charts-dashboards/exploring-data">这里</a>。<br>这里列举一下自己跑教程时踩的一些坑：<br>（1）上传CSV文件时，一定要在“Parse Dates”解析日期那里手动填上“Travel Date”，否则如果不明确指定时间的话，在数据库里存的该项的数据类型是Text，无法进行后面的时间序列的计算。<br>（2）在添加“指标Metrics”时，保存的指标指的是“编辑数据集”时的“指标Metrics”那个选项卡的指标。<br>（3）配置“分组Group by”时，选择“Time”这一项，就会自动使用之前在Time那块定义的时间列、时间粒度等。<br>（4）添加“注释层annotation layer”那一块时，注意使用最新版的superset，已测试1.1版本会有bug，1.3版本已经修复该bug，见该<a href="https://github.com/apache/superset/pull/13969">PR</a>。<br>（5）在Advanced Analystics一项中，有对时间序列数据的更强大的操作，比如求平均、时间平移、使用python函数重新采样等操作。</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>superset开发团队基于开源的superset推出了SaaS云服务Preset，可以使得用户在无需安装任何软件的情况下直接使用superset。<br>Preset除了提供开箱即用的superset，其官网上的教程也比superset官网上的要详细很多，所以可以参考preset的文档来学习superset，如下：<br><a href="https://docs.preset.io/">https://docs.preset.io/</a></p>]]></content>
    
    
    <summary type="html">%%%%%2021-9-2更新%%%%%%
更新使用docker安装连接宿主机的数据库

介绍
Apache Superset是一个现代的、企业级的商业智能（Business Intelligence）网络应用程序，它使得用户可以使用无代码可视化构建器和SQL编辑器来轻松探索和可视化自己的数据。
其最初由Airbnb开源，后来由Apache进行孵化，并且于今年（2021年）1 月 21 日宣布毕业并成为 Apache 软件基金会（ASF）的顶级项目（Top-Level Project），截止到现在（2021年8月25日）已经在GitHub上收获了超过4万颗star。
官网地址在这里。
示例看板</summary>
    
    
    
    <category term="digitalization" scheme="http://qixinbo.github.io/categories/digitalization/"/>
    
    
    <category term="Visualization" scheme="http://qixinbo.github.io/tags/Visualization/"/>
    
  </entry>
  
  <entry>
    <title>一键深度学习：将常用深度学习算法集成在ImagePy软件</title>
    <link href="http://qixinbo.github.io/2021/08/16/onebuttondl/"/>
    <id>http://qixinbo.github.io/2021/08/16/onebuttondl/</id>
    <published>2021-08-15T16:00:00.000Z</published>
    <updated>2021-08-16T07:45:35.143Z</updated>
    
    <content type="html"><![CDATA[<h1 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h1><p>日常工作中，调用深度学习算法通常需要在命令行中进行，该过程通常涉及复杂的流程，比如修改配置文件、指定文件路径、打开命令行调用算法运行。此时如果能有一个图形界面软件实现“一键调用”，就会极大地节省工作量，提高工作效率，避免来来回回地反复修改文件、执行命令等。</p><p>最近新写了一个库，就是把常用的深度学习算法都集成在了ImagePy中，这样用户和开发者就能直接在ImagePy中愉快地“玩”算法了。</p><h1 id="OneButtonDeepLearning"><a href="#OneButtonDeepLearning" class="headerlink" title="OneButtonDeepLearning"></a>OneButtonDeepLearning</h1><p>该仓库在<a href="https://github.com/qixinbo/OneButtonDeepLearning">这里https://github.com/qixinbo/OneButtonDeepLearning</a>。<br>宗旨就是：让深度学习算法触手可及、一键调用，不必每次在命令行进行复杂配置。</p><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>只需将要使用的模型文件夹复制到<code>imagepy/plugins</code>文件夹下，再次启动ImagePy后即可在菜单栏看到该算法。</p><h2 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h2><p>如果运行深度学习算法的环境没有事先搭建好，那么在模型的<code>menus</code> 下都有一个配置文件，直接运行:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><br>即可下载相应的依赖包。</p><h1 id="当前模型"><a href="#当前模型" class="headerlink" title="当前模型"></a>当前模型</h1><h2 id="光学字符识别OCR"><a href="#光学字符识别OCR" class="headerlink" title="光学字符识别OCR"></a>光学字符识别OCR</h2><p><a href="https://github.com/PaddlePaddle/PaddleOCR">PaddleOCR</a> aims to create multilingual, awesome, leading, and practical OCR tools that help users train better models and apply them into practice.</p><p><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/OCR/menus/OCR/demo.png" alt="ocr-demo"></p><h2 id="目标检测YOLOv5"><a href="#目标检测YOLOv5" class="headerlink" title="目标检测YOLOv5"></a>目标检测YOLOv5</h2><p><a href="https://github.com/ultralytics/yolov5">YOLOv5</a> is a family of compound-scaled object detection models trained on the COCO dataset.</p><p><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/YOLOv5/menus/YOLOv5/demo.png" alt="yolov5-demo"></p><h2 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h2><p><a href="https://github.com/deepinsight/insightface">InsightFace</a> is an open source 2D&amp;3D deep face analysis toolbox, and efficiently implements a rich variety of state of the art algorithms of face recognition, face detection and face alignment, which optimized for both training and deployment.</p><p><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/FaceAnalysis/menus/Face/demo.png" alt="face-demo"></p><h2 id="胞状物体分割Cellpose"><a href="#胞状物体分割Cellpose" class="headerlink" title="胞状物体分割Cellpose"></a>胞状物体分割Cellpose</h2><p><a href="https://github.com/MouseLand/cellpose">Cellpose</a> is a generalist algorithm for cell and nucleus segmentation.</p><p><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/Cellpose/menus/Cellpose/demo.png" alt="cellpose-demo"></p><h2 id="胞状物体分割BulkSeg"><a href="#胞状物体分割BulkSeg" class="headerlink" title="胞状物体分割BulkSeg"></a>胞状物体分割BulkSeg</h2><p><a href="https://github.com/qixinbo/BulkSeg">BulkSeg</a> which is inspired by Cellpose, is a fast and generalist algorithm for segmenting bulk-like objects.<br><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/BulkSeg/menus/BulkSeg/demo.png" alt="bulkseg-demo"></p><h2 id="物体分割DeepLab"><a href="#物体分割DeepLab" class="headerlink" title="物体分割DeepLab"></a>物体分割DeepLab</h2><p><a href="https://github.com/pytorch/vision/blob/master/torchvision/models/segmentation/deeplabv3.py">DeepLab</a> is a state-of-art deep learning model for semantic image segmentation, where the goal is to assign semantic labels (e.g., person, dog, cat and so on) to every pixel in the input image.<br><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/DeepLab/menus/DeepLab/demo.png" alt="deeplab-demo"></p><h1 id="计划"><a href="#计划" class="headerlink" title="计划"></a>计划</h1><p>下一步计划添加的模型有：</p><ul><li>图像生成</li><li>风格迁移</li></ul>]]></content>
    
    
    <summary type="html">起因
日常工作中，调用深度学习算法通常需要在命令行中进行，该过程通常涉及复杂的流程，比如修改配置文件、指定文件路径、打开命令行调用算法运行。此时如果能有一个图形界面软件实现“一键调用”，就会极大地节省工作量，提高工作效率，避免来来回回地反复修改文件、执行命令等。

最近新写了一个库，就是把常用的深度学习算法都集成在了ImagePy中，这样用户和开发者就能直接在ImagePy中愉快地“玩”算法了。

OneButtonDeepLearning
该仓库在这里https://github.com/qixinbo/OneButtonDeepLearning。
宗旨就是：让深度学习算法触手可及、一键调用</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="Machine Learning" scheme="http://qixinbo.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析： 27 -- 工作流workflow组件</title>
    <link href="http://qixinbo.github.io/2021/07/10/ImagePy_27/"/>
    <id>http://qixinbo.github.io/2021/07/10/ImagePy_27/</id>
    <published>2021-07-09T16:00:00.000Z</published>
    <updated>2021-07-09T05:48:56.278Z</updated>
    
    <content type="html"><![CDATA[<p>ImagePy的工作流worflow功能能够以可视化的方式逐步执行已定义的一系列图像处理动作，即有机地将复杂的图像处理步骤串联起来，也提供了可视化便捷的交互方式，可以认为是更人性化的“宏命令”。<br><img src="https://user-images.githubusercontent.com/6218739/125029058-a4018000-e0bb-11eb-841c-58f2cffa19c8.png" alt="image"><br>本文就是解析一下这个组件的底层原理。</p><h1 id="文本解析"><a href="#文本解析" class="headerlink" title="文本解析"></a>文本解析</h1><p>如下parse函数是读取描述workflow的文件，然后根据每行的标识对其进行解析，比如如果是两个井号开头，则这一行代表是chapter，以及在某个chapter下面还有若干section及其提示信息hint。在底层来说，就是将这些文件信息存储为有层级的python字典。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">cont</span>):</span></span><br><span class="line">ls = cont.split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">workflow = &#123;<span class="string">&#x27;title&#x27;</span>:ls[<span class="number">0</span>], <span class="string">&#x27;chapter&#x27;</span>:[]&#125;</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> ls[<span class="number">2</span>:]:</span><br><span class="line">line = line.strip()</span><br><span class="line"><span class="keyword">if</span> line == <span class="string">&#x27;&#x27;</span>:<span class="keyword">continue</span></span><br><span class="line"><span class="keyword">if</span> line.startswith(<span class="string">&#x27;## &#x27;</span>):</span><br><span class="line">chapter = &#123;<span class="string">&#x27;title&#x27;</span>:line[<span class="number">3</span>:], <span class="string">&#x27;section&#x27;</span>:[]&#125;</span><br><span class="line">workflow[<span class="string">&#x27;chapter&#x27;</span>].append(chapter)</span><br><span class="line"><span class="keyword">elif</span> line[<span class="number">1</span>:<span class="number">3</span>] == <span class="string">&#x27;. &#x27;</span>:</span><br><span class="line">section = &#123;<span class="string">&#x27;title&#x27;</span>:line[<span class="number">3</span>:]&#125;</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">section[<span class="string">&#x27;hint&#x27;</span>] = line</span><br><span class="line">chapter[<span class="string">&#x27;section&#x27;</span>].append(section)</span><br><span class="line"><span class="keyword">return</span> workflow</span><br></pre></td></tr></table></figure></p><h1 id="界面实现"><a href="#界面实现" class="headerlink" title="界面实现"></a>界面实现</h1><p>先来看整体的界面布局图：<br><img src="https://user-images.githubusercontent.com/6218739/125015230-aa82fe00-e0a1-11eb-9bdb-623c5516413f.png" alt="Untitled"><br>可以看出，整个界面由三部分构成：<br>（1）微调按钮<br>它使用的组件是wxPython的SpinButton：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.spn_scroll = wx.SpinButton( self, wx.ID_ANY, wx.DefaultPosition, wx.DefaultSize, wx.SP_HORIZONTAL )</span><br></pre></td></tr></table></figure><br>它是用来切换后面的工作流中包含的各个Chapter控件的显示，具体看一下它绑定的事件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">self.spn_scroll.Bind( wx.EVT_SPIN, self.on_spn )</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">on_spn</span>(<span class="params">self, event</span>):</span></span><br><span class="line">v = self.spn_scroll.GetValue()</span><br><span class="line">self.scr_workflow.Scroll(v, <span class="number">0</span>)</span><br><span class="line">self.spn_scroll.SetValue(self.scr_workflow.GetViewStart()[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></p><p>（2）工作流组件显示<br>这个部分是核心，是用来显示工作流中包含的各个图像处理功能组件，并赋予相应的功能。<br>因为事先不知道一个工作流中具体包含多少个图像处理功能，因此，需要使用可以滚动显示的方式来承载未知个数的组件，具体应用的是wxPython的ScrolledCanvas这种画布：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.scr_workflow = wx.ScrolledCanvas( self, wx.ID_ANY, wx.DefaultPosition, wx.DefaultSize)</span><br></pre></td></tr></table></figure><br>然后再将之前解析的工作流一个个添加到该Canvas中。<br>第一层级是以chapter为单位，多个chapter用水平排列的方式添加到canvas中；<br>第二层级是在每个chapter中，以垂直排列的方式依次添加chapter的标题、包含的Sections（即具体图像处理功能）及下面的Snap、load等等（目前这两个没有实际功能）。<br>添加的Section要与具体的图像处理操作绑定，所以要给它添加鼠标事件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> section <span class="keyword">in</span> chapter[<span class="string">&#x27;section&#x27;</span>]:</span><br><span class="line">btn = wx.Button( self.pan_chapter, wx.ID_ANY, section[<span class="string">&#x27;title&#x27;</span>], wx.DefaultPosition, wx.DefaultSize, wx.BU_EXACTFIT )</span><br><span class="line">sizer_section.Add( btn, <span class="number">0</span>, wx.ALL, <span class="number">3</span> )</span><br><span class="line">btn.Bind(wx.EVT_BUTTON, <span class="keyword">lambda</span> e, x=section[<span class="string">&#x27;title&#x27;</span>]: self.f(x))</span><br><span class="line">btn.Bind( wx.EVT_ENTER_WINDOW, <span class="keyword">lambda</span> e, info=section[<span class="string">&#x27;hint&#x27;</span>]: self.info(info))</span><br></pre></td></tr></table></figure><br>可以看出，有两个事件绑定，一个是鼠标单击事件，与一个匿名函数进行了绑定，该函数所做的是将section的title传入self.f函数中，并执行它（默认的f函数就是print）。另一个事件是当鼠标进入该button时，会在右侧的info窗口显示hint内容。<br>这个地方需要深究一下鼠标单击事件，即这个button是怎样执行具体的图像处理功能的：<br>首先，刚才已提到，该button与self.f是绑定的，即点击button时，会将title传入f函数来执行，那么就看一下f函数是啥。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Bind</span>(<span class="params">self, event, f=<span class="built_in">print</span></span>):</span> self.f = f</span><br></pre></td></tr></table></figure><br>从这个Bind函数可知，可以从外部传入一个f函数，然后赋值给该workflow组件的f函数。<br>那进一步探究外部是怎样传入f函数的。<br>具体看一下imagepy这个app中的实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_show_workflow</span>(<span class="params">self, cont, title=<span class="string">&#x27;ImagePy&#x27;</span></span>):</span></span><br><span class="line">    pan = WorkFlowPanel(self)</span><br><span class="line">    pan.SetValue(cont)</span><br><span class="line">    pan.Bind(<span class="literal">None</span>, <span class="keyword">lambda</span> x:self.run_macros([<span class="string">&#x27;%s&gt;None&#x27;</span>%x]))</span><br></pre></td></tr></table></figure><br>在imagepy这个app中，f函数就是一个匿名函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lambda</span> x:self.run_macros([<span class="string">&#x27;%s&gt;None&#x27;</span>%x])</span><br></pre></td></tr></table></figure><br>它执行了imagepy的宏执行命令，关键就是在这个地方了，它巧妙地将工作流中地命令映射到了执行宏命令上。<br>同时需要注意地是，这里的宏命令中的参数那一项是None，即默认不传入参数，因此就会跳出GUI窗口来让用户输入自己的参数，这正是宏命令与工作流的区别：底层都是宏命令，但一个是带参数的，一个是不带参数的。<br>（3）消息窗口<br>最右边就是消息提示窗口：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.txt_info = wx.TextCtrl( self, wx.ID_ANY, wx.EmptyString, wx.DefaultPosition, wx.DefaultSize, wx.TE_AUTO_URL|wx.TE_MULTILINE|wx.TE_READONLY )</span><br></pre></td></tr></table></figure><br>前面已经说了，当鼠标进入某个button时，会在这里显示该button的提示消息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">btn.Bind( wx.EVT_ENTER_WINDOW, <span class="keyword">lambda</span> e, info=section[<span class="string">&#x27;hint&#x27;</span>]: self.info(info))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">info</span>(<span class="params">self, info</span>):</span></span><br><span class="line">self.txt_info.SetValue(info)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">ImagePy的工作流worflow功能能够以可视化的方式逐步执行已定义的一系列图像处理动作，即有机地将复杂的图像处理步骤串联起来，也提供了可视化便捷的交互方式，可以认为是更人性化的“宏命令”。

本文就是解析一下这个组件的底层原理。

文本解析
如下parse函数是读取描述workflow的文件，然后根据每行的标识对其进行解析，比如如果是两个井号开头，则这一行代表是chapter，以及在某个chapter下面还有若干section及其提示信息hint。在底层来说，就是将这些文件信息存储为有层级的python字典。
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15


d</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析： 26 -- 矢量图形的操作</title>
    <link href="http://qixinbo.github.io/2021/03/31/ImagePy_26/"/>
    <id>http://qixinbo.github.io/2021/03/31/ImagePy_26/</id>
    <published>2021-03-30T16:00:00.000Z</published>
    <updated>2021-03-31T09:18:59.187Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本文是对ImagePy的矢量图形绘制工具进行深度解析。<br>矢量图形相对于位图来说，有其特有的操作，比如两个矢量进行求交集、求并集、求差等。<br>阅读本文之前，可以先参考<a href="https://qixinbo.info/2020/06/14/imagepy_20/">之前的这篇文章</a>，以对ImagePy的矢量图形有初步了解。</p><h1 id="功能函数"><a href="#功能函数" class="headerlink" title="功能函数"></a>功能函数</h1><h2 id="将矢量图形转化为点集"><a href="#将矢量图形转化为点集" class="headerlink" title="将矢量图形转化为点集"></a>将矢量图形转化为点集</h2><p>该函数的作用是将矢量图形转换为点集，这里的点作为锚点，可以供后续编辑。<br>比如对于矩形这一矢量，在shp中定义了它的起始点和长宽，通过该函数，可以将该矩形转为9个点的点集，即将该矩形分成田字格。<br>（具体到语法上，使用了numpy的mgrid函数，其中的步长设为了复数的形式，具体可以参考<a href="https://numpy.org/doc/stable/reference/generated/numpy.mgrid.html">这里</a>）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark</span>(<span class="params">shp, types = <span class="string">&#x27;all&#x27;</span></span>):</span></span><br><span class="line">pts = []</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (types==<span class="string">&#x27;all&#x27;</span> <span class="keyword">or</span> shp.dtype <span class="keyword">in</span> types): <span class="keyword">return</span> pts</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;point&#x27;</span>:</span><br><span class="line">pts.append([shp.body])</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;points&#x27;</span>:</span><br><span class="line">pts.append(shp.body)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;line&#x27;</span>:</span><br><span class="line">pts.append(shp.body)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;lines&#x27;</span>:</span><br><span class="line">pts.extend(shp.body)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;polygon&#x27;</span> <span class="keyword">and</span> <span class="built_in">len</span>(shp.body)==<span class="number">1</span>:</span><br><span class="line">pts.append(shp.body[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;polygons&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(i) != <span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line">pts.append(i[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangle&#x27;</span>:</span><br><span class="line">l,t,w,h = shp.body</span><br><span class="line">ps = np.mgrid[l:l+w:<span class="number">3j</span>, t:t+h:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts.append(ps)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangles&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(shp.body)):</span><br><span class="line">l,t,w,h = shp.body[i]</span><br><span class="line">ps = np.mgrid[l:l+w:<span class="number">3j</span>, t:t+h:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts.append(ps)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;ellipse&#x27;</span>:</span><br><span class="line">x0, y0, l1, l2, ang = shp.body</span><br><span class="line">mat = np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">  [np.sin(-ang),np.cos(-ang)]])</span><br><span class="line">ps = np.mgrid[-l1:l1:<span class="number">3j</span>, -l2:l2:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts.append(mat.dot(ps.T).T + (x0, y0))</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;ellipses&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(shp.body)):</span><br><span class="line">x0, y0, l1, l2, ang = shp.body[i]</span><br><span class="line">mat = np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">  [np.sin(-ang),np.cos(-ang)]])</span><br><span class="line">ps = np.mgrid[-l1:l1:<span class="number">3j</span>, -l2:l2:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts.append(mat.dot(ps.T).T + (x0, y0))</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;layer&#x27;</span>:</span><br><span class="line">minl, obj = <span class="number">1e8</span>, <span class="literal">None</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line">pts.extend(mark(i, types))</span><br><span class="line"><span class="keyword">return</span> pts</span><br></pre></td></tr></table></figure></p><h2 id="选择对象"><a href="#选择对象" class="headerlink" title="选择对象"></a>选择对象</h2><p>该函数的功能是选择与鼠标点击位置距离在一定范围内且距离最近的那个矢量对象。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pick_obj</span>(<span class="params">shp, x, y, lim, types=<span class="string">&#x27;all&#x27;</span></span>):</span></span><br><span class="line">obj, minl = <span class="literal">None</span>, lim</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (types==<span class="string">&#x27;all&#x27;</span> <span class="keyword">or</span> shp.dtype <span class="keyword">in</span> types): </span><br><span class="line"><span class="keyword">return</span> m, obj, minl</span><br><span class="line"><span class="comment"># 如果是layer类型，那么就遍历里面的元素</span></span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;layer&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line">o, l = pick_obj(i, x, y, lim, types)</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">obj, minl = o, l</span><br><span class="line"><span class="keyword">elif</span> shp.dtype <span class="keyword">in</span> <span class="string">&#x27;polygons&#x27;</span>:</span><br><span class="line">b = shp.to_geom().contains(Point([x, y]).to_geom())</span><br><span class="line"><span class="keyword">if</span> b : <span class="keyword">return</span> shp, <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment"># 首先将鼠标位置传给ImagePy的Point这一结构</span></span><br><span class="line"><span class="comment"># 然后调用to_geom方法就转换为shapely的Point对象</span></span><br><span class="line"><span class="comment"># 然后通过distance函数计算shp中的矢量与鼠标所在位置的Point矢量的距离</span></span><br><span class="line">d = shp.to_geom().distance(Point([x, y]).to_geom())</span><br><span class="line"><span class="comment"># 找到最近的或小于阈值minl的矢量，然后返回它</span></span><br><span class="line"><span class="keyword">if</span> d&lt;minl: obj, minl = shp, d</span><br><span class="line"><span class="keyword">return</span> obj, minl</span><br></pre></td></tr></table></figure></p><h2 id="选择锚点"><a href="#选择锚点" class="headerlink" title="选择锚点"></a>选择锚点</h2><p>该函数的功能是选择与鼠标所在位置小于某个距离的那个锚点。<br>如果锚点被选中，就会返回该锚点所在的矢量对象，同时表示该锚点的一个标识。比如对于椭圆上一个锚点，有“lt”左上、“rt”右上、“o”中心点等多种锚点。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pick_point</span>(<span class="params">shp, x, y, lim, types=<span class="string">&#x27;all&#x27;</span></span>):</span></span><br><span class="line">m, obj, minl = <span class="literal">None</span>, <span class="literal">None</span>, lim</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (types==<span class="string">&#x27;all&#x27;</span> <span class="keyword">or</span> shp.dtype <span class="keyword">in</span> types): </span><br><span class="line"><span class="keyword">return</span> m, obj, minl</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;point&#x27;</span>:</span><br><span class="line">l = ((shp.body-(x, y))**<span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, shp.body, l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;points&#x27;</span>:</span><br><span class="line">l = norm(shp.body-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, shp.body[n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;line&#x27;</span>:</span><br><span class="line">l = norm(shp.body-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, shp.body[n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;lines&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> shp.body:</span><br><span class="line">l = norm(line-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, line[n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;polygon&#x27;</span> <span class="keyword">and</span> <span class="built_in">len</span>(shp.body)==<span class="number">1</span>:</span><br><span class="line">l = norm(shp.body[<span class="number">0</span>]-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, shp.body[<span class="number">0</span>][n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;polygons&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(i) != <span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line">l = norm(i[<span class="number">0</span>]-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, i[<span class="number">0</span>][n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangle&#x27;</span>:</span><br><span class="line">l,t,w,h = shp.body</span><br><span class="line">pts = np.mgrid[l:l+w:<span class="number">3j</span>, t:t+h:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">names = [<span class="string">&#x27;lt&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;rt&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;lb&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>]</span><br><span class="line">l = norm(pts-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line"><span class="keyword">if</span> l[n] &lt; minl:</span><br><span class="line">m, obj, minl = shp, names[n], l[n]</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangles&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(shp.body)):</span><br><span class="line">l,t,w,h = shp.body[i]</span><br><span class="line">pts = np.mgrid[l:l+w:<span class="number">3j</span>, t:t+h:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">names = [<span class="string">&#x27;lt&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;rt&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;lb&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>]</span><br><span class="line">l = norm(pts-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line"><span class="keyword">if</span> l[n] &lt; minl:</span><br><span class="line">m, obj, minl = shp, (names[n], i), l[n]</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;ellipse&#x27;</span>:</span><br><span class="line">x0, y0, l1, l2, ang = shp.body</span><br><span class="line">mat = np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">  [np.sin(-ang),np.cos(-ang)]])</span><br><span class="line">pts = np.mgrid[-l1:l1:<span class="number">3j</span>, -l2:l2:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts = mat.dot(pts.T).T + (x0, y0)</span><br><span class="line">names = [<span class="string">&#x27;lt&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;rt&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;lb&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>]</span><br><span class="line">l = norm(pts-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line"><span class="keyword">if</span> l[n] &lt; minl:</span><br><span class="line">m, obj, minl = shp, names[n], l[n]</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;ellipses&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(shp.body)):</span><br><span class="line">x0, y0, l1, l2, ang = shp.body[i]</span><br><span class="line">mat = np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">  [np.sin(-ang),np.cos(-ang)]])</span><br><span class="line">pts = np.mgrid[-l1:l1:<span class="number">3j</span>, -l2:l2:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts = mat.dot(pts.T).T + (x0, y0)</span><br><span class="line">names = [<span class="string">&#x27;lt&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;rt&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;lb&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>]</span><br><span class="line">l = norm(pts-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line"><span class="keyword">if</span> l[n] &lt; minl:</span><br><span class="line">m, obj, minl = shp, (names[n], i), l[n]</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;layer&#x27;</span>:</span><br><span class="line"><span class="comment"># minl, obj = 1e8, None</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line">h, o, l = pick_point(i, x, y, lim, types)</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = h, o, l</span><br><span class="line"><span class="keyword">return</span> m, obj, minl</span><br></pre></td></tr></table></figure></p><h2 id="拖动锚点"><a href="#拖动锚点" class="headerlink" title="拖动锚点"></a>拖动锚点</h2><p>这个函数接收当前的矢量对象、它的某个锚点以及当前鼠标位置，然后通过该锚点的类型，来对该矢量对象的范围进行调整。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drag</span>(<span class="params">shp, pt, x, y, types=<span class="string">&#x27;all&#x27;</span></span>):</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (types==<span class="string">&#x27;all&#x27;</span> <span class="keyword">or</span> shp.dtype <span class="keyword">in</span> types): <span class="keyword">return</span></span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangle&#x27;</span>:</span><br><span class="line">body = shp.body</span><br><span class="line"><span class="keyword">if</span> pt == <span class="string">&#x27;o&#x27;</span>:body[:<span class="number">2</span>] = (x, y) - body[<span class="number">2</span>:]/<span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;l&#x27;</span> <span class="keyword">in</span> pt:body[[<span class="number">0</span>,<span class="number">2</span>]] = x, body[<span class="number">0</span>]+body[<span class="number">2</span>]-x</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;r&#x27;</span> <span class="keyword">in</span> pt:body[<span class="number">2</span>] = x - body[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;t&#x27;</span> <span class="keyword">in</span> pt:body[[<span class="number">1</span>,<span class="number">3</span>]] = y, body[<span class="number">1</span>]+body[<span class="number">3</span>]-y</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> pt:body[<span class="number">3</span>] = y - body[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">elif</span> shp.dtype == <span class="string">&#x27;rectangles&#x27;</span>:</span><br><span class="line">pt, i = pt</span><br><span class="line">body = shp.body[i]</span><br><span class="line"><span class="keyword">if</span> pt == <span class="string">&#x27;o&#x27;</span>:body[:<span class="number">2</span>] = (x, y) - body[<span class="number">2</span>:]/<span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;l&#x27;</span> <span class="keyword">in</span> pt:body[[<span class="number">0</span>,<span class="number">2</span>]] = x, body[<span class="number">0</span>]+body[<span class="number">2</span>]-x</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;r&#x27;</span> <span class="keyword">in</span> pt:body[<span class="number">2</span>] = x - body[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;t&#x27;</span> <span class="keyword">in</span> pt:body[[<span class="number">1</span>,<span class="number">3</span>]] = y, body[<span class="number">1</span>]+body[<span class="number">3</span>]-y</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> pt:body[<span class="number">3</span>] = y - body[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">elif</span> shp.dtype == <span class="string">&#x27;ellipse&#x27;</span>:</span><br><span class="line"><span class="keyword">if</span> pt == <span class="string">&#x27;o&#x27;</span>: </span><br><span class="line">shp.body[:<span class="number">2</span>] = x, y</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">x0, y0, l1, l2, ang = shp.body</span><br><span class="line">v1, v2 = (np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">[np.sin(-ang),np.cos(-ang)]]) * (l1, l2)).T</span><br><span class="line">l, r, t, b = np.array([-v1, v1, -v2, v2]) + (x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;l&#x27;</span> <span class="keyword">in</span> pt: l = v1.dot([x-x0, y-y0])*v1/l1**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;r&#x27;</span> <span class="keyword">in</span> pt: r = v1.dot([x-x0, y-y0])*v1/l1**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;t&#x27;</span> <span class="keyword">in</span> pt: t = v2.dot([x-x0, y-y0])*v2/l2**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> pt: b = v2.dot([x-x0, y-y0])*v2/l2**<span class="number">2</span>+(x0, y0)</span><br><span class="line">k = np.linalg.inv(np.array([-v2,v1]).T).dot((l+r-t-b)/<span class="number">2</span>)</span><br><span class="line">shp.body[:<span class="number">2</span>] = (l+r)/<span class="number">2</span> + v2*k[<span class="number">0</span>]</span><br><span class="line">shp.body[<span class="number">2</span>:<span class="number">4</span>] = np.dot(r-l, v1)/l1/<span class="number">2</span>, np.dot(b-t, v2)/l2/<span class="number">2</span></span><br><span class="line"><span class="keyword">elif</span> shp.dtype == <span class="string">&#x27;ellipses&#x27;</span>:</span><br><span class="line">pt, i = pt</span><br><span class="line">body = shp.body[i]</span><br><span class="line"><span class="keyword">if</span> pt == <span class="string">&#x27;o&#x27;</span>: </span><br><span class="line">body[:<span class="number">2</span>] = x, y</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">x0, y0, l1, l2, ang = body</span><br><span class="line">v1, v2 = (np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">[np.sin(-ang),np.cos(-ang)]]) * (l1, l2)).T</span><br><span class="line">l, r, t, b = np.array([-v1, v1, -v2, v2]) + (x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;l&#x27;</span> <span class="keyword">in</span> pt: l = v1.dot([x-x0, y-y0])*v1/l1**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;r&#x27;</span> <span class="keyword">in</span> pt: r = v1.dot([x-x0, y-y0])*v1/l1**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;t&#x27;</span> <span class="keyword">in</span> pt: t = v2.dot([x-x0, y-y0])*v2/l2**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> pt: b = v2.dot([x-x0, y-y0])*v2/l2**<span class="number">2</span>+(x0, y0)</span><br><span class="line">k = np.linalg.inv(np.array([-v2,v1]).T).dot((l+r-t-b)/<span class="number">2</span>)</span><br><span class="line">body[:<span class="number">2</span>] = (l+r)/<span class="number">2</span> + v2*k[<span class="number">0</span>]</span><br><span class="line">body[<span class="number">2</span>:<span class="number">4</span>] = np.dot(r-l, v1)/l1/<span class="number">2</span>, np.dot(b-t, v2)/l2/<span class="number">2</span></span><br><span class="line"><span class="keyword">else</span>: pt[:] = x, y</span><br></pre></td></tr></table></figure></p><h2 id="移动对象"><a href="#移动对象" class="headerlink" title="移动对象"></a>移动对象</h2><p>该函数目的是对矢量对象进行移动。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">offset</span>(<span class="params">shp, dx, dy</span>):</span></span><br><span class="line"><span class="keyword">if</span> shp.dtype <span class="keyword">in</span> &#123;<span class="string">&#x27;rectangle&#x27;</span>, <span class="string">&#x27;ellipse&#x27;</span>, <span class="string">&#x27;circle&#x27;</span>&#125;:</span><br><span class="line">shp.body[:<span class="number">2</span>] += dx, dy</span><br><span class="line"><span class="keyword">elif</span> shp.dtype <span class="keyword">in</span> &#123;<span class="string">&#x27;rectangles&#x27;</span>, <span class="string">&#x27;ellipses&#x27;</span>, <span class="string">&#x27;circles&#x27;</span>&#125;:</span><br><span class="line">shp.body[:,:<span class="number">2</span>] += dx, dy</span><br><span class="line"><span class="keyword">elif</span> <span class="built_in">isinstance</span>(shp, np.ndarray):</span><br><span class="line">shp += dx, dy</span><br><span class="line"><span class="keyword">elif</span> <span class="built_in">isinstance</span>(shp.body, <span class="built_in">list</span>):</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body: offset(i, dx, dy)</span><br></pre></td></tr></table></figure></p><h1 id="BaseEditor鼠标动作"><a href="#BaseEditor鼠标动作" class="headerlink" title="BaseEditor鼠标动作"></a>BaseEditor鼠标动作</h1><h2 id="鼠标中键拖动"><a href="#鼠标中键拖动" class="headerlink" title="鼠标中键拖动"></a>鼠标中键拖动</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line">self.p = x, y</span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">2</span>:</span><br><span class="line">self.status = <span class="string">&#x27;move&#x27;</span></span><br><span class="line">self.oldxy = key[<span class="string">&#x27;px&#x27;</span>], key[<span class="string">&#x27;py&#x27;</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line">self.cursor = <span class="string">&#x27;arrow&#x27;</span></span><br><span class="line"><span class="keyword">if</span> self.status == <span class="string">&#x27;move&#x27;</span>:</span><br><span class="line">ox, oy = self.oldxy</span><br><span class="line">up = (<span class="number">1</span>,-<span class="number">1</span>)[key[<span class="string">&#x27;canvas&#x27;</span>].up]</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].move(key[<span class="string">&#x27;px&#x27;</span>]-ox, (key[<span class="string">&#x27;py&#x27;</span>]-oy)*up)</span><br><span class="line">self.oldxy = key[<span class="string">&#x27;px&#x27;</span>], key[<span class="string">&#x27;py&#x27;</span>]</span><br></pre></td></tr></table></figure><h2 id="alt-右键以删除一个shape"><a href="#alt-右键以删除一个shape" class="headerlink" title="alt+右键以删除一个shape"></a>alt+右键以删除一个shape</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">3</span>:</span><br><span class="line">obj, l = pick_obj(shp, x, y, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line"><span class="keyword">if</span> obj <span class="keyword">is</span> <span class="literal">None</span>: <span class="keyword">del</span> shp.body[:]</span><br><span class="line"><span class="keyword">else</span>: shp.body.remove(obj)</span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br></pre></td></tr></table></figure><h2 id="shift-右键以合并shape"><a href="#shift-右键以合并shape" class="headerlink" title="shift+右键以合并shape"></a>shift+右键以合并shape</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">3</span>:</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">layer = geom2shp(geom_union(shp.to_geom()))</span><br><span class="line">shp.body = layer.body</span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br></pre></td></tr></table></figure><h2 id="右键根据当前区域大小缩放"><a href="#右键根据当前区域大小缩放" class="headerlink" title="右键根据当前区域大小缩放"></a>右键根据当前区域大小缩放</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">3</span>:</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">or</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">or</span> key[<span class="string">&#x27;ctrl&#x27;</span>]):</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].fit()</span><br></pre></td></tr></table></figure><h2 id="alt-ctrl以显示锚点"><a href="#alt-ctrl以显示锚点" class="headerlink" title="alt+ctrl以显示锚点"></a>alt+ctrl以显示锚点</h2><p>（注意该组合键是放在鼠标移动这个事件中，所以此时要鼠标移动一下，才会看到锚点）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">self.status = <span class="string">&#x27;pick&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="string">&#x27;anchor&#x27;</span> <span class="keyword">in</span> key[<span class="string">&#x27;canvas&#x27;</span>].marks: </span><br><span class="line">pts = mark(shp)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>: </span><br><span class="line">pts = Points(np.vstack(pts), color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = pts</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;anchor&#x27;</span> <span class="keyword">in</span> key[<span class="string">&#x27;canvas&#x27;</span>].marks:</span><br><span class="line">m, obj, l = pick_point(key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>], x, y, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> m <span class="keyword">is</span> <span class="literal">None</span>: self.cursor = <span class="string">&#x27;hand&#x27;</span></span><br></pre></td></tr></table></figure><br>最开始时，画布中是没有锚点的，此时就会将矢量对象通过mark函数转为锚点的点集，然后在画布上显示出来（具体原理可以见上面的mark函数解析）。<br>当画布中有了锚点后，如果鼠标靠近了某个锚点，通过pick_point这个函数捕捉到该锚点，就会将鼠标的样式设置为“手形”。</p><h2 id="alt-ctrl-鼠标左键拖动锚点"><a href="#alt-ctrl-鼠标左键拖动锚点" class="headerlink" title="alt+ctrl+鼠标左键拖动锚点"></a>alt+ctrl+鼠标左键拖动锚点</h2><p>需要提前非常注意的一点是，当同时按住alt和ctrl后，就会在鼠标移动事件中将此时的status设为pick模式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.status = <span class="string">&#x27;pick&#x27;</span></span><br></pre></td></tr></table></figure><br>此时在鼠标按下事件中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line">self.p = x, y</span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> self.status==<span class="string">&#x27;pick&#x27;</span>:</span><br><span class="line">m, obj, l = pick_point(shp, x, y, <span class="number">5</span>)</span><br><span class="line">self.pick_m, self.pick_obj = m, obj</span><br></pre></td></tr></table></figure><br>如果是捕捉到了某锚点，那么self.pick_m和self.pick_obj都会有值。<br>此时如果移动鼠标，那么：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> self.pick_obj <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> self.pick_m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">drag(self.pick_m, self.pick_obj, x, y)</span><br><span class="line">pts = mark(self.pick_m)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>:</span><br><span class="line">pts = np.vstack(pts)</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = Points(pts, color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">self.pick_m.dirty = <span class="literal">True</span></span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br></pre></td></tr></table></figure><br>就会触发drag这个函数来对锚点进行拖动。</p><h2 id="alt-ctrl-鼠标左键拖动整个矢量对象"><a href="#alt-ctrl-鼠标左键拖动整个矢量对象" class="headerlink" title="alt+ctrl+鼠标左键拖动整个矢量对象"></a>alt+ctrl+鼠标左键拖动整个矢量对象</h2><p>上面拖动锚点，是因为在鼠标按下时能够捕捉到锚点，而如果捕捉不到锚点（即与锚点离得较远），此时就会尝试选择整个对象，即：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> self.pick_m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">m, l = pick_obj(shp, x, y, <span class="number">5</span>)</span><br><span class="line">self.pick_m, self.pick_obj = m, <span class="literal">None</span></span><br></pre></td></tr></table></figure><br>（注意到此时self.pick_m是None，即没有捕捉到锚点的前提下）<br>此时如果探测到了矢量对象，那么self.pick_m就会有值，但self.pick_obj没有值。<br>此时如果移动鼠标，那么：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> self.pick_obj <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> self.pick_m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">offset(self.pick_m, x-self.p[<span class="number">0</span>], y-self.p[<span class="number">1</span>])</span><br><span class="line">pts = mark(self.pick_m)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>:</span><br><span class="line">pts = np.vstack(pts)</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = Points(pts, color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">self.p = x, y</span><br><span class="line">self.pick_m.dirty =shp.dirty = <span class="literal">True</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h1 id="特定形状Editor的鼠标动作"><a href="#特定形状Editor的鼠标动作" class="headerlink" title="特定形状Editor的鼠标动作"></a>特定形状Editor的鼠标动作</h1><h2 id="调用BaseEditor"><a href="#调用BaseEditor" class="headerlink" title="调用BaseEditor"></a>调用BaseEditor</h2><p>BaseEditor中有预置的鼠标动作，何时调用它。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inbase</span>(<span class="params">key, btn</span>):</span></span><br><span class="line">status = key[<span class="string">&#x27;ctrl&#x27;</span>], key[<span class="string">&#x27;alt&#x27;</span>], key[<span class="string">&#x27;shift&#x27;</span>]</span><br><span class="line"><span class="keyword">return</span> status == (<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>) <span class="keyword">or</span> btn <span class="keyword">in</span> &#123;<span class="number">2</span>,<span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure><br>即同时按住Ctrl和alt，或点击了鼠标中键或右键，就先响应BaseEditor中的行为。</p><h2 id="自定义动作"><a href="#自定义动作" class="headerlink" title="自定义动作"></a>自定义动作</h2><p>有几个特定的矢量图形绘制时都有如下动作，即：<br>（1）按住alt，求差集；<br>（2）按住shift，求并集；<br>（3）同时按住shift和alt，求交集。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">or</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">obj = shp.body.pop(-<span class="number">1</span>)</span><br><span class="line">rst = geom_union(shp.to_geom())</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">rst = rst.difference(obj.to_geom())</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">rst = rst.union(obj.to_geom())</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">rst = rst.intersection(obj.to_geom())</span><br><span class="line">layer = geom2shp(geom_flatten(rst))</span><br><span class="line">shp.body = layer.body</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">简介
本文是对ImagePy的矢量图形绘制工具进行深度解析。
矢量图形相对于位图来说，有其特有的操作，比如两个矢量进行求交集、求并集、求差等。
阅读本文之前，可以先参考之前的这篇文章，以对ImagePy的矢量图形有初步了解。

功能函数
将矢量图形转化为点集
该函数的作用是将矢量图形转换为点集，这里的点作为锚点，可以供后续编辑。
比如对于矩形这一矢量，在shp中定义了它的起始点和长宽，通过该函数，可以将该矩形转为9个点的点集，即将该矩形分成田字格。
（具体到语法上，使用了numpy的mgrid函数，其中的步长设为了复数的形式，具体可以参考这里）
1
2
3
4
5
6
7
8
9
10
11
</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>算法赏析——判断某点是否在某区域内</title>
    <link href="http://qixinbo.github.io/2021/03/28/algorithm-contain/"/>
    <id>http://qixinbo.github.io/2021/03/28/algorithm-contain/</id>
    <published>2021-03-27T16:00:00.000Z</published>
    <updated>2021-03-29T08:44:14.706Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>给定一个多边形区域，怎样判断某个点是否在该区域内？<br>如下图所示的蓝色多边形框，判断某点是否在该框内。<br><img src="https://user-images.githubusercontent.com/6218739/112778360-f66fe100-9076-11eb-9ec4-5e197aebdebd.png" alt="area"></p><h1 id="定义域"><a href="#定义域" class="headerlink" title="定义域"></a>定义域</h1><p>先写出该蓝色框的坐标序列：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">poly = np.array([(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">1</span>,<span class="number">0</span>),(<span class="number">0.7</span>,<span class="number">0.7</span>),(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">0</span>,<span class="number">1</span>),(<span class="number">0.5</span>,<span class="number">0.5</span>),(<span class="number">0</span>,<span class="number">0</span>)])</span><br></pre></td></tr></table></figure><br>注意，该坐标序列是首尾相接的。<br>然后，定义出任意数量、任意位置的随机点：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pts = np.random.rand(<span class="number">80</span>).reshape((<span class="number">40</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><br>这里给出了40个随机点。</p><h1 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h1><p>为了简单起见，以随机点[0.3, 0.4]为例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">o = np.array([(<span class="number">0.3</span>, <span class="number">0.4</span>)])</span><br></pre></td></tr></table></figure></p><h2 id="计算点与区域边界点形成的向量"><a href="#计算点与区域边界点形成的向量" class="headerlink" title="计算点与区域边界点形成的向量"></a>计算点与区域边界点形成的向量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vs = poly - o</span><br></pre></td></tr></table></figure><p>可以看作是以随机点为中心，区域边界点指向该中心的向量。<br>此例中，vs的值就是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[-<span class="number">0.3</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.7</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.4</span>  <span class="number">0.3</span>]</span><br><span class="line"> [ <span class="number">0.7</span>  <span class="number">0.6</span>]</span><br><span class="line"> [-<span class="number">0.3</span>  <span class="number">0.6</span>]</span><br><span class="line"> [ <span class="number">0.2</span>  <span class="number">0.1</span>]</span><br><span class="line"> [-<span class="number">0.3</span> -<span class="number">0.4</span>]]</span><br></pre></td></tr></table></figure></p><h2 id="计算点与区域边界点的距离"><a href="#计算点与区域边界点的距离" class="headerlink" title="计算点与区域边界点的距离"></a>计算点与区域边界点的距离</h2><p>然后计算该向量的绝对长度：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls = np.linalg.norm(vs, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><br>ls的值为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0.5</span>        <span class="number">0.80622577</span>     <span class="number">0.5</span>        <span class="number">0.92195445</span>   <span class="number">0.67082039</span>    <span class="number">0.2236068</span>  <span class="number">0.5</span>]</span><br></pre></td></tr></table></figure></p><h2 id="计算相邻向量的外积"><a href="#计算相邻向量的外积" class="headerlink" title="计算相邻向量的外积"></a>计算相邻向量的外积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cs = np.cross(vs[:-<span class="number">1</span>], vs[<span class="number">1</span>:])</span><br></pre></td></tr></table></figure><p>这一步是计算以随机点为中心所形成的向量中，两个相邻向量所形成的外积。<br>可以详细看看numpy的cross函数的两个输入：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[-<span class="number">0.3</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.7</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.4</span>  <span class="number">0.3</span>]</span><br><span class="line"> [ <span class="number">0.7</span>  <span class="number">0.6</span>]</span><br><span class="line"> [-<span class="number">0.3</span>  <span class="number">0.6</span>]</span><br><span class="line"> [ <span class="number">0.2</span>  <span class="number">0.1</span>]]</span><br></pre></td></tr></table></figure><br>和<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[ <span class="number">0.7</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.4</span>  <span class="number">0.3</span>]</span><br><span class="line"> [ <span class="number">0.7</span>  <span class="number">0.6</span>]</span><br><span class="line"> [-<span class="number">0.3</span>  <span class="number">0.6</span>]</span><br><span class="line"> [ <span class="number">0.2</span>  <span class="number">0.1</span>]</span><br><span class="line"> [-<span class="number">0.3</span> -<span class="number">0.4</span>]]</span><br></pre></td></tr></table></figure><br>即第一个输入是排除了vs的最后一个向量，而第二个输入是排除了vs的第一个向量，这样两者一交错，就是在cross时计算的就是两个相邻向量的外积。<br>外积的概念可以参见<a href="https://zh.wikipedia.org/zh-cn/%E5%8F%89%E7%A7%AF">维基百科</a><br><img src="https://user-images.githubusercontent.com/6218739/112794912-4d3ae200-909a-11eb-8fa4-cda6b524613e.png" alt="cross"><br>而numpy的具体cross函数的计算方式见<a href="https://numpy.org/doc/stable/reference/generated/numpy.cross.html">这里</a>。<br>因为这里输入的两个向量都是二维的，因此计算出来的虽然应该仍然是个向量，但这里只返回它的z轴长度（In cases where both input vectors have dimension 2, the z-component of the cross product is returned）。<br>因此，cs的值为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ <span class="number">0.4</span>   <span class="number">0.37</span>  <span class="number">0.03</span>  <span class="number">0.6</span>  -<span class="number">0.15</span> -<span class="number">0.05</span>]</span><br></pre></td></tr></table></figure><br>这里比较重要的是数值的符号。</p><h2 id="计算相邻向量的内积"><a href="#计算相邻向量的内积" class="headerlink" title="计算相邻向量的内积"></a>计算相邻向量的内积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dot = (vs[:-<span class="number">1</span>]*vs[<span class="number">1</span>:]).<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>这一步是计算以随机点为中心所形成的向量中，两个相邻向量所形成的内积。<br>内积的概念可以参见<a href="https://zh.wikipedia.org/zh-cn/%E7%82%B9%E7%A7%AF">维基百科</a>。<br><img src="https://user-images.githubusercontent.com/6218739/112796213-42814c80-909c-11eb-98bd-a62fd9a24ba1.png" alt="dot"><br>里面重要的一点：从代数角度看，先对两个数字序列中的每组对应元素求积，再对所有积求和，结果即为点积。从几何角度看，点积则是两个向量的长度与它们夹角余弦的积。这两种定义在笛卡尔坐标系中等价。</p><h2 id="计算相邻向量的长度乘积"><a href="#计算相邻向量的长度乘积" class="headerlink" title="计算相邻向量的长度乘积"></a>计算相邻向量的长度乘积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls = ls[:-<span class="number">1</span>] * ls[<span class="number">1</span>:]</span><br></pre></td></tr></table></figure><p>这句简单，就是相邻两个向量的长度的乘积。</p><h2 id="计算相邻向量的角度"><a href="#计算相邻向量的角度" class="headerlink" title="计算相邻向量的角度"></a>计算相邻向量的角度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ang = np.arccos(dot/ls) * np.sign(cs)</span><br></pre></td></tr></table></figure><p>该行有两部分组成：<br>（1）前一部分就是两个向量的点积除以这两个向量的长度乘积。由点积的定义可知，这样的除法得到了角度的余弦值。这样求反余弦后，就可以得到两个向量之间的角度。<br>（2）第二部分就是对上面的角度赋予符号，这个符号的正负是通过相邻向量的外积来得到的。</p><h2 id="计算角度之和"><a href="#计算角度之和" class="headerlink" title="计算角度之和"></a>计算角度之和</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ang.<span class="built_in">sum</span>() &gt; np.pi</span><br></pre></td></tr></table></figure><p>对上述角度求和，然后判断其大小。<br>这里就是整个算法的点睛之笔，假设一个人站在了这个随机点上，然后他在原地转圈：<br>（1）如果随机点在区域内部，那么这个人转一圈，其转过的角度就是2*pi；<br>（2）如果随机点在区域外部，那么这个人没法转一个完整的圈，而是转一个角度，然后又转回来，因此最终转过的角度就是0。<br>所以就可以根据这个角度之和来判断随机点与区域的关系。</p><p>将以上函数封装成一个统一的函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">contain</span>(<span class="params">poly, o</span>):</span></span><br><span class="line">    vs = poly - o</span><br><span class="line">    ls = np.linalg.norm(vs, axis=<span class="number">1</span>)</span><br><span class="line">    cs = np.cross(vs[:-<span class="number">1</span>], vs[<span class="number">1</span>:])</span><br><span class="line">    dot = (vs[:-<span class="number">1</span>]*vs[<span class="number">1</span>:]).<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">    ls = ls[:-<span class="number">1</span>] * ls[<span class="number">1</span>:]</span><br><span class="line">    ang = np.arccos(dot/ls) * np.sign(cs)</span><br><span class="line">    <span class="keyword">return</span> ang.<span class="built_in">sum</span>() &gt; np.pi</span><br></pre></td></tr></table></figure></p><h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">msk = np.array([contain(poly, i) <span class="keyword">for</span> i <span class="keyword">in</span> pts])</span><br><span class="line"></span><br><span class="line">plt.plot(*poly.T)</span><br><span class="line">plt.plot(*pts[msk].T, <span class="string">&#x27;go&#x27;</span>)</span><br><span class="line">plt.plot(*pts[~msk].T, <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果为：<br><img src="https://user-images.githubusercontent.com/6218739/112799536-11574b00-90a1-11eb-812e-21cdbdf4f45e.png" alt="vis"></p>]]></content>
    
    
    <summary type="html">问题描述
给定一个多边形区域，怎样判断某个点是否在该区域内？
如下图所示的蓝色多边形框，判断某点是否在该框内。


定义域
先写出该蓝色框的坐标序列：
1
2
3
4


import numpy as np
import matplotlib.pyplot as plt

poly = np.array([(0,0),(1,0),(0.7,0.7),(1,1),(0,1),(0.5,0.5),(0,0)])



注意，该坐标序列是首尾相接的。
然后，定义出任意数量、任意位置的随机点：
1


pts = np.random.rand(80).reshape((40,2))



这里给出了</summary>
    
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/categories/algorithm/"/>
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>算法赏析——寻找线条的转折点</title>
    <link href="http://qixinbo.github.io/2021/03/27/algorithm-find-peak/"/>
    <id>http://qixinbo.github.io/2021/03/27/algorithm-find-peak/</id>
    <published>2021-03-26T16:00:00.000Z</published>
    <updated>2021-03-29T08:44:33.703Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>图像中有一条线，如何判断这条线的转折点？<br>比如下面一张图：<br><img src="https://user-images.githubusercontent.com/6218739/112800422-35fff280-90a2-11eb-8a43-45d6a4682e3a.png" alt="test"><br>目的是找到图中的三个转折点。</p><h1 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h1><h2 id="找到轮廓线"><a href="#找到轮廓线" class="headerlink" title="找到轮廓线"></a>找到轮廓线</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">&#x27;test.png&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">conts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">xs, ys = conts[:,:,<span class="number">0</span>], conts[:,:,<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>这一步实际作用是通过寻找轮廓线，从像素类型的位图中提取有意义的这条线的坐标序列，即矢量序列。<br>同时将横坐标和纵坐标分别提取出来。</p><h2 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gxs = ndimg.gaussian_filter(xs, <span class="number">15</span>, mode=<span class="string">&#x27;wrap&#x27;</span>)</span><br><span class="line">gys = ndimg.gaussian_filter(ys, <span class="number">15</span>, mode=<span class="string">&#x27;wrap&#x27;</span>)</span><br></pre></td></tr></table></figure><p>对横纵坐标分别做高斯模糊，相当于对一维数据做高斯模糊，同时注意上面的轮廓线寻找到的序列是首尾相连，要用到wrap这个模式。</p><h2 id="新旧坐标对比"><a href="#新旧坐标对比" class="headerlink" title="新旧坐标对比"></a>新旧坐标对比</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ds = ((xs-gxs)**<span class="number">2</span>+(ys-gys)**<span class="number">2</span>)**<span class="number">0.5</span></span><br></pre></td></tr></table></figure><p>将高斯模糊后的坐标与之前的坐标进行对比，用标准差来衡量差距大小。</p><h2 id="寻找局部极大值"><a href="#寻找局部极大值" class="headerlink" title="寻找局部极大值"></a>寻找局部极大值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">maxds = ndimg.maximum_filter(ds, <span class="number">100</span>, mode=<span class="string">&#x27;wrap&#x27;</span>)</span><br><span class="line">idx = np.where((ds &gt; ds.std()*<span class="number">3</span>) &amp; (ds==maxds))[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>这个地方首先使用一个极大值滤波，然后再通过两个判断条件：是否大于标准差的3倍以及同时等于局部极大值。<br>这样就找到了局部极大值点所在的位置。<br>当然也可以直接用那种寻找局部极值的算法，但不如这种“极大值滤波+大于某个阈值”的方法来得简单直接。</p><h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ax = plt.subplot(<span class="number">211</span>)</span><br><span class="line">ax.plot(xs, ys)</span><br><span class="line">ax.plot(gxs, gys)</span><br><span class="line">plt.plot(xs[idx], ys[idx], <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">212</span>)</span><br><span class="line">ax.plot(ds)</span><br><span class="line">ax.plot(maxds)</span><br><span class="line">ax.plot(ds/ds*ds.std()*<span class="number">3</span>)</span><br><span class="line">ax.plot(idx, ds[idx], <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>将结果可视化出来：<br><img src="https://user-images.githubusercontent.com/6218739/112804493-115a4980-90a7-11eb-8992-f2f8fb80b3b9.png" alt="vis_peak"></p>]]></content>
    
    
    <summary type="html">问题描述
图像中有一条线，如何判断这条线的转折点？
比如下面一张图：

目的是找到图中的三个转折点。

解法
找到轮廓线
1
2
3


img = cv2.imread(&#39;test.png&#39;, 0)
conts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0][0]
xs, ys = conts[:,:,0], conts[:,:,1]


这一步实际作用是通过寻找轮廓线，从像素类型的位图中提取有意义的这条线的坐标序列，即矢量序列。
同时将横坐标和纵坐标分别提取出来。

高斯模糊
1
2


gxs = </summary>
    
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/categories/algorithm/"/>
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析： 25 -- 智能画笔</title>
    <link href="http://qixinbo.github.io/2021/03/26/ImagePy_25/"/>
    <id>http://qixinbo.github.io/2021/03/26/ImagePy_25/</id>
    <published>2021-03-25T16:00:00.000Z</published>
    <updated>2021-03-26T07:44:48.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本文介绍ImagePy中的智能画笔工具，它能够很方便地对图像进行像素级标注，尤其是在复杂图像上进行多种类别的标注时，用好这个智能画笔，能使效率飞升。<br>先来一连串的功能介绍镇楼：<br>（1）鼠标左键<br>左键：具有联想功能的局部标注<br>Ctrl+左键单击：吸取颜色<br>Ctrl+左键：普通画笔<br>Shift+左键：落笔选定保护色，在矩形框内闭合且非保护色区域被填充<br>Alt+左键：落笔选定保护色，在矩形框内对该色进行描边<br>Ctrl+Alt+左键：落笔选定保护色，对任意的非保护色的区域进行标注</p><p>（2）鼠标右键<br>右键：全局填充<br>Shift+右键：落笔所在的保护色的内部闭合区域被填充<br>Ctrl+右键：落笔所在的保护色的外边缘被描边<br>Alt+右键：落笔所在的保护色的内边缘被描边<br>Ctrl+Alt+右键：落笔选定保护色，外部非保护色区域被填充</p><p>（3）鼠标中键/滚轮<br>中键/滚轮：缩放，按住则拖动画布<br>Shift+滚轮：调节联想功能的粘性系数<br>Ctrl+滚轮：调节画笔的宽度<br>Ctrl+Alt+滚轮：调节矩形框大小</p><p>那么主角就是下面这个工具了：<br><img src="https://user-images.githubusercontent.com/6218739/111566949-1e3e8980-87d9-11eb-94d0-04e023349d42.png" alt="aipen"><br>对应源码在<a href="https://github.com/Image-Py/imagepy/blob/master/imagepy/tools/Draw/aibrush_tol.py">这里</a>。</p><h1 id="控制参数"><a href="#控制参数" class="headerlink" title="控制参数"></a>控制参数</h1><p>智能画笔工具有如此强大的功能，自然有相应的参数可以供调节：<br><img src="https://user-images.githubusercontent.com/6218739/111739860-b5314180-88be-11eb-89d0-dfc741c7de40.png" alt="para-view"><br>（1）win：矩形框窗口尺寸，控制局部标注区域的大小<br>（2）color：矩形框窗口颜色<br>（3）stickiness：粘性系数<br>（4）radius：画笔宽度<br>（5）tolerance：填充的容忍度<br>（6）connect：邻域</p><h1 id="功能解析"><a href="#功能解析" class="headerlink" title="功能解析"></a>功能解析</h1><h2 id="鼠标左键"><a href="#鼠标左键" class="headerlink" title="鼠标左键"></a>鼠标左键</h2><h3 id="吸取颜色"><a href="#吸取颜色" class="headerlink" title="吸取颜色"></a>吸取颜色</h3><p>Ctrl+左键单击来吸取颜色的代码如下：<br>（代码逻辑就是左键按下时记录下鼠标位置，鼠标弹起时判断是否是左键+Ctrl，同时鼠标未移动，符合条件后就将当前图像中的颜色数值传递给颜色管理器中的前景色）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    self.oldp = self.pickp = (y, x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_up</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    <span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> (y,x)==self.pickp <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">        x = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(x,<span class="number">0</span>), ips.img.shape[<span class="number">1</span>])))</span><br><span class="line">        y = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(y,<span class="number">0</span>), ips.img.shape[<span class="number">0</span>])))</span><br><span class="line">        self.app.manager(<span class="string">&#x27;color&#x27;</span>).add(<span class="string">&#x27;front&#x27;</span>, ips.img[y, x])</span><br></pre></td></tr></table></figure></p><h3 id="获取局部区域"><a href="#获取局部区域" class="headerlink" title="获取局部区域"></a>获取局部区域</h3><p>鼠标左键相关的动作是与局部标注相关联的，因此在介绍鼠标左键功能实现时非常重要的一点就是先介绍这个局部区域是怎样获得的。<br>奥秘就在如下代码中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    <span class="comment"># 获取当前鼠标位置</span></span><br><span class="line">    x = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(x,<span class="number">0</span>), img.shape[<span class="number">1</span>])))</span><br><span class="line">    y = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(y,<span class="number">0</span>), img.shape[<span class="number">0</span>])))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 获取当前位置与上一个位置之间的连续坐标，注意这里的加号是作用在tuple上，即连接两个元组，而不是数值相加</span></span><br><span class="line">    rs, cs = line(*[<span class="built_in">int</span>(<span class="built_in">round</span>(i)) <span class="keyword">for</span> i <span class="keyword">in</span> self.oldp + (y, x)])</span><br><span class="line">    <span class="comment"># 确保这些坐标都在图像内部</span></span><br><span class="line">    np.clip(rs, <span class="number">0</span>, img.shape[<span class="number">0</span>]-<span class="number">1</span>, out=rs)</span><br><span class="line">    np.clip(cs, <span class="number">0</span>, img.shape[<span class="number">1</span>]-<span class="number">1</span>, out=cs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">        start = time()</span><br><span class="line">        w = self.para[<span class="string">&#x27;win&#x27;</span>]</span><br><span class="line">        <span class="comment"># 以上述坐标为中心，获取其上下左右间距为w的矩形窗口，同时还保证这个窗口也在图像内部</span></span><br><span class="line">     <span class="comment"># 这样一来，如果在图像中抠出该窗口，那么窗口中心就是w</span></span><br><span class="line">        sr = (<span class="built_in">max</span>(<span class="number">0</span>,r-w), <span class="built_in">min</span>(img.shape[<span class="number">0</span>], r+w))</span><br><span class="line">        sc = (<span class="built_in">max</span>(<span class="number">0</span>,c-w), <span class="built_in">min</span>(img.shape[<span class="number">1</span>], c+w))</span><br><span class="line">        <span class="comment"># 如果上述坐标本身数值就小于窗口大小，那么窗口中心就得是实际的这个坐标</span></span><br><span class="line">        r, c = <span class="built_in">min</span>(r, w), <span class="built_in">min</span>(c, w)</span><br><span class="line">        <span class="comment"># 从原图中抠出该窗口</span></span><br><span class="line">        backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">           <span class="comment"># 从背景图中同步抠出该窗口</span></span><br><span class="line">            backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br></pre></td></tr></table></figure></p><h3 id="局部区域和画笔展示"><a href="#局部区域和画笔展示" class="headerlink" title="局部区域和画笔展示"></a>局部区域和画笔展示</h3><p>在执行鼠标左键操作时，会涉及局部区域和画笔在界面上的展示。<br>局部区域是用矩形框显示，画笔是用一个小的圆形显示，以及会有一个文本显示矩形框尺寸和粘度大小。源码为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">     <span class="keyword">if</span> self.status == <span class="literal">None</span> <span class="keyword">and</span> ips.mark != <span class="literal">None</span>:</span><br><span class="line">         ips.mark = <span class="literal">None</span></span><br><span class="line">         ips.update()</span><br><span class="line">     <span class="keyword">if</span> <span class="keyword">not</span> self.status <span class="keyword">in</span> [<span class="string">&#x27;local_pen&#x27;</span>,<span class="string">&#x27;local_brush&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;local_sketch&#x27;</span>,<span class="string">&#x27;local_in&#x27;</span>,<span class="string">&#x27;local_out&#x27;</span>,<span class="string">&#x27;move&#x27;</span>]:  <span class="keyword">return</span></span><br><span class="line">     img, color = ips.img, self.app.manager(<span class="string">&#x27;color&#x27;</span>).get(<span class="string">&#x27;front&#x27;</span>)</span><br><span class="line">     x = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(x,<span class="number">0</span>), img.shape[<span class="number">1</span>])))</span><br><span class="line">     y = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(y,<span class="number">0</span>), img.shape[<span class="number">0</span>])))</span><br><span class="line"></span><br><span class="line">   <span class="comment"># 绘制的形状传给ips的mark属性，在ips.update时就会将其绘制出来</span></span><br><span class="line">     ips.mark = self.make_mark(x, y)</span><br><span class="line">     self.oldp = (y, x)</span><br><span class="line">     ips.update()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 具体绘制的函数</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">make_mark</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">     wins = self.para[<span class="string">&#x27;win&#x27;</span>]</span><br><span class="line">     rect = &#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;rectangle&#x27;</span>, <span class="string">&#x27;body&#x27;</span>:(x-wins, y-wins, wins*<span class="number">2</span>, wins*<span class="number">2</span>), <span class="string">&#x27;color&#x27;</span>:self.para[<span class="string">&#x27;color&#x27;</span>]&#125;</span><br><span class="line">     <span class="comment"># 只需将矩形框、文本、圆形的属性用非常简单的语句描述出来即可</span></span><br><span class="line">     mark = &#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;layer&#x27;</span>, <span class="string">&#x27;body&#x27;</span>:[rect]&#125;</span><br><span class="line">     r = <span class="number">2</span> <span class="keyword">if</span> self.status==<span class="string">&#x27;local_brush&#x27;</span> <span class="keyword">else</span> self.para[<span class="string">&#x27;r&#x27;</span>]/<span class="number">2</span></span><br><span class="line">     mark[<span class="string">&#x27;body&#x27;</span>].append(&#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;circle&#x27;</span>, <span class="string">&#x27;body&#x27;</span>:(x, y, r), <span class="string">&#x27;color&#x27;</span>:self.para[<span class="string">&#x27;color&#x27;</span>]&#125;)</span><br><span class="line">     mark[<span class="string">&#x27;body&#x27;</span>].append(&#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;body&#x27;</span>:(x-wins, y-wins, </span><br><span class="line">         <span class="string">&#x27;S:%s W:%s&#x27;</span>%(self.para[<span class="string">&#x27;ms&#x27;</span>], self.para[<span class="string">&#x27;win&#x27;</span>])), <span class="string">&#x27;pt&#x27;</span>:<span class="literal">False</span>, <span class="string">&#x27;color&#x27;</span>:self.para[<span class="string">&#x27;color&#x27;</span>]&#125;)</span><br><span class="line">     <span class="keyword">return</span> mark2shp(mark)</span><br></pre></td></tr></table></figure></p><h3 id="普通画笔功能"><a href="#普通画笔功能" class="headerlink" title="普通画笔功能"></a>普通画笔功能</h3><p>Ctrl键和鼠标左键实现普通画笔功能：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">1</span> <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;local_pen&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status == <span class="string">&#x27;local_pen&#x27;</span>:</span><br><span class="line">                local_pen(imgclip, r, c, self.para[<span class="string">&#x27;r&#x27;</span>], color)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_pen</span>(<span class="params">img, r, c, R, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 以r和c为中心，R/2为半径进行画圆，获取该圆内的坐标</span></span><br><span class="line">    rs, cs = circle(r, c, R/<span class="number">2</span>+<span class="number">1e-6</span>, shape=img.shape)</span><br><span class="line">    img[rs, cs] = color</span><br></pre></td></tr></table></figure></p><h3 id="有联想功能的画笔"><a href="#有联想功能的画笔" class="headerlink" title="有联想功能的画笔"></a>有联想功能的画笔</h3><p>左键点击后拖动就会对区域进行有联想功能的填充，使用的算法是Felzenszwalb算法，原理是使用像素之间的颜色距离来衡量两者的相似性，具体原理可以参照<a href="https://blog.csdn.net/ttransposition/article/details/38024557">该博客</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">1</span>:</span><br><span class="line">            self.status = <span class="string">&#x27;local_brush&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status == <span class="string">&#x27;local_brush&#x27;</span>:</span><br><span class="line">                <span class="keyword">if</span> (imgclip[r,c] - color).<span class="built_in">sum</span>()==<span class="number">0</span>: <span class="keyword">continue</span></span><br><span class="line">                local_brush(imgclip, backclip, r, c, color, <span class="number">0</span>, self.para[<span class="string">&#x27;ms&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_brush</span>(<span class="params">img, back, r, c, color, sigma, msize</span>):</span></span><br><span class="line">    <span class="comment"># 使用felzenszwalb算法对该局部区域进行分割</span></span><br><span class="line">    lab = felzenszwalb(back, <span class="number">1</span>, sigma, msize)</span><br><span class="line">    <span class="comment"># 对分割后的区域进行泛洪填充，将区域分为True和False，True的地方即标注颜色</span></span><br><span class="line">    msk = flood(lab, (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    img[msk] = color</span><br></pre></td></tr></table></figure></p><h3 id="落笔选定保护色，在矩形框内闭合且非保护色区域被填充"><a href="#落笔选定保护色，在矩形框内闭合且非保护色区域被填充" class="headerlink" title="落笔选定保护色，在矩形框内闭合且非保护色区域被填充"></a>落笔选定保护色，在矩形框内闭合且非保护色区域被填充</h3><p>Shift+左键用来实现上述功能。<br>这里要注意有三个关键点：保护色、矩形框内闭合区域、非保护色区域。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="comment"># 设定保护色</span></span><br><span class="line">        self.pickcolor = ips.img[y, x]</span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">1</span> <span class="keyword">and</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;local_in&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        img, color = ips.img, self.app.manager(<span class="string">&#x27;color&#x27;</span>).get(<span class="string">&#x27;front&#x27;</span>)</span><br><span class="line">        color = (np.mean(color), color)[img.ndim==<span class="number">3</span>]</span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status == <span class="string">&#x27;local_in&#x27;</span>:</span><br><span class="line">                local_in_fill(imgclip, r, c, self.para[<span class="string">&#x27;r&#x27;</span>], self.pickcolor, color)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_in_fill</span>(<span class="params">img, r, c, R, color, bcolor</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 判断当前颜色是否是保护色，返回True和False矩阵</span></span><br><span class="line">    msk = (img == color).<span class="built_in">min</span>(axis=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 将上面判断保护色后的结果进行“填充孔洞”，如果不是保护色区域的孔洞，则不会填充</span></span><br><span class="line">    filled = binary_fill_holes(msk)</span><br><span class="line">    <span class="comment"># 将填充孔洞后的结果与原掩膜进行“异或”操作，两者相异的地方结果为1</span></span><br><span class="line">   <span class="comment"># 这样就把孔洞内非保护色的区域给提取了出来，</span></span><br><span class="line">   <span class="comment"># 因此，即使非保护色，如果不属于保护色内的孔洞，也不会被提取出来</span></span><br><span class="line">    filled ^= msk</span><br><span class="line">    <span class="comment"># 获得当前画笔描绘的区域</span></span><br><span class="line">    rs, cs = circle(r, c, R/<span class="number">2</span>+<span class="number">1e-6</span>, shape=img.shape)</span><br><span class="line">    <span class="comment"># 将原掩膜全部置为0</span></span><br><span class="line">    msk[:] = <span class="number">0</span></span><br><span class="line">   <span class="comment"># 将当前画笔描绘的区域置为1</span></span><br><span class="line">    msk[rs, cs] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 将孔洞内非保护色区域与现在的掩膜进行“与”操作，两者都为1，结果才为1</span></span><br><span class="line">    msk &amp;= filled</span><br><span class="line">    <span class="comment"># 将最终的掩膜处的图像置为当前的前景色</span></span><br><span class="line">    img[msk] = bcolor</span><br></pre></td></tr></table></figure></p><h3 id="落笔选定保护色，在矩形框内对该色进行描边"><a href="#落笔选定保护色，在矩形框内对该色进行描边" class="headerlink" title="落笔选定保护色，在矩形框内对该色进行描边"></a>落笔选定保护色，在矩形框内对该色进行描边</h3><p>Alt+左键用来实现上述功能。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="comment"># 设定保护色</span></span><br><span class="line">        self.pickcolor = ips.img[y, x]</span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">1</span> <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;local_sketch&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        img, color = ips.img, self.app.manager(<span class="string">&#x27;color&#x27;</span>).get(<span class="string">&#x27;front&#x27;</span>)</span><br><span class="line">        color = (np.mean(color), color)[img.ndim==<span class="number">3</span>]</span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status == <span class="string">&#x27;local_sketch&#x27;</span>:</span><br><span class="line">                local_sketch(imgclip, r, c, self.para[<span class="string">&#x27;r&#x27;</span>], self.pickcolor, color)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_sketch</span>(<span class="params">img, r, c, R, color, bcolor</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 判断当前颜色是否是保护色，返回True和False矩阵</span></span><br><span class="line">    msk = (img == color).<span class="built_in">min</span>(axis=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 对该掩膜进行膨胀操作</span></span><br><span class="line">    dilation = binary_dilation(msk, np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">    <span class="comment"># 对膨胀后的掩膜与原掩膜进行“异或”操作，这样就提取出了保护色的边界</span></span><br><span class="line">    dilation ^= msk</span><br><span class="line">    rs, cs = circle(r, c, R/<span class="number">2</span>+<span class="number">1e-6</span>, shape=img.shape)</span><br><span class="line">    msk[:] = <span class="number">0</span></span><br><span class="line">    msk[rs, cs] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 取出既是边界，同时又是画笔所描绘的地方</span></span><br><span class="line">    msk &amp;= dilation</span><br><span class="line">    <span class="comment"># 将这个地方赋以前景色</span></span><br><span class="line">    img[msk] = bcolor</span><br></pre></td></tr></table></figure></p><h3 id="落笔选定保护色，对任意的非保护色的区域进行标注"><a href="#落笔选定保护色，对任意的非保护色的区域进行标注" class="headerlink" title="落笔选定保护色，对任意的非保护色的区域进行标注"></a>落笔选定保护色，对任意的非保护色的区域进行标注</h3><p>Ctrl+Alt+左键实现如上功能：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="comment"># 设定保护色</span></span><br><span class="line">        self.pickcolor = ips.img[y, x]</span><br><span class="line">        <span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;local_out&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        img, color = ips.img, self.app.manager(<span class="string">&#x27;color&#x27;</span>).get(<span class="string">&#x27;front&#x27;</span>)</span><br><span class="line">        color = (np.mean(color), color)[img.ndim==<span class="number">3</span>]</span><br><span class="line">        <span class="keyword">for</span> r,c <span class="keyword">in</span> <span class="built_in">zip</span>(rs, cs):</span><br><span class="line">            backclip = imgclip = img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ips.back <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">                backclip = ips.back.img[<span class="built_in">slice</span>(*sr), <span class="built_in">slice</span>(*sc)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.status==<span class="string">&#x27;local_out&#x27;</span>:</span><br><span class="line">                local_out_fill(imgclip, r, c, self.para[<span class="string">&#x27;r&#x27;</span>], self.pickcolor, color)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_out_fill</span>(<span class="params">img, r, c, R, color, bcolor</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 判断当前颜色是否不是保护色（注意这里选择“非保护色”），返回True和False矩阵</span></span><br><span class="line">    msk = (img != color).<span class="built_in">max</span>(axis=<span class="number">2</span>)</span><br><span class="line">    rs, cs = circle(r, c, R/<span class="number">2</span>+<span class="number">1e-6</span>, shape=img.shape)</span><br><span class="line">    buf = np.zeros_like(msk)</span><br><span class="line">    buf[rs, cs] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 挑选出既是非保护色，然后又是鼠标描绘的地方</span></span><br><span class="line">    msk &amp;= buf</span><br><span class="line">    img[msk] = bcolor</span><br></pre></td></tr></table></figure></p><h2 id="鼠标右键"><a href="#鼠标右键" class="headerlink" title="鼠标右键"></a>鼠标右键</h2><p>鼠标右键的操作都是与全局标注相关的。</p><h3 id="全局填充"><a href="#全局填充" class="headerlink" title="全局填充"></a>全局填充</h3><p>右键单击就实现了全局填充的功能。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span>:</span><br><span class="line">            <span class="keyword">if</span> (ips.img[y, x] - color).<span class="built_in">sum</span>()==<span class="number">0</span>: <span class="keyword">return</span></span><br><span class="line">            conn = &#123;<span class="string">&#x27;4-connect&#x27;</span>:<span class="number">1</span>, <span class="string">&#x27;8-connect&#x27;</span>:<span class="number">2</span>&#125;</span><br><span class="line">            conn = conn[self.para[<span class="string">&#x27;con&#x27;</span>]]</span><br><span class="line">            tor = self.para[<span class="string">&#x27;tor&#x27;</span>]</span><br><span class="line">            fill_normal(ips.img, y, x, color, conn, tor)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fill_normal</span>(<span class="params">img, r, c, color, con, tor</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    msk = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="comment"># 将多通道的图像拆分成每一个通道来泛洪填充</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        <span class="comment"># 以鼠标点击的像素为中心，以tolerance为容差，以及设定邻域范围，然后在单一通道上进行填充</span></span><br><span class="line">      <span class="comment"># 虽然是每一通道分别处理，但是所有通道都是与msk进行“与”操作</span></span><br><span class="line">      <span class="comment"># 所以msk最终是满足所有通道的填充结果</span></span><br><span class="line">        msk &amp;= flood(img[:,:,i], (r, c), connectivity=con, tolerance=tor)</span><br><span class="line">    img[msk] = color</span><br></pre></td></tr></table></figure></p><h3 id="落笔所在保护色的内部闭合区域被填充"><a href="#落笔所在保护色的内部闭合区域被填充" class="headerlink" title="落笔所在保护色的内部闭合区域被填充"></a>落笔所在保护色的内部闭合区域被填充</h3><p>Shift+右键完成上述功能：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span> <span class="keyword">and</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;global_in_fill&#x27;</span></span><br><span class="line">            global_in_fill(ips.img, y, x, color)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">global_in_fill</span>(<span class="params">img, r, c, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    msk = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="comment"># 以鼠标所在的颜色为种子点，进行泛洪填充</span></span><br><span class="line">   <span class="comment"># 但与上面的填充不同的是，这里不设定tolerance，即严格地与该保护色相等地地方才填充</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        msk &amp;= flood(img[:,:,i], (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 填充的地方如果有孔洞，那么就填充起来</span></span><br><span class="line">    filled = binary_fill_holes(msk)</span><br><span class="line">    <span class="comment"># 填充孔洞后的图像与原先泛洪后的图像进行“异或”操作，就得到了孔洞区域</span></span><br><span class="line">    filled ^= msk</span><br><span class="line">    <span class="comment"># 将孔洞区域赋值为前景色</span></span><br><span class="line">    img[filled] = color</span><br></pre></td></tr></table></figure></p><h3 id="落笔所在的保护色的外边缘被描边"><a href="#落笔所在的保护色的外边缘被描边" class="headerlink" title="落笔所在的保护色的外边缘被描边"></a>落笔所在的保护色的外边缘被描边</h3><p>Ctrl+右键完成上述功能。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span> <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;global_out_line&#x27;</span></span><br><span class="line">            global_out_line(ips.img, y, x, color)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">global_out_line</span>(<span class="params">img, r, c, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    msk = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="comment"># 同样的严格按照鼠标所在的颜色进行泛洪填充</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        msk &amp;= flood(img[:,:,i], (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 对内部孔洞进行填充</span></span><br><span class="line">    msk = binary_fill_holes(msk)</span><br><span class="line">    <span class="comment"># 膨胀一下</span></span><br><span class="line">    dilation = binary_dilation(msk, np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">    <span class="comment"># 膨胀的图像与未膨胀的图像进行异或，得到外边缘</span></span><br><span class="line">    dilation ^= msk</span><br><span class="line">    img[dilation] = color</span><br></pre></td></tr></table></figure></p><h3 id="落笔所在保护色的内边缘被描边"><a href="#落笔所在保护色的内边缘被描边" class="headerlink" title="落笔所在保护色的内边缘被描边"></a>落笔所在保护色的内边缘被描边</h3><p>Alt+右键完成上述功能。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span> <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;global_in_line&#x27;</span></span><br><span class="line">            global_in_line(ips.img, y, x, color)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">global_in_line</span>(<span class="params">img, r, c, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    msk = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="comment"># 同样的严格按照鼠标所在的颜色进行泛洪填充</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        msk &amp;= flood(img[:,:,i], (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 对内部孔洞进行填充</span></span><br><span class="line">    inarea = binary_fill_holes(msk)</span><br><span class="line">    <span class="comment"># 填充孔洞后的图像与未填充孔洞的图像进行异或，得到孔洞区域</span></span><br><span class="line">    inarea ^= msk</span><br><span class="line">    <span class="comment"># 对孔洞区域腐蚀一下，然后与原孔洞进行异或，从而得到这个孔洞的外边缘，也就是保护色填充区域的内边缘。</span></span><br><span class="line">    inarea ^= binary_erosion(inarea, np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">    img[inarea] = color</span><br></pre></td></tr></table></figure></p><h3 id="落笔选定保护色，外部非保护色区域被填充"><a href="#落笔选定保护色，外部非保护色区域被填充" class="headerlink" title="落笔选定保护色，外部非保护色区域被填充"></a>落笔选定保护色，外部非保护色区域被填充</h3><p>Ctrl+Alt+右键完成该功能。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">        <span class="keyword">elif</span> btn==<span class="number">3</span> <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">            self.status = <span class="string">&#x27;global_out_fill&#x27;</span></span><br><span class="line">            global_out_fill(ips.img, y, x, color)</span><br><span class="line">            ips.update()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">global_out_fill</span>(<span class="params">img, r, c, color</span>):</span></span><br><span class="line">    img = img.reshape((img.shape+(<span class="number">1</span>,))[:<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 同样的严格按照鼠标所在的颜色进行泛洪填充，注意如果与保护色不连续的地方，也是不会被填充的，因为水流不过去</span></span><br><span class="line">    ori = np.ones(img.shape[:<span class="number">2</span>], dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img.shape[<span class="number">2</span>]):</span><br><span class="line">        ori &amp;= flood(img[:,:,i], (r, c), connectivity=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 对内部孔洞进行填充</span></span><br><span class="line">    filled = binary_fill_holes(ori)</span><br><span class="line">    <span class="comment"># 膨胀一下</span></span><br><span class="line">    dilation = binary_dilation(ori)</span><br><span class="line">    <span class="comment"># 获得泛洪填充区域的外边缘</span></span><br><span class="line">    dilation ^= filled</span><br><span class="line">    <span class="comment"># 获得这些外边缘像素的坐标序列</span></span><br><span class="line">    rs, cs = np.where(dilation)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(rs)==<span class="number">0</span>: <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 挑选图像中与鼠标所在的保护色相等的地方，返回1和0的掩膜矩阵</span></span><br><span class="line">    msk = ((img == img[r,c]).<span class="built_in">min</span>(axis=<span class="number">2</span>)).astype(np.uint8)</span><br><span class="line">    <span class="comment"># 对该掩膜进行泛洪填充，种子点就是外边缘像素中的一个（注意这里只是用了这个外边缘像素的位置，填充时参考的数值是掩膜中的0）</span></span><br><span class="line">   <span class="comment"># 这里用的是flood_fill，原理与flood相同，只是flood返回的是掩膜，而flood_fill则是对原矩阵进行直接数值填充</span></span><br><span class="line">   <span class="comment"># 这里填充的新值设为2</span></span><br><span class="line">   <span class="comment"># 这里还有一个隐藏功能，就是保护色的内部孔洞区域仍然是0，所以这些内部孔洞在后面也不会被填充为前景色。</span></span><br><span class="line">    flood_fill(msk, (rs[<span class="number">0</span>], cs[<span class="number">0</span>]), <span class="number">2</span>, connectivity=<span class="number">2</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 将值为2的地方设为前景色</span></span><br><span class="line">    img[msk==<span class="number">2</span>] = color</span><br></pre></td></tr></table></figure></p><h2 id="鼠标中键"><a href="#鼠标中键" class="headerlink" title="鼠标中键"></a>鼠标中键</h2><p>鼠标中键的功能非常容易理解，比如滚动滚轮进行缩放、按住滚轮来拖动画布等都是常规的画布操作。<br>而与Shift、Ctrl和Alt等的组合用法，其实就是对上面参数（win、stickiness和radius）的调节。<br>鼠标中键相关操作的源码对应实现分别为：</p><h3 id="拖动画布"><a href="#拖动画布" class="headerlink" title="拖动画布"></a>拖动画布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    <span class="keyword">if</span> btn==<span class="number">2</span>: </span><br><span class="line">        self.oldp = key[<span class="string">&#x27;canvas&#x27;</span>].to_panel_coor(x,y)</span><br><span class="line">        self.status = <span class="string">&#x27;move&#x27;</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, ips, x, y, btn, **key</span>):</span></span><br><span class="line">    x = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(x,<span class="number">0</span>), img.shape[<span class="number">1</span>])))</span><br><span class="line">    y = <span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(<span class="built_in">max</span>(y,<span class="number">0</span>), img.shape[<span class="number">0</span>])))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> self.status == <span class="string">&#x27;move&#x27;</span>:</span><br><span class="line">        x,y = key[<span class="string">&#x27;canvas&#x27;</span>].to_panel_coor(x,y)</span><br><span class="line">        key[<span class="string">&#x27;canvas&#x27;</span>].move(x-self.oldp[<span class="number">0</span>], y-self.oldp[<span class="number">1</span>])</span><br><span class="line">        self.oldp = x, y</span><br><span class="line">        ips.update()</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure><h3 id="通过滚轮调节参数"><a href="#通过滚轮调节参数" class="headerlink" title="通过滚轮调节参数"></a>通过滚轮调节参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_wheel</span>(<span class="params">self, ips, x, y, d, **key</span>):</span></span><br><span class="line">    <span class="keyword">if</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> d&gt;<span class="number">0</span>: self.para[<span class="string">&#x27;ms&#x27;</span>] = <span class="built_in">min</span>(<span class="number">50</span>, self.para[<span class="string">&#x27;ms&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> d&lt;<span class="number">0</span>: self.para[<span class="string">&#x27;ms&#x27;</span>] = <span class="built_in">max</span>(<span class="number">10</span>, self.para[<span class="string">&#x27;ms&#x27;</span>]-<span class="number">1</span>)</span><br><span class="line">        ips.mark = self.make_mark(x, y)</span><br><span class="line">    <span class="keyword">elif</span> key[<span class="string">&#x27;ctrl&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> d&gt;<span class="number">0</span>: self.para[<span class="string">&#x27;win&#x27;</span>] = <span class="built_in">min</span>(<span class="number">64</span>, self.para[<span class="string">&#x27;win&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> d&lt;<span class="number">0</span>: self.para[<span class="string">&#x27;win&#x27;</span>] = <span class="built_in">max</span>(<span class="number">28</span>, self.para[<span class="string">&#x27;win&#x27;</span>]-<span class="number">1</span>)</span><br><span class="line">        ips.mark = self.make_mark(x, y)</span><br><span class="line">    <span class="keyword">elif</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> d&gt;<span class="number">0</span>: self.para[<span class="string">&#x27;r&#x27;</span>] = <span class="built_in">min</span>(<span class="number">30</span>, self.para[<span class="string">&#x27;r&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> d&lt;<span class="number">0</span>: self.para[<span class="string">&#x27;r&#x27;</span>] = <span class="built_in">max</span>(<span class="number">2</span>, self.para[<span class="string">&#x27;r&#x27;</span>]-<span class="number">1</span>)</span><br><span class="line">        ips.mark = self.make_mark(x, y)</span><br></pre></td></tr></table></figure><h3 id="缩放画布"><a href="#缩放画布" class="headerlink" title="缩放画布"></a>缩放画布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> self.status == <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> d&gt;<span class="number">0</span>:key[<span class="string">&#x27;canvas&#x27;</span>].zoomout(x, y, <span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> d&lt;<span class="number">0</span>:key[<span class="string">&#x27;canvas&#x27;</span>].zoomin(x, y, <span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">ips.update()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">简介
本文介绍ImagePy中的智能画笔工具，它能够很方便地对图像进行像素级标注，尤其是在复杂图像上进行多种类别的标注时，用好这个智能画笔，能使效率飞升。
先来一连串的功能介绍镇楼：
（1）鼠标左键
左键：具有联想功能的局部标注
Ctrl+左键单击：吸取颜色
Ctrl+左键：普通画笔
Shift+左键：落笔选定保护色，在矩形框内闭合且非保护色区域被填充
Alt+左键：落笔选定保护色，在矩形框内对该色进行描边
Ctrl+Alt+左键：落笔选定保护色，对任意的非保护色的区域进行标注

（2）鼠标右键
右键：全局填充
Shift+右键：落笔所在的保护色的内部闭合区域被填充
Ctrl+右键：落笔所在的</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>hexo博客在不同电脑间迁移记录</title>
    <link href="http://qixinbo.github.io/2021/03/25/hexo-migration/"/>
    <id>http://qixinbo.github.io/2021/03/25/hexo-migration/</id>
    <published>2021-03-24T16:00:00.000Z</published>
    <updated>2021-06-01T03:32:14.721Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>该博客是基于hexo搭建的，部署在github pages里，用netlify加速。之前一直用自己的笔记本写博客，现在需要换用另一台电脑，因此需要在新电脑上将环境重新搭建一遍，顺便对hexo及其next主题进行升级。</p><h1 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h1><p>下载地址见<a href="https://nodejs.org/en/download/">这里</a>。<br>然后正常安装。<br>安装完成后，输入node -v和npm -v，如果出现版本号，那么就安装成功了。</p><h1 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h1><p>下载地址见<a href="https://git-scm.com/download/win">这里</a>。<br>然后正常安装，只不过最后一步添加路径时选择Use Git from the Windows Command Prompt，这样我们就可以直接在命令提示符里打开git了。<br>安装完成后在命令提示符中输入git —version验证是否安装成功。</p><h1 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h1><p>新建一个文件夹，如Blog，然后安装hexo：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i hexo-cli -g</span><br></pre></td></tr></table></figure><br>安装完成后输入hexo -v验证是否安装成功。<br>还要安装用于hexo的git部署插件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></p><h1 id="初始化博客"><a href="#初始化博客" class="headerlink" title="初始化博客"></a>初始化博客</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><h1 id="安装next主题"><a href="#安装next主题" class="headerlink" title="安装next主题"></a>安装next主题</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/theme-<span class="built_in">next</span>/hexo-theme-<span class="built_in">next</span> themes/<span class="built_in">next</span></span><br></pre></td></tr></table></figure><h1 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h1><p>离开该目录，然后将备份在github上的博客仓库下载下来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/qixinbo/blogBackup.git</span><br></pre></td></tr></table></figure><br>复制该blogBackup文件下的以下文件及文件夹到Blog文件夹下，并覆盖原始文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_config.yml文件</span><br><span class="line">theme/<span class="built_in">next</span>下的_config.yml文件</span><br><span class="line">source文件夹</span><br><span class="line">.git文件夹</span><br><span class="line">将<span class="built_in">next</span>/source/images下的wechat_reward复制到相应位置</span><br></pre></td></tr></table></figure><br>注意，由于next主题时有大版本更新，原有的配置可能不适用于新版本，此时直接覆盖可能会出错，解决方法只有对照两个配置文件，然后手工更改配置。</p><h1 id="重新备份"><a href="#重新备份" class="headerlink" title="重新备份"></a>重新备份</h1><p>在Blog文件夹下重新git备份（因为.git文件夹已经自带了配置信息，这里无需再次配置）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">&quot;migration&quot;</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure></p><h1 id="重新部署"><a href="#重新部署" class="headerlink" title="重新部署"></a>重新部署</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d -g</span><br></pre></td></tr></table></figure><p>如果出现实际效果与本地不符，可以尝试清理缓存：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure></p><h1 id="其他可能问题"><a href="#其他可能问题" class="headerlink" title="其他可能问题"></a>其他可能问题</h1><h2 id="添加rss"><a href="#添加rss" class="headerlink" title="添加rss"></a>添加rss</h2><p>首先安装必要插件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-feed --save</span><br></pre></td></tr></table></figure><br>然后在next主题配置文件中添加：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#订阅RSS</span></span><br><span class="line">feed:</span><br><span class="line">  <span class="built_in">type</span>: atom</span><br><span class="line">  path: atom.xml</span><br><span class="line">  limit: false</span><br></pre></td></tr></table></figure><br>并且增加RSS字段：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">follow_me:</span><br><span class="line">  RSS: /atom.xml || fa fa-rss</span><br></pre></td></tr></table></figure></p><h2 id="首页自动生成摘要"><a href="#首页自动生成摘要" class="headerlink" title="首页自动生成摘要"></a>首页自动生成摘要</h2><p>首先安装必要插件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-auto-excerpt</span><br></pre></td></tr></table></figure><br>然后在next的主题配置文件中添加：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">auto_excerpt:</span><br><span class="line">  enable: true</span><br><span class="line">  length: <span class="number">150</span></span><br></pre></td></tr></table></figure></p><h2 id="LaTeX公式渲染"><a href="#LaTeX公式渲染" class="headerlink" title="LaTeX公式渲染"></a>LaTeX公式渲染</h2><p>首先卸载原有的渲染器，然后安装下面的其中一个（实测pandoc不行，而应该安装kramed）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked</span><br><span class="line">npm install hexo-renderer-pandoc <span class="comment"># 或者 hexo-renderer-kramed</span></span><br></pre></td></tr></table></figure><br>然后在next主题的配置文件中，进行配置：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Math Formulas Render Support</span></span><br><span class="line">math:</span><br><span class="line">  <span class="comment"># Default (true) will load mathjax / katex script on demand.</span></span><br><span class="line">  <span class="comment"># That is it only render those page which has `mathjax: true` in Front-matter.</span></span><br><span class="line">  <span class="comment"># If you set it to false, it will load mathjax / katex srcipt EVERY PAGE.</span></span><br><span class="line">  per_page: false <span class="comment"># 这个per_page非常重要，如果为True，那么就只渲染带`mathjax: true`的页面，设为False则渲染所有页面，所以可能速度会慢。</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># hexo-renderer-pandoc (or hexo-renderer-kramed) required for full MathJax support.</span></span><br><span class="line">  mathjax:</span><br><span class="line">    enable: true</span><br><span class="line">    cdn: //cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML</span><br><span class="line">    <span class="comment"># See: https://mhchem.github.io/MathJax-mhchem/</span></span><br><span class="line">    mhchem: false</span><br><span class="line"></span><br><span class="line">  <span class="comment"># hexo-renderer-markdown-it-plus (or hexo-renderer-markdown-it with markdown-it-katex plugin) required for full Katex support.</span></span><br><span class="line">  katex:</span><br><span class="line">    enable: false</span><br><span class="line">    cdn: //cdn.jsdelivr.net/npm/katex@<span class="number">0</span>/dist/katex.<span class="built_in">min</span>.css</span><br><span class="line">    <span class="comment"># See: https://github.com/KaTeX/KaTeX/tree/master/contrib/copy-tex</span></span><br><span class="line">    copy_tex: false</span><br></pre></td></tr></table></figure></p><h2 id="修改dns服务器"><a href="#修改dns服务器" class="headerlink" title="修改dns服务器"></a>修改dns服务器</h2><p>将hexo博客部署在netlify上，可以充分利用netlify的cdn加速。这里需要将dns解析服务器由原来的dnspod改为netlify。<br>首先需要在netlify上对域名开启netlify的dns服务，这一步在网页上可以很方便的操作。<br>然后在godaddy（这是域名服务商）上设置nameservers：<br>原来是dnspod家的：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">F1G1NS1.DNSPOD.NET</span><br><span class="line">F1G1NS2.DNSPOD.NET</span><br></pre></td></tr></table></figure><br>现在改为netlify家的：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dns1.p04.nsone.net</span><br><span class="line">dns2.p04.nsone.net</span><br><span class="line">dns3.p04.nsone.net</span><br><span class="line">dns4.p04.nsone.net</span><br></pre></td></tr></table></figure><br>改完后无论是境内还是境外，速度飞起~~</p><h2 id="连接不上github"><a href="#连接不上github" class="headerlink" title="连接不上github"></a>连接不上github</h2><p>在执行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d -g</span><br></pre></td></tr></table></figure><br>出现了一次连接不上github的问题，但在该终端下直接：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push</span><br></pre></td></tr></table></figure><br>却是可以的，这可能跟wifi有关。。也可能跟代理有关。<br>反正是换了一个wifi，关闭代理，就神奇地好了。。<br><a href="https://java4all.cn/2020/01/24/github%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/">这篇博客</a>也遇到了这个问题。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://zhuanlan.zhihu.com/p/35668237">超详细Hexo+Github博客搭建小白教程</a><br><a href="https://zhuanlan.zhihu.com/p/26625249">GitHub+Hexo 搭建个人网站详细教程</a><br><a href="https://hasaik.com/posts/19c94341.html">为Hexo添加RSS订阅</a><br><a href="https://suyin-blog.club/2020/2M3YWE7/">给 Hexo 中的 Next 主题添加 RSS 功能</a><br><a href="https://ninesix.cc/post/hexo-yilia-auto-excerpt.html">hexo博文摘要生成方案</a></p>]]></content>
    
    
    <summary type="html">简介
该博客是基于hexo搭建的，部署在github pages里，用netlify加速。之前一直用自己的笔记本写博客，现在需要换用另一台电脑，因此需要在新电脑上将环境重新搭建一遍，顺便对hexo及其next主题进行升级。

安装Node.js
下载地址见这里。
然后正常安装。
安装完成后，输入node -v和npm -v，如果出现版本号，那么就安装成功了。

安装git
下载地址见这里。
然后正常安装，只不过最后一步添加路径时选择Use Git from the Windows Command Prompt，这样我们就可以直接在命令提示符里打开git了。
安装完成后在命令提示符中输入git </summary>
    
    
    
    <category term="coding" scheme="http://qixinbo.github.io/categories/coding/"/>
    
    
    <category term="blog" scheme="http://qixinbo.github.io/tags/blog/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle肾小球图像分割比赛全解析</title>
    <link href="http://qixinbo.github.io/2021/02/14/kaggle-hubmap/"/>
    <id>http://qixinbo.github.io/2021/02/14/kaggle-hubmap/</id>
    <published>2021-02-13T16:00:00.000Z</published>
    <updated>2021-03-26T07:45:46.819Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h1><h2 id="赛事描述"><a href="#赛事描述" class="headerlink" title="赛事描述"></a>赛事描述</h2><p>Kaggle上正在进行一项名为“HuBMAP: Hacking the Kidney”的竞赛，链接见<a href="https://www.kaggle.com/c/hubmap-kidney-segmentation">这里</a>，总奖金是6万美金，该竞赛的目的是为了检测人体组织中的functional tissue units (FTUs)。FTU的定义是：three-dimensional block of cells centered around a capillary, such that each cell in this block is within diffusion distance from any other cell in the same block，感觉类似于细胞的概念，正中是细胞核，周围是细胞质。</p><h2 id="算法评估标准"><a href="#算法评估标准" class="headerlink" title="算法评估标准"></a>算法评估标准</h2><p>该竞赛使用Dice系数来评估算法的优劣。关于Dice系数，可以见如下博客解析：<br><a href="https://www.aiuai.cn/aifarm1159.html">医学图像分割之 Dice Loss</a></p><p>竞赛所提交的文件使用游程编码方式（RLE，run-length encoding）来减小文件体积。<br>关于掩膜mask与rle编码与解码的代码，可以参见网友Paulo Pinto的notebook：<br><a href="https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode">RLE functions - Run Lenght Encode &amp; Decode</a></p><h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><h2 id="数据集概览"><a href="#数据集概览" class="headerlink" title="数据集概览"></a>数据集概览</h2><p>该赛事中的数据一共有20张肾的图像，每一张都对其中的肾小球FTU进行了标注，有8张用于训练集，5张用于公榜测试集，剩下7张用于私榜测试集。<br>每一张图像都是非常大的TIFF格式，500MB-5GB大小。</p><p>训练集中的标注有两种形式：游程编码和未编码的JSON格式。<br>可以使用外部数据和/或预训练的机器学习模型，不过这些数据和模型必须在CC BY 4.0下授权。<br>下载数据集（这是在google colab上运行，colab上的机器性能较好；如果直接使用kaggle上的notebook，则数据集直接内置）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!kaggle competitions download -c hubmap-kidney-segmentation</span><br></pre></td></tr></table></figure><br>然后进行数据的探索性分析，该过程参考了以下notebook：<br><a href="https://www.kaggle.com/ihelon/hubmap-exploratory-data-analysis">HuBMAP - Exploratory Data Analysis</a></p><h2 id="导入必要的包"><a href="#导入必要的包" class="headerlink" title="导入必要的包"></a>导入必要的包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pathlib, sys, os, random, time</span><br><span class="line"><span class="keyword">import</span> numba, cv2, gc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> albumentations <span class="keyword">as</span> A</span><br><span class="line"><span class="keyword">import</span> rasterio</span><br><span class="line"><span class="keyword">from</span> rasterio.windows <span class="keyword">import</span> Window</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> D</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> T</span><br></pre></td></tr></table></figure><h2 id="配置路径及超参数"><a href="#配置路径及超参数" class="headerlink" title="配置路径及超参数"></a>配置路径及超参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BASE_PATH = <span class="string">&quot;../input/hubmap-kidney-segmentation/&quot;</span></span><br><span class="line">TRAIN_PATH = os.path.join(BASE_PATH, <span class="string">&quot;train/&quot;</span>)</span><br><span class="line">TEST_PATH = os.path.join(BASE_PATH, <span class="string">&quot;test/&quot;</span>)</span><br><span class="line"></span><br><span class="line">EPOCHES = <span class="number">5</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">DEVICE = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="文件分析"><a href="#文件分析" class="headerlink" title="文件分析"></a>文件分析</h2><p>（1）训练集文件分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_train = pd.read_csv(os.path.join(BASE_PATH, <span class="string">&quot;train.csv&quot;</span>))</span><br><span class="line">df_train</span><br></pre></td></tr></table></figure></p><p>得到：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">           <span class="built_in">id</span>                        encoding</span><br><span class="line"><span class="number">0</span>        2f6ecfcdf        <span class="number">296084587</span> <span class="number">4</span> <span class="number">296115835</span> <span class="number">6</span> <span class="number">296115859</span> <span class="number">14</span> <span class="number">296147109.</span>..</span><br><span class="line"><span class="number">1</span>        aaa6a05cc        <span class="number">30989109</span> <span class="number">59</span> <span class="number">31007591</span> <span class="number">64</span> <span class="number">31026074</span> <span class="number">68</span> <span class="number">31044556</span> <span class="number">7.</span>..</span><br><span class="line"><span class="number">2</span>        cb2d976f4        <span class="number">78144363</span> <span class="number">5</span> <span class="number">78179297</span> <span class="number">15</span> <span class="number">78214231</span> <span class="number">25</span> <span class="number">78249165</span> <span class="number">35.</span>..</span><br><span class="line"><span class="number">3</span>        0486052bb        <span class="number">101676003</span> <span class="number">6</span> <span class="number">101701785</span> <span class="number">8</span> <span class="number">101727568</span> <span class="number">9</span> <span class="number">101753351</span> ...</span><br><span class="line"><span class="number">4</span>        e79de561c        <span class="number">7464094</span> <span class="number">14</span> <span class="number">7480273</span> <span class="number">41</span> <span class="number">7496453</span> <span class="number">67</span> <span class="number">7512632</span> <span class="number">82</span> <span class="number">75.</span>..</span><br><span class="line"><span class="number">5</span>        095bf7a1f        <span class="number">113430380</span> <span class="number">22</span> <span class="number">113468538</span> <span class="number">67</span> <span class="number">113506697</span> <span class="number">111</span> <span class="number">113544.</span>..</span><br><span class="line"><span class="number">6</span>        54f2eec69        <span class="number">124601765</span> <span class="number">36</span> <span class="number">124632133</span> <span class="number">109</span> <span class="number">124662536</span> <span class="number">147</span> <span class="number">12469.</span>..</span><br><span class="line"><span class="number">7</span>        1e2425f28        <span class="number">49453112</span> <span class="number">7</span> <span class="number">49479881</span> <span class="number">22</span> <span class="number">49506657</span> <span class="number">31</span> <span class="number">49533433</span> <span class="number">40.</span>..</span><br></pre></td></tr></table></figure><br>train.csv文件中包含了图像的id及其游程编码。可以看出图像的名称就是id名。<br>（2）提交文件分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_sub = pd.read_csv(os.path.join(BASE_PATH, <span class="string">&quot;sample_submission.csv&quot;</span>))</span><br><span class="line">df_sub</span><br></pre></td></tr></table></figure><br>得到：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   <span class="built_in">id</span>                          predicted</span><br><span class="line"><span class="number">0</span>        b9a3865fc        NaN</span><br><span class="line"><span class="number">1</span>        b2dc8411c        NaN</span><br><span class="line"><span class="number">2</span>        26dc41664        NaN</span><br><span class="line"><span class="number">3</span>        c68fe75ea        NaN</span><br><span class="line"><span class="number">4</span>        afa5e8098        NaN</span><br></pre></td></tr></table></figure><br>提交文件就是对公共测试集上的图像的预测，可以看出id就是公共测试集中的图像名称，predicted一栏需要后面填入。<br>（3）数据集大小分析：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;number of train images: &quot;, df_train.shape[0])</span><br><span class="line">print(&quot;number of test images: &quot;, df_sub.shape[0])</span><br></pre></td></tr></table></figure><br>分别是8和5。<br>（4）元数据分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_meta = pd.read_csv(os.path.join(BASE_PATH, <span class="string">&quot;HuBMAP-20-dataset_information.csv&quot;</span>))</span><br><span class="line">df_meta.sample(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><br>该文件中包含了数据集中的每一张图像额外的信息，比如它的主人的身体信息、性别、种族等。<br>同时指明训练集中除了肾小球的标注文件，比如1e2425f28.json，还有其他解剖组织的标注文件，比如1e2425f28-anatomical-structure.json。<br>该文件是为了辅助理解该赛题背后的医学知识，有可能对特征功能有用，但目前看没法直接使用。</p><h2 id="工具函数"><a href="#工具函数" class="headerlink" title="工具函数"></a>工具函数</h2><p>以下是关于游程编码和解码、读取图像、可视化的工具代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图像分块</span></span><br><span class="line"><span class="comment"># min_overlap这个参数指的是有可能出现的最小的overlap，而不是保证这个overlap一定会出现</span></span><br><span class="line"><span class="comment"># 即自适应产生的overlap肯定会大于该min_overlap</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_grid</span>(<span class="params">shape, window=<span class="number">256</span>, min_overlap=<span class="number">32</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Return Array of size (N,4), where N - number of tiles,</span></span><br><span class="line"><span class="string">        2nd axis represente slices: x1,x2,y1,y2</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x, y = shape</span><br><span class="line">    nx = x // (window - min_overlap) + <span class="number">1</span></span><br><span class="line">    x1 = np.linspace(<span class="number">0</span>, x, num=nx, endpoint=<span class="literal">False</span>, dtype=np.int64)</span><br><span class="line">    x1[-<span class="number">1</span>] = x - window</span><br><span class="line">    x2 = (x1 + window).clip(<span class="number">0</span>, x)</span><br><span class="line">    ny = y // (window - min_overlap) + <span class="number">1</span></span><br><span class="line">    y1 = np.linspace(<span class="number">0</span>, y, num=ny, endpoint=<span class="literal">False</span>, dtype=np.int64)</span><br><span class="line">    y1[-<span class="number">1</span>] = y - window</span><br><span class="line">    y2 = (y1 + window).clip(<span class="number">0</span>, y)</span><br><span class="line">    slices = np.zeros((nx,ny, <span class="number">4</span>), dtype=np.int64)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nx):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(ny):</span><br><span class="line">            slices[i,j] = x1[i], x2[i], y1[j], y2[j]   </span><br><span class="line">    <span class="keyword">return</span> slices.reshape(nx*ny,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 固定随机数，以保证可复现性</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_seeds</span>(<span class="params">seed=<span class="number">42</span></span>):</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 游程编码转为图像掩膜</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rle2mask</span>(<span class="params">mask_rle, shape</span>):</span></span><br><span class="line">    <span class="comment"># shape的形状是(width, height), width是通常理解的图像宽度</span></span><br><span class="line">    <span class="comment"># 原始的rle编码是str类型，里面的元素成对出现，即start起始像素及length长度</span></span><br><span class="line">    s = mask_rle.split()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将s中的start和length分别提取出来，因为它们在原始列表中是成对出现，所以这里对这两种数据都是每隔两个元素提取一次</span></span><br><span class="line">    <span class="comment"># 然后再通过python的列表生成式语法另存成numpy数组</span></span><br><span class="line">    <span class="comment"># https://www.liaoxuefeng.com/wiki/1016959663602400/1017317609699776</span></span><br><span class="line">    starts, lengths = [np.asarray(x, dtype=<span class="built_in">int</span>) <span class="keyword">for</span> x <span class="keyword">in</span> (s[<span class="number">0</span>:][::<span class="number">2</span>], s[<span class="number">1</span>:][::<span class="number">2</span>])]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 原始csv文件中的游程编码是从绝对位置开始，因此转化为numpy数组时需要减1</span></span><br><span class="line">    starts -= <span class="number">1</span></span><br><span class="line">    ends = starts + lengths</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据原始图像大小建立一个空白图像</span></span><br><span class="line">    img = np.zeros(shape[<span class="number">0</span>]*shape[<span class="number">1</span>], dtype=np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据起始像素和结束像素，在该空白图像上创建掩膜</span></span><br><span class="line">    <span class="comment"># 1为mask，0为背景</span></span><br><span class="line">    <span class="keyword">for</span> lo, hi <span class="keyword">in</span> <span class="built_in">zip</span>(starts, ends):</span><br><span class="line">        img[lo: hi] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将img按输入shape变换形状，这里就体现了shape中元素顺序的关键</span></span><br><span class="line">    <span class="comment"># 因为RLE编码是先从上到下，然后再从左到右进行的，所以分割时是先满足高度要求，即先按一列一列地来分组</span></span><br><span class="line">    <span class="comment"># 因为输入的shape是宽度在前，高度在后，正好reshape就按这个shape来变换形状</span></span><br><span class="line">    <span class="comment"># 比如原图如果宽为5，高为2，那么就reshape((5, 2))，即分成5组，每组2个元素</span></span><br><span class="line">    <span class="comment"># 然后因为图像存成numpy数组时是行数乘以列数，即转置一下即可</span></span><br><span class="line">    <span class="keyword">return</span> img.reshape(shape).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像掩膜转为游程编码</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/qq_35985044/article/details/104332577</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask2rle</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="comment"># 将掩膜按从上到下、从左到右的顺序压平</span></span><br><span class="line">    pixels = img.T.flatten()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前后各加一个0作为缓冲区</span></span><br><span class="line">    pixels = np.concatenate([[<span class="number">0</span>], pixels, [<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 以下记录的是掩膜值开始发生变化的位置，使用的方法是将数组错移一位，并与原数组比较</span></span><br><span class="line">    <span class="comment"># 这样每一段重复的序列在前后位置都有一个变化的位置记录，前后位置是成对出现的</span></span><br><span class="line">    <span class="comment"># +1是为了做位置调整</span></span><br><span class="line">    runs = np.where(pixels[<span class="number">1</span>:] != pixels[:-<span class="number">1</span>])[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这一步比较抽象，首先记住runs记录了像素值发生变化的位置</span></span><br><span class="line">    <span class="comment"># runs[1::2]是从第二个位置开始，每隔两个元素提取一次，即该表达式提取的是“成对出现的前后位置”中的“后”这一位置</span></span><br><span class="line">    <span class="comment"># runs[::2]则是从第一个位置开始，每隔两个元素提取一次，即该表达式提取的是“成对出现的前后位置”中的“前”这一位置</span></span><br><span class="line">    <span class="comment"># 然后两者相减，并在原来“后”这一位置存储差值，即每个重复序列的长度</span></span><br><span class="line">    runs[<span class="number">1</span>::<span class="number">2</span>] -= runs[::<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将上述元素逐个取出，并且使用空格符连接成字符串</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> runs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用numba加速</span></span><br><span class="line"><span class="comment"># 可以参考如下nb里的讨论部分</span></span><br><span class="line"><span class="comment"># https://www.kaggle.com/leighplt/pytorch-fcn-resnet50/comments</span></span><br><span class="line"><span class="meta">@numba.njit()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask2rle_numba_1d</span>(<span class="params">pixels</span>):</span></span><br><span class="line">    size = <span class="built_in">len</span>(pixels)</span><br><span class="line">    points = []</span><br><span class="line">    <span class="keyword">if</span> pixels[<span class="number">0</span>] == <span class="number">1</span>: points.append(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, size):</span><br><span class="line">        <span class="keyword">if</span> pixels[i] != pixels[i-<span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(points) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                points.append(i+<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                points.append(i+<span class="number">1</span> - points[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pixels[-<span class="number">1</span>] == <span class="number">1</span>: points.append(size-points[-<span class="number">1</span>]+<span class="number">1</span>)   </span><br><span class="line">    <span class="keyword">return</span> points</span><br><span class="line"></span><br><span class="line"><span class="comment"># 该函数必须得与上面的分开，因为最后的join函数不支持numba</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask2rle_numba</span>(<span class="params">image</span>):</span></span><br><span class="line">    pixels = image.T.flatten()</span><br><span class="line">    points = mask2rle_numba_1d(pixels)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> points)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取训练集图像</span></span><br><span class="line"><span class="comment"># 对于大型tif图像，推荐使用rasterio来读取，读取速度会提升很多倍</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_image</span>(<span class="params">image_id, scale=<span class="literal">None</span>, verbose=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="comment"># python3.6引入的f-string，用于格式化字符串</span></span><br><span class="line">    <span class="comment"># https://blog.csdn.net/sunxb10/article/details/81036693</span></span><br><span class="line">    image = tifffile.imread(os.path.join(TRAIN_PATH, <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.tiff&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集中有几张图像是(1, 1, 3, X, Y)这样的格式，需要将其转为正确的(X, Y, 3)格式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(image.shape) == <span class="number">5</span>:</span><br><span class="line">        image = image.sequeeze().transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这个地方用到了pandas对象的布尔数组索引</span></span><br><span class="line">    <span class="comment"># https://www.pypandas.cn/docs/user_guide/indexing.html#%E7%B4%A2%E5%BC%95%E7%9A%84%E4%B8%8D%E5%90%8C%E9%80%89%E6%8B%A9</span></span><br><span class="line">    <span class="comment"># 特别需要注意的是第二个参数的顺序，这里是图像的宽度在前，高度在后</span></span><br><span class="line">    mask = rle2mask(df_train[df_train[<span class="string">&quot;id&quot;</span>] == image_id][<span class="string">&#x27;encoding&#x27;</span>].values[<span class="number">0</span>], (image.shape[<span class="number">1</span>], image.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开启详细显示信息模式</span></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Mask shape: <span class="subst">&#123;mask.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 缩放</span></span><br><span class="line">    <span class="keyword">if</span> scale:</span><br><span class="line">        <span class="comment"># 注意opencv的resize函数要求的参数是先宽后高，注意顺序</span></span><br><span class="line">        new_size = (image.shape[<span class="number">1</span>] // scale, image.shape[<span class="number">0</span>] // scale)</span><br><span class="line">        image = cv2.resize(image, new_size)</span><br><span class="line">        mask = cv2.resize(mask, new_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Mask shape: <span class="subst">&#123;mask.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image, mask</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取测试集图像</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_test_image</span>(<span class="params">image_id, scale=<span class="literal">None</span>, verbose=<span class="number">1</span></span>):</span></span><br><span class="line">    image = tifffile.imread(os.path.join(TEST_PATH, <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.tiff&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(image.shape) == <span class="number">5</span>:</span><br><span class="line">        image = image.sequeeze().tranpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> scale:</span><br><span class="line">        new_size = (image.shape[<span class="number">1</span>] // scale, image.shape[<span class="number">0</span>] // scale)</span><br><span class="line">        image = cv2.resize(image, new_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;image_id&#125;</span>] Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化图像及其掩膜</span></span><br><span class="line"><span class="comment"># 主要是应用了matplotlib库，其用法可参考如下链接</span></span><br><span class="line"><span class="comment"># https://lijin-thu.github.io/06.%20matplotlib/06.01%20pyplot%20tutorial.html</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_image_and_mask</span>(<span class="params">image, mask, image_id</span>):</span></span><br><span class="line">    <span class="comment"># 产生一幅图，指定其大小</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一行三列的子图</span></span><br><span class="line">    <span class="comment"># 这里是第一个子图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.title(<span class="string">f&quot;Image <span class="subst">&#123;image_id&#125;</span>&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二个子图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.imshow(mask, cmap=<span class="string">&quot;hot&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.title(<span class="string">f&quot;Image <span class="subst">&#123;image_id&#125;</span> + mask&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第三个子图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.imshow(mask, cmap=<span class="string">&quot;hot&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">f&quot;Mask&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化图像及其掩膜的一部分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_slice_image_and_mask</span>(<span class="params">image, mask, start_h, end_h, start_w, end_w</span>):</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line">    sub_image = image[start_h : end_h, start_w : end_w, :]</span><br><span class="line">    sub_mask = mask[start_h : end_h, start_w : end_w]</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(sub_image)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">    plt.imshow(sub_image)</span><br><span class="line">    plt.imshow(sub_mask, cmap=<span class="string">&quot;hot&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.imshow(sub_mask, cmap=<span class="string">&quot;hot&quot;</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p>依据这些工具函数，可以很方便地进行数据集的读取和调用。<br>以训练集中的某张图像为例，观察其部分原图及其标注：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">image_id = <span class="string">&quot;0486052bb&quot;</span></span><br><span class="line">image, mask = read_image(image_id, <span class="number">2</span>)</span><br><span class="line">plot_image_and_mask(image, mask, image_id)</span><br><span class="line"></span><br><span class="line">plot_slice_image_and_mask(image, mask, <span class="number">5000</span>, <span class="number">7500</span>, <span class="number">2500</span>, <span class="number">5000</span>)</span><br><span class="line">plot_slice_image_and_mask(image, mask, <span class="number">5250</span>, <span class="number">5720</span>, <span class="number">3500</span>, <span class="number">4000</span>)</span><br></pre></td></tr></table></figure><br>结果如下图：<br><img src="https://user-images.githubusercontent.com/6218739/100980887-e7719a00-3580-11eb-9dcd-2921740efa80.png" alt="vis"></p><h2 id="无网络连接安装依赖"><a href="#无网络连接安装依赖" class="headerlink" title="无网络连接安装依赖"></a>无网络连接安装依赖</h2><p>因为这个比赛的notebook不允许使用Internet，因此，如果调用了kaggle默认环境所没有的模块和包时，需要事先自己在线下准备好。<br>具体做法可以参考<a href="https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/113195">该教程</a>：<br>（1）首先打开notebook的网络，然后使用pip下载所依赖的包的whl文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip download [package_name]</span><br></pre></td></tr></table></figure><br>记住此时download的顺序以及版本号（这点一定要注意），后面要按该顺序的逆序进行安装。<br>（2）将这些whl文件上传到kaggle的dataset中；<br>这一步又涉及怎样将这些文件先下载下来，此时可以参考<a href="https://www.kaggle.com/getting-started/168312">该教程</a>：<br>一种是直接在右侧的output侧栏中点击下载；<br>一种是通过命令下载：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%cd /kaggle/working</span><br><span class="line">from IPython.display import FileLink -&gt; FileLink(r&#x27;*name of file*&#x27;)</span><br></pre></td></tr></table></figure><br>注意，在kaggle上上传非whl的安装包时，比如上传的时.tar.gz格式的源码包，kaggle会自动将其解压成文件夹。<br>因此，需要将此种文件后缀名需要更改为.xyz，然后上传。<br>上传时如果发现其他dataset仓库已经有相同的软件包，可以直接用那里的，也可以选择include duplicates上传自己的。<br>（3）在该notebook中引用上面的dataset，然后按逆序安装这些whl。<br>对于非whl的文件，注意将其copy到本地路径后，再修改为.tar.gz后缀名，然后正常pip install即可。</p><h1 id="正确提交一次和跑一遍模型"><a href="#正确提交一次和跑一遍模型" class="headerlink" title="正确提交一次和跑一遍模型"></a>正确提交一次和跑一遍模型</h1><h2 id="正确提交一次"><a href="#正确提交一次" class="headerlink" title="正确提交一次"></a>正确提交一次</h2><p>这里首先通过正确提交一次，保证提交文件是正确的，否则可能花了很多时间搭建算法和训练，最后却卡在提交上，没法及时提交。<br>因为Kaggle的submission目前看像是一个玄学，大家都在尝试怎样提交成功，比如下面的讨论：<br><a href="https://www.kaggle.com/c/tensorflow2-question-answering/discussion/116409">Scoring error on submission - even with sample_submission.csv</a><br><a href="https://www.kaggle.com/c/tensorflow2-question-answering/discussion/123466">Scoring error again</a><br>原因就是如第一个帖子中Julia所说，kaggle官方为了确保测试集不会被大家hack或产生leak，将测试集藏得很深。<br>想要提交成功，要假设测试集就在那里，且文件的ID千万不能硬编码，要做到“自适应”，同时里面的内容一开始可以全部设为0，但也注意有些竞赛对于数值也有要求，比如下面的帖子中，因为最后的score要计算Spearman系数，所以每一个array中至少要有两个不同的值：<br><a href="https://www.kaggle.com/c/google-quest-challenge/discussion/126777">Unable to fix submission scoring error</a><br>针对于此例，一个很小的提交如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">DATA_PATH = <span class="string">&#x27;../input/hubmap-kidney-segmentation&#x27;</span></span><br><span class="line">identity = rasterio.Affine(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">p = pathlib.Path(DATA_PATH)</span><br><span class="line">subm = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(p.glob(<span class="string">&#x27;test/*.tiff&#x27;</span>)):</span><br><span class="line">    dataset = rasterio.<span class="built_in">open</span>(filename.as_posix(), transform = identity)</span><br><span class="line">    preds = np.zeros(dataset.shape, dtype=np.uint8)</span><br><span class="line">    subm[i] = &#123;<span class="string">&#x27;id&#x27;</span>:filename.stem, <span class="string">&#x27;predicted&#x27;</span>: mask2rle_numba(preds)&#125;</span><br><span class="line">    <span class="keyword">del</span> preds</span><br><span class="line">    gc.collect();</span><br><span class="line"></span><br><span class="line">submission = pd.DataFrame.from_dict(subm, orient=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line">submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p><h2 id="跑一遍模型"><a href="#跑一遍模型" class="headerlink" title="跑一遍模型"></a>跑一遍模型</h2><p>这里实际是用随机权重的模型在测试集上跑一遍，保证整个流程是通路的，然后再进行模型的训练，即“以终为始”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span>():</span></span><br><span class="line">    model = torchvision.models.segmentation.fcn_resnet50(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原来的用于多类分割的模型最后一层改为目前的两类分割</span></span><br><span class="line">    model.classifier[<span class="number">4</span>] = nn.Conv2d(<span class="number">512</span>, <span class="number">1</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这一步也非常重要，因为不能有网络连接，如果不事先下载好这些权重文件，notebook运行过程中会联网下载，导致提交不成功</span></span><br><span class="line">!mkdir -p /root/.cache/torch/hub/checkpoints/</span><br><span class="line">!cp ../<span class="built_in">input</span>/pytorch-pretrained-models/resnet50-19c8e357.pth /root/.cache/torch/hub/checkpoints/</span><br><span class="line">!cp ../<span class="built_in">input</span>/pretrain-coco-weights-pytorch/fcn_resnet50_coco-1167a1af.pth /root/.cache/torch/hub/checkpoints/</span><br><span class="line"></span><br><span class="line">model = get_model()</span><br><span class="line">model.to(DEVICE);</span><br><span class="line"></span><br><span class="line">identity = rasterio.Affine(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个变换一定要与训练集的变换相同</span></span><br><span class="line">trfm = T.Compose([</span><br><span class="line">    T.ToPILImage(),</span><br><span class="line">    T.Resize(NEW_SIZE),</span><br><span class="line">    T.ToTensor(),</span><br><span class="line">    T.Normalize([<span class="number">0.625</span>, <span class="number">0.448</span>, <span class="number">0.688</span>],</span><br><span class="line">                [<span class="number">0.131</span>, <span class="number">0.177</span>, <span class="number">0.101</span>]),</span><br><span class="line">])</span><br><span class="line"> </span><br><span class="line">p = pathlib.Path(DATA_PATH)</span><br><span class="line"></span><br><span class="line">subm = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 真正使用过程中，在训练模型后，在这里要加载训练好的模型</span></span><br><span class="line"><span class="comment"># model.load_state_dict(torch.load(&quot;../input/models/HuBMAP_model_best.pth&quot;))</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历测试集中的文件</span></span><br><span class="line"><span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(p.glob(<span class="string">&#x27;test/*.tiff&#x27;</span>)):</span><br><span class="line">    <span class="comment"># 使用rasterio来打开tiff文件，实测速度会很快</span></span><br><span class="line">    <span class="comment"># transform参数是用来进行仿射变换，这里不涉及坐标系变换，可以不用</span></span><br><span class="line">    <span class="comment"># 常用用法可见：</span></span><br><span class="line">    <span class="comment"># https://theonegis.github.io/geos/%E4%BD%BF%E7%94%A8Rasterio%E8%AF%BB%E5%8F%96%E6%A0%85%E6%A0%BC%E6%95%B0%E6%8D%AE/index.html</span></span><br><span class="line">    dataset = rasterio.<span class="built_in">open</span>(filename.as_posix(), transform = identity)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 因为原始图像很大，为防止爆内存，将其分块处理</span></span><br><span class="line">    slices = make_grid(dataset.shape, window=WINDOW, min_overlap=MIN_OVERLAP)</span><br><span class="line">    <span class="comment"># 创建一个存储预测结果的缓存</span></span><br><span class="line">    preds = np.zeros(dataset.shape, dtype=np.uint8)</span><br><span class="line">    <span class="comment"># 对分块图像进行遍历</span></span><br><span class="line">    <span class="keyword">for</span> (x1,x2,y1,y2) <span class="keyword">in</span> slices:</span><br><span class="line">        <span class="comment"># read方法将rasterio的数据集格式转为numpy.ndarray</span></span><br><span class="line">        image = dataset.read([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], window=Window.from_slices((x1,x2),(y1,y2)))</span><br><span class="line">        <span class="comment"># 改变一下维度次序</span></span><br><span class="line">        image = np.moveaxis(image, <span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 与训练集采用同样的tranform变换</span></span><br><span class="line">        image = trfm(image)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="comment"># 将image放入DEVICE中，cpu或gpu</span></span><br><span class="line">            image = image.to(DEVICE)[<span class="literal">None</span>]</span><br><span class="line">            <span class="comment"># 模型对图像进行预测</span></span><br><span class="line">            <span class="comment"># 这个地方需要注意的是model的返回值</span></span><br><span class="line">            <span class="comment"># torchvision模型库中的classification和segmentation、detection的模型返回值不同</span></span><br><span class="line">            <span class="comment"># 比如，用于classification的模型，比如AlexNet，其model(X)返回的就是预测值y的tensor</span></span><br><span class="line">            <span class="comment"># 而segmentation的模型，比如fcn_resnet50，它的返回值是一个有序字典，其中的key有out和aux</span></span><br><span class="line">            <span class="comment"># 所以下面的代码需要使用out这个key来获得预测值tensor</span></span><br><span class="line">            <span class="comment"># 可以参考：</span></span><br><span class="line">            <span class="comment"># https://pytorch.org/docs/stable/torchvision/models.html</span></span><br><span class="line">            <span class="comment"># https://github.com/pytorch/vision/blob/d0063f3d83beac01e85f3027c4de6499a8985469/torchvision/models/segmentation/fcn.py#L9</span></span><br><span class="line">            <span class="comment"># https://colab.research.google.com/github/spmallick/learnopencv/blob/master/PyTorch-Segmentation-torchvision/intro-seg.ipynb#scrollTo=ZsIngeXleQ1H</span></span><br><span class="line">            score = model(image)[<span class="string">&#x27;out&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 这个得分有可能是负的，为了一致性，将其使用sigmoid激活，转为0到1</span></span><br><span class="line">            score_sigmoid = score.sigmoid().cpu().numpy()</span><br><span class="line">            score_sigmoid = cv2.resize(score_sigmoid, (WINDOW, WINDOW))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 以0.5作为阈值，输出mask</span></span><br><span class="line">            preds[x1:x2,y1:y2] = (score_sigmoid &gt; <span class="number">0.5</span>).astype(np.uint8)</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># 将预测值转为RLE编码</span></span><br><span class="line">    subm[i] = &#123;<span class="string">&#x27;id&#x27;</span>:filename.stem, <span class="string">&#x27;predicted&#x27;</span>: mask2rle_numba(preds)&#125;</span><br><span class="line">    <span class="comment"># 删除临时变量</span></span><br><span class="line">    <span class="keyword">del</span> preds</span><br><span class="line">    <span class="comment"># 回收内存，防止内部爆掉，这一步非常重要</span></span><br><span class="line">    gc.collect();</span><br><span class="line"></span><br><span class="line">submission = pd.DataFrame.from_dict(subm, orient=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line">submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h1 id="制作数据集"><a href="#制作数据集" class="headerlink" title="制作数据集"></a>制作数据集</h1><p>因为原始图像太大了，单张甚至达到5G大小，极易爆内存，因此需要将其切分成小图像，才能进行可行的训练。</p><h2 id="在线制作数据集"><a href="#在线制作数据集" class="headerlink" title="在线制作数据集"></a>在线制作数据集</h2><p>这一节之所以称为“在线制作”，是因为数据集的加载和切分都是在程序运行时才开始进行，与之对应的，下面一节采用的是事先将原来的数据集切分好，等到用的时候直接读入即可。<br>这一节的在线制作是直接制作了适用于PyTorch的数据集格式，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line">identity = rasterio.Affine(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义数据集的制作可以参考如下链接：</span></span><br><span class="line"><span class="comment"># https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HubDataset</span>(<span class="params">D.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root_dir, transform,</span></span></span><br><span class="line"><span class="function"><span class="params">                 window=<span class="number">256</span>, overlap=<span class="number">32</span>, threshold = <span class="number">100</span></span>):</span></span><br><span class="line">        <span class="comment"># 加载路径使用pathlib，后续推荐使用它来替代os.path</span></span><br><span class="line">        <span class="comment"># 具体使用方法可以参考：</span></span><br><span class="line">        <span class="comment"># https://docs.python.org/zh-cn/3/library/pathlib.html</span></span><br><span class="line">        self.path = pathlib.Path(root_dir)</span><br><span class="line">        self.overlap = overlap</span><br><span class="line">        self.window = window</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.csv = pd.read_csv((self.path / <span class="string">&#x27;train.csv&#x27;</span>).as_posix(),</span><br><span class="line">                               index_col=[<span class="number">0</span>])</span><br><span class="line">        self.threshold = threshold</span><br><span class="line">        self.x, self.y = [], []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 运行下面的分块函数</span></span><br><span class="line">        self.build_slices()</span><br><span class="line">        self.<span class="built_in">len</span> = <span class="built_in">len</span>(self.x)</span><br><span class="line">        self.as_tensor = T.Compose([</span><br><span class="line">            <span class="comment"># ToTensor函数接受PIL Image或numpy.ndarray，将其先由HWC转置为CHW格式，再转为float后每个像素除以255，</span></span><br><span class="line">            <span class="comment"># 从而将数据范围变换到[0, 1]之间</span></span><br><span class="line">            <span class="comment"># https://www.cnblogs.com/ocean1100/p/9494640.html</span></span><br><span class="line">            T.ToTensor(),</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 标准化的操作是减去均值并除以标准差，即将数据变换为均值为0、标准差为1的标准正态分布</span></span><br><span class="line">            <span class="comment"># 之所以标准化，常用的解释是：（1）突出特征；（2）方便反向传播的计算，具体讨论可以参考：</span></span><br><span class="line">            <span class="comment"># http://www.soolco.com/post/62169_1_1.html</span></span><br><span class="line">            T.Normalize([<span class="number">0.625</span>, <span class="number">0.448</span>, <span class="number">0.688</span>],</span><br><span class="line">                        [<span class="number">0.131</span>, <span class="number">0.177</span>, <span class="number">0.101</span>]),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分块</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_slices</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.masks = []</span><br><span class="line">        self.files = []</span><br><span class="line">        self.slices = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.csv.index.values):</span><br><span class="line">            filepath = (self.path /<span class="string">&#x27;train&#x27;</span>/(filename+<span class="string">&#x27;.tiff&#x27;</span>)).as_posix()</span><br><span class="line">            self.files.append(filepath)</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Transform&#x27;</span>, filename)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> rasterio.<span class="built_in">open</span>(filepath, transform = identity) <span class="keyword">as</span> dataset:</span><br><span class="line">                self.masks.append(rle_decode(self.csv.loc[filename, <span class="string">&#x27;encoding&#x27;</span>], dataset.shape))</span><br><span class="line">                slices = make_grid(dataset.shape, window=self.window, min_overlap=self.overlap)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 排除掉一些没有目标对象的分块</span></span><br><span class="line">                <span class="keyword">for</span> slc <span class="keyword">in</span> tqdm(slices):</span><br><span class="line">                    x1,x2,y1,y2 = slc</span><br><span class="line">                    <span class="keyword">if</span> self.masks[-<span class="number">1</span>][x1:x2,y1:y2].<span class="built_in">sum</span>() &gt; self.threshold <span class="keyword">or</span> np.random.randint(<span class="number">100</span>) &gt; <span class="number">120</span>:</span><br><span class="line">                        self.slices.append([i,x1,x2,y1,y2])</span><br><span class="line"></span><br><span class="line">                        image = dataset.read([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">                            window=Window.from_slices((x1,x2),(y1,y2)))</span><br><span class="line"></span><br><span class="line">                         <span class="comment"># if image.std().mean() &lt; 10:</span></span><br><span class="line">                         <span class="comment">#     continue</span></span><br><span class="line"></span><br><span class="line">                         <span class="comment"># print(image.std().mean(), self.masks[-1][x1:x2,y1:y2].sum())</span></span><br><span class="line"></span><br><span class="line">                        image = np.moveaxis(image, <span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">                        self.x.append(image)</span><br><span class="line">                        self.y.append(self.masks[-<span class="number">1</span>][x1:x2,y1:y2])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get data operation</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        image, mask = self.x[index], self.y[index]</span><br><span class="line">        augments = self.transform(image=image, mask=mask)</span><br><span class="line">        <span class="keyword">return</span> self.as_tensor(augments[<span class="string">&#x27;image&#x27;</span>]), augments[<span class="string">&#x27;mask&#x27;</span>][<span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Total number of samples in the dataset</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line">WINDOW=<span class="number">1024</span></span><br><span class="line">MIN_OVERLAP=<span class="number">32</span></span><br><span class="line">NEW_SIZE=<span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># albumentations是一个基于OpenCV的数据增强库，拥有非常简单且强大的可以用于多种任务（分割、检测）的接口，易于定制且添加其他框架非常方便。</span></span><br><span class="line"><span class="comment"># 它可以对数据集进行逐像素的转换，如模糊、下采样、高斯噪声、高斯模糊、动态模糊、RGB转换、随机雾化等；</span></span><br><span class="line"><span class="comment"># 也可以进行空间转换（同时也会对目标标签进行转换），如裁剪、翻转、随机裁剪等</span></span><br><span class="line"><span class="comment"># 数据增强的方式是这样的：</span></span><br><span class="line"><span class="comment"># 比如在一个epoch之内，我是把所有的图片都过一遍，对于每张图片我都是进行一个transform的操作，比如transform内部有0.5的概率进行左右flip，</span></span><br><span class="line"><span class="comment"># 那么这张图片左右flip的概率就是0.5，可能这一个epoch不flip，下一个epoch就会flip.</span></span><br><span class="line"><span class="comment"># 换句话说，现有的数据增强是带有随机性的，比如是否随机镜像翻转，随机crop的时候选择哪块区域，加多强的噪声等，每次增强的结果可能都不一样，</span></span><br><span class="line"><span class="comment"># 这样模型相当于看到了很多份不同的图像。如果没有概率性的操作，即p=1， 做一次增强之后便不再变化，则和不做增强是等价的，即模型在整个训练过程中只能看到一份相同的不断重复的数据。</span></span><br><span class="line"><span class="comment"># 可以详见</span></span><br><span class="line"><span class="comment"># https://discuss.gluon.ai/t/topic/1666</span></span><br><span class="line">trfm = A.Compose([</span><br><span class="line">    A.Resize(NEW_SIZE,NEW_SIZE),</span><br><span class="line">    A.HorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">    A.VerticalFlip(p=<span class="number">0.5</span>),</span><br><span class="line"></span><br><span class="line">    A.OneOf([</span><br><span class="line">        A.RandomContrast(),</span><br><span class="line">        A.RandomGamma(),</span><br><span class="line">        A.RandomBrightness(),</span><br><span class="line">        A.ColorJitter(brightness=<span class="number">0.07</span>, contrast=<span class="number">0.07</span>,</span><br><span class="line">                   saturation=<span class="number">0.1</span>, hue=<span class="number">0.1</span>, always_apply=<span class="literal">False</span>, p=<span class="number">0.3</span>),</span><br><span class="line">        ], p=<span class="number">0.3</span>),</span><br><span class="line"></span><br><span class="line">    A.OneOf([</span><br><span class="line">        A.ElasticTransform(alpha=<span class="number">120</span>, sigma=<span class="number">120</span> * <span class="number">0.05</span>, alpha_affine=<span class="number">120</span> * <span class="number">0.03</span>),</span><br><span class="line">        A.GridDistortion(),</span><br><span class="line">        A.OpticalDistortion(distort_limit=<span class="number">2</span>, shift_limit=<span class="number">0.5</span>),</span><br><span class="line">        ], p=<span class="number">0.0</span>),</span><br><span class="line">    A.ShiftScaleRotate(),</span><br><span class="line">])</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型库里的模型时，有的模型所需要的输入图像的尺寸是固定的，比如必须是64*64等，所以在图像增强后要保证图像的尺寸满足该要求。</span></span><br><span class="line"><span class="comment"># 可以采取以下方法来满足任意图像尺寸的输入：</span></span><br><span class="line"><span class="comment">#（1）传统办法：预处理，也就是边缘补0，或者切割，或者重采样、resize来得到相同大小的输入图片作为input。</span></span><br><span class="line"><span class="comment">#（2）模型方法：使用Kaiming He大佬的SPP-Net可以输入任意大小的图片，原文arxiv地址：https://arxiv.org/abs/1406.4729</span></span><br><span class="line"><span class="comment">#（3）优雅方法：加一层torch.nn.AdaptiveMaxPool2d。</span></span><br><span class="line"><span class="comment"># 具体讨论可以见</span></span><br><span class="line"><span class="comment"># https://www.zhihu.com/question/45873400</span></span><br><span class="line"></span><br><span class="line">ds = HubDataset(DATA_PATH, window=WINDOW, overlap=MIN_OVERLAP, transform=trfm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分验证集和训练集</span></span><br><span class="line">valid_idx, train_idx = [], []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ds)):</span><br><span class="line">    <span class="comment"># 挑出第8张图片的所有切片作为验证集</span></span><br><span class="line">    <span class="keyword">if</span> ds.slices[i][<span class="number">0</span>] == <span class="number">7</span>:</span><br><span class="line">        valid_idx.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        train_idx.append(i)</span><br><span class="line"></span><br><span class="line">train_ds = D.Subset(ds, train_idx)</span><br><span class="line">valid_ds = D.Subset(ds, valid_idx)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define training and validation data loaders</span></span><br><span class="line">loader = D.DataLoader(</span><br><span class="line">    train_ds, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">vloader = D.DataLoader(</span><br><span class="line">    valid_ds, batch_size=BATCH_SIZE, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p><h2 id="离线制作数据集"><a href="#离线制作数据集" class="headerlink" title="离线制作数据集"></a>离线制作数据集</h2><p>如上所述，上述制作数据集的方式是离线进行的，该数据集准备过程参考了如下notebook：<br><a href="https://www.kaggle.com/iafoss/256x256-images">256x256 images</a><br>具体切分方式与上面在线制作时不同，但表达的意思相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对迭代器进行tqdm封装，传入total参数来指明预计迭代次数</span></span><br><span class="line"><span class="comment"># https://ptorch.com/news/170.html</span></span><br><span class="line"><span class="comment"># 如果想选择dataframe某一行作为测试，可以参考dataframe各种索引方法</span></span><br><span class="line"><span class="comment"># https://www.jianshu.com/p/32bfb327bf07</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, rles <span class="keyword">in</span> tqdm(df_mask.iterrows(), total=<span class="built_in">len</span>(df_mask)):</span><br><span class="line">    <span class="built_in">print</span>(index)</span><br><span class="line">    img, mask = read_image(index)</span><br><span class="line">    shape = img.shape</span><br><span class="line">    tile_before_compress = compress * tile_size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算填充量，使得可以整除</span></span><br><span class="line">    pad0 = tile_before_compress - shape[<span class="number">0</span>] % tile_before_compress</span><br><span class="line">    pad1 = tile_before_compress - shape[<span class="number">1</span>] % tile_before_compress</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用0填充</span></span><br><span class="line">    <span class="comment"># https://numpy.org/doc/stable/reference/generated/numpy.pad.html</span></span><br><span class="line">    <span class="comment"># 对于img，x和y两个维度都填充，第三维度则不填充，所以第三维度设为(0, 0)</span></span><br><span class="line">    img = np.pad(img, ((pad0 // <span class="number">2</span>, pad0 - pad0 // <span class="number">2</span>), (pad1 // <span class="number">2</span>, pad1 - pad1 // <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>)), constant_values=<span class="number">0</span>)</span><br><span class="line">    mask = np.pad(mask, ((pad0 // <span class="number">2</span>, pad0 - pad0 // <span class="number">2</span>), (pad1 // <span class="number">2</span>, pad1 - pad1 // <span class="number">2</span>)), constant_values=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 压缩图像</span></span><br><span class="line">    img = cv2.resize(img, (img.shape[<span class="number">1</span>]//compress, img.shape[<span class="number">0</span>]//compress), interpolation = cv2.INTER_AREA)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将图像分块成tile大小</span></span><br><span class="line">    img = img.reshape(img.shape[<span class="number">0</span>] // tile_size, tile_size, img.shape[<span class="number">1</span>] // tile_size, tile_size, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将图像的通道调整顺序，横纵个数放在前面，然后让两者相乘，得到分块总个数</span></span><br><span class="line">    img = img.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>).reshape(-<span class="number">1</span>, tile_size, tile_size, <span class="number">3</span>)</span><br><span class="line">    mask = cv2.resize(mask, (mask.shape[<span class="number">1</span>]//compress, mask.shape[<span class="number">0</span>]//compress), interpolation = cv2.INTER_AREA)</span><br><span class="line">    mask = mask.reshape(mask.shape[<span class="number">0</span>] // tile_size, tile_size, mask.shape[<span class="number">1</span>] // tile_size, tile_size)</span><br><span class="line">    mask = mask.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).reshape(-<span class="number">1</span>, tile_size, tile_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用zip函数将img和mask中的元素打包在一块，统一调用</span></span><br><span class="line">    <span class="comment"># https://www.runoob.com/python3/python3-func-zip.html</span></span><br><span class="line">    <span class="keyword">for</span> i, (im, m) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(img, mask)):</span><br><span class="line">        x_tot.append((im / <span class="number">255.0</span>).reshape(-<span class="number">1</span>, <span class="number">3</span>).mean(<span class="number">0</span>))</span><br><span class="line">        x2_tot.append((im / <span class="number">255.0</span>).reshape(-<span class="number">1</span>, <span class="number">3</span>).mean(<span class="number">0</span>))</span><br><span class="line">        cv2.imwrite(OUT_IMG + <span class="string">f&#x27;<span class="subst">&#123;index&#125;</span>_<span class="subst">&#123;i&#125;</span>.png&#x27;</span>, cv2.cvtColor(im, cv2.COLOR_RGB2BGR))</span><br><span class="line">        cv2.imwrite(OUT_MASK + <span class="string">f&#x27;<span class="subst">&#123;index&#125;</span>_<span class="subst">&#123;i&#125;</span>.png&#x27;</span>, m)</span><br><span class="line"></span><br><span class="line">img_avr = np.array(x_tot).mean(<span class="number">0</span>)</span><br><span class="line">img_std = np.sqrt(np.array(x2_tot).mean(<span class="number">0</span>) - img_avr**<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mean: &quot;</span>, img_avr, <span class="string">&quot;, std:&quot;</span>, img_std)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>首先通过上面的get_model()加载模型，然后再定义一系列的必要步骤，包括优化器、损失评价等，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义Soft Dice Loss</span></span><br><span class="line"><span class="comment"># 网友总结了用于图像分割的常用的损失函数的PyTorch实现，见：</span></span><br><span class="line"><span class="comment"># https://github.com/JunMa11/SegLoss</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftDiceLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, smooth=<span class="number">1.</span>, dims=(<span class="params">-<span class="number">2</span>,-<span class="number">1</span></span>)</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SoftDiceLoss, self).__init__()</span><br><span class="line">        self.smooth = smooth</span><br><span class="line">        self.dims = dims</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        tp = (x * y).<span class="built_in">sum</span>(self.dims)</span><br><span class="line">        fp = (x * (<span class="number">1</span> - y)).<span class="built_in">sum</span>(self.dims)</span><br><span class="line">        fn = ((<span class="number">1</span> - x) * y).<span class="built_in">sum</span>(self.dims)</span><br><span class="line">        dc = (<span class="number">2</span> * tp + self.smooth) / (<span class="number">2</span> * tp + fp + fn + self.smooth)</span><br><span class="line">        dc = dc.mean()</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> - dc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数1</span></span><br><span class="line">bce_fn = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数2</span></span><br><span class="line">dice_fn = SoftDiceLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终损失是两种损失函数的加权平均</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_fn</span>(<span class="params">y_pred, y_true</span>):</span></span><br><span class="line">    bce = bce_fn(y_pred, y_true)</span><br><span class="line">    dice = dice_fn(y_pred.sigmoid(), y_true)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.8</span>*bce+ <span class="number">0.2</span>*dice</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在验证集上运行模型</span></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validation</span>(<span class="params">model, loader, loss_fn</span>):</span></span><br><span class="line">    losses = []</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> image, target <span class="keyword">in</span> loader:</span><br><span class="line">        image, target = image.to(DEVICE), target.<span class="built_in">float</span>().to(DEVICE)</span><br><span class="line">        output = model(image)[<span class="string">&#x27;out&#x27;</span>]</span><br><span class="line">        loss = loss_fn(output, target)</span><br><span class="line">        losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(losses).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">### 为了让中间输出结果好看，专门定制了一个显示效果</span></span><br><span class="line">header = <span class="string">r&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Train | Valid</span></span><br><span class="line"><span class="string">Epoch |  Loss |  Loss | Time, m</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#          Epoch         metrics            time</span></span><br><span class="line">raw_line = <span class="string">&#x27;&#123;:6d&#125;&#x27;</span> + <span class="string">&#x27;\u2502&#123;:7.3f&#125;&#x27;</span>*<span class="number">2</span> + <span class="string">&#x27;\u2502&#123;:6.2f&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line">best_loss = <span class="number">10</span></span><br><span class="line">EPOCHES = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始迭代训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, EPOCHES+<span class="number">1</span>):</span><br><span class="line">    losses = []</span><br><span class="line">    <span class="comment"># 计时开始</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这里显式地设置model是train模式，以使dropout和batchnorm等网络层中的参数不固定</span></span><br><span class="line">    <span class="comment"># 它仅仅是一个flag，与之类似的：model.eval()是设定eval模式，即这些网络层中的参数固定，以保证测试结果的可重复性</span></span><br><span class="line">    <span class="comment"># https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch</span></span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始在训练集数据中迭代</span></span><br><span class="line">    <span class="keyword">for</span> image, target <span class="keyword">in</span> loader:</span><br><span class="line">        image, target = image.to(DEVICE), target.<span class="built_in">float</span>().to(DEVICE)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(image)[<span class="string">&#x27;out&#x27;</span>]</span><br><span class="line">        loss = loss_fn(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在验证集上运行模型</span></span><br><span class="line">    vloss = validation(model, vloader, loss_fn)</span><br><span class="line">    <span class="built_in">print</span>(raw_line.<span class="built_in">format</span>(epoch, np.array(losses).mean(), vloss,</span><br><span class="line">                              (time.time()-start_time)/<span class="number">60</span>**<span class="number">1</span>))</span><br><span class="line">    losses = []</span><br><span class="line">    <span class="comment"># 及时地将最佳模型存储下来</span></span><br><span class="line">    <span class="keyword">if</span> vloss &lt; best_loss:</span><br><span class="line">        best_loss = vloss</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&#x27;model_best.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练结束后删除这些存储数据地变量，并回收内存</span></span><br><span class="line"><span class="keyword">del</span> loader, vloader, train_ds, valid_ds, ds</span><br><span class="line">gc.collect();</span><br></pre></td></tr></table></figure></p><p>训练完后的模型就开始接下来在上面的测试集上进行推导，并提交结果文件（注意在kaggle上提交时，可以把前面的训练过程去掉，直接提交训练好的模型）。</p>]]></content>
    
    
    <summary type="html">概览
赛事描述
Kaggle上正在进行一项名为“HuBMAP: Hacking the Kidney”的竞赛，链接见这里，总奖金是6万美金，该竞赛的目的是为了检测人体组织中的functional tissue units (FTUs)。FTU的定义是：three-dimensional block of cells centered around a capillary, such that each cell in this block is within diffusion distance from any other cell in the same block，感觉类似于细胞的概念，</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="kaggle" scheme="http://qixinbo.github.io/tags/kaggle/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法笔记</title>
    <link href="http://qixinbo.github.io/2020/12/26/algorithm/"/>
    <id>http://qixinbo.github.io/2020/12/26/algorithm/</id>
    <published>2020-12-25T16:00:00.000Z</published>
    <updated>2021-03-26T06:44:49.138Z</updated>
    
    <content type="html"><![CDATA[<p>本文是对极客时间app上王争老师的&lt;数据结构与算法之美&gt;的课堂笔记。</p><h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><p>算法与数据结构是编程的内功。</p><p>从广义上讲，数据结构就是指一组数据的存储和逻辑结构。算法就是操作数据的一组方法。</p><p>数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。 因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。（比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。）</p><p><img src="https://user-images.githubusercontent.com/6218739/100428771-548fb600-30cf-11eb-99f1-a46d7204f313.png" alt="base"></p><p><img src="https://user-images.githubusercontent.com/6218739/100430003-29a66180-30d1-11eb-9cf3-1e09f6111ded.png" alt="algo"></p><p>数据结构与算法中最重要的概念——复杂度分析：数据结构和算法解决的是如何更省、更快地存储和处理数据的问题，因此，我们就需要一个考量效率和资源消耗的方法，这就是复杂度分析方法。所以，如果你只掌握了数据结构和算法的特点、用法，但是没有学会复杂度分析，那就相当于只知道操作口诀，而没掌握心法。只有把心法了然于胸，才能做到无招胜有招！</p><h1 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h1><h2 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h2><p>时间复杂度：大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。</p><p>实际分析时间复杂度时就是计算代码执行次数。</p><p>（1）加法法则：总复杂度等于量级最大的那段代码的复杂度（如果两段代码复杂度无法事先评估，则此时需要两者复杂度相加）；</p><p>（2）乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。</p><p>常见复杂度量级（按数量级递增）：常数阶O(1)（只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度都记作 O(1)）、对数阶O(logn)、线性阶O(n)、线性对数阶O(nlogn)、平方阶O(n^2)、立方阶O(n^3)、…、k次方阶O(n^k)、指数阶O(2^n)、阶乘阶O(n!)。</p><p>为了表示代码在不同情况下的不同时间复杂度，需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。</p><p>最好情况时间复杂度（best case time complexity）：在最理想的情况下，执行这段代码的时间复杂度。</p><p>最坏情况时间复杂度（worst case time complexity）：在最糟糕的情况下，执行这段代码的时间复杂度。</p><p>平均情况时间复杂度（average case time complexity）：最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，使用平均情况时间复杂度，计算方法是将各种情况按权值加和，得到平均值，所以又称为加权平均时间复杂度或者期望时间复杂度。</p><p>实际上，在大多数情况下，并不需要区分最好、最坏、平均情况时间复杂度三种情况。很多时候，使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，才会使用这三种复杂度表示法来区分。</p><h2 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h2><p>空间复杂度全称是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。</p><p>常见的空间复杂度就是 O(1)、O(n)、O(n^2)。</p><p>空间复杂度是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。</p><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><p>数组结构有线性表Linear List和非线性表Nonlinear List之分。</p><p>线性表是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。数组、链表、队列、栈等是线性表结构。</p><p>在非线性表中，数据之间并不是简单的前后关系，比如二叉树、堆、图等。</p><h2 id="数组Array"><a href="#数组Array" class="headerlink" title="数组Array"></a>数组Array</h2><p>数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。</p><p>这两个特性使得数组可以“随机访问”，即数组适合“查找”，但同时也会造成低效的“插入”和“删除”。</p><p>插入操作：假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。这个处理思想在快排中也会用到。</p><p>删除操作：跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。这就是 JVM 标记清除垃圾回收算法的核心思想。</p><p>针对数组类型，很多语言都提供了容器类，比如 Java 中的 ArrayList、C++ STL 中的 vector。容器可以将很多数组操作的细节封装起来，且支持动态扩容。但数组也有优点，其作为基本数据结构，在极端情况下有性能优势。</p><p>为什么数组从0开始编号：从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。如果从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。另外一个原因是历史原因，C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。</p><h2 id="链表Linked-List"><a href="#链表Linked-List" class="headerlink" title="链表Linked List"></a>链表Linked List</h2><p>链表不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。内存块称为“结点”。</p><p>三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表。</p><p>单链表：为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。把这个记录下个结点地址的指针叫作后继指针 next。其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。但因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。</p><p>利用哨兵简化难度：把有哨兵结点的链表叫带头链表。相反，没有哨兵结点的链表就叫作不带头链表。如果引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。如果没有哨兵结点，针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。（实际上，这种利用哨兵简化编程难度的技巧，在很多代码实现中都有用到，比如插入排序、归并排序、动态规划等。）</p><p>循环链表：循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。</p><p>双向链表：双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。</p><p>从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。原因如下：</p><p>在实际的软件开发中，从链表中删除一个数据无外乎这两种情况：</p><p>（1）删除结点中“值等于某个给定值”的结点；</p><p>（2）删除给定指针指向的结点。</p><p>对于第一种情况，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过指针操作将其删除。尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。</p><p>对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p-&gt;next=q，说明 p 是 q 的前驱结点。但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。</p><p>除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。</p><p>因此，在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。这就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。</p><h2 id="跳表Skip-List"><a href="#跳表Skip-List" class="headerlink" title="跳表Skip List"></a>跳表Skip List</h2><p>链表加多级索引的结构，就是跳表。比如每两个结点提取一个结点到上一级，我们把抽出来的那一级叫做索引或索引层。</p><p>在跳表中查询任意数据的时间复杂度是 O(logn)，这个查找的时间复杂度跟二分查找是一样的。换句话说，其实是基于单链表实现了二分查找，不过这种查询效率的提升，前提是建立了很多级索引，也就是用空间换时间的设计思路。</p><p>跳表的空间复杂度是 O(n)。实际上，在软件开发中，我们不必太在意索引占用的额外空间。在讲数据结构和算法时，我们习惯性地把要处理的数据看成整数，但是在实际的软件开发中，原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略了。</p><p>实际上，跳表这个动态数据结构，不仅支持查找操作，还支持动态的插入、删除操作，而且插入、删除操作的时间复杂度也是 O(logn)。</p><p>因此，跳表是一种各方面性能都比较优秀的动态数据结构，可以支持快速地插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树（Red-black tree）。不过，跳表也不能完全替代红黑树。因为红黑树比跳表的出现要早一些，很多编程语言中的 Map 类型都是通过红黑树来实现的。我们做业务开发的时候，直接拿来用就可以了，不用费劲自己去实现一个红黑树，但是跳表并没有一个现成的实现，所以在开发中，如果你想使用跳表，必须要自己实现。</p><h2 id="栈Stack"><a href="#栈Stack" class="headerlink" title="栈Stack"></a>栈Stack</h2><p>后进者先出，先进者后出，这就是典型的“栈”结构。</p><p>事实上，从功能上来说，数组或链表确实可以替代栈，但特定的数据结构是对特定场景的抽象，而且，数组或链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然也就更容易出错。当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构。</p><p>栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作顺序栈，用链表实现的栈，我们叫作链式栈。</p><p>不管是顺序栈还是链式栈，我们存储数据只需要一个大小为 n 的数组就够了。在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度是 O(1)（注意，这里存储数据需要一个大小为 n 的数组，并不是说空间复杂度就是 O(n)。因为，这 n 个空间是必须的，无法省掉。）。</p><p>不管是顺序栈还是链式栈，入栈、出栈只涉及栈顶个别数据的操作，所以时间复杂度都是 O(1)。</p><p>栈在函数调用中的应用：操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。</p><p>栈在表达式求值中的应用：比如一个只包含加减乘除四则运算的算术表达式，编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。</p><p><img src="https://user-images.githubusercontent.com/6218739/100187781-c88d5b00-2f23-11eb-9b58-89281033ad3e.png" alt="stack"></p><p>栈在括号匹配中的应用：我们用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如“(”跟“)”匹配，“[”跟“]”匹配，“{”跟“}”匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。</p><p>内存中的堆栈和数据结构堆栈不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构。内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。</p><p>代码区：存储方法体的二进制代码。高级调度（作业调度）、中级调度（内存调度）、低级调度（进程调度）控制代码区执行代码的切换。</p><p>静态数据区：存储全局变量、静态变量、常量，常量包括final修饰的常量和String常量。系统自动分配和回收。</p><p>栈区：存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。</p><p>堆区：new一个对象的引用或地址存储在栈区，指向该对象存储在堆区中的真实数据。</p><h2 id="队列Queue"><a href="#队列Queue" class="headerlink" title="队列Queue"></a>队列Queue</h2><p>先进者先出，这就是典型的“队列”。</p><p>我们知道，栈只支持两个基本操作：入栈 push()和出栈 pop()。队列跟栈非常相似，支持的操作也很有限，最基本的操作也是两个：入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。</p><p>作为一种非常基础的数据结构，队列的应用也非常广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。</p><p>跟栈一样，队列可以用数组来实现，也可以用链表来实现。用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。</p><p>对于栈来说，我们只需要一个栈顶指针就可以了。但是实现队列需要两个指针：一个是 head 指针，指向队头；一个是 tail 指针，指向队尾。</p><p>用数组来实现队列的时候，在 tail==n 时，会有数据搬移操作，这样入队操作性能就会受到影响。此时可以使用循环队列（循环队列，顾名思义，它长得像一个环。原本数组是有头有尾的，是一条直线。现在我们把首尾相连，扳成了一个环。）。</p><p>一些在业务中常用的队列应用：</p><p>（1）阻塞队列：其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。上述的定义就是一个“生产者 - 消费者模型”。这种基于阻塞队列实现的“生产者 - 消费者模型”，可以有效地协调生产和消费的速度。当“生产者”生产数据的速度过快，“消费者”来不及消费时，存储数据的队列很快就会满了。这个时候，生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续“生产”。而且不仅如此，基于阻塞队列，我们还可以通过协调“生产者”和“消费者”的个数，来提高数据的处理效率。比如可以多配置几个“消费者”，来应对一个“生产者”。</p><p>（2）并发队列：线程安全的队列我们叫作并发队列。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。</p><p>对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。</p><p>有一种特殊的队列，称为优先级队列：优先级队列，顾名思义，它首先应该是一个队列。队列最大的特性就是先进先出。不过，在优先级队列中，数据的出队顺序不是先进先出，而是按照优先级来，优先级最高的，最先出队。优先级队列这一概念可以由下面的“堆”这一数据结构来高效实现。</p><h2 id="散列表Hash-Table"><a href="#散列表Hash-Table" class="headerlink" title="散列表Hash Table"></a>散列表Hash Table</h2><p>散列表，又称哈希表、Hash表，用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。</p><p>散列表用的就是数组支持按照下标随机访问时，时间复杂度是 O(1) 的特性。我们通过散列函数（或称哈希函数、Hash函数）把元素的键值key映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。</p><p>散列函数：散列函数，顾名思义，它是一个函数。我们可以把它定义成 hash(key)，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。</p><p>散列函数设计的三点基本要求：</p><p>（1）散列函数计算得到的散列值是一个非负整数（因为数组下标是从 0 开始的）；</p><p>（2）如果 key1 = key2，那 hash(key1) == hash(key2)；</p><p>（3）如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。</p><p>第三点要求看起来合情合理，但是在真实的情况下，要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的。即便像业界著名的MD5、SHA、CRC等哈希算法，也无法完全避免这种散列冲突。而且，因为数组的存储空间有限，也会加大散列冲突的概率。所以我们几乎无法找到一个完美的无冲突的散列函数，即便能找到，付出的时间成本、计算成本也是很大的，所以针对散列冲突问题，我们需要通过其他途径来解决。</p><p>常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。</p><p>（1）开放寻址法：开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。一个比较简单的重新探测新的位置的方法是线性探测（Linear Probing）。当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。</p><p>当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。</p><p>（2）链表法：链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。当插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)。当查找、删除一个元素时，我们同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。那查找或删除操作的时间复杂度跟链表的长度 k 成正比，也就是 O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。</p><p>基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。</p><p>散列表这种数据结构虽然支持非常高效的数据插入、删除、查找操作，但是散列表中的数据都是通过散列函数打乱之后无规律存储的。也就说，它无法支持按照某种顺序快速地遍历数据。如果希望按照顺序遍历散列表中的数据，那我们需要将散列表中的数据拷贝到数组中，然后排序，再遍历。因为散列表是动态数据结构，不停地有数据的插入、删除，所以每当我们希望按顺序遍历散列表中的数据的时候，都需要先排序，那效率势必会很低。为了解决这个问题，我们将散列表和链表（或者跳表）结合在一起使用。</p><h2 id="位图Bitmap"><a href="#位图Bitmap" class="headerlink" title="位图Bitmap"></a>位图Bitmap</h2><p>位图是一种比较“特殊”的散列表。</p><p>位图是用一个 bit 位来标记某个元素对应的 value， 而 key 即是该元素。由于采用了 bit 为单位来存储数据，因此在存储空间方面，可以大大节省。</p><h2 id="布隆过滤器Bloom-Filter"><a href="#布隆过滤器Bloom-Filter" class="headerlink" title="布隆过滤器Bloom Filter"></a>布隆过滤器Bloom Filter</h2><p>布隆过滤器是对位图数据结构的一种改进。</p><p>布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。</p><h2 id="树Tree"><a href="#树Tree" class="headerlink" title="树Tree"></a>树Tree</h2><p>树中的几个概念：树中的每个元素叫做“节点”；用来连接相邻节点之间的关系，叫做“父子关系”。没有父节点的节点叫做根节点。把没有子节点的节点叫做叶子节点或者叶节点。</p><p>节点的高度：该节点到叶子节点的最长路径（边数）；</p><p>节点的深度：根节点到该节点所经历的边的个数；</p><p>节点的层数：节点的深度+1；</p><p>树的高度：根节点的高度。</p><h3 id="二叉树Binary-Tree"><a href="#二叉树Binary-Tree" class="headerlink" title="二叉树Binary Tree"></a>二叉树Binary Tree</h3><p>二叉树，顾名思义，每个节点最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。不过，二叉树并不要求每个节点都有两个子节点，有的节点只有左子节点，有的节点只有右子节点。</p><p>除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树叫做满二叉树。</p><p>叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做完全二叉树。（堆其实就是一种完全二叉树，最常用的存储方式就是数组。）</p><p>有两种方法可用于存储一棵二叉树，一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法。对于链式存储：每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针，大部分二叉树代码都是通过这种结构来实现的；对于基于数组的顺序存储法：把根节点存储在下标 i = 1 的位置，那左子节点存储在下标 2 <em> i = 2 的位置，右子节点存储在 2 </em> i + 1 = 3 的位置，因此如果节点 X 存储在数组中下标为 i 的位置，下标为 2 <em> i 的位置存储的就是左子节点，下标为 2 </em> i + 1 的位置存储的就是右子节点。反过来，下标为 i/2 的位置存储就是它的父节点。通过这种方式，我们只要知道根节点存储的位置（一般情况下，为了方便计算子节点，根节点会存储在下标为 1 的位置），这样就可以通过下标计算，把整棵树都串起来。</p><p>对于完全二叉树，仅仅“浪费”了一个下标为 0 的存储位置。如果是非完全二叉树，其实会浪费比较多的数组存储空间。所以，如果某棵二叉树是一棵完全二叉树，那用数组存储无疑是最节省内存的一种方式。因为数组的存储方式并不需要像链式存储法那样，要存储额外的左右子节点的指针。这也是为什么完全二叉树会单独拎出来的原因，也是为什么完全二叉树要求最后一层的子节点都靠左的原因。</p><p>二叉树的遍历，经典的方法有三种，前序遍历、中序遍历和后序遍历。其中，前、中、后序，表示的是节点与它的左右子树节点遍历打印的先后顺序。</p><p>（1）前序遍历是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。</p><p>（2）中序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。</p><p>（3）后序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。</p><p>实际上，二叉树的前、中、后序遍历就是一个递归的过程。比如，前序遍历，其实就是先打印根节点，然后再递归地打印左子树，最后递归地打印右子树。二叉树遍历的时间复杂度是 O(n)。</p><h4 id="二叉查找树Binary-Search-Tree"><a href="#二叉查找树Binary-Search-Tree" class="headerlink" title="二叉查找树Binary Search Tree"></a>二叉查找树Binary Search Tree</h4><p>二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树。顾名思义，二叉查找树是为了实现快速查找而生的。不过，它不仅仅支持快速查找一个数据，还支持快速插入、删除一个数据。</p><p>这些都依赖于二叉查找树的特殊结构。二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。</p><p>散列表的插入、删除、查找操作的时间复杂度可以做到常量级的 O(1)，非常高效。而二叉查找树在比较平衡的情况下，插入、删除、查找操作时间复杂度才是 O(logn)，相对散列表，好像并没有什么优势，那我们为什么还要用二叉查找树呢？有下面几个原因：</p><p>（1）第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。</p><p>（2）第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。</p><p>（3）第三，笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。</p><p>（4）第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。</p><p>（5）最后，为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。</p><p>综合这几点，平衡二叉查找树在某些方面还是优于散列表的，所以，这两者的存在并不冲突。我们在实际的开发过程中，需要结合具体的需求来选择使用哪一个。</p><h4 id="红黑树Red-Black-Tree"><a href="#红黑树Red-Black-Tree" class="headerlink" title="红黑树Red-Black Tree"></a>红黑树Red-Black Tree</h4><p>平衡二叉树的严格定义（注意是严格定义）：二叉树中任意一个节点的左右子树的高度相差不能大于 1。</p><p>平衡二叉查找树不仅满足上面平衡二叉树的定义，还满足二叉查找树的特点。</p><p>最先被发明的平衡二叉查找树是AVL 树，它严格符合平衡二叉查找树的定义，即任何节点的左右子树高度相差不超过 1，是一种高度平衡的二叉查找树。但是很多平衡二叉查找树其实并没有严格符合上面的定义（树中任意一个节点的左右子树的高度相差不能大于 1），比如红黑树，它从根节点到各个叶子节点的最长路径，有可能会比最短路径大一倍。</p><p>发明平衡二叉查找树这类数据结构的初衷是，解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的问题。所以，平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。</p><p>所以，如果我们现在设计一个新的平衡二叉查找树，只要树的高度不比 log2n 大很多（比如树的高度仍然是对数量级的），尽管它不符合我们前面讲的严格的平衡二叉查找树的定义，但我们仍然可以说，这是一个合格的平衡二叉查找树。</p><p>红黑树的英文是“Red-Black Tree”，简称 R-B Tree。它是一种不严格的平衡二叉查找树。红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求：</p><p>（1）根节点是黑色的；</p><p>（2）每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；</p><p>（3）任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；</p><p>（4）每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点。</p><p>它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。因为红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是用到动态插入、删除、查找数据的场景，都可以用到它。</p><h4 id="堆Heap"><a href="#堆Heap" class="headerlink" title="堆Heap"></a>堆Heap</h4><p>堆是一种特殊的树。只要满足这两点，它就是一个堆：</p><p>（1）堆是一个完全二叉树；</p><p>（2）堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。</p><p>对于每个节点的值都大于等于子树中每个节点值的堆，叫做“大顶堆”。对于每个节点的值都小于等于子树中每个节点值的堆，叫做“小顶堆”。</p><p>往堆中插入一个元素和删除堆顶元素的时间复杂度都是 O(logn)。</p><p>最直接、最高效的实现优先级队列的方法是使用堆。这是因为，堆和优先级队列非常相似。一个堆就可以看作一个优先级队列。很多时候，它们只是概念上的区分而已。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。</p><h3 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h3><p>B+树是一种数据结构，是一个N叉排序树，每个节点通常有多个孩子，一棵B+树包含根节点、内部节点和叶子节点。根节点可能是一个叶子节点， 也可能是一个包含两个或两个以上孩子节点的节点。</p><p>B+树通常用于数据库和操作系统的文件系统中。NTFS、ReiserFS、NSS、XFS、JFS、ReFS和BFS等文件系统都在使用B+树作为元数据索引。B+树的特点是能够保持数据稳定有序， 其插入与修改拥有较稳定的对数时间复杂度。B+树元素自底向上插入。</p><h2 id="图Graph"><a href="#图Graph" class="headerlink" title="图Graph"></a>图Graph</h2><p>图中的元素叫做顶点（vertex）。图中的一个顶点可以与任意其他顶点建立连接关系，这种建立的关系叫做边（edge）。跟顶点相连接的边的条数，叫做顶点的度（degree）。</p><p>边有方向的图叫做“有向图”。边没有方向的图叫做“无向图”。</p><p>在有向图中，把度分为入度（In-degree）和出度（Out-degree）。顶点的入度，表示有多少条边指向这个顶点；顶点的出度，表示有多少条边是以这个顶点为起点指向其他顶点。</p><p>有一种特别的图，称为带权图（weighted graph）。在带权图中，每条边都有一个权重（weight）。</p><p>在内存中存储图这种数据结构的方法有：</p><p>（1）邻接矩阵存储方法：图最直观的一种存储方法就是，邻接矩阵（Adjacency Matrix）。邻接矩阵的底层依赖一个二维数组。对于无向图来说，如果顶点 i 与顶点 j 之间有边，我们就将 A[i][j]和 A[j][i]标记为 1；对于有向图来说，如果顶点 i 到顶点 j 之间，有一条箭头从顶点 i 指向顶点 j 的边，那我们就将 A[i][j]标记为 1。同理，如果有一条箭头从顶点 j 指向顶点 i 的边，我们就将 A[j][i]标记为 1。对于带权图，数组中就存储相应的权重。</p><p>优点：首先，邻接矩阵的存储方式简单、直接，因为基于数组，所以在获取两个顶点的关系时，就非常高效。其次，用邻接矩阵存储图的另外一个好处是方便计算。这是因为，用邻接矩阵的方式存储图，可以将很多图的运算转换成矩阵之间的运算。</p><p>缺点：如果存储的是稀疏图（Sparse Matrix），即顶点很多，但每个顶点的边并不多，那邻接矩阵的存储方法就更加浪费空间了。</p><p>（2）邻接表存储方法：每个顶点对应一条链表，链表中存储的是与这个顶点相连接的其他顶点。尽管邻接表的存储方式比较节省存储空间，但链表不方便查找，所以查询效率没有邻接矩阵存储方式高。</p><p>可以将邻接表中的链表改成平衡二叉查找树。实际开发中，我们可以选择用红黑树。这样，我们就可以更加快速地查找两个顶点之间是否存在边了。当然，这里的二叉查找树可以换成其他动态数据结构，比如跳表、散列表等。除此之外，我们还可以将链表改成有序动态数组，可以通过二分查找的方法来快速定位两个顶点之间否是存在边。</p><h2 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a>Trie树</h2><p>Trie 树，也叫“字典树”。顾名思义，它是一个树形结构（多叉树）。它是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。</p><p>Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起。其中，根节点不包含任何信息。每个节点表示一个字符串中的字符，从根节点到红色节点的一条路径表示一个字符串（注意：红色节点并不都是叶子节点）。</p><p>字符串的匹配问题，笼统上讲，其实就是数据的查找问题。对于支持动态数据高效操作的数据结构，有散列表、红黑树、跳表等等。实际上，这些数据结构也可以实现在一组字符串中查找字符串的功能。而Trie 树实际上对要处理的字符串有极其严苛的要求：</p><p>（1）第一，字符串中包含的字符集不能太大。如果字符集太大，那存储空间可能就会浪费很多。即便可以优化，但也要付出牺牲查询、插入效率的代价。</p><p>（2）第二，要求字符串的前缀重合比较多，不然空间消耗会变大很多。</p><p>（3）第三，如果要用 Trie 树解决问题，那就要自己从零开始实现一个 Trie 树，还要保证没有 bug，这个在工程上是将简单问题复杂化，除非必须，一般不建议这样做。</p><p>（4）第四，通过指针串起来的数据块是不连续的，而 Trie 树中用到了指针，所以，对缓存并不友好，性能上会打个折扣。</p><p>综合这几点，针对在一组字符串中查找字符串的问题，在工程中更倾向于用散列表或者红黑树。因为这两种数据结构，都不需要自己去实现，直接利用编程语言中提供的现成类库就行了。实际上，Trie 树不适合精确匹配查找，这种问题更适合用散列表或者红黑树来解决。Trie 树比较适合的是查找前缀匹配的字符串，比如搜索引擎的关键词提示。</p><h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><h2 id="递归Recursion"><a href="#递归Recursion" class="headerlink" title="递归Recursion"></a>递归Recursion</h2><p>写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。</p><p>在实际的软件开发中，编写递归代码时，需要注意的问题有：</p><p>（1）递归代码要警惕堆栈溢出：在“栈”那一节讲过，函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。</p><p>（2）递归代码要警惕重复计算：比如想要计算 f(5)，需要先计算 f(4) 和 f(3)，而计算 f(4) 还需要计算 f(3)，因此，f(3) 就被计算了很多次，这就是重复计算问题。为了避免重复计算，我们可以通过一个数据结构（比如散列表）来保存已经求解过的 f(k)。当递归调用到 f(k) 时，先看下是否已经求解过了。如果是，则直接从散列表中取值返回，不需要重复计算，这样就能避免刚讲的问题了。</p><h2 id="哈希Hash"><a href="#哈希Hash" class="headerlink" title="哈希Hash"></a>哈希Hash</h2><p>将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。</p><p>一个优秀的哈希算法需要满足的几点要求：</p><p>（1）从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；</p><p>（2）对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；</p><p>（3）散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小（不可能完全不冲突，因为哈希算法产生的哈希值的长度是固定且有限的，而要哈希的数据是无穷的。）；</p><p>（4）哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。</p><p>之前的散列函数中也用到了哈希算法，不过散列函数对于散列算法冲突的要求要低很多。即便出现个别散列冲突，只要不是过于严重，我们都可以通过开放寻址法或者链表法解决。不仅如此，散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，也就是，一组数据是否能均匀地散列在各个槽中。除此之外，散列函数执行的快慢，也会影响散列表的性能，所以，散列函数用的散列算法一般都比较简单，比较追求效率。</p><h2 id="排序Sort"><a href="#排序Sort" class="headerlink" title="排序Sort"></a>排序Sort</h2><h3 id="冒泡排序Bubble-Sort"><a href="#冒泡排序Bubble-Sort" class="headerlink" title="冒泡排序Bubble Sort"></a>冒泡排序Bubble Sort</h3><p>冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。</p><p>冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为 O(1)，是一个原地排序算法。</p><p>在冒泡排序中，只有交换才可以改变两个元素的前后顺序。为了保证冒泡排序算法的稳定性，当有相邻的两个元素大小相等的时候，我们不做交换，相同大小的数据在排序前后不会改变顺序，所以冒泡排序是稳定的排序算法。</p><p>最好情况下，要排序的数据已经是有序的了，我们只需要进行一次冒泡操作，就可以结束了，所以最好情况时间复杂度是 O(n)。而最坏的情况是，要排序的数据刚好是倒序排列的，我们需要进行 n 次冒泡操作，所以最坏情况时间复杂度为 O(n2)。平均情况下的时间复杂度就是 O(n2)。</p><h3 id="插入排序Insertion-Sort"><a href="#插入排序Insertion-Sort" class="headerlink" title="插入排序Insertion Sort"></a>插入排序Insertion Sort</h3><p>首先，我们将数组中的数据分为两个区间，已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束。</p><p>从实现过程可以很明显地看出，插入排序算法的运行并不需要额外的存储空间，所以空间复杂度是 O(1)，也就是说，这是一个原地排序算法。</p><p>在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现元素的后面，这样就可以保持原有的前后顺序不变，所以插入排序是稳定的排序算法。</p><p>如果要排序的数据已经是有序的，我们并不需要搬移任何数据。如果我们从尾到头在有序数据组里面查找插入位置，每次只需要比较一个数据就能确定插入的位置。所以这种情况下，最好是时间复杂度为 O(n)。注意，这里是从尾到头遍历已经有序的数据。如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，所以最坏情况时间复杂度为 O(n2)。因为在数组中插入一个数据的平均时间复杂度是 O(n)，所以，对于插入排序来说，每次插入操作都相当于在数组中插入一个数据，循环执行 n 次插入操作，所以平均时间复杂度为 O(n2)。</p><p>虽然冒泡排序和插入排序在时间复杂度上是一样的，都是 O(n2)，但是如果我们希望把性能优化做到极致，那肯定首选插入排序。</p><h3 id="选择排序Selection-Sort"><a href="#选择排序Selection-Sort" class="headerlink" title="选择排序Selection Sort"></a>选择排序Selection Sort</h3><p>选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。</p><p>选择排序空间复杂度为 O(1)，是一种原地排序算法。选择排序的最好情况时间复杂度、最坏情况和平均情况时间复杂度都为 O(n2)。</p><p>选择排序是一种不稳定的排序算法。因为选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样破坏了稳定性。</p><h3 id="归并排序Merge-Sort"><a href="#归并排序Merge-Sort" class="headerlink" title="归并排序Merge Sort"></a>归并排序Merge Sort</h3><p>如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。</p><p>归并排序使用的就是分治思想。分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。</p><p>归并排序是一个稳定的排序算法。</p><p>归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)。</p><p>归并排序不是原地排序算法，空间复杂度是 O(n)。</p><h3 id="快速排序Quick-Sort"><a href="#快速排序Quick-Sort" class="headerlink" title="快速排序Quick Sort"></a>快速排序Quick Sort</h3><p>快排的思想是这样的：如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。根据分治、递归的处理思想，我们可以用递归排序下标从 p 到 q-1 之间的数据和下标从 q+1 到 r 之间的数据，直到区间缩小为 1，就说明所有的数据都有序了。</p><p>快速排序并不是一个稳定的排序算法。</p><p>快排和归并的区别：可以发现，归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法。我们前面讲过，归并之所以是非原地排序算法，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。</p><p>在大部分情况下的时间复杂度都可以做到 O(nlogn)，只有在极端情况下，才会退化到 O(n2)。</p><p>以下三种算法：桶排序、计数排序、基数排序，时间复杂度都是 O(n)。因为这些排序算法的时间复杂度是线性的，所以我们把这类排序算法叫作线性排序（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。</p><h3 id="桶排序Bucket-Sort"><a href="#桶排序Bucket-Sort" class="headerlink" title="桶排序Bucket Sort"></a>桶排序Bucket Sort</h3><p>桶排序，顾名思义，会用到“桶”，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。</p><p>桶排序对要排序数据的要求是非常苛刻的：首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。</p><p>桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。</p><h3 id="计数排序Counting-Sort"><a href="#计数排序Counting-Sort" class="headerlink" title="计数排序Counting Sort"></a>计数排序Counting Sort</h3><p>计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。</p><p>计数排序的名称来源于其利用另外一个数组来计数的实现方式。</p><p>计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。</p><h3 id="基数排序Radix-Sort"><a href="#基数排序Radix-Sort" class="headerlink" title="基数排序Radix Sort"></a>基数排序Radix Sort</h3><p>以对11位的手机号码排序为例：先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。</p><p>基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。</p><h3 id="堆排序Heap-Sort"><a href="#堆排序Heap-Sort" class="headerlink" title="堆排序Heap Sort"></a>堆排序Heap Sort</h3><p>借助于堆这种数据结构实现的排序算法，叫做堆排序。</p><p>整个堆排序的过程，都只需要极个别临时存储空间，所以堆排序是原地排序算法。堆排序包括建堆和排序两个操作，建堆过程的时间复杂度是 O(n)，排序过程的时间复杂度是 O(nlogn)，所以，堆排序整体的时间复杂度是 O(nlogn)。堆排序不是稳定的排序算法，因为在排序的过程，存在将堆的最后一个节点跟堆顶节点互换的操作，所以就有可能改变值相同数据的原始相对顺序。</p><h3 id="如何实现一个通用的、高性能的排序函数"><a href="#如何实现一个通用的、高性能的排序函数" class="headerlink" title="如何实现一个通用的、高性能的排序函数"></a>如何实现一个通用的、高性能的排序函数</h3><p>为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 O(nlogn) 的排序算法来实现排序函数。</p><p>时间复杂度是 O(nlogn) 的排序算法不止一个，比如归并排序、快速排序，以及后面的堆排序。虽然归并排序可以做到平均情况、最坏情况下的时间复杂度都是 O(nlogn)，但归并排序并不是原地排序算法，空间复杂度是 O(n)，所以它不太适合作为通用排序函数（Glibc中的qsort()函数在数据量小时会优先使用归并排序来排序输入数据，排序的数据量比较大的时候，qsort() 会改为用快速排序算法来排序，实际上，当要排序的区间中，元素的个数小于等于 4 时，qsort() 就退化为插入排序，不再继续用递归来做快速排序）。堆排序和快速排序都有比较多的应用，比如 Java 语言采用堆排序实现排序函数，C 语言使用快速排序实现排序函数。</p><p>快速排序有两个问题：</p><p>（1）最坏情况下快速排序的时间复杂度是 O(n^2)，这种 O(n^2) 时间复杂度出现的主要原因还是因为分区点选得不够合理。最理想的分区点是：被分区点分开的两个分区中，数据的数量差不多。比较常用、比较简单的分区算法有：一个是三数取中法：从区间的首、尾、中间，分别取出一个数，然后对比大小，取这 3 个数的中间值作为分区点。这样每间隔某个固定的长度，取数据出来比较，将中间值作为分区点的分区算法，肯定要比单纯取某一个数据更好。但是，如果要排序的数组比较大，那“三数取中”可能就不够了，可能要“五数取中”或者“十数取中”。另一个是随机法：随机法就是每次从要排序的区间中，随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好，但是从概率的角度来看，也不大可能会出现每次分区点都选得很差的情况，所以平均情况下，这样选的分区点是比较好的。时间复杂度退化为最糟糕的 O(n2) 的情况，出现的可能性不大。</p><p>（2）快速排序是用递归来实现的，而递归要警惕堆栈溢出。为了避免快速排序里，递归过深而堆栈过小，导致堆栈溢出，我们有两种解决办法：第一种是限制递归深度。一旦递归过深，超过了我们事先设定的阈值，就停止递归。第二种是通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。</p><h2 id="二分查找Binary-Search"><a href="#二分查找Binary-Search" class="headerlink" title="二分查找Binary Search"></a>二分查找Binary Search</h2><p>二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。</p><p>二分查找应用场景的局限性：</p><p>首先，二分查找依赖的是顺序表结构，简单点说就是数组，主要原因是二分查找算法需要按照下标随机访问元素；</p><p>其次，二分查找针对的是有序数据。如果数据没有序，我们需要先排序。如果我们针对的是一组静态的数据，没有频繁地插入、删除，我们可以进行一次排序，多次二分查找。这样排序的成本可被均摊，二分查找的边际成本就会比较低。但是，如果我们的数据集合有频繁的插入和删除操作，要想用二分查找，要么每次插入、删除操作之后保证数据仍然有序，要么在每次二分查找之前都先进行排序。针对这种动态数据集合，无论哪种方法，维护有序的成本都是很高的。</p><p>再次，数据量太小不适合二分查找。如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。</p><p>最后，数据量太大也不适合二分查找。二分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。</p><p>大部分情况下，用二分查找可以解决的问题，用散列表、二叉树这些支持快速查找的动态数据结构都可以解决。但是，不管是散列表还是二叉树，都会需要比较多的额外的内存空间。而二分查找底层依赖的是数组，除了数据本身之外，不需要额外存储其他信息，是最省内存空间的存储方式，所以如果内存受限，则可能只能应用二分查找。</p><h2 id="优先搜索First-Search"><a href="#优先搜索First-Search" class="headerlink" title="优先搜索First Search"></a>优先搜索First Search</h2><p>优先搜索算法是基于“图”这种数据结构的。这是因为，图这种数据结构的表达能力很强，大部分涉及搜索的场景都可以抽象成“图”。</p><p>图上的搜索算法，最直接的理解就是，在图中找出从一个顶点出发，到另一个顶点的路径。具体方法有很多，比如最简单、最“暴力”的深度优先、广度优先搜索，还有 A<em>、IDA</em> 等启发式搜索算法。</p><h3 id="广度优先搜索Breadth-First-Search"><a href="#广度优先搜索Breadth-First-Search" class="headerlink" title="广度优先搜索Breadth First Search"></a>广度优先搜索Breadth First Search</h3><p>广度优先搜索（Breadth-First-Search），简称 BFS。直观地讲，它其实就是一种“地毯式”层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索。</p><p>广度优先搜索需要借助队列来实现，遍历得到的路径就是，起始顶点到终止顶点的最短路径。</p><p>广度优先搜索的时间复杂度是 O(V+E)，其中，V 表示顶点的个数，E 表示边的个数，空间复杂度是 O(V)。</p><h3 id="深度优先搜索Depth-First-Search"><a href="#深度优先搜索Depth-First-Search" class="headerlink" title="深度优先搜索Depth First Search"></a>深度优先搜索Depth First Search</h3><p>深度优先搜索（Depth-First-Search），简称 DFS。最直观的例子就是“走迷宫”。</p><p>假设你站在迷宫的某个岔路口，然后想找到出口。你随意选择一个岔路口来走，走着走着发现走不通的时候，你就回退到上一个岔路口，重新选择一条路继续走，直到最终找到出口。这种走法就是一种深度优先搜索策略。</p><p>实际上，深度优先搜索用的是一种比较著名的回溯思想。这种思想解决问题的过程，非常适合用递归来实现。换种说法，深度优先搜索是借助栈来实现的。</p><p>图上的深度优先搜索算法的时间复杂度是 O(E)，E 表示边的个数，空间复杂度就是 O(V)，V表示顶点的个数 。</p><h2 id="字符串匹配String-Match"><a href="#字符串匹配String-Match" class="headerlink" title="字符串匹配String Match"></a>字符串匹配String Match</h2><p>主串和模式串：比如在字符串 A 中查找字符串 B，那字符串 A 就是主串，字符串 B 就是模式串。把主串的长度记作 n，模式串的长度记作 m。因为是在主串中查找模式串，所以 n&gt;m。</p><p>单模式串匹配算法，是在一个模式串和一个主串之间进行匹配，也就是说，在一个主串中查找一个模式串。包括下面的BF 算法、RK 算法、BM 算法、KMP 算法。</p><p>多模式串匹配算法，就是在多个模式串和一个主串之间做匹配，也就是说，在一个主串中查找多个模式串。包括下面的Trie树算法、AC自动机等。</p><h3 id="暴力匹配Brute-Force"><a href="#暴力匹配Brute-Force" class="headerlink" title="暴力匹配Brute Force"></a>暴力匹配Brute Force</h3><p>暴力匹配算法，简称为BF算法，也叫朴素匹配算法。从名字可以看出，这种算法的字符串匹配方式很“暴力”，当然也就会比较简单、好懂，但相应的性能也不高。</p><p>作为最简单、最暴力的字符串匹配算法，BF 算法的思想可以用一句话来概括，那就是，在主串中，检查起始位置分别是 0、1、2…n-m 且长度为 m 的 n-m+1 个子串，看有没有跟模式串匹配的。</p><p>尽管理论上，BF 算法的时间复杂度很高，是 O(n*m)，但在实际的开发中，它却是一个比较常用的字符串匹配算法。原因有两点：</p><p>（1）第一，实际的软件开发中，大部分情况下，模式串和主串的长度都不会太长。而且每次模式串与主串中的子串匹配的时候，当中途遇到不能匹配的字符的时候，就可以就停止了，不需要把 m 个字符都比对一下。所以，尽管理论上的最坏情况时间复杂度是 O(n*m)，但是，统计意义上，大部分情况下，算法执行效率要比这个高很多。</p><p>（2）第二，朴素字符串匹配算法思想简单，代码实现也非常简单。简单意味着不容易出错，如果有 bug 也容易暴露和修复。在工程中，在满足性能要求的前提下，简单是首选。这也是常说的KISS（Keep it Simple and Stupid）设计原则。</p><h3 id="RK算法"><a href="#RK算法" class="headerlink" title="RK算法"></a>RK算法</h3><p>RK 算法的全称叫 Rabin-Karp 算法，是由它的两位发明者 Rabin 和 Karp 的名字来命名的。它其实就是BF 算法的升级版。</p><p>在BF算法中，每次检查主串与子串是否匹配，需要依次比对每个字符，所以 BF 算法的时间复杂度就比较高，是 O(n*m)。RK算法则对朴素的字符串匹配算法稍加改造，引入哈希算法，时间复杂度立刻就会降低。</p><p>RK 算法的思路：通过哈希算法对主串中的 n-m+1 个子串分别求哈希值，然后逐个与模式串的哈希值比较大小。如果某个子串的哈希值与模式串相等，那就说明对应的子串和模式串匹配了（这里先不考虑哈希冲突的问题）。因为哈希值是一个数字，数字之间比较是否相等是非常快速的，所以模式串和子串比较的效率就提高了。</p><p>理想情况下，RK 算法的时间复杂度是 O(n)，跟 BF 算法相比，效率提高了很多。不过这样的效率取决于哈希算法的设计方法，如果存在冲突的情况下，时间复杂度可能会退化。极端情况下，哈希算法大量冲突，时间复杂度就退化为 O(n*m)。</p><h3 id="BM算法"><a href="#BM算法" class="headerlink" title="BM算法"></a>BM算法</h3><p>BM（Boyer-Moore）算法是一种非常高效的字符串匹配算法，有实验统计，它的性能是著名的KMP 算法的 3 到 4 倍。</p><p>BM 算法的核心思想：把模式串和主串的匹配过程，看作模式串在主串中不停地往后滑动。当遇到不匹配的字符时，BF 算法和 RK 算法的做法是，模式串往后滑动一位，然后从模式串的第一个字符开始重新匹配。而BM 算法是在模式串与主串匹配的过程中，当模式串和主串某个字符不匹配的时候，能够跳过一些肯定不会匹配的情况，将模式串往后多滑动几位。</p><h3 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a>KMP算法</h3><p>在所有的字符串匹配算法里，最知名的一种非 KMP 算法莫属。很多时候，提到字符串匹配，首先想到的就是 KMP 算法。</p><p>KMP 算法是根据三位作者（D.E.Knuth，J.H.Morris 和 V.R.Pratt）的名字来命名的，算法的全称是 Knuth Morris Pratt 算法，简称为 KMP 算法。</p><p>KMP 算法的核心思想，跟 BM 算法非常相近，都是根据规律在遇到坏字符的时候，把模式串往后多滑动几位。</p><h3 id="Trie树算法"><a href="#Trie树算法" class="headerlink" title="Trie树算法"></a>Trie树算法</h3><p>Trie 树是一种解决字符串快速匹配问题的数据结构。如果用来构建 Trie 树的这一组字符串中，前缀重复的情况不是很多，那 Trie 树这种数据结构总体上来讲是比较费内存的，是一种空间换时间的解决问题思路。尽管比较耗费内存，但是对内存不敏感或者内存消耗在接受范围内的情况下，在 Trie 树中做字符串匹配还是非常高效的，时间复杂度是 O(k)，k 表示要匹配的字符串的长度。但是，Trie 树的优势并不在于，用它来做动态集合数据的查找，因为，这个工作完全可以用更加合适的散列表或者红黑树来替代。Trie 树最有优势的是查找前缀匹配的字符串，比如搜索引擎中的关键词提示功能这个场景，就比较适合用它来解决，也是 Trie 树比较经典的应用场景。</p><h3 id="AC自动机"><a href="#AC自动机" class="headerlink" title="AC自动机"></a>AC自动机</h3><p>AC 自动机算法，全称是 Aho-Corasick 算法。</p><p>AC 自动机实际上就是在 Trie 树之上，加了类似 KMP 的 next 数组，只不过此处的 next 数组是构建在树上罢了。</p><h2 id="贪心算法Greedy-Algorithm"><a href="#贪心算法Greedy-Algorithm" class="headerlink" title="贪心算法Greedy Algorithm"></a>贪心算法Greedy Algorithm</h2><p>贪心算法有很多经典的应用，比如霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法。</p><p>贪心算法解决问题的步骤：</p><p>（1）第一步，当我们看到这类问题的时候，首先要联想到贪心算法：针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。</p><p>（2）第二步，我们尝试看下这个问题是否可以用贪心算法解决：每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。</p><p>（3）第三步，我们举几个例子看下贪心算法产生的结果是否是最优的。大部分情况下，举几个例子验证一下就可以了。严格地证明贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。而且，从实践的角度来说，大部分能用贪心算法解决的问题，贪心算法的正确性都是显而易见的，也不需要严格的数学推导证明。</p><p>实际上，用贪心算法解决问题的思路，并不总能给出最优解。主要原因是，前面的选择，会影响后面的选择。</p><p>贪心算法的最难的一块是如何将要解决的问题抽象成贪心算法模型，只要这一步搞定之后，贪心算法的编码一般都很简单。</p><h2 id="分治算法Divide-and-Conquer"><a href="#分治算法Divide-and-Conquer" class="headerlink" title="分治算法Divide and Conquer"></a>分治算法Divide and Conquer</h2><p>分治算法（divide and conquer）的核心思想其实就是四个字，分而治之 ，也就是将原问题划分成 n 个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。</p><p>这个定义看起来有点类似递归的定义。关于分治和递归的区别，分治算法是一种处理问题的思想，递归是一种编程技巧。实际上，分治算法一般都比较适合用递归来实现。分治算法的递归实现中，每一层递归都会涉及这样三个操作：</p><p>（1）分解：将原问题分解成一系列子问题；</p><p>（2）解决：递归地求解各个子问题，若子问题足够小，则直接求解；</p><p>（3）合并：将子问题的结果合并成原问题。</p><p>分治算法能解决的问题，一般需要满足下面这几个条件：</p><p>（1）原问题与分解成的小问题具有相同的模式；</p><p>（2）原问题分解成的子问题可以独立求解，子问题之间没有相关性，这一点跟动态规划有明显区别；</p><p>（3）具有分解终止条件，也就是说，当问题足够小时，可以直接求解；</p><p>（4）可以将子问题合并成原问题，而这个合并操作的复杂度不能太高，否则就起不到减小算法总体复杂度的效果了。</p><p>两种分治算法的典型的应用场景，一个是用来指导编码，降低问题求解的时间复杂度，另一个是解决海量数据处理问题。比如 MapReduce 本质上就是利用了分治思想。</p><h2 id="回溯算法Backtracking-Algorithm"><a href="#回溯算法Backtracking-Algorithm" class="headerlink" title="回溯算法Backtracking Algorithm"></a>回溯算法Backtracking Algorithm</h2><p>回溯的处理思想，有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。</p><p>回溯算法的思想非常简单，大部分情况下，都是用来解决广义的搜索问题，也就是，从一组可能的解中，选择出一个满足要求的解。回溯算法非常适合用递归来实现，在实现的过程中，剪枝操作是提高回溯效率的一种技巧。利用剪枝，我们并不需要穷举搜索所有的情况，从而提高搜索效率。</p><p>尽管回溯算法的原理非常简单，但是却可以解决很多问题，比如我们开头提到的深度优先搜索、八皇后、0-1 背包问题、图的着色、旅行商问题、数独、全排列、正则表达式匹配等等。</p><h2 id="动态规划Dynamic-Programming"><a href="#动态规划Dynamic-Programming" class="headerlink" title="动态规划Dynamic Programming"></a>动态规划Dynamic Programming</h2><p>动态规划所能解决的问题可以总结为“一个模型三个特征”：</p><p>（1）一个模型：它指的是动态规划适合解决的问题的模型，可定义为“多阶段决策最优解模型”。一般是用动态规划来解决最优问题。而解决问题的过程，需要经历多个决策阶段。每个决策阶段都对应着一组状态。然后寻找一组决策序列，经过这组决策序列，能够产生最终期望求解的最优值。</p><p>（2）三个特征：分别是最优子结构、无后效性和重复子问题。</p><p>（2.1）最优子结构：最优子结构指的是问题的最优解包含子问题的最优解。反过来说就是，可以通过子问题的最优解，推导出问题的最优解。如果把最优子结构对应到前面定义的动态规划问题模型上，也可以理解为，后面阶段的状态可以通过前面阶段的状态推导出来。</p><p>（2.2）无后效性：无后效性有两层含义，第一层含义是，在推导后面阶段的状态的时候，只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。第二层含义是，某阶段状态一旦确定，就不受之后阶段的决策影响。无后效性是一个非常“宽松”的要求。只要满足前面提到的动态规划问题模型，其实基本上都会满足无后效性。</p><p>（2.3）重复子问题：不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。</p><p>解决动态规划问题，一般有两种思路：状态转移表法和状态转移方程法。</p><p>（1）状态转移表法：</p><p>一般能用动态规划解决的问题，都可以使用回溯算法的暴力搜索解决。所以，当拿到问题的时候，可以先用简单的回溯算法解决，然后定义状态，每个状态表示一个节点，然后对应画出递归树。从递归树中，很容易可以看出来是否存在重复子问题，以及重复子问题是如何产生的。以此来寻找规律，看是否能用动态规划解决。找到重复子问题之后，接下来，有两种处理思路，第一种是直接用回溯加“备忘录”的方法，来避免重复子问题。从执行效率上来讲，这跟动态规划的解决思路没有差别。第二种是使用动态规划的解决方法，状态转移表法。</p><p>状态转移表法解题思路大致可以概括为：回溯算法实现 - 定义状态 - 画递归树 - 找重复子问题 - 画状态转移表 - 根据递推关系填表 - 将填表过程翻译成代码。</p><p>（2）状态转移方程法：</p><p>状态转移方程法有点类似递归的解题思路。需要分析某个问题如何通过子问题来递归求解，也就是所谓的最优子结构。根据最优子结构，写出递归公式，也就是所谓的状态转移方程。有了状态转移方程，代码实现就非常简单了。一般情况下，有两种代码实现方法，一种是递归加“备忘录”，另一种是迭代递推。</p><p>状态转移方程法的大致思路可以概括为，找最优子结构 - 写状态转移方程 - 将状态转移方程翻译成代码。</p><h3 id="四种算法对比"><a href="#四种算法对比" class="headerlink" title="四种算法对比"></a>四种算法对比</h3><p>贪心、回溯、动态规划可以解决的问题模型类似，都可以抽象成多阶段决策最优解模型。尽管分治算法也能解决最优问题，但是大部分问题的背景都不适合抽象成多阶段决策模型。</p><p>（1）回溯算法是个“万金油”。基本上能用的动态规划、贪心解决的问题，都可以用回溯算法解决。回溯算法相当于穷举搜索。穷举所有的情况，然后对比得到最优解。不过，回溯算法的时间复杂度非常高，是指数级别的，只能用来解决小规模数据的问题。对于大规模数据的问题，用回溯算法解决的执行效率就很低了。</p><p>（2）尽管动态规划比回溯算法高效，但是，并不是所有问题，都可以用动态规划来解决。能用动态规划解决的问题，需要满足三个特征，最优子结构、无后效性和重复子问题。在重复子问题这一点上，动态规划和分治算法的区分非常明显。分治算法要求分割成的子问题，不能有重复子问题，而动态规划正好相反，动态规划之所以高效，就是因为回溯算法实现中存在大量的重复子问题。</p><p>（3）贪心算法实际上是动态规划算法的一种特殊情况。它解决问题起来更加高效，代码实现也更加简洁。不过，它可以解决的问题也更加有限。它能解决的问题需要满足三个条件，最优子结构、无后效性和贪心选择性（这里不怎么强调重复子问题）。其中，最优子结构、无后效性跟动态规划中的无异。“贪心选择性”的意思是，通过局部最优的选择，能产生全局的最优选择。每一个阶段，都选择当前看起来最优的决策，所有阶段的决策完成之后，最终由这些局部最优解构成全局最优解。</p><h2 id="拓扑排序Topological-Sorting"><a href="#拓扑排序Topological-Sorting" class="headerlink" title="拓扑排序Topological Sorting"></a>拓扑排序Topological Sorting</h2><p>拓扑排序应用非常广泛，解决的问题的模型也非常一致。凡是需要通过局部顺序来推导全局顺序的，一般都能用拓扑排序来解决。除此之外，拓扑排序还能检测图中环的存在。</p><p>拓扑排序本身就是基于有向无环图的一个算法。</p><p>拓扑排序有两种实现方法，分别是 Kahn 算法和 DFS 深度优先搜索算法。</p><p>对于 Kahn 算法来说，如果最后输出出来的顶点个数，少于图中顶点个数，图中还有入度不是 0 的顶点，那就说明，图中存在环。</p><h2 id="最短路径Shortest-Path-Algorithm"><a href="#最短路径Shortest-Path-Algorithm" class="headerlink" title="最短路径Shortest Path Algorithm"></a>最短路径Shortest Path Algorithm</h2><p>前面两种关于图的搜索算法，深度优先搜索和广度优先搜索，主要是针对无权图的搜索算法。针对有权图，也就是图中的每条边都有一个权重，常用最短路径算法（Shortest Path Algorithm）计算两点之间的最短路径（经过的边的权重和最小）。</p><p>单源最短路径算法（一个顶点到一个顶点），最出名的是Dijkstra 算法。</p><p>最短路径算法还有很多，比如 Bellford 算法、Floyd 算法等等。</p><h3 id="A-算法"><a href="#A-算法" class="headerlink" title="A*算法"></a>A*算法</h3><p>A星算法属于一种启发式搜索算法（Heuristically Search Algorithm）。实际上，启发式搜索算法并不仅仅只有 A星 算法，还有很多其他算法，比如 IDA* 算法、蚁群算法、遗传算法、模拟退火算法等。</p><p>启发式搜索算法利用估价函数，避免“跑偏”，贪心地朝着最有可能到达终点的方向前进。这种算法找出的路线，并不是最短路线。但是，实际的软件开发中的路线规划问题，我们往往并不需要非得找最短路线。所以，鉴于启发式搜索算法能很好地平衡路线质量和执行效率，它在实际的软件开发中的应用更加广泛。</p><h2 id="并行算法Parallel-Algorithm"><a href="#并行算法Parallel-Algorithm" class="headerlink" title="并行算法Parallel Algorithm"></a>并行算法Parallel Algorithm</h2><p>并行计算是一个工程上的实现思路，尽管跟算法关系不大，但是，在实际的软件开发中，它确实可以非常巧妙地提高程序的运行效率，是一种非常好用的性能优化手段。特别是，当要处理的数据规模达到一定程度之后，我们无法通过继续优化算法，来提高执行效率 的时候，我们就需要在实现的思路上做文章，利用更多的硬件资源，来加快执行的效率。所以，在很多超大规模数据处理中，并行处理的思想，应用非常广泛，比如 MapReduce 实际上就是一种并行计算框架。</p>]]></content>
    
    
    <summary type="html">本文是对极客时间app上王争老师的&lt;数据结构与算法之美&gt;的课堂笔记。

基础概念
算法与数据结构是编程的内功。

从广义上讲，数据结构就是指一组数据的存储和逻辑结构。算法就是操作数据的一组方法。

数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。 因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。（比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。）





数据结构与算法中最重要的概念——复杂度分析：数据结构和算法解决的是如何更省、更</summary>
    
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/categories/algorithm/"/>
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析：24 -- 骨架图转图论sknw解析</title>
    <link href="http://qixinbo.github.io/2020/11/20/ImagePy_24/"/>
    <id>http://qixinbo.github.io/2020/11/20/ImagePy_24/</id>
    <published>2020-11-19T16:00:00.000Z</published>
    <updated>2021-03-26T07:44:44.855Z</updated>
    
    <content type="html"><![CDATA[<p>sknw是一个从骨架图中创建图网络的库，代码在<a href="https://github.com/Image-Py/sknw">这里</a>。</p><p>它不仅可以实现将单线转变成图graph的效果，而且里面的trace函数还可以实现像素追踪，将图像中的单线的坐标序列依次提取出来，从而将图像转变为矢量图。（sknw可以对闭合曲线进行坐标提取，对于闭合曲线，也可以使用find_contour来提取这些坐标序列）</p><h1 id="输入图像"><a href="#输入图像" class="headerlink" title="输入图像"></a>输入图像</h1><p>输入图像必须是一个二值的骨架图。<br>比如，这里的示例图像矩阵为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">img = np.array([</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]])</span><br></pre></td></tr></table></figure></p><h1 id="标识节点"><a href="#标识节点" class="headerlink" title="标识节点"></a>标识节点</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">node_img = mark_node(img)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark_node</span>(<span class="params">ske</span>):</span></span><br><span class="line">    buf = np.pad(ske, (<span class="number">1</span>,<span class="number">1</span>), mode=<span class="string">&#x27;constant&#x27;</span>)</span><br><span class="line">    nbs = neighbors(buf.shape)</span><br><span class="line">    acc = np.cumprod((<span class="number">1</span>,)+buf.shape[::-<span class="number">1</span>][:-<span class="number">1</span>])[::-<span class="number">1</span>]</span><br><span class="line">    mark(buf, nbs)</span><br><span class="line">    <span class="keyword">return</span> buf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark</span>(<span class="params">img, nbs</span>):</span> <span class="comment"># mark the array use (0, 1, 2)</span></span><br><span class="line">    img = img.ravel()</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img)):</span><br><span class="line">        <span class="keyword">if</span> img[p]==<span class="number">0</span>:<span class="keyword">continue</span></span><br><span class="line">        s = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">            <span class="keyword">if</span> img[p+dp]!=<span class="number">0</span>:s+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> s==<span class="number">2</span>:img[p]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:img[p]=<span class="number">2</span></span><br></pre></td></tr></table></figure><p>这一步是将上面的骨架图中的特有节点标识出来（注意：新形成的图是在原图周围附加了一圈0作为缓冲）：<br>（1）像素值原来为0的地方，仍然为0；<br>（2）如果某非0像素，其八邻域有2个非0像素，那么标识该像素为1；这种像素代表了骨架图中的中间段的像素（其中有一部分1代表了环形闭合结构，在后面会特殊处理）；<br>（3）如果某非0像素，其八邻域中的非0像素个数不是2（比如是1、3等），那么标识该像素为2，这种像素代表了骨架图中端点和交点部分的像素。</p><p>经过标识后，得到的图像矩阵为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure></p><h1 id="泛洪填充"><a href="#泛洪填充" class="headerlink" title="泛洪填充"></a>泛洪填充</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">img = img.ravel()</span><br><span class="line">buf = np.zeros(<span class="number">131072</span>, dtype=np.int64)</span><br><span class="line">num = <span class="number">10</span></span><br><span class="line">nodes = []</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img)):</span><br><span class="line">    <span class="keyword">if</span> img[p] == <span class="number">2</span>:</span><br><span class="line">        isiso, nds = fill(img, p, num, nbs, acc, buf)</span><br><span class="line">        <span class="keyword">if</span> isiso <span class="keyword">and</span> <span class="keyword">not</span> iso: <span class="keyword">continue</span></span><br><span class="line">        num += <span class="number">1</span></span><br><span class="line">        nodes.append(nds)</span><br></pre></td></tr></table></figure><p>依次观察值为2的像素，对其进行等值填充（主要函数就是fill函数），并记录这些节点在原图中的坐标位置。<br>fill函数为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fill</span>(<span class="params">img, p, num, nbs, acc, buf</span>):</span></span><br><span class="line">    img[p] = num</span><br><span class="line">    buf[<span class="number">0</span>] = p</span><br><span class="line">    cur = <span class="number">0</span>; s = <span class="number">1</span>; iso = <span class="literal">True</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        p = buf[cur]</span><br><span class="line">        <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">            cp = p+dp</span><br><span class="line">            <span class="keyword">if</span> img[cp]==<span class="number">2</span>:</span><br><span class="line">                img[cp] = num</span><br><span class="line">                buf[s] = cp</span><br><span class="line">                s+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> img[cp]==<span class="number">1</span>: iso=<span class="literal">False</span></span><br><span class="line">        cur += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> cur==s:<span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> iso, idx2rc(buf[:s], acc)</span><br></pre></td></tr></table></figure><br>原理就是探究这些值为2的像素的邻居是否仍然是2，若是，则将其亦纳入探究范围，这样就标识出了这些节点。<br>经过上述代码后，得到的nodes数值为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[array([[<span class="number">0</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">1</span>, <span class="number">7</span>]], dtype=int16), array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">3</span>, <span class="number">0</span>]], dtype=int16), array([[<span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">6</span>]], dtype=int16), array([[<span class="number">6</span>, <span class="number">8</span>]], dtype=int16), array([[<span class="number">8</span>, <span class="number">3</span>]], dtype=int16)]</span><br></pre></td></tr></table></figure><br>如何理解呢？很好理解，比如第一个坐标[0,3]就是第一个值为2的像素在原图中的位置，而坐标组合([[2, 3], [3, 2], [3, 3]])代表那三个相邻的值为2的像素。<br>同时img中的像素值也发生了变化，比如第一个值为2的像素，它的值由2变成了10（如上代码硬编码），而第一个值为2的像素则变成了11，同理，那三个相邻的值为2的像素变成了12，依次类推，最后一个值为2的像素变成了16。</p><h1 id="像素追溯"><a href="#像素追溯" class="headerlink" title="像素追溯"></a>像素追溯</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">edges = []</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img)):</span><br><span class="line">    <span class="keyword">if</span> img[p] &lt;<span class="number">10</span>: <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">        <span class="keyword">if</span> img[p+dp]==<span class="number">1</span>:</span><br><span class="line">            edge = trace(img, p+dp, nbs, acc, buf)</span><br><span class="line">            edges.append(edge)</span><br></pre></td></tr></table></figure><p>像素追溯部分的观察点就变成了与上述节点相邻且值为1的那些像素，即骨架图中的中间部分的像素（原理就是通过是否大于10而选择过滤出上面那些节点，然而通过其邻居是否是1来过滤得到这些值为1的像素），然后通过trace函数寻找其两端所连接的具体节点标识。</p><p>trace函数为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trace</span>(<span class="params">img, p, nbs, acc, buf</span>):</span></span><br><span class="line">    c1 = <span class="number">0</span>; c2 = <span class="number">0</span>;</span><br><span class="line">    newp = <span class="number">0</span></span><br><span class="line">    cur = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        buf[cur] = p</span><br><span class="line">        img[p] = <span class="number">0</span></span><br><span class="line">        cur += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">            cp = p + dp</span><br><span class="line">            <span class="keyword">if</span> img[cp] &gt;= <span class="number">10</span>:</span><br><span class="line">                <span class="keyword">if</span> c1==<span class="number">0</span>:</span><br><span class="line">                    c1 = img[cp]</span><br><span class="line">                    buf[<span class="number">0</span>] = cp</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    c2 = img[cp]</span><br><span class="line">                    buf[cur] = cp</span><br><span class="line">            <span class="keyword">if</span> img[cp] == <span class="number">1</span>:</span><br><span class="line">                newp = cp</span><br><span class="line">        p = newp</span><br><span class="line">        <span class="keyword">if</span> c2!=<span class="number">0</span>:<span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> (c1-<span class="number">10</span>, c2-<span class="number">10</span>, idx2rc(buf[:cur+<span class="number">1</span>], acc))</span><br></pre></td></tr></table></figure><br>trace的原理就是：观察这些值为1的像素的邻居，若为大于10，即找到了那些节点nodes，分别通过c1和c2来存储两侧的节点；若为1，则也将其设为进一步的观察点。<br>经过上述代码后，得到的edges的数值为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="number">0</span>, <span class="number">2</span>, array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>]], dtype=int16)), (<span class="number">3</span>, <span class="number">2</span>, array([[<span class="number">3</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">2</span>]], dtype=int16)), (<span class="number">2</span>, <span class="number">4</span>, array([[<span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">5</span>]], dtype=int16)), (<span class="number">4</span>, <span class="number">6</span>, array([[<span class="number">6</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">8</span>, <span class="number">3</span>]], dtype=int16)), (<span class="number">4</span>, <span class="number">5</span>, array([[<span class="number">6</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">8</span>]], dtype=int16))]</span><br></pre></td></tr></table></figure><br>如何理解呢？也很好理解。比如第一个元组((0, 2, array([[0, 3], [1, 3], [2, 3]])，前两个元素0和2分别是img中的值为10和12的像素减去10所得，第三个元素就是第一个值为1的元素的坐标，以及它所连接的两个值为2的节点的坐标。其他元组也是这个意思。通过这样的元组表示，就很自然地为后面的图graph中的首尾节点及中间连接做了准备。</p><p>同时img中的像素值又发生了变化：与上面值为2的节点相连接的值为1的像素的值都变为了0（见trace函数中的硬编码），这是为了接下来的闭合曲线的处理。</p><h2 id="闭合曲线的处理"><a href="#闭合曲线的处理" class="headerlink" title="闭合曲线的处理"></a>闭合曲线的处理</h2><p>上面的代码可以处理非闭合的曲线，因为很容易根据八邻域中的节点数目来获得交点部分所在。而对于闭合曲线，比如原图中左下方的四个1所形成的闭合曲线，其中无法找到值为2的这种像素，且无法对应到图graph中的节点的概念，因此需要特殊处理一下（这里是否处理这种闭合曲线，是用ring这个参数来指定）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img)):</span><br><span class="line">    <span class="keyword">if</span> img[p]!=<span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line">    img[p] = num; num += <span class="number">1</span></span><br><span class="line">    nodes.append(idx2rc([p], acc))</span><br><span class="line">    <span class="keyword">for</span> dp <span class="keyword">in</span> nbs:</span><br><span class="line">        <span class="keyword">if</span> img[p+dp]==<span class="number">1</span>:</span><br><span class="line">            edge = trace(img, p+dp, nbs, acc, buf)</span><br><span class="line">            edges.append(edge)</span><br></pre></td></tr></table></figure><br>注意，因为上面已经将值为1且与2相连的像素置为0，所以这里寻找的是剩下的值为1的像素。若为1，然后会将它继续添加到节点nodes中。<br>然后再对其邻居点进行追溯trace，不断地将邻居的为1的像素加入到edge中，最终得到的edge结果为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">7</span>, <span class="number">7</span>, array([[<span class="number">5</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">1</span>]], dtype=int16))</span><br></pre></td></tr></table></figure><br>代表由7号节点到7号节点的一个循环。</p><h1 id="创建图graph"><a href="#创建图graph" class="headerlink" title="创建图graph"></a>创建图graph</h1><p>经过上述节点标识和像素追溯，可以得到节点及其边为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">nodes =</span><br><span class="line">[array([[<span class="number">0</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">1</span>, <span class="number">7</span>]], dtype=int16), array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">3</span>, <span class="number">0</span>]], dtype=int16), array([[<span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">6</span>]], dtype=int16), array([[<span class="number">6</span>, <span class="number">8</span>]], dtype=int16), array([[<span class="number">8</span>, <span class="number">3</span>]], dtype=int16), array([[<span class="number">5</span>, <span class="number">1</span>]], dtype=int16)]</span><br><span class="line"> </span><br><span class="line">edges =</span><br><span class="line">[(<span class="number">0</span>, <span class="number">2</span>, array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>]], dtype=int16)), (<span class="number">3</span>, <span class="number">2</span>, array([[<span class="number">3</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">2</span>]], dtype=int16)), (<span class="number">2</span>, <span class="number">4</span>, array([[<span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">5</span>]], dtype=int16)), (<span class="number">4</span>, <span class="number">6</span>, array([[<span class="number">6</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">8</span>, <span class="number">3</span>]], dtype=int16)), (<span class="number">4</span>, <span class="number">5</span>, array([[<span class="number">6</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">8</span>]], dtype=int16)), (<span class="number">7</span>, <span class="number">7</span>, array([[<span class="number">5</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">1</span>]], dtype=int16))]</span><br></pre></td></tr></table></figure><br>使用networkx库来构建graph：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_graph</span>(<span class="params">nodes, edges, multi=<span class="literal">False</span></span>):</span></span><br><span class="line">    graph = nx.MultiGraph() <span class="keyword">if</span> multi <span class="keyword">else</span> nx.Graph()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nodes)):</span><br><span class="line">        graph.add_node(i, pts=nodes[i], o=nodes[i].mean(axis=<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">for</span> s,e,pts <span class="keyword">in</span> edges:</span><br><span class="line">        l = np.linalg.norm(pts[<span class="number">1</span>:]-pts[:-<span class="number">1</span>], axis=<span class="number">1</span>).<span class="built_in">sum</span>()</span><br><span class="line">        graph.add_edge(s,e, pts=pts, weight=l)</span><br><span class="line">    <span class="keyword">return</span> graph</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">sknw是一个从骨架图中创建图网络的库，代码在这里。

它不仅可以实现将单线转变成图graph的效果，而且里面的trace函数还可以实现像素追踪，将图像中的单线的坐标序列依次提取出来，从而将图像转变为矢量图。（sknw可以对闭合曲线进行坐标提取，对于闭合曲线，也可以使用find_contour来提取这些坐标序列）

输入图像
输入图像必须是一个二值的骨架图。
比如，这里的示例图像矩阵为：
1
2
3
4
5
6
7
8
9
10


img = np.array([
    [0,0,0,1,0,0,0,0,0],
    [0,0,0,1,0,0,0,1,0],
    [0,0,0,1,0</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>胞状物体通用分割算法Cellpose解析：使用篇</title>
    <link href="http://qixinbo.github.io/2020/10/24/cellpose-1/"/>
    <id>http://qixinbo.github.io/2020/10/24/cellpose-1/</id>
    <published>2020-10-23T16:00:00.000Z</published>
    <updated>2021-03-26T06:46:44.635Z</updated>
    
    <content type="html"><![CDATA[<p>Cellpose是一个对于胞状物体（比如细胞、晶粒、核、砖块等）进行分割的非常优秀的通用算法，其体现了深度学习在分割这类物体时的强大能力，同时其泛化效果也远超过传统图像处理算法，展现了数据驱动的深度学习所特有的“暴力美学”。</p><h1 id="试用"><a href="#试用" class="headerlink" title="试用"></a>试用</h1><p>Cellpose的源代码见<a href="https://github.com/MouseLand/cellpose">这里</a>。<br>同时开发者还搭建了网站来方便用户试用Cellpose：<br><a href="http://www.cellpose.org/">Cellpose快速体验网站</a>：用户可以直接上传自己的图像来直接调用Cellpose，第一时间获得Cellpose的处理效果。<br>如果用户觉得好，那么可以接着往下深度体验或钻研Cellpose了。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>Cellpose的安装有多种方式：</p><h2 id="Google-Colab在线运行"><a href="#Google-Colab在线运行" class="headerlink" title="Google Colab在线运行"></a>Google Colab在线运行</h2><p>开发者提供了一个运行在Google Colab上的运行示例脚本，用户可以直接拷贝一份这个脚本到自己的Colab上，然后在线运行。<br>这种方式的优缺点如下：<br>优点：可以白嫖Google的算力，不用自己费劲在本地搭建环境及购买硬件；<br>缺点：Colab有运行时间和资源，且其不支持运行Cellpose的图形交互界面。</p><h2 id="可直接执行的二进制程序"><a href="#可直接执行的二进制程序" class="headerlink" title="可直接执行的二进制程序"></a>可直接执行的二进制程序</h2><p>开发者使用PyInstaller在Intel处理器上对源代码进行了打包，形成了一个可执行的二进制程序（有Intel MKL加速，但没有GPU支持）。<br>适用于Windows 10操作系统的程序从<a href="http://www.cellpose.org/windows">这里</a>下载。下载后的程序就是传统的exe程序，可以双击运行它来启动GUI。也有命令行模式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cellpose.exe --<span class="built_in">dir</span> Pictures/ --chan <span class="number">2</span> --save_png</span><br></pre></td></tr></table></figure><p>这种方式的优缺点如下：<br>优点：直接运行开发者打包好的程序，无需自己配置本地环境；<br>缺点：无法调用GPU计算，计算速度受限；程序启动速度慢；无法自己训练模型，只能使用已有算法模型。</p><h2 id="pip包安装"><a href="#pip包安装" class="headerlink" title="pip包安装"></a>pip包安装</h2><p>开发者也在pip仓库中上传了Cellpose代码，因此可以使用pip包管理方式来直接安装Cellpose包。<br>这里还有四种不同的安装方式：分别取决于是否安装GUI、是否支持GPU计算。</p><p>第一种：使用CPU计算且无GUI，则：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install cellpose</span><br></pre></td></tr></table></figure></p><p>第二种：使用CPU计算且有GUI，则：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install cellpose[gui]</span><br></pre></td></tr></table></figure><br>第三种和第四种都是使用GPU计算，因此需要提前配置好GPU环境，即三步走：安装最新GPU驱动、安装CUDA、安装cuDNN，这三步对于深度学习框架都是通用的，可以从搜索引擎上直接搜索教程。<br>以上依赖安装时注意CUDA版本一定要与mxnet对应好，所以最好是先确定mxnet所需的CUDA版本，然后再具体安装CUDA和cuDNN。<br>配置好GPU环境后，再安装mxnet的GPU版本：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mxnet-cu102</span><br></pre></td></tr></table></figure><br>最后按上面第一种或第二种的pip命令来安装cellpose的无GUI版或有GUI版。</p><h2 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a>源码安装</h2><p>最自由的方式就是直接从源码安装（虽然从pip包中实质也能获得源码，但pip包有可能不是最新的）。<br>首先还是配置环境，根据是否要支持GPU，选择是否安装GPU驱动、CUDA和cuDNN。<br>然后将github源码克隆一下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/MouseLand/cellpose.git</span><br></pre></td></tr></table></figure><br>进入cellpose文件夹，运行：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose</span><br></pre></td></tr></table></figure><br>这种方式拥有最大的自由度和灵活性，能训练、能推理、也能自定义代码来满足自己的定制化需求。</p><h1 id="上手"><a href="#上手" class="headerlink" title="上手"></a>上手</h1><h2 id="上手前准备"><a href="#上手前准备" class="headerlink" title="上手前准备"></a>上手前准备</h2><p>对于深度学习来说，它的三大要素是算法、算力和数据。对于Cellpose，关于这三方面：<br>算力：经过上面的安装过程，算力已经确定，可以是Google Colab的免费算力，也可以是本地环境的CPU或者GPU；<br>算法：Cellpose的算法模型的基础框架是UNet，具体算法在源码中可以查阅；Cellpose的开发者还提供了其在大量图像上进行训练的预训练模型，该模型会在第一次运行Cellpose时自动从开发者服务器上进行下载；<br>数据：开发者没有提供其训练数据集，不过提供了16张测试图片，可以从该<a href="https://drive.google.com/open?id=18syVlaix8cIlrnNF20pEWKMWUsKx9R9z">Google Drive网盘</a>上下载。</p><h2 id="GUI模式"><a href="#GUI模式" class="headerlink" title="GUI模式"></a>GUI模式</h2><p>终端输入：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose</span><br></pre></td></tr></table></figure><br>启动GUI。<br>（1）在GUI中加载图像（拖入图像或从File菜单中加载）；<br>（2）设置模型：Cellpose中有两个模型，cytoplasm和nuclei，即细胞质模型和细胞核模型。比如下面这种图：<br><img src="https://user-images.githubusercontent.com/6218739/95010065-1ccd3a80-0659-11eb-9847-b4255b058238.png" alt="cyto-nuclei"><br>根据生物课本上的知识，绿色部分就是细胞质，红色部分是细胞核，根据这两种物质，Cellpose分别有cyto和nuclei两种名称的模型来识别。用户自己的图像有可能不是这种生物图片，但可以根据相似性，来选择用细胞质（细胞质模型其实就是细胞cell模型，即将细胞核也纳入到整个细胞中）还是细胞核模型来分割。<br>（3）设置通道：选择要分割的图像通道，比如上图中，如果想分割细胞质，即选择green通道；如果想分割细胞核，则选择red通道。如果是分割细胞质，且图中还有细胞核，则将chan设置为细胞质所在通道，而chan2通道设置为细胞核所在通道；如果分割细胞质但里面没有细胞核，则只设置chan即可，chan2设为None；<br>（4）点击calibrate按钮来预估图中物体的尺寸；也可以手动输入cell diameter来设置。该预估的尺寸会通过左下方的红色圆盘体现；<br>（5）点击run segmentation来运行模型。当进度条为100%时，模型预测完毕，可以通过是否勾选MASKS ON来调节是否显示分割后的掩膜。<br>对于上面这张图，如果是分割细胞质/细胞，那么结果为：<br><img src="https://user-images.githubusercontent.com/6218739/95039137-8b1a0780-0702-11eb-9ee0-260f64e3b548.png" alt="cyto"><br>如果是分割细胞核，那么结果为：<br><img src="https://user-images.githubusercontent.com/6218739/95039218-bef52d00-0702-11eb-92ae-d077946cd115.png" alt="nuclei"></p><h2 id="命令行模式"><a href="#命令行模式" class="headerlink" title="命令行模式"></a>命令行模式</h2><p>上面GUI界面中的参数输入同样可以通过命令行模式来实现：<br>比如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose --<span class="built_in">dir</span> ~/images_cyto/test/ --pretrained_model cyto --chan <span class="number">2</span> --chan2 <span class="number">3</span> --save_png</span><br></pre></td></tr></table></figure><br>还有其他参数可以设置，比如：<br>dir：图像所在路径；<br>img_filter：文件名最后的字符（除了扩展名）作为过滤器；<br>chan：要处理的通道，0是灰度通道，1是red通道，2是green通道，3是blue通道；<br>chan2：在要处理cyto、同时图中有nuclei时设置，其为nuclei所在通道，0代表None，代表不设置，其他数值所代表的意思同上；<br>pretrained_model：cyto是细胞质分割模型，nuclei是细胞核分割模型；<br>diameter：图中物体的平均直径，默认是30；如果设为0，则Cellpose会自动估计；<br>use_gpu：使用GPU，如果不添加该参数，则使用CPU；<br>save_png：将分割掩膜存为png，轮廓存为ImageJ所使用的text文件；<br>save_tif：将分割掩膜存为tif，轮廓存为ImageJ所使用的text文件；<br>fast_model：通过关闭数据增强以及平均化4 networks来加速代码运行；<br>all_channels：在所有图像通道上都运行Cellpose，仅用于自定义模型；<br>no_npy：不存储_seg.npy文件；<br>batch_size：批处理尺寸。</p><p>所有的参数可以通过help参数来查看：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose -h</span><br></pre></td></tr></table></figure></p><h2 id="代码模式"><a href="#代码模式" class="headerlink" title="代码模式"></a>代码模式</h2><p>与上面两种方式类似，也可以在Python代码中直接调用Cellpose进行编程：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cellpose <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">import</span> skimage.io</span><br><span class="line"></span><br><span class="line">model = models.Cellpose(gpu=<span class="literal">False</span>, model_type=<span class="string">&#x27;cyto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">files = [<span class="string">&#x27;img0.tif&#x27;</span>, <span class="string">&#x27;img1.tif&#x27;</span>]</span><br><span class="line"></span><br><span class="line">imgs = [skimage.io.imread(f) <span class="keyword">for</span> f <span class="keyword">in</span> files]</span><br><span class="line"></span><br><span class="line">masks, flows, styles, diams = model.<span class="built_in">eval</span>(imgs, diameter=<span class="literal">None</span>, channels=[<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                                         threshold=<span class="number">0.4</span>, do_3D=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><br>可以看出，使用代码调用Cellpose也非常简单，主要就是两步：配置模型models.Cellpose和使用模型进行推理model.eval。</p><h1 id="制作数据集"><a href="#制作数据集" class="headerlink" title="制作数据集"></a>制作数据集</h1><p>Cellpose的GUI界面不仅能像上面那样用于运行模型，更重要的是可以利用它来制作数据集，从而基于自己的数据来训练模型。<br>制作数据集的步骤也非常简单：<br>（1）打开GUI，手动标注物体：右键点击开始标注，再次右键点击或者鼠标回到开始时的圆圈位置则结束标注；（标注时一定将图像中的物体全部都标注完，否则算法会将未标注的物体视为另一类，则会将算法弄晕）<br>（2）存储标注图像：选择File菜单下的Save masks as PNG，则会将标注图像存为文件；（这个地方有一个坑：此处存储的masks数据格式为np.uint16，如果使用opencv的imread函数读入并显示，会都显示为0；而需要使用skimage的imread函数才能正确读入）<br>（3）对文件进行组织：将原始图像和标注图像放到一个文件夹内，两者的匹配还需要遵循一定的命名规则，默认为：例如，原始图像名为wells_000.tif，则标注图像需要命名为wells_000_masks.tif。（也可以通过img_filter和mask_filter这两个参数来修改该默认规则）</p><h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>上一步制作好自己的数据集后，可以训练针对该数据集的Cellpose模型。<br>（在开始训练之前，有一参数需要特别注意，即diameter参数：开发者提供的Cellpose预训练模型中将所有图像进行了resize，使得图像中物体的中位直径都为30像素（细胞质模型）或17像素（细胞核模型）；因此如果想训练快速且结果准确，就需要提前将图像resize成其中物体的中位直径约为30像素或17像素；或使用—diameter参数指定图像中大约的中位直径为多少像素。）<br>训练Cellpose模型可以有两种方式：<br>（1）在预训练模型基础上进行训练：<br>这种方式又可以分为两种：<br>一种是在开发者提供的预训练模型上进行训练：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose --train --<span class="built_in">dir</span> ~/images_cyto/train/ --test_dir ~/images_cyto/test/ --pretrained_model cyto --chan <span class="number">2</span> --chan2 <span class="number">1</span></span><br></pre></td></tr></table></figure><br>可以看出，相比于之前的只运行模型，多了—train这个参数及训练集和测试集数据所在路径。<br>另外一种是在某一给定的预训练模型上进行训练：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose --<span class="built_in">dir</span> ~/images_cyto/test/ --pretrained_model ~/images_cyto/test/model/cellpose_35_0 --save_png</span><br></pre></td></tr></table></figure><br>（2）从头训练模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cellpose --train --<span class="built_in">dir</span> ~/images_nuclei/train/ --pretrained_model <span class="literal">None</span></span><br></pre></td></tr></table></figure><br>即，将参数pretrained_model置为None。</p><h1 id="贡献标注数据"><a href="#贡献标注数据" class="headerlink" title="贡献标注数据"></a>贡献标注数据</h1><p>上面两步介绍了制作自己的数据集及自己训练模型，实际上开发者还提供了一个额外功能：上传自己的标注数据到开发者服务器上，用于再次训练模型。这样的好处有：（1）对于用户：用户可以不必自己训练模型，等开发者根据用户上传的数据再次训练好模型后，用户就可以直接使用；（2）对于开发者：通过用户“投喂”更多类别的图像，就可以形成更大的数据集来训练Cellpose，从而使得Cellpose的泛化能力和精度都得以提高。<br>这里有几点注意事项：<br>（1）先测试一下现有的Cellpose模型在自己的数据上的效果，期间可以尝试更改一下diameter，可能结果会有一点不同；<br>（2）如果测试效果挺好，即错误较少，那么就没有必要上传这些数据了，因为再次训练的模型性能提高也不大；<br>（3）如果测试效果很差，那么极有可能自己的数据与Cellpose的训练集中的数据差别很大，那么此时再次基于这些数据的再次训练就有可能有很大提高；<br>（4）对于上传的数据，物体直径至少有10像素，每张图像上至少有数十个物体：如果图像太小，可以考虑将多张图像拼接起来；如果图像太大，可以考虑将它裁剪成小图，另外，如果图像中有大量非感兴趣的物体，可以将它们直接裁掉；<br>（5）手动标注时，将物体的边界轮廓勾画出来（对于细胞结构，务必使得轮廓将细胞膜、细胞质和细胞核都包裹进去，这是为了与Cellpose开发者的标注方法一致）；<br>（6）不要直接使用模型预测的结果来上传数据，这会造成“误差”的恶性循环。</p>]]></content>
    
    
    <summary type="html">Cellpose是一个对于胞状物体（比如细胞、晶粒、核、砖块等）进行分割的非常优秀的通用算法，其体现了深度学习在分割这类物体时的强大能力，同时其泛化效果也远超过传统图像处理算法，展现了数据驱动的深度学习所特有的“暴力美学”。

试用
Cellpose的源代码见这里。
同时开发者还搭建了网站来方便用户试用Cellpose：
Cellpose快速体验网站：用户可以直接上传自己的图像来直接调用Cellpose，第一时间获得Cellpose的处理效果。
如果用户觉得好，那么可以接着往下深度体验或钻研Cellpose了。

安装
Cellpose的安装有多种方式：

Google Colab在线运行
开</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="cellpose" scheme="http://qixinbo.github.io/tags/cellpose/"/>
    
  </entry>
  
</feed>
