<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>数字旗手</title>
  
  <subtitle>电气化、自动化、数字化、智能化、智慧化</subtitle>
  <link href="http://qixinbo.github.io/atom.xml" rel="self"/>
  
  <link href="http://qixinbo.github.io/"/>
  <updated>2021-12-05T02:26:53.973Z</updated>
  <id>http://qixinbo.github.io/</id>
  
  <author>
    <name>Xin-Bo Qi(亓欣波)</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>开源深度学习计算平台ImJoy解析：5 -- 插件开发流程</title>
    <link href="http://qixinbo.github.io/2021/12/05/ImJoy_5/"/>
    <id>http://qixinbo.github.io/2021/12/05/ImJoy_5/</id>
    <published>2021-12-04T16:00:00.000Z</published>
    <updated>2021-12-05T02:26:53.973Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://imjoy.io/docs/#/development">Developing Plugins for ImJoy</a></p><p><a href="https://qixinbo.info/2021/12/04/imjoy_4/">上一篇文章</a>中介绍了插件的文件格式，这一篇介绍如何进行实际的插件开发。</p><h1 id="指定依赖"><a href="#指定依赖" class="headerlink" title="指定依赖"></a>指定依赖</h1><p>对于一个插件，其往往不是单一的功能实现，往往需要其他软件库的配合。<br>插件的依赖在其文件的<code>config</code> 块的<code>requirements</code>字段中进行指定。<br>根据不同的插件类型，可以指定不一样的依赖。</p><h2 id="Web-Worker-和-Window-插件"><a href="#Web-Worker-和-Window-插件" class="headerlink" title="Web Worker 和 Window 插件"></a>Web Worker 和 Window 插件</h2><p>对于这两类插件，可以通过一个JavaScript库的url数组来指定依赖。这些库会被<code>importScripts</code>方法导入。<br>例如，要指定最新的 <a href="https://plot.ly/javascript/">plotly.js</a> 库，可以这样写：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;https://cdn.plot.ly/plotly-latest.min.js&quot;]</span><br></pre></td></tr></table></figure></p><p>特别地，对于window插件，还可以指定CSS库的url，这些需要以<code>.css</code> 结尾，否则需要在url 后添加前缀<code>css:</code>。<br>例如，要使用<a href="https://www.w3schools.com/w3css/">W3.CSS框架</a>，可以这样指定：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;https://www.w3schools.com/w3css/4/w3.css&quot;]</span><br></pre></td></tr></table></figure><br>如果url不以<code>.css</code>结尾，则需要在其前面加上<code>css:</code>，例如：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;css:https://fonts.googleapis.com/icon?family=Material+Icons&quot;]</span><br></pre></td></tr></table></figure><br>ImJoy在这个<a href="https://github.com/imjoy-team/static.imjoy.io">GitHub仓库</a>中托管常用的库。可以使用简单的url来引用在<code>docs</code>文件夹中的所有文件：<code>https://static.imjoy.io</code> + <code>RelativePathInDocs</code>。<br>例如，在文件夹<code>static.imjoy.io/docs/js/</code>中的文件<code>FileSaver.js</code>可以这样引用：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;https://static.imjoy.io/js/FileSaver.js&quot;]</span><br></pre></td></tr></table></figure><br>如果url不以<code>.js</code>结尾，则需要在其前面加上<code>js:</code>，例如：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;js:https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.11.2&quot;]</span><br></pre></td></tr></table></figure><br>对于离线访问的场景，Javascript和CSS文件在被添加到<code>requirements</code>后会被自动缓存。<br>还可以使用 <code>cache:</code> 前缀将其他资源（例如图像、字体文件）添加到离线缓存中，例如：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;cache:https://use.fontawesome.com/releases/v5.8.2/webfonts/fa-solid-900.woff2&quot;]</span><br></pre></td></tr></table></figure><br>需要注意的是，离线缓存过程不会跟踪所依赖的资源，需要手动将它们添加为依赖后才能缓存。<br>在<code>script</code>标签中导入 ES 模块时（使用 <code>type=&quot;module&quot;</code>），建议在 <code>requirements</code> 中明确添加 es 模块的 URL，并在 URL 前加上 <code>cache:</code> 前缀。这将允许 ImJoy 缓存动态脚本以供离线使用。</p><h2 id="Web-Python插件"><a href="#Web-Python插件" class="headerlink" title="Web Python插件"></a>Web Python插件</h2><p>可以使用所需 Python 模块的字符串列表来指定依赖。例如，<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;numpy&quot;, &quot;matplotlib&quot;]</span><br></pre></td></tr></table></figure><br>默认情况下，这些包是从ImJoy开发者在<a href="https://github.com/imjoy-team/static.imjoy.io/tree/master/docs/pyodide">该Github仓库</a>上的静态托管加载的。特别地，对于 <code>scipy</code>，需要包含一个绝对路径的url：<br><code>&quot;requirements&quot;: [&quot;https://alpha.iodide.app/pyodide-0.10.0/scipy.js&quot;]</code>。<br>如果想导入额外的 js 文件，需要在 javascript url 之前使用 <code>js:</code> 前缀。<br>注意，<code>web-python</code>插件是基于<a href="https://github.com/iodide-project/pyodide/">pyodide</a>的，目前该技术只支持有限数量的 python 模块。</p><h2 id="Native-Python插件"><a href="#Native-Python插件" class="headerlink" title="Native Python插件"></a>Native Python插件</h2><p>也是通过一个字符串列表来指定依赖，然后添加一个前缀用于指定依赖的类型：<code>conda:</code>、<code>pip:</code>和<code>repo:</code>。<br>一般语法是<code>&quot;requirements&quot;: [&quot;prefix:requirementToInstall&quot;]</code>。<br>下表列出所有支持的依赖、ImJoy实际执行的命令，以及相应的例子。</p><div class="table-container"><table><thead><tr><th>Prefix</th><th>Command</th><th>Example</th></tr></thead><tbody><tr><td><code>conda</code></td><td><code>conda install -y</code></td><td><code>&quot;conda:scipy==1.0&quot;</code></td></tr><tr><td><code>pip</code></td><td><code>pip install</code></td><td><code>&quot;pip:scipy==1.0&quot;</code></td></tr><tr><td><code>repo</code></td><td><code>git clone</code> (new repo) <br> <code>git pull</code> (existing repo)</td><td><code>&quot;repo:https://github.com/userName/myRepo&quot;</code></td></tr><tr><td><code>cmd</code></td><td>Any other command</td><td><code>&quot;cmd:pip install -r myRepo/requirements.txt&quot;</code></td></tr></tbody></table></div><p>一些注意点：<br>（1）如果没有使用前缀，那么依赖将被视为<code>pip</code>库。<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;numpy&quot;, &quot;scipy==1.0&quot;]</span><br></pre></td></tr></table></figure><br>（2）如果通过<code>env</code>字段定义了一个虚拟环境，那么所有<code>pip</code>和<code>conda</code> 软件包将安装到此环境中。更多的信息将在下面的“虚拟环境”一节进行介绍。<br>（3）可以直接在一个前缀后以一个字符串的形式列出多个依赖：<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;conda:numpy scipy==1.0&quot;]</span><br></pre></td></tr></table></figure><br>或在一个列表中单独指定前缀：<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;conda:numpy&quot;, &quot;conda:scipy==1.0&quot;]</span><br></pre></td></tr></table></figure><br>（4）不同的依赖类型可以合并为一个列表：<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;conda:numpy&quot;, &quot;pip:scipy==1.0&quot;, &quot;repo:https://github.com/userName/myRepo&quot;]</span><br></pre></td></tr></table></figure></p><h3 id="从GitHub安装Python包"><a href="#从GitHub安装Python包" class="headerlink" title="从GitHub安装Python包"></a>从GitHub安装Python包</h3><p>如果想引用的python模块有一个可用的 <code>setup.py</code> 文件，则可以直接从 Github 使用它，而无需上传到 Python Package Index (<a href="https://pypi.org">PyPI</a>)。方法是按照下面的 PyPI 格式提供github仓库的URL。<a href="https://packaging.python.org/tutorials/packaging-projects/">这个链接</a>对这个方法有详细解释。<br>通用语法如下所示，参数以“{}”表示：<br> <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;pip:git+https://github.com/&#123;username&#125;/&#123;reponame&#125;@&#123;tagname&#125;#egg=&#123;reponame&#125;&quot;]</span><br></pre></td></tr></table></figure><br>语法 <code>&quot;pip:git+https...&quot;</code> 被 ImJoy 翻译成命令 <code>pip install git+https...</code>，该命令允许直接从Git安装python包，即<a href="https://pip.pypa.io/en/stable/topics/vcs-support/">pip install from GIT</a>。<br>必须指定以下参数：<br>（1）<code>username</code>：GitHub 帐户的名称。<br>（2）<code>reponame</code>：GitHub 存储库的名称。<br>（3）<code>tagname</code>：可以加上标签。这个参数可以是一个commit的hash tag，一个<a href="https://git-scm.com/book/en/v2/Git-Basics-Tagging">Git tag</a>，或<a href="https://help.github.com/articles/creating-releases/">GitHub release</a>。该参数可以精确地选择仓库的版本。<br>（4）<code>eggname</code>：这通常是仓库的名称。这个参数会告诉pip进行依赖项检查。<br>需要注意的是，一旦安装了软件包，它将不会被升级，除非指定一个新标签。有关的完整说明，请参阅 <a href="https://pip.pypa.io/en/latest/reference/pip_install/#git">pip 文档</a>。<br>测试起见的话，可以在终端使用<code>pip</code>命令加上上面指定的参数：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://github.com/&#123;username&#125;/&#123;reponame&#125;@&#123;tagname&#125;<span class="comment">#egg=&#123;reponame&#125;</span></span><br></pre></td></tr></table></figure></p><h2 id="插件依赖的典型场景"><a href="#插件依赖的典型场景" class="headerlink" title="插件依赖的典型场景"></a>插件依赖的典型场景</h2><p>以下描述了添加依赖时的典型场景。</p><h3 id="pip库"><a href="#pip库" class="headerlink" title="pip库"></a>pip库</h3><p>想添加的python 模块在 pip 仓库（<code>pip.pypa.io</code>）中，此时非常简单，将该python模块的 pip 名称添加到 <code>requirements</code> 中即可，也可以添加版本号。<br>例如，要添加 <code>scipy</code>的1.0 版本，可以指定<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;pip:scipy==1.0&quot;]</span><br></pre></td></tr></table></figure></p><h3 id="带有-setup-py-的仓库"><a href="#带有-setup-py-的仓库" class="headerlink" title="带有 setup.py 的仓库"></a>带有 <code>setup.py</code> 的仓库</h3><p>当python包中存在<code>setup.py</code> 时，<code>pip</code> 命令可以从 GitHub 仓库安装包及其依赖项。<br>例如：帐户 <code>myUserName</code>在GitHub上托管了<code>myRepo</code>仓库，其最新的 Git 标签是“v0.1.1”。然后可以这样添加：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: &quot;pip:git+https://github.com/myUserName/myRepo@v0.1.1#egg=myRepo&quot;</span><br></pre></td></tr></table></figure></p><h3 id="带有-requirements-txt-的仓库"><a href="#带有-requirements-txt-的仓库" class="headerlink" title="带有 requirements.txt 的仓库"></a>带有 <code>requirements.txt</code> 的仓库</h3><p>文件<code>requirements.txt</code>中列出了某个python库所依赖的所有软件包及其版本。有关更多详细信息，请参阅 <a href="https://pip.pypa.io/en/stable/user_guide/#requirements-files">此处</a>。<br>下面这个例子给出了如何引入这种带<code>requirements.txt</code>的python库。<br>比如，帐户 <code>myUserName</code>有一个GitHub 仓库 <code>myRepo</code> ，将此仓库添加到插件工作区，并安装依赖：<br> <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;repo:https://github.com/myUserName/myRepo&quot;, &quot;cmd: pip install -r myRepo/requirements.txt&quot;]</span><br></pre></td></tr></table></figure><br>然后，在自己要编写的 Python 插件中，可以将上述路径添加到 Python 系统路径中，这样就可以导入想要的库：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sys.path.insert(<span class="number">0</span>, <span class="string">&#x27;./myRepo&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span>  ... <span class="keyword">import</span> ...</span><br></pre></td></tr></table></figure></p><h3 id="带有-environment-yml-的仓库"><a href="#带有-environment-yml-的仓库" class="headerlink" title="带有 environment.yml 的仓库"></a>带有 <code>environment.yml</code> 的仓库</h3><p>yaml 文件 <code>environment.yml</code> 定义了一个带有 conda 和 pip 依赖关系的虚拟环境。详细的文件格式描述可以在<a href="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#create-env-file-manually">这里</a>找到。<br>仍然是上面的例子：帐户 <code>myUserName</code>有一个GitHub 仓库 <code>myRepo</code>，可以这样添加：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;requirements&quot;: [&quot;repo:https://github.com/myUserName/myRepo&quot;]</span><br></pre></td></tr></table></figure><br>并在<code>env</code>字段中安装虚拟环境：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;env&quot;: [&quot;conda env create -f myRepo/environment.yml&quot;]</span><br></pre></td></tr></table></figure></p><h3 id="托管在Dropbox上的仓库"><a href="#托管在Dropbox上的仓库" class="headerlink" title="托管在Dropbox上的仓库"></a>托管在Dropbox上的仓库</h3><p>还可以在 dropbox 上托管代码（以及数据）并通过https 请求来安装它。不过国内用户基本用不到这种场景。</p><h2 id="虚拟环境"><a href="#虚拟环境" class="headerlink" title="虚拟环境"></a>虚拟环境</h2><p>默认情况下，来自ImJoy的Python插件将在默认的conda环境中执行。然而，这些插件也可以具有特定的虚拟conda环境，这提供了一种隔离插件的方法。这样一来，就可以使用不同版本的Python运行它们，或者使用不同的conda或pip包。<br>建议每个插件及不同的标签使用独自的虚拟环境以保证稳定性。进一步地，建议为python、pip和conda包指定完整版本号(X.X.X)。通过指定完整版本，conda将尝试跨虚拟环境重用相同版本（和python版本）的包，从而减少所需的磁盘空间。<br>例如，以下两个环境将重用指定的 scipy 包，但不会重用 numpy 包：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n test_env1 python&#x3D;3.6.8 scipy&#x3D;1.1.0 numpy&#x3D;1.16.1</span><br><span class="line">conda create -n test_env2 python&#x3D;3.6.8 scipy&#x3D;1.1.0 numpy&#x3D;1.15.4</span><br></pre></td></tr></table></figure><br>为了在特定的 conda 环境中运行插件，可以通过在插件的 <code>&lt;config&gt;</code> 部分设置 <code>env</code> 字段来指定它。<br><code>env</code> 可以是字符串或数组。在一行中需要执行多个命令时，需要使用 <code>&amp;&amp;</code> 或 <code>||</code>（注意操作系统的差别）。如果有多个相互独立的命令，可以使用一个数组来存储这些命令。例如：<br><code>&quot;env&quot;: [&quot;export CUDA_VISIBLE_DEVICES=1&quot;, &quot;conda create -n XXXXX python=3.7&quot;]</code>。<br>还可以直接从“environment.yml”文件创建环境，例如<br><code>&quot;env&quot;: &quot;conda env create -f ANNA-PALM/environment.yml&quot;</code>。<br>有关更多信息，请参阅专用的 <a href="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file">conda 帮助页面</a>。</p><h1 id="插件开发"><a href="#插件开发" class="headerlink" title="插件开发"></a>插件开发</h1><p>配置好插件的属性及依赖后，最重要的部分是在 <code>&lt;script&gt;</code> 块中编写实际的插件代码。<br>ImJoy的插件系统建立在远程过程调用（RPC）之上，使用一套编码和解码方案在插件之间传输数据和功能。ImJoy开发者开发出了一组 API 函数（称为<code>ImJoy APIs</code>），以便插件与主应用程序以及插件彼此之间进行交互。<br>任何 ImJoy 插件都可以通过名为<code>api</code>的预定义对象访问<code>ImJoy APIs</code>。<a href="https://imjoy.io/docs/#/api">ImJoy API 函数</a> 这一部分展示了这些API可用的完整列表（稍后的博客会详细介绍）。</p><h2 id="导出插件函数"><a href="#导出插件函数" class="headerlink" title="导出插件函数"></a>导出插件函数</h2><p>每个插件都需要导出一个带有一组函数的插件对象，这些函数将被注册为插件 API 函数（也称为<code>Plugin APIs</code>）。这是通过在插件代码末尾调用<code>api.export</code>来完成的。一旦导出，这些函数就可以在 ImJoy 中注册，并且可以由用户从 ImJoy 用户界面或其他插件调用。重要的是，<code>setup</code> 和 <code>run</code> 是两个必须被定义和导出的插件 API 函数。</p><h2 id="回调函数"><a href="#回调函数" class="headerlink" title="回调函数"></a>回调函数</h2><p>未导出为<code>Plugin API</code> 函数的插件函数，可以作为对象object发送给另一个插件或 ImJoy主程序。这些函数将被视为一个“回调”函数并且只能被调用一次。<br>一个典型的例子是通知函数，它可以告诉调用它的插件”计算已完成“。这样的功能必须只调用一次。</p><h2 id="插件菜单"><a href="#插件菜单" class="headerlink" title="插件菜单"></a>插件菜单</h2><p>大多数插件都可以从插件菜单访问，默认情况下，当用户单击插件菜单中的插件名称时，将调用 <code>run</code> 函数。在插件（或<code>op</code>，下面会详述）的执行过程中，它可以从它的第一个参数（通常命名为<code>ctx</code>）中访问不同的字段：<br>（1）<code>ctx.config</code>：GUI 中使用 <code>ui</code> 字段定义的数值（来自插件文件的<code>&lt;config&gt;</code> 块或来自单独的操作<code>api.register</code>，更多信息如下）。例如，如果你在插件<code>&lt;config&gt;</code>中定义了一个ui字符串（例如<code>&quot;ui&quot;: &quot;option &#123;id: &#39;opt1&#39;, type: &#39;number&#39;&#125;&quot;</code>），你可以通过<code>ctx.config.opt1</code>访问它。<br>（2）<code>ctx.data</code>：它存储来自当前活动窗口的数据和运行插件的状态。请注意，仅当数据与插件或 op 定义的 <code>inputs</code>字段的 json 模板语法匹配时，才会将其传递给插件。比如拖拽进来后缀为png的文件时，它会匹配在<code>inputs</code>字段定义了png格式的插件，然后该文件就传给该插件进行处理。<br>（3）<code>ctx._variables</code>：当插件在工作流中执行时，工作流中设置的变量将作为 <code>ctx._variables</code> 传递。如果用户使用诸如“Set [number]”之类的操作，它将被设置为实际变量值。</p><p>结果可以直接被返回，它们将显示为通用结果窗口。如果想对结果定义特定的窗口类型，可以返回一个至少有两个字段 <code>type</code> 和 <code>data</code> 的对象。ImJoy 将使用 <code>type</code> 来查找用于渲染存储在 <code>data</code> 中的结果的窗口。<br>在下面的示例中，来自 url 的图像将显示在图像窗口中或传递给工作流中的下一个操作。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> &#123; <span class="string">&quot;type&quot;</span>: <span class="string">&quot;imjoy/image&quot;</span>, <span class="string">&quot;data&quot;</span>: &#123;<span class="string">&quot;src&quot;</span>: <span class="string">&quot;https://imjoy.io/static/img/imjoy-icon.png&quot;</span>&#125; &#125;</span><br></pre></td></tr></table></figure><br>ImJoy 使用 postMessage 在插件之间交换数据。这意味着对于 JavaScript插件，对象在传输过程中被复制。如果交换的数据特别大，那么创建的对象就不应该直接传输。要启用这种模式，可以在返回对象时将 <code>_transfer=true</code> 添加到对象中。在上面例子中，可以在返回 <code>ctx</code> 时设置 <code>ctx._transfer = true</code>。然而，它会只加速 <code>ArrayBuffers</code> 或 <code>ArrayBufferViews</code> 的传输（以及ndarrays 由 Python 生成），传输完毕后，将无法访问它。<br>(注意：在Python中，<code>ctx</code>的数据类型是字典，ImJoy添加了允许点表示法的接口，就像在JavaScript中一样。如果愿意，也可以在两种语言中使用<code>[]</code>访问字典或对象。）</p><h2 id="插件操作符（操作）"><a href="#插件操作符（操作）" class="headerlink" title="插件操作符（操作）"></a>插件操作符（操作）</h2><p>可以使用 Plugin API 为插件定义独立的运算符（或 <code>ops</code>）（有关详细信息可参考api.register）。这些<code>ops</code> 的定义方式与<code>&lt;config&gt;</code>块类似：可以定义一个接口来设置参数，它有一个专门的运行功能。当按下插件列表中的向下箭头按钮时，会显示这些不同的操作<code>ops</code>。</p><h2 id="数据交换"><a href="#数据交换" class="headerlink" title="数据交换"></a>数据交换</h2><h3 id="加载-保存文件"><a href="#加载-保存文件" class="headerlink" title="加载/保存文件"></a>加载/保存文件</h3><p>在 ImJoy 中可以以不同方式访问存储在文件系统上的文件。<br>一方面，在没有插件引擎的情况下，若想访问本地文件，用户需要打开或拖动文件导入ImJoy，对于结果文件则只能通过触发下载来保存。<br>另一方面，插件引擎拥有对本地文件系统的完全访问权限，native python 插件可以直接从本地文件系统读取和写入。<br><img src="https://user-images.githubusercontent.com/6218739/144711988-32c6ef87-129a-4942-a5b8-2a0bb1185085.png" alt="data-access"></p><p>因此，ImJoy提供了几种不同的方法来处理插件的加载/保存文件：<br>（1）如果Plugin Engine正在运行，那么对于所有类型插件，有 3 个api函数可以访问本地文件系统：<code>api.showFileDialog</code>、<code>api.getFileUrl</code>、<code>api.requestUploadUrl</code>。特别地，对于在插件引擎上运行的Python插件，可以直接使用标准的 python 文件操作来将文件加载或写入文件系统。<br>（2）如果Plugin Engine未运行，JavaScript或Web Python 插件访问文件的唯一途径是要求用户将文件或文件夹直接拖到 ImJoy 工作区中。这将呈现一个包含文件或文件夹内容的窗口。然后这些数据可以被插件访问并进行处理。要将结果导出为文件，可以使用<code>api.exportFile</code> 函数来触发下载。<br>与通过插件引擎运行的插件相比，在浏览器中运行的web插件无法直接访问本地文件系统，因此它们提供比 <code>native-python</code> 插件更高的安全性。</p><h3 id="通过函数调用来交换数据"><a href="#通过函数调用来交换数据" class="headerlink" title="通过函数调用来交换数据"></a>通过函数调用来交换数据</h3><p>对于运行时生成的少量数据（例如：数组、对象等），可以将数据对象作为参数传递给API函数（或者从API函数返回数据对象），从而将它们发送到另一个插件。<br>例如，可以将包含小型numpy数组、字符串、字节的数据（<10MB）从远程插件引擎中运行的`native-python`插件直接发送到在浏览器中运行的`window`插件。为了快速显示小图像，还可以将其保存为 png 格式并将其编码为 base64 字符串，然后可以使用标准的 HTML `《img>` 标签直接显示。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;output.png&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = f.read()</span><br><span class="line">    result = base64.b64encode(data).decode(<span class="string">&#x27;ascii&#x27;</span>)</span><br><span class="line">    imgurl = <span class="string">&#x27;data:image/png;base64,&#x27;</span> + result</span><br><span class="line">    api.createWindow(name=<span class="string">&#x27;unet prediction&#x27;</span>, <span class="built_in">type</span>=<span class="string">&#x27;imjoy/image&#x27;</span>, w=<span class="number">7</span>, h=<span class="number">7</span>, data= &#123;<span class="string">&quot;src&quot;</span>: imgurl&#125;)</span><br></pre></td></tr></table></figure></p><h3 id="通过窗口传递数据"><a href="#通过窗口传递数据" class="headerlink" title="通过窗口传递数据"></a>通过窗口传递数据</h3><p>ImJoy中显示的窗口可以包含数据，例如图像，因此您可以将窗口用作将数据从一个插件传递到另一个插件的一种方式。<br>选择此类窗口并执行插件时（通过单击插件菜单），所包含的数据将被传送到该插件。<br>重要的是，如果窗口中包含的数据对象匹配某插件的 <code>&lt;config&gt;</code> 中 <code>inputs</code> 定义的 json 模式，ImJoy 就会将窗口中包含的数据传递给该插件。然后插件可以通过访问 <code>ctx.data</code> 来处理数据（通常在 <code>run</code> 函数内）。<br>ImJoy 原生支持 Numpy 数组和TensorFlow张量的转换和传输。插件开发人员可以直接使用这些数据类型并在插件之间进行交换，而不用管它们是在 Python 还是 JavaScript 中。</p><h3 id="处理大数据量"><a href="#处理大数据量" class="headerlink" title="处理大数据量"></a>处理大数据量</h3><p>对于大数据量，一种方式是以较小的块chunks来发送大文件，但这不是最佳的，并且可能会阻碍引擎和ImJoy应用程序之间的正常通信。建议将数据存储在磁盘上（例如在工作区目录中），然后使用<code>api.getFileUrl</code> 生成访问文件的 url。然后可以将生成的 url 发送到 Web 应用程序，并通过下载链接或使用 JavaScript 库（如“axios”）进行访问。很多库如 Three.js、Vega 等都可以直接通过 url 加载文件。</p><h2 id="工作流管理"><a href="#工作流管理" class="headerlink" title="工作流管理"></a>工作流管理</h2><p>ImJoy在 <code>ctx</code> 中提供了额外的字段，允许跟踪、维护和重建整个分析工作流程。<br>（1）<code>ctx._op</code>：给出正在执行的操作的名称。当一个插件注册了多个 op 并且没有为 op 指定回调函数时，<code>run</code> 函数将被调用，可以使用 <code>ctx._op</code> 来确定正在执行哪个 op。<br>（2）<code>ctx._source_op</code>：给出启动当前动作的op的名称。<br>（3）<code>ctx._workflow_id</code>：当插件在工作流中执行时，它的 id 将被传递到这里。当插件从插件菜单执行时，ImJoy 将尝试重用当前活动窗口中的工作流 id，如果没有窗口处于活动状态，则会分配一个新的工作流 id。所有具有相同 <code>_workflow_id</code> 的数据窗口在管道或计算图中虚拟连接。重要的是，通过将 <code>_workflow_id</code> 与 <code>_op</code> 和 <code>_source_op</code> 结合起来，<code>_workflow_id</code>、<code>_variables</code>、<code>_op</code> 和<code>_source_op</code> 可用于实现插件之间的交互，这意味着如果用户在结果窗口中更改了状态，下游工作流将自动更新。</p><h2 id="Native-Python插件的执行标志"><a href="#Native-Python插件的执行标志" class="headerlink" title="Native Python插件的执行标志"></a>Native Python插件的执行标志</h2><p>可以使用 <code>&lt;config&gt;</code> 块中的 <code>flags</code> 字段来控制 Python 插件进程的执行。接下来，将解释插件引擎上运行的 Python 进程如何与 ImJoy 界面交互。<br><img src="https://user-images.githubusercontent.com/6218739/144712604-1b9ba517-ea26-424f-ac87-9a5ffb2e98f1.png" alt="python-process"><br>上图中的几个概念：</p><ul><li>Interface：ImJoy 的web界面。可以在多个浏览器窗口（即多个界面）上运行 ImJoy。</li><li>Plugin Engine：在后台运行以执行来自不同 Python 插件的 Python 代码。</li><li>Python Plugin：包含 Python 代码的插件。一些插件可能有<code>tags</code>来进一步指定它们的执行细节。</li><li>Python Process：在插件引擎上运行的特定 Python 插件。进程可以在任务管理器上看到。</li><li>Workspace：已安装的 ImJoy 插件的集合。对于带有<code>tags</code> 的插件，用户选择合适的标签。工作区中的每个 Python 插件都有自己的进程。每个工作区都有一个唯一的名称。</li><li>ImJoy instance：是在一个 ImJoy 界面中运行的工作区。</li></ul><p>下面将介绍控制python插件执行的三个执行标志：</p><ul><li>默认（没有设置任何标志）：每个 ImJoy 实例在插件引擎上都有自己的进程。如果关闭该界面，则会终止该进程。</li><li><code>single-instance</code>：该标志将只允许一个进程为整个插件引擎运行。对于具有相同名称和标签的插件，那么<code>single-instance</code> 意味着它们访问相同的进程。</li><li><code>allow-detach</code>： 该标志表示进程在其 ImJoy 实例关闭时不会被终止。例如，这允许在后台执行长时间的计算任务，这些任务不需要额外的用户反馈并自动终止。还可用于保护长时间的计算任务免受浏览器不稳定的影响。如果希望能够附加到分离的进程，可以从相同的浏览器和工作区重新连接，或者结合使用 <code>single-instance</code> 标志，这样尽管从不同的浏览器和工作区连接，仍然能连接到之前的进程。</li></ul><p>当 ImJoy 尝试重新连接之前分离的插件进程时，如果在插件类中定义了<code>resume()</code>，那么<code>resume()</code>将被调用，否则像往常一样调用<code>setup()</code>。请注意，当存在<code>resume</code>时，在重新附加期间不会调用 <code>setup</code>。<br>这是 <code>flags</code> 选项在 <code>&lt;config&gt;</code> 块中的样子：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;config lang=&quot;json&quot;&gt;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">  &quot;flags&quot;: [&quot;single-instance&quot;, &quot;allow-detach&quot;],</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">&lt;/config&gt;</span><br></pre></td></tr></table></figure><br><code>flags</code> 也可以使用 <code>tags</code> 进行配置，例如：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;config lang=&quot;json&quot;&gt;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">  &quot;tags&quot;: [&quot;Single&quot;, &quot;Multi&quot;],</span><br><span class="line">  &quot;flags&quot;: &#123;&quot;Single&quot;: [&quot;single-instance&quot;, &quot;allow-detach&quot;], &quot;Multi&quot;: []&#125;,</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">&lt;/config&gt;</span><br></pre></td></tr></table></figure><br>上面的 <code>&lt;config&gt;</code> 块将创建一个带有两个标签（<code>Single</code> 和 <code>Multi</code>）的插件。在安装期间，用户可以选择希望使用哪种运行时行为（插件进程的单个实例（<code>Single</code>），或者在同一个工作区打开多个 ImJoy 界面对应的多插件进程（<code>Multi</code>））。</p><h1 id="构建用户界面"><a href="#构建用户界面" class="headerlink" title="构建用户界面"></a>构建用户界面</h1><p>ImJoy的一个重要部分是提供一种灵活的方式与用户交互，以丰富的交互方式指定输入信息或生成输出。<br>ImJoy自带有一组基本元素，例如表单和进度条，它们提供了一种与用户交互的方式。<br>还可以使用自定义窗口构建更先进和强大的用户界面，开发人员可以利用基于Web的UI库来生成控件、交互式图表或呈现 3D 视图。</p><h2 id="基本的用户输入和输出"><a href="#基本的用户输入和输出" class="headerlink" title="基本的用户输入和输出"></a>基本的用户输入和输出</h2><p>获取用户输入的最简单方法是使用 ImJoy 生成的表单。<br>可以在 <code>&lt;config&gt;</code> 块中定义一个 <code>gui</code> 字符串，它将在插件菜单下呈现为表单。如果插件使用了多个插件操作op（将在API一文中解析），还可以为每个插件操作单独提供<code>gui</code>字符串。<br>当用户通过插件菜单运行插件或 op 时，<code>gui</code> 字符串中定义的所有字段值将被包装为 <code>config</code> 对象并传递到 <code>run</code> 函数中。然后可以通过 <code>ctx.config.FIELD_ID</code> 访问它们。<br>对于其他类型的输入，可以使用其他ImJoy API，例如弹出一个文件对话框<code>api.showFileDialog</code>。<br>为了显示结果或向用户提供反馈，ImJoy 提供了多个 API 函数来显示结果，例如使用<code>api.alert()</code>或<code>api.showMessage()</code>显示消息，使用<code>api.log()</code>或<code>api.error()</code>记录消息或错误，以及<code>api.showProgress</code>表示进度、<code>api.showStatus</code>更新ImJoy状态等。这些API函数将在API一节中详细解析。</p><h2 id="自定义窗口的用户输入和输出"><a href="#自定义窗口的用户输入和输出" class="headerlink" title="自定义窗口的用户输入和输出"></a>自定义窗口的用户输入和输出</h2><p>对于更灵活的用户界面，开发者可以制作专门的窗口插件。由于是基于<code>iframe</code>，所以大部分前端（HTML/CSS/JS）框架都可以在<code>window</code>插件中使用。此外，这样的接口可以与另一个插件通信，例如执行实际分析的 Python 插件。<br>使用<code>window</code>插件模板可以轻松创建这样的插件。除了其他插件之外，<code>window</code>插件还有两个额外的代码块：<code>&lt;window&gt;</code> 和<code>&lt;style&gt;</code>。用户可以将前端代码添加到相应的代码块中。创建后，这个新的<code>window</code>插件将用作模板来创建新的窗口实例。<br>ImJoy提供了两个API函数，用于从<code>window</code>插件创建窗口<code>api.createWindow</code>或显示对话框<code>api.showDialog</code>。<br>除此之外，对于常用的窗口类型，ImJoy 支持一组内部窗口类型，详见<code>api.createWindow</code>这个API。</p><h2 id="更多示例插件"><a href="#更多示例插件" class="headerlink" title="更多示例插件"></a>更多示例插件</h2><p>请前往<a href="https://imjoy.io/docs/#/demos">Demos</a>。</p><h1 id="托管和部署插件"><a href="#托管和部署插件" class="headerlink" title="托管和部署插件"></a>托管和部署插件</h1><p>这一部分提供了有关如何托管或部署 ImJoy 插件的详细信息。<br>这包括从存储单个文件到设置开发者自己的 ImJoy 插件库。然后插件可以直接作为文件分发或使用专用的 url 语法从而允许自动安装。<br>ImJoy 插件的默认方式及推荐方式都是部署在 GitHub 上（或作为单个文件或在插件仓库中），然后使用插件 url 分发。<br>这里推荐 GitHub，因为它提供稳定性和版本控制，保证了重现性和可追溯性。</p><h2 id="托管单个插件文件"><a href="#托管单个插件文件" class="headerlink" title="托管单个插件文件"></a>托管单个插件文件</h2><p>这是开发过程中的典型案例。<br>插件代码可以托管在网络上，例如GitHub、Gist 或 Dropbox。</p><h2 id="自定义的ImJoy插件库"><a href="#自定义的ImJoy插件库" class="headerlink" title="自定义的ImJoy插件库"></a>自定义的ImJoy插件库</h2><p>可以轻松地为现有 GitHub 项目创建 ImJoy 插件仓库。<br>可以在 <a href="https://github.com/imjoy-team/imjoy-project-template">此处</a> 找到模板项目。<br>然后将 ImJoy 插件保存在一个专用文件夹中，并添加一个清单文件 <code>manifest.imjoy.json</code> 到 GitHub 根文件夹。<br>此清单指定了仓库中有哪些插件，以及在哪里可以找到它们。该文件的架构如下所示，完整的模板可以在<a href="https://github.com/imjoy-team/imjoy-project-template/blob/master/manifest.imjoy.json">这里</a>找到。<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;NAME OF THE REPOSITORY&quot;</span>,</span><br><span class="line"> <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;DESCRIBE THE REPOSITORY&quot;</span>,</span><br><span class="line"> <span class="attr">&quot;version&quot;</span>: <span class="string">&quot;0.1.0&quot;</span>,</span><br><span class="line"> <span class="attr">&quot;uri_root&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line"> <span class="attr">&quot;plugins&quot;</span>: [</span><br><span class="line">   <span class="comment">//copy and paste the &lt;config&gt; block of your plugin here</span></span><br><span class="line"> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>然后就可以自动或手动更新此清单：<br>（1）对于自动更新，ImJoy提供了一个<a href="https://github.com/imjoy-team/imjoy-project-template/blob/master/update_manifest.js">node脚本</a>。此脚本需要执行node.js。然后在包含<code>manifest.imjoy.json</code>文件的根文件夹中使用命令 <code>node update_manifest.js</code> 运行它，它会自动搜索ImJoy插件及生成清单。请注意，当第一次使用此nodejs脚本时，必须手动更改插件仓库的名称<code>name</code>。对于后续更新，该名称将保持不变。<br>（2）对于手动更新，按照下列步骤操作：<br>（2.1）将所有插件文件放在 GitHub 仓库中的一个文件夹中。例如一个名为<a href="https://github.com/imjoy-team/imjoy-project-template/tree/master/imjoy-plugins">imjoy-plugins</a>的文件夹。<br>（2.2）修改<code>manifest.imjoy.json</code>。对于每个插件：<br>（2.2.1）从插件代码中复制并粘贴<code>&lt;config&gt;</code>块的内容到 <code>manifest.imjoy.json</code> 中的 <code>plugins</code> 块。<br>（2.2.2）添加一个名为<code>&quot;uri&quot;</code>的字段，并将值设置为插件的实际文件名，包括 GitHub 仓库中的相对路径。例如，对于一个名为“untitledPlugin.imjoy.html”的插件文件，设定<code>&quot;uri&quot;: &quot;imjoy-plugins/untitledPlugin.imjoy.html&quot;</code>。如果你将插件的名字设为与插件文件的名字相同，则可以跳过此步骤。<br>在ImJoy中，可以以一个简单的url形式<code>http://imjoy.io/#/app?repo=GITHUB_USER_NAME/REPO_NAME</code>呈现仓库中所有插件的列表，其中<code>GITHUB_USER_NAME</code>是用户名，<code>REPO_NAME</code>是包含 ImJoy 插件的GitHub仓库的名称。然后用户就可以通过此列表来安装插件。有关如何生成此 url 的更多详细信息，并查看如何可以安装特定的插件，可以参阅下面的专门部分。</p><h2 id="官方ImJoy插件库"><a href="#官方ImJoy插件库" class="headerlink" title="官方ImJoy插件库"></a>官方ImJoy插件库</h2><p><code>ImJoy.io</code> 上显示的 ImJoy 插件库通过<a href="https://github.com/imjoy-team/imjoy-plugins">GitHub</a>部署。<br>为了将开发者自己的插件部署到<a href="https://github.com/imjoy-team/imjoy-plugins">该插件库</a>，可以fork该库，添加插件并发送pull request。PR被接受后，用户将能够从官方的插件仓库安装这个插件。</p><h1 id="分发插件"><a href="#分发插件" class="headerlink" title="分发插件"></a>分发插件</h1><p>要分发自己开发的插件，有两个主要选项。<br>（1）可以创建一个完整的url地址。单击时，ImJoy 将自动打开并安装插件。此链接可直接通过电子邮件或社交网络分享。在下面将详细说明如何创建此链接以及支持哪些选项。<br>（2）可以直接发送插件文件（扩展名<code>*.imjoy.html</code>）。这个文件可以被拖入ImJoy工作区，此时它会被自动识别为插件。</p><h2 id="使用自定义库分发插件"><a href="#使用自定义库分发插件" class="headerlink" title="使用自定义库分发插件"></a>使用自定义库分发插件</h2><p>如果开发的插件依赖于非标准库和模块，那么开发者必须随着插件一块提供这些库。可以将这些库和模块上传到 GitHub 仓库、GitHub Gist 或其他数据共享平台（例如 Dropbox）并将它们链接到插件代码中。<br>（1）对于JavaScript插件，需要创建一个 Gist 或 GitHub。将插件（以<code>.imjoy.html</code> 结尾）文件与其他 JavaScript 文件一起上传。在插件文件中，可以将 url 添加到插件 <code>requirements</code> 中。但是由于 GitHub 限制，不能直接使用 GitHub url，不过可以使用 <a href="https://combinatronics.com/">combinatronics.com</a> 进行转换。<br>（2）对于Python插件，建议将这些非标准库打包为 pip 模块，并放在GitHub上。</p><h2 id="存储在-Dropbox-上的代码-数据的分发"><a href="#存储在-Dropbox-上的代码-数据的分发" class="headerlink" title="存储在 Dropbox 上的代码/数据的分发"></a>存储在 Dropbox 上的代码/数据的分发</h2><p>此示例描述了如何部署和分发存储在 Dropbox 上的 Python 插件。<br>这允许共享私有项目。<br>（1）将code或data以 zip 文件的形式存储在 Dropbox 上。这允许通过替换 zip 文件来替换代码/数据（请参阅下面的注释）。<br>（2）将ImJoy 插件文件 (<code>.imjoy.html</code>) 使用私有或公开的gist托管。<br>假设 Python 代码位于存储在 Dropbox 上的 Zip 存档<code>testcode.zip</code>中，并且可通过链接“DROPBOXLINK/testcode.zip”获得。然后，可以将以下代码片段放在插件的 <code>setup()</code> 函数中以使其可用。该片段执行以下步骤：<br>（1）执行 <a href="http://docs.python-requests.org">http 请求</a>。注意此请求中的<code>dl=1</code>选项。默认情况下，此值设置为 0。<br>（2）使用返回的请求对象在本地生成zip文件，解压，最后删除。<br>（3）将本地路径添加到系统路径中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://DROPBOXLINK/testcode.zip?dl=1&#x27;</span></span><br><span class="line">r = requests.get(url, allow_redirects=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># download the zip file</span></span><br><span class="line">name_zip = os.path.join(<span class="string">&#x27;.&#x27;</span>,<span class="string">&#x27;testcode.zip&#x27;</span>)</span><br><span class="line"><span class="built_in">open</span>(name_zip, <span class="string">&#x27;wb&#x27;</span>).write(r.content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># extract to the current folder (i.e. workspace)</span></span><br><span class="line"><span class="keyword">with</span> zipfile.ZipFile(name_zip, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.extractall(<span class="string">&#x27;./&#x27;</span>)</span><br><span class="line">os.remove(name_zip)</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you want to import your python modules, append the folder to sys.path</span></span><br><span class="line">sys.path.append(os.path.join(<span class="string">&#x27;.&#x27;</span>,<span class="string">&#x27;testcode&#x27;</span>))</span><br></pre></td></tr></table></figure><br>一些注意点：<br>（1）代码本地存储在<code>USER_HOME/ImJoyWorkspace/WORKSPACENAME/testcode</code>中，其中WORKSPACENAME为当前ImJoy工作空间的名称。可以在提供的 URL 中自动设置工作区以分发插件。<br>（2）更新zip存档时，不要删除旧的，用新版本替换它。这保证了相同的链接是有效的。<br>（3）该代码每次都会安装当前版本的ZIP插件。</p><h2 id="生成用于共享的插件url"><a href="#生成用于共享的插件url" class="headerlink" title="生成用于共享的插件url"></a>生成用于共享的插件url</h2><p>分发插件的最简单方法是创建一个url，它可以通过电子邮件或社交网络共享。<br>基本格式是<code>http://imjoy.io/#/app?plugin=PLUGIN_URI</code>。注意要用实际plugin URI（统一资源标识符）来替换<code>PLUGIN_URI</code>。例如：<a href="https://imjoy.io/#/app?plugin=https://github.com/imjoy-team/imjoy-plugins/blob/master/repository/imageWindow.imjoy.html">https://imjoy.io/#/app?plugin=https://github.com/imjoy-team/imjoy-plugins/blob/master/repository/imageWindow.imjoy.html</a>。当用户点击此链接时，将显示一个插件安装对话框，提示安装指定的插件，用户只需单击“安装”即可确认。<br>此 url 支持一些额外参数来控制插件加载方式。这些参数将在下面的专门部分中进行描述。<br>有两种类型的URI，具体取决于插件的部署方式：<br>（1）如果插件部署在<code>ImJoy Plugin Repository</code>（如上所述），就可以使用格式为“GITHUB_USER_NAME/REPO_NAME:PLUGIN_NAME”的简短URI。比如可以用<code>imjoy-team/imjoy-project-template:Untitled Plugin</code>来表示托管在 <a href="https://github.com/oeway/DRFNS-Lite">https://github.com/oeway/DRFNS-Lite</a> 上的插件。<br>还可以通过在 <code>PLUGIN_NAME</code> 后添加 <code>@TAG</code> 来指定plugin的标签。例如：<code>oeway/DRFNS-Lite:DRFNS-Lite@GPU</code>。<br>如果还想指定一个git commit hashtag来将插件固定为某些提交，可以在<code>REPO_NAME</code>之后添加<code>@COMMIT_HASHTAG</code>。例如：<code>oeway/DRFNS-Lite@4063b24:DRFNS-Lite</code>，其中<code>4063b24</code>是<a href="https://github.com/oeway/DRFNS-Lite/tree/4063b24f01eab459718ba87678dd5c5db1e1eda1">4063b24f01eab459718ba87678dd5c5db1e1eda1</a>的短格式。<br>（2）还可以使用url指向任何托管的插件网站，包括开发者自己的项目站点、博客、GitHub、Gist或Dropbox。注意，插件文件需要以<code>.imjoy.html</code> 结尾。下面将介绍如何为不同的托管平台获取此 url：<br>（2.1）GitHub上的文件，只需复制文件链接即可。例如：<code>https://github.com/imjoy-team/imjoy-plugins/blob/master/repository/imageRecognition.imjoy.html</code>。<br>（2.2）对于Gist或其他Git提供者（如GitLab），如果Gist中只有一个文件，可以直接使用Gist链接（从浏览器地址栏复制）或获取插件<code>raw</code>文件的链接。对于具有多个文件的 Gist，需要为要使用的插件文件指定 <code>raw</code> 链接。要创建 Gist <code>raw</code> 链接：<br>（2.2.1）在自己的 GitHub 账户上访问Gist<a href="https://gist.github.com/">https://gist.github.com/</a><br>（2.2.2）创建新的 Gist，指定插件名称后跟 <code>.imjoy.html</code>，然后复制并粘贴插件代码。<br>（2.2.3）创建公共或私有 Gist。<br>（2.2.4）可以从<code>Raw</code>按钮获得Gist的链接（这链接到文件的未处理版本）。该链接如下所示：<code>https://gist.githubusercontent.com/oeway/aad257cd9aaab448766c6dc287cb8614/raw/909d0a86e45a9640c0e108adea5ecd7e78b81301/chartJSDemo.imjoy.html</code>。<br>（2.2.5）需要注意，当更新文件时，此url会更改。<br>（2.3）对于Dropbox，需要修改可共享的url如下：<br>（2.3.1）将<code>dl=0</code>替换为<code>dl=1</code>；<br>（2.3.2）将 <code>https://www.dropbox.com/</code> 替换为 <code>https://dl.dropboxusercontent.com/</code>。</p><p>要指定插件标签，只需在 <code>.imjoy.html</code> 后附加 <code>@TAG</code>。例如：<br><code>https://raw.githubusercontent.com/oeway/DRFNS-Lite/master/DRFNS-Lite.imjoy.html@GPU</code>。<br>可以在 ImJoy 中测试插件 url 是否有效：将其粘贴到 <code>+ PLUGINS</code> 对话框中，（<code>Install from URL</code>）并按<code>Enter</code>。如果一切正常，应该能够查看使用插件呈现的卡片，然后可以单击<code>INSTALL</code>。</p><h2 id="支持的url参数"><a href="#支持的url参数" class="headerlink" title="支持的url参数"></a>支持的url参数</h2><p>可以使用自定义参数来构建 ImJoy url，以便于安装。这些 url 参数可以在 <code>https://imjoy.io/#/app?</code> 之后使用，使用 <code>PARAM=VALUE</code> 语法。<br>这些参数相互独立，多个参数可以通过<code>&amp;</code>连接。例如我们要指定<code>par1=99</code>和<code>par2=hello</code>，相应的 url 将是 <code>https://imjoy.io/#/app?par1=99&amp;par2=hello</code>。<br>目前支持以下 url 参数：<br>（1）<code>plugin</code> 或 <code>p</code>：在插件管理对话框中显示指定的插件。如果存在具有相同名称和版本的插件，则不会显示该对话框。如果需要，添加 <code>upgrade=1</code> 以强制显示插件对话框。例如：<code>https://imjoy.io/#/app?p=imjoy-team/imjoy-demo-plugins:alert&amp;upgrade=1</code>。<br>（2）<code>workspace</code> 或 <code>w</code>：工作区的名称。 ImJoy 将切换到指定的工作区（如果存在），或创建一个新的工作区。例如，<code>https://imjoy.io/#/app?workspace=test</code><br>（3）<code>engine</code> 或 <code>e</code>：定义插件引擎的url。例如：<code>http://imjoy.io/#/app?engine=http://127.0.0.1:9527</code>。注意，如果想通过http（而非https）连接到远程机器，则只能使用 <code>http://imjoy.io</code> 而不是 <code>https://imjoy.io</code>。如果在某些浏览器（例如Firefox）中使用localhost，则此限制也存在。为避免这种情况，需要使用 <code>http://127.0.0.1:9527</code> 而不是 <code>http://localhost:9527</code>，因为大多数浏览器会认为 <code>127.0.0.1</code> 是安全连接，而<code>localhost</code>不是。但是，有一个例外，在 Safari 上，使用 <code>127.0.0.1</code> 不起作用，因为<a href="https://bugs.webkit.org/show_bug.cgi?id=171934">此限制</a>，请使用Firefox或Chrome。<br>（4）<code>token</code> 或 <code>t</code>：定义连接令牌。例如：<code>http://imjoy.io/#/app?token=2760239c-c0a7-4a53-a01e-d6da48b949bc</code><br>（5）<code>repo</code> 或 <code>r</code>：指定指向 ImJoy 插件仓库的清单文件。这可以是一个完整的 repo 链接，例如 <code>repo=https://github.com/imjoy-team/imjoy-plugins</code>或简化的 GitHub 链接 <code>repo=imjoy-team/imjoy-plugins</code>。如果从非GitHub网站（例如GitLab）托管插件库，就使用指向 <code>manifest.imjoy.json</code> 文件的 <code>raw</code> 链接。<br>（6）<code>start</code> 或 <code>s</code>：定义一个启动插件名称，它会在 ImJoy web 应用程序加载后自动启动。所有 url 参数将作为 <code>ctx.config</code> 传递给插件到 <code>run(ctx)</code> 函数。这允许添加自定义参数并在 <code>run(ctx)</code> 中使用它们。例如，插件可以使用<code>load=URL</code> 自动加载图像，并使用<code>width=1024&amp;height=2048</code> 设置图像的宽度和高度。例如，将<code>123</code>作为<code>ctx.data.x</code>传递给插件的<code>run</code>函数：<code>https://imjoy.io/#/app?x=123&amp;start=AwesomePlugin</code>。如果正在启动一个<code>window</code>插件，还可以将<code>standalone</code>或<code>fullscreen</code>设置为<code>1</code>以使窗口脱离工作区或处于全屏模式。例如：<code>https://imjoy.io/#/app?x=123&amp;start=AwesomeWindowPlugin&amp;fullscreen=1</code>。<br>（7）<code>load</code> 或 <code>l</code>：定义一个用于发起 http GET 请求的 URL，这个参数应该只在定义了一个带有 <code>start</code> 或 <code>s</code> 的启动插件时使用。从 URL 获取的数据将作为 <code>ctx.data.loaded</code> 传递给启动插件 <code>run(ctx)</code> 函数。<br>（8）<code>expose</code>：当 imjoy 嵌入到 iframe 中时，该参数指定是否应该将其 API 暴露给外部上下文（默认情况下不会暴露）。要启用，可以将 <code>expose=1</code> 添加到 URL 查询。</p><h2 id="添加ImJoy徽章"><a href="#添加ImJoy徽章" class="headerlink" title="添加ImJoy徽章"></a>添加ImJoy徽章</h2><p>如果开发者在项目中使用 ImJoy，建议将ImJoy徽章之一添加到项目仓库（例如在 Github 上）或网站。ImJoy有两个官方徽章：<img src="https://imjoy.io/static/badge/launch-imjoy-badge.svg" alt="launch ImJoy">和<img src="https://imjoy.io/static/badge/powered-by-imjoy-badge.svg" alt="powered by ImJoy">。<br>对于存储 ImJoy 插件的仓库，可以使用<img src="https://imjoy.io/static/badge/launch-imjoy-badge.svg" alt="launch ImJoy">徽章。<br>Markdown：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[![launch ImJoy](https:&#x2F;&#x2F;imjoy.io&#x2F;static&#x2F;badge&#x2F;launch-imjoy-badge.svg)](https:&#x2F;&#x2F;imjoy.io&#x2F;#&#x2F;app?plugin&#x3D;&lt;YOUR PLUGIN URL&gt;)</span><br></pre></td></tr></table></figure><br>reStructuredText：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.. image:: https:&#x2F;&#x2F;imjoy.io&#x2F;static&#x2F;badge&#x2F;launch-imjoy-badge.svg</span><br><span class="line"> :target: https:&#x2F;&#x2F;imjoy.io&#x2F;#&#x2F;app?plugin&#x3D;&lt;YOUR PLUGIN URL&gt;</span><br></pre></td></tr></table></figure></p><p>对于其他情况，例如，如果只是想感谢ImJoy，则可以使用<img src="https://imjoy.io/static/badge/powered-by-imjoy-badge.svg" alt="powered by ImJoy">。<br>Markdown:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[![powered by ImJoy](https:&#x2F;&#x2F;imjoy.io&#x2F;static&#x2F;badge&#x2F;powered-by-imjoy-badge.svg)](https:&#x2F;&#x2F;imjoy.io&#x2F;)</span><br></pre></td></tr></table></figure></p><p>reStructuredText:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.. image:: https:&#x2F;&#x2F;imjoy.io&#x2F;static&#x2F;badge&#x2F;powered-by-imjoy-badge.svg</span><br><span class="line"> :target: https:&#x2F;&#x2F;imjoy.io&#x2F;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">参考文献
Developing Plugins for ImJoy

上一篇文章中介绍了插件的文件格式，这一篇介绍如何进行实际的插件开发。

指定依赖
对于一个插件，其往往不是单一的功能实现，往往需要其他软件库的配合。
插件的依赖在其文件的config 块的requirements字段中进行指定。
根据不同的插件类型，可以指定不一样的依赖。

Web Worker 和 Window 插件
对于这两类插件，可以通过一个JavaScript库的url数组来指定依赖。这些库会被importScripts方法导入。
例如，要指定最新的 plotly.js 库，可以这样写：
1


&quot;requireme</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImJoy" scheme="http://qixinbo.github.io/tags/ImJoy/"/>
    
  </entry>
  
  <entry>
    <title>开源深度学习计算平台ImJoy解析：4 -- 插件文件格式</title>
    <link href="http://qixinbo.github.io/2021/12/04/ImJoy_4/"/>
    <id>http://qixinbo.github.io/2021/12/04/ImJoy_4/</id>
    <published>2021-12-03T16:00:00.000Z</published>
    <updated>2021-12-04T08:26:24.680Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://imjoy.io/docs/#/development">Developing Plugins for ImJoy</a></p><h1 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h1><p>ImJoy插件文件本质上是包括一系列自定义块的html文件（受<code>.vue</code> 格式启发）。<br>如下是一个插件文件的典型组成。需要注意的是，这些块的顺序无关紧要，因此可以将块打乱。<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">config</span> <span class="attr">lang</span>=<span class="string">&quot;json&quot;</span>&gt;</span></span><br><span class="line">   ** 该代码块以Json格式定义插件的属性**</span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br><span class="line"></span><br><span class="line">《script lang=&quot;javascript&quot;&gt;</span><br><span class="line">   ** 该代码块以JavaScript 或 Python 格式编写插件功能**</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">window</span> <span class="attr">lang</span>=<span class="string">&quot;html&quot;</span>&gt;</span></span><br><span class="line">   ** 该代码块以HTML 格式编写界面**（适用于window类型插件）</span><br><span class="line"><span class="tag">&lt;/<span class="name">window</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">style</span> <span class="attr">lang</span>=<span class="string">&quot;css&quot;</span>&gt;</span></span><br><span class="line">   ** 该代码块以CSS 格式定义界面样式**（适用于window类型插件）</span><br><span class="line"><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">docs</span> <span class="attr">lang</span>=<span class="string">&quot;markdown&quot;</span>&gt;</span></span><br><span class="line">   ** 该代码块以Markdown 格式编写插件文档 **</span><br><span class="line"><span class="tag">&lt;/<span class="name">docs</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">attachment</span> <span class="attr">name</span>=<span class="string">&quot;XXXXX&quot;</span>&gt;</span></span><br><span class="line">   ** 该代码块用于存储文本数据**</span><br><span class="line"><span class="tag">&lt;/<span class="name">attachment</span>&gt;</span></span><br></pre></td></tr></table></figure><br>其中，只有<code>&lt;config&gt;</code>和<code>《script&gt;</code>这两个代码块是必须的，其他块都是可选的。</p><h1 id="config块"><a href="#config块" class="headerlink" title="config块"></a>config块</h1><p>使用 <a href="https://www.json.org/">JSON</a> 或 <a href="https://yaml.org/">YAML</a> 格式的字段来定义插件的通用属性。<br><code>json</code>格式的配置为（注意JSON本身不支持注释，所以下面#号以后的内容只是为了这里方便说明，实际要去除；一些需要详细解释的字段会在下面单独说明）：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">config</span> <span class="attr">lang</span>=<span class="string">&quot;json&quot;</span>&gt;</span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;Untitled Plugin&quot;, # 插件名称。它必须是唯一的，以避免与其他插件冲突</span><br><span class="line">  &quot;type&quot;: &quot;web-worker&quot;, # 插件类型，选项有：`web-worker`、`window`、`native-python` 和`web-python`</span><br><span class="line">  &quot;ui&quot;: &quot;image processing&quot;, # 配置在插件下方显示的内容，详细用法将在下面详述</span><br><span class="line">  &quot;url&quot;: &quot;&quot;, # 当前文件的路径，用户从插件存储库安装插件时需使用该url来下载该插件</span><br><span class="line">  &quot;cover&quot;: &quot;&quot;, # 插件封面图片的url，详细用法将在下面详述</span><br><span class="line">  &quot;labels&quot;: [], # 定义一个“labels”列表来分类插件以允许基于语义标签进行搜索或过滤。</span><br><span class="line">  &quot;authors&quot;: [], # 作者姓名列表。</span><br><span class="line">  &quot;license&quot;: &quot;&quot;, # 插件所采用的许可证</span><br><span class="line">  &quot;repository&quot;: &quot;&quot;, # 插件项目存储库的url路径</span><br><span class="line">  &quot;website&quot;: &quot;&quot;, # 插件项目网站的url</span><br><span class="line">  &quot;tags&quot;: [], # 插件所支持的配置标签，详细用法将在下面详述</span><br><span class="line">  &quot;version&quot;: &quot;0.1.0&quot;, # 指定插件版本</span><br><span class="line">  &quot;api_version&quot;: &quot;0.1.6&quot;, # 指定插件所基于的 ImJoy 的 api 版本。</span><br><span class="line">  &quot;description&quot;: &quot;A plugin for image processing.&quot;, # 插件的简短描述</span><br><span class="line">  &quot;flags&quot;: [&quot;functional&quot;], # 用来控制插件行为，详细用法将在下面详述</span><br><span class="line">  &quot;icon&quot;: &quot;extension&quot;, # 定义插件菜单的图标，详细用法将在下面详述</span><br><span class="line">  &quot;inputs&quot;: null, # 定义用来触发插件的输入条件，比如拖进来一个文件，详细用法将在下面详述</span><br><span class="line">  &quot;outputs&quot;: null, # 定义插件的输出，详细用法将在下面详述</span><br><span class="line">  &quot;cmd&quot;: &quot;python&quot;, # 仅适用于python插件，用于运行插件的命令。默认情况下，它将使用`python`运行。根据安装的不同，它也可能是“python3”或“python27”等。</span><br><span class="line">  &quot;env&quot;: null, # 仅适用于python插件，虚拟环境或docker镜像命令，用于创建插件运行的环境。具体用法见另一篇博客的“指定依赖”一节</span><br><span class="line">  &quot;permissions&quot;: [], # 指定权限，详细用法将在下面详述</span><br><span class="line">  &quot;requirements&quot;: [], # 定义插件依赖，具体用法见另一篇博客的“指定依赖”一节</span><br><span class="line">  &quot;dependencies&quot;: [], # 指定当前插件依赖的其他ImJoy插件，详细用法将在下面详述</span><br><span class="line">  &quot;default&quot;: &#123;&#125;, # 仅适用于window插件，定义窗口的默认值，详细用法将在下面详述</span><br><span class="line">  &quot;base_frame&quot;: null, # 仅适用于window插件，定义在该窗口插件中内嵌的外部html的url路径，详细用法将在下面详述</span><br><span class="line">  &quot;runnable&quot;: true # 定义插件是否可以通过点击插件菜单来执行，详细用法将在下面详述</span><br><span class="line">&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br></pre></td></tr></table></figure><br>而<code>yaml</code>格式的配置为:<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">config</span> <span class="attr">lang</span>=<span class="string">&quot;yaml&quot;</span>&gt;</span></span><br><span class="line">name: Untitled Plugin</span><br><span class="line">type: web-worker</span><br><span class="line">tags: []</span><br><span class="line">ui: image processing</span><br><span class="line">cover: &#x27;&#x27;</span><br><span class="line">version: 0.1.0</span><br><span class="line">api_version: 0.1.6</span><br><span class="line">description: A plugin for image processing.</span><br><span class="line">icon: extension</span><br><span class="line">inputs: </span><br><span class="line">outputs: </span><br><span class="line">env: </span><br><span class="line">permissions: []</span><br><span class="line">requirements: []</span><br><span class="line">dependencies: []</span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h2 id="cover字段"><a href="#cover字段" class="headerlink" title="cover字段"></a>cover字段</h2><p><code>cover</code>字段用来指定插件封面图片的url，它将显示在图像安装对话框中，以及插件文档的顶部。<br>示例：<code>&quot;cover&quot;:&quot;https://imjoy.io/static/img/imjoy-card-plain.png&quot;</code>。<br>建议封面图片的纵横比为 16:9。 它可以托管在 GitHub 存储库中，此时应该使用图像的绝对路径URL。<br>可以使用多个图像，将 <code>cover</code> 设置为一个数组即可：<code>&quot;cover&quot;: [&quot;url_to_image1&quot;, &quot;url_to_image2&quot;, &quot;url_to_image3&quot;]</code>。</p><h2 id="tags字段"><a href="#tags字段" class="headerlink" title="tags字段"></a>tags字段</h2><p><code>tags</code>字段用来定义插件所支持的配置标签。<br>（注意：这里的<code>tags</code>不是用于分类或分组目的，分类或分组可以使用<code>labels</code>字段实现。）<br>这些定义的标签为插件执行提供了灵活的可配置的模式，比如可以配置插件是在 CPU 或 GPU 上运行。<br>以Unet Segmentation这个插件为例，如下是安装该插件时的界面及其源代码：<br><img src="https://user-images.githubusercontent.com/6218739/144185494-b3db5ddc-de2d-4d3b-a9fe-6e8549e062a5.png" alt="unet-tags"><br>可以看出，该插件在tags字段中定义了<code>CPU</code>、<code>GPU</code>、<code>Windows-CPU</code>、<code>Windows-GPU</code>四个标签，那么相应地，就可以在后面的环境配置和依赖库解析时，对其进行不同的要求：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;env&quot;</span>: </span><br><span class="line">&#123;<span class="string">&quot;CPU&quot;</span>: [<span class="string">&quot;conda config --add channels conda-forge&quot;</span>, <span class="string">&quot;conda create -n tf-cpu python=3.6&quot;</span>],</span><br><span class="line"><span class="string">&quot;GPU&quot;</span>: [<span class="string">&quot;conda config --add channels conda-forge&quot;</span>, <span class="string">&quot;conda create -n tf-gpu python=3.6&quot;</span>],</span><br><span class="line"><span class="string">&quot;Windows-CPU&quot;</span>: [<span class="string">&quot;conda config --add channels conda-forge&quot;</span>, <span class="string">&quot;conda create -n tf-cpu python=3.6&quot;</span>],</span><br><span class="line"><span class="string">&quot;Windows-GPU&quot;</span>: [<span class="string">&quot;conda config --add channels conda-forge&quot;</span>, <span class="string">&quot;conda create -n tf-gpu python=3.6&quot;</span>]</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">&quot;requirements&quot;</span>: </span><br><span class="line">&#123;<span class="string">&quot;CPU&quot;</span>: [<span class="string">&quot;repo:https://github.com/zhixuhao/unet&quot;</span>, <span class="string">&quot;pip:h5py scikit-image keras==2.1.4 numpy==1.18.0 tensorflow==1.15.4&quot;</span>],</span><br><span class="line"><span class="string">&quot;GPU&quot;</span>: [<span class="string">&quot;repo:https://github.com/zhixuhao/unet&quot;</span>, <span class="string">&quot;pip:h5py scikit-image keras==2.1.4 numpy==1.18.0 tensorflow-gpu==1.15.4&quot;</span>],</span><br><span class="line"><span class="string">&quot;Windows-CPU&quot;</span>: [<span class="string">&quot;repo:https://github.com/zhixuhao/unet&quot;</span>, <span class="string">&quot;pip:h5py scikit-image keras==2.1.4 numpy==1.18.0 tensorflow==1.15.4&quot;</span>],</span><br><span class="line"><span class="string">&quot;Windows-GPU&quot;</span>: [<span class="string">&quot;repo:https://github.com/zhixuhao/unet&quot;</span>, <span class="string">&quot;pip:h5py scikit-image keras==2.1.4 numpy==1.18.0 tensorflow-gpu==1.15.4&quot;</span>]</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><br>如果插件定义了tags，它们将出现在代码编辑器的顶部以及安装过程中。如果使用<code>url</code>分发插件，还可以具体指定插件将使用哪个标签安装。<br>在<code>&lt;config&gt;</code>代码块中，以下字段可以被tags所配置：<code>env</code>、<code>requirements</code>、<code>dependencies</code>、<code>icon</code>、<code>ui</code>、<code>type</code>、<code>flags</code>、<code>cover</code>。<br><code>&lt;script&gt;</code>代码块也可以被tags配置，此时必须把<code>tags</code>字段作为属性放到<code>&lt;script&gt;</code>中，同时注意原来的<code>lang</code>属性还要保留。比如：开发者可能想在插件的稳定版和开发版之间自由切换。那么可以定义这样的标签： <code>&quot;tags&quot;: [&quot;stable&quot;, &quot;dev&quot;]</code>，同时定义两个脚本块：<code>&lt;script lang=&quot;python&quot; tag=&quot;stable&quot;&gt;</code> 和 <code>&lt;script lang=&quot;python &quot;tag=&quot;dev&quot;&gt;</code>。在开发和测试插件时，ImJoy 编辑器会识别插件有多个标签，此时选择其中一个标签，那么加载插件时就会加载此标签下的相应代码。</p><h2 id="ui字段"><a href="#ui字段" class="headerlink" title="ui字段"></a>ui字段</h2><p><code>ui</code>字段是为了配置在插件下方显示的内容。<br>以HPA Classification插件为例，安装完成后，在ImJoy的左侧插件区，点击插件右侧的箭头，会看到<code>ui</code>字段定义的内容：<br><img src="https://user-images.githubusercontent.com/6218739/144191940-48d0ab2b-5c8c-4607-9543-b05daf28a1ee.png" alt="hpa-ui"></p><p>以下是<code>ui</code>字段的一个详细用法示例：<br><img src="https://user-images.githubusercontent.com/6218739/144377959-51a13531-9ce3-4752-8c13-7d841bcec51d.png" alt="ui-full"><br>包含了各种输入框的用法，以及同一个ui的三种写法：<code>option1</code>、<code>option11</code>、<code>option12</code>。<br>对于每个元素，都定义了一个唯一的<code>id</code>，然后可以使用 <code>ctx.config.id</code>来访问插件中此元素的值。</p><h2 id="flags字段"><a href="#flags字段" class="headerlink" title="flags字段"></a>flags字段</h2><p><code>flags</code>字段定义一个标志数组，用来控制插件的行为。<br>一个重要的flag是 <code>functional</code>：<code>functional</code>标志表示插件暴露的所有api函数都是<a href="https://segmentfault.com/a/1190000039807327">纯函数</a>。这意味着它们的输出将仅取决于输入。同时纯函数保证在调用任何插件 api 函数之后对插件没有副作用。这意味着应该避免修改插件函数中的全局变量（不过一个例外是<code>setup()</code> 函数）。<br>使一个插件具有<code>functional</code>标志，可以使调试更容易，重要的是其他插件或工作流调用<code>functional</code>插件时能严格重现其行为。<code>functional</code>插件对于 ImJoy 在将来执行并行化和批处理时至关重要。<br>作者还没有编写真正的测试来验证插件是否是<code>functional</code>，所以当前需要确定自己的插件仅包含纯函数时才添加 <code>functional</code> 标志。<br>此外，<code>flags</code>还支持运行时控制。这些标志允许用户界面和插件引擎如何处理 ImJoy 实例：</p><ul><li><code>single-instance</code>（仅适用于 python 插件）：在此标志下，Python引擎只会运行一个插件进程，即使从不同的浏览器或工作区调用了该插件。在这种情况下，不同的 ImJoy 实例将共享相同的插件进程。当插件需要独占有限的资源（例如 GPU）时，这尤其有用。</li><li><code>allow-detach</code>（仅适用于 python 插件）：在此标志下，允许插件进程与用户界面分离。这意味着当用户界面断开或关闭时，插件不会被杀死。然而，为了重新连接到这个进程，需要从同一个浏览器和相同的工作区重新连接，或添加 <code>single-instance</code> 标志。比如：如果想制作一个插件，它可以在没有用户界面的情况下在后台运行，那就对该插件赋予<code>&quot;flags&quot;: [&quot;single-instance&quot;, &quot;allow-detach&quot;]</code>。那么重新启动时，用户界面将自动重新连接到此进程。需要注意的是，如果多个 ImJoy 实例附加到此插件进程，每个实例都会调用 <code>setup()</code> 函数。这可能会导致冲突，因此建议 (1) 将与接口相关的代码保留在 <code>setup()</code> 中，例如<code>api.register()</code>; (2)将只想每个进程运行一次的代码移动到插件类的<code>__init__</code> 函数中。</li></ul><h2 id="icon字段"><a href="#icon字段" class="headerlink" title="icon字段"></a>icon字段</h2><p>定义插件菜单中使用的图标。可以选择以下格式：<br>（1）在<a href="https://material.io/tools/icons/">https://material.io/tools/icons/</a>找到图标，直接使用指定的名称即可；<br><img src="https://user-images.githubusercontent.com/6218739/144605127-ece26296-0933-4534-a798-cba6c4f0ace5.png" alt="icon"><br>实测使用该网站上的图标名称时，不能使用带空格的名称，以及全部要用小写。<br>（2）可以直接复制粘贴emoji符号，例如从<a href="https://getemoji.com/">这里</a>。<br><img src="https://user-images.githubusercontent.com/6218739/144605559-f3a9798b-23e1-4427-8185-3de397873d6c.png" alt="emoji"><br>（3）指定 JPEG、PNG 或 GIF 格式图像的 URL，推荐大小：64x64。<br><img src="https://user-images.githubusercontent.com/6218739/144605914-ada14870-30c1-45f8-b563-db5439a4710f.png" alt="gif-icon"><br>（4）如果设置为<code>null</code>或<code>&quot;&quot;</code>，它会默认使用第一条的material icon的<code>extension</code>图标。</p><h2 id="inputs字段"><a href="#inputs字段" class="headerlink" title="inputs字段"></a>inputs字段</h2><p>定义用于触发插件的输入条件，包括文件输入或数据匹配模式。例如，当用户将某个后缀的文件拖放到工作区时，相应的插件被激活。<br>基本上可以使用标准的 json 模式（<a href="http://json-schema.org/）来验证输入数据对象。例如，要定义插件使用">http://json-schema.org/）来验证输入数据对象。例如，要定义插件使用</a> png 文件，可以指定 <code>&quot;inputs&quot;: &#123;&quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: &#123;&quot;name&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;maxLength&quot; : 100&#125;&#125;, &quot;required&quot;: [&quot;name&quot;]&#125;</code>。在后台，ImJoy使用 <a href="https://github.com/epoberezkin/ajv">ajv</a> 库来验证对象。为了简化模式的使用，还使用以下关键字扩展了标准的 json 模式：<br>（1）<code>file</code>：对于文件对象，使用 <a href="https://en.wikipedia.org/wiki/Media_type">mime types</a> 或文件扩展名。可以使用以下关键字之一：</p><ul><li><code>mime</code>：常见的 mime 类型字符串（或列表）。例如<code>&#123;&quot;file&quot;: &#123;&quot;mime&quot;: &quot;image/png&quot;&#125;&#125;</code>。还可以指定一个 mime 类型列表：<code>&quot;mime&quot;: [&quot;image/png&quot;, &quot;image/jpeg&quot;, &quot;image/tiff&quot;]</code>。</li><li><code>ext</code>：文件扩展名字符串（或列表）。例如<code>&#123;&quot;file&quot;: &#123;&quot;ext&quot;: &quot;png&quot;&#125;&#125;</code>，或者可以指定一个扩展名列表：<code>&#123;&quot;file&quot;: &#123;&quot;ext&quot;: [&quot;png&quot;, &quot;jpg&quot;, &quot; jpeg&quot;]&#125;&#125;</code>。</li></ul><p>（2）<code>ndarray</code>：例如<code>&#123;&quot;ndarray&quot;: &#123;&quot;shape&quot;: [10, 10], &quot;dtype&quot;: &quot;uint8&quot;&#125;&#125;</code>。</p><ul><li><code>shape</code>：数组的形状。需要为每个维度指定一个数字，或者使用 <code>null</code> 表示该维度的任何大小。例如：<code>&#123;&quot;type&quot;: &quot;ndarray&quot;, &quot;shape&quot;: [10, 10]&#125;</code>，或者如果第一维可以是任意大小：<code>&#123;&quot;type&quot;: &quot;ndarray&quot;, &quot;shape&quot;: [null，10]&#125;</code></li><li><code>dtype</code>：数组的数据类型。例如：<code>&#123;&quot;ndarray&quot;: &#123;&quot;dtype&quot;: &quot;uint8&quot;&#125;&#125;</code> 或者如果同时支持 <code>uint8</code> 和 <code>float32</code>：<code>&#123;&quot;ndarray&quot;: &#123;&quot;dtype&quot;: [&quot;uint8&quot;, &quot; float32&quot;]&#125;&#125;</code>。支持的 <code>dtype</code> 是：<code>[&quot;int8&quot;, &quot;int16&quot;, &quot;int32&quot;, &quot;uint8&quot;, &quot;uint16&quot;, &quot;uint32&quot;, &quot;float32&quot;, &quot;float64&quot;, &quot;array&quot;]</code>。</li><li><code>ndim</code>：维数。例如：<code>&#123;&quot;ndarray&quot;: &#123;&quot;ndim&quot;: 2&#125;&#125;</code> 或者如果同时支持 2D 和 3D：<code>&#123;&quot;ndarray&quot;: &#123;&quot;ndim&quot;: [2, 3]&#125;&#125;</code></li></ul><p>（3）对于通过 http 或其他协议暴露的远程 url，<code>&#123;&quot;type&quot;: &quot;url&quot;, &quot;extension&quot;: &quot;zarr&quot;&#125;</code>。<br>另外需注意，如果在模式中使用正则表达式来验证字符串，可能需要设置 <code>maxLength</code>，否则它会非常慢，甚至在验证长字符串时可能会崩溃。例如，如果想匹配一个包含以<code>.tiff</code>结尾的<code>file_name</code>的对象，那么可以这样设置：<code>&#123;&quot;properties&quot;: &#123;&quot;file_name&quot;: &#123;&quot;type&quot;: &quot;string&quot;,&quot;pattern&quot;: &quot;.*\\.tiff$&quot;, &quot;maxLength&quot;: 1024&#125;&#125;&#125;</code>。</p><h2 id="outputs字段"><a href="#outputs字段" class="headerlink" title="outputs字段"></a>outputs字段</h2><p>使用 json-schema 语法 (<a href="http://json-schema.org/">http://json-schema.org/</a>) 定义输出。<br>格式与<code>inputs</code>相同。</p><h2 id="permissions字段"><a href="#permissions字段" class="headerlink" title="permissions字段"></a>permissions字段</h2><p>对于 <code>window</code> 插件，可以声明以下权限：</p><ul><li>摄像头camera</li><li>音乐数字接口midi</li><li>地理位置geolocation</li><li>麦克风microphone</li><li>加密媒体encryted-media</li><li>全屏full-screen</li><li>支付请求payment-request</li></ul><p>例如，如果某个<code>window</code>插件需要网络摄像头的访问权限，需要添加以下权限：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">“permissions”：[“camera”]，</span><br></pre></td></tr></table></figure><br>注意，摄像头和麦克风等设备只有在 ImJoy 为 <code>https</code> 时才能工作，这意味着如果是从<a href="https://imjoy.io">https://imjoy.io</a> 运行这个插件，那么是可以工作的，但如果使用的是自己托管的以<code>http</code>协议访问的ImJoy服务器，那么它就不会运行。解决方法是使用隧道服务，例如使用 <a href="https://telebit.cloud">Telebit</a> 或 <a href="https://ngrok.com">ngrok</a> 将 <code>http</code> url 转换为 <code>https</code>。</p><h2 id="dependencies字段"><a href="#dependencies字段" class="headerlink" title="dependencies字段"></a>dependencies字段</h2><p>该字段指定当前插件依赖的其他ImJoy插件。这些所依赖的插件将在安装过程中自动安装。<br>要定义依赖项，请使用以下格式：<br>1) 对于没有tag的依赖，使用 <code>REPOSITORY:PLUGIN_NAME</code> 或 <code>PLUGIN_URL</code>，例如：<code>imjoy-team/imjoy-plugins:Image Window</code>；<br>2) 对于带有指定tag的依赖，使用<code>REPOSITORY:PLUGIN_NAME@TAG</code> 或<code>PLUGIN_URL@TAG</code>，例如：<code>imjoy-team/imjoy-plugins:Unet Segmentation@GPU</code>。在这种情况下，标签“GPU”用于指定托管在 GitHub 存储库<code>imjoy-team/imjoy-plugins</code>（<a href="https://github.com/imjoy-team/）上的名为`Unet">https://github.com/imjoy-team/）上的名为`Unet</a> Segmentation<code>的插件。如果插件没有托管在GitHub上或者该GitHub仓库不是ImJoy插件仓库的标准格式（即在仓库的根目录中没有定义</code>manifest.imjoy.json<code>文件），则可以直接使用 url，例如：</code><a href="https://github.com/imjoy-team/imjoy-demo-plugins/blob/master/repository/3dDemos.imjoy.html`（标签可以用`@TAG`添加）。">https://github.com/imjoy-team/imjoy-demo-plugins/blob/master/repository/3dDemos.imjoy.html`（标签可以用`@TAG`添加）。</a></p><h2 id="default字段"><a href="#default字段" class="headerlink" title="default字段"></a>default字段</h2><p>仅适用于<code>window</code>插件，用于定义一个对象的默认值。<br>例如，可以通过设置 <code>&quot;defaults&quot;: &#123;&quot;w&quot;: 10, &quot;h&quot;: 7&#125;</code> 来指定默认窗口大小。<br>或者，可以使用 <code>&quot;defaults&quot;: &#123;&quot;fullscreen&quot;: true&#125;</code> 默认使窗口处于全屏模式。<br>要使窗口默认处于独立模式（全屏并与工作区分离），可以设置 <code>&quot;defaults&quot;: &#123;&quot;standalone&quot;: true&#125;</code>。<br>如果要将窗口显示为对话框，设置 <code>&quot;defaults&quot;: &#123;&quot;as_dialog&quot;: true&#125;</code>。</p><h2 id="base-frame字段"><a href="#base-frame字段" class="headerlink" title="base_frame字段"></a>base_frame字段</h2><p>仅适用于window插件，定义在该窗口插件中内嵌的外部html的url路径。<br>虽然可以在<code>base_frame</code>字段中使用任何其他网站的url，但是为了Imjoy内核可以与该html进行通信，它需要满足以下条件：<br>（1）该网站需要允许嵌入，不过这并不总是能够有效，因为它们可能有严格的 <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">内容安全策略</a>的限制，通常是通过<code>X-Content-Security-Policy</code>的header，或页面中的 <code>&lt;meta&gt;</code> 元素来实现该限制。要解决这个问题，如果你可以控制该站点，需要将 <code>*.imjoy.io</code> 添加到header中。<br>（2）在<code>base_frame</code>里面，需要开启<code>imjoy-rpc</code>协议。这可以按照 <a href="https://github.com/imjoy-team/ImJoy-core">imjoy-core</a> 仓库中的说明轻松搞定。参考“ImJoy RPC library to your website”这一部分进行操作，基本上就是需要导入<code>imjoy-loader</code>，并加载imjoy RPC库，然后导出想公开给其他ImJoy插件的api。<br>完成上述操作后，就可以将第三方网站集成为一个ImJoy插件。</p><h2 id="runnable"><a href="#runnable" class="headerlink" title="runnable"></a>runnable</h2><p>定义插件是否可以通过点击插件菜单来执行（默认情况下，所有插件都是<code>runnable</code>）。<br>对于不单独运行的辅助插件，（例如，<code>native-python</code> 插件可以被<code>window</code> 插件调用，不一定由用户直接执行），设置<code>&quot;runnable&quot;: false</code> 会向下移动插件到插件菜单的底部，并使其不可点击。</p><h1 id="docs块"><a href="#docs块" class="headerlink" title="docs块"></a>docs块</h1><p>在该块中，使用 Markdown 语言来编写插件文档。<br>Markdown语言的介绍见<a href="https://guides.github.com/features/mastering-markdown/">这里</a>。<br>注意，如果在文档中提供的链接将在另一个选项卡中打开，则 ImJoy 实例将继续运行。</p><h1 id="window块"><a href="#window块" class="headerlink" title="window块"></a>window块</h1><p>在该块中，使用HTML 代码来编写窗口的显示内容。<br>ImJoy 使用 vue.js 来解析插件文件，它强制要求仅有根元素存在于模板中。这意味着在<code>&lt;window&gt;</code>块中必须使用一个<code>div</code>来包装所有节点：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">window</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span> line 1<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span> line 2<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">window</span>&gt;</span></span><br></pre></td></tr></table></figure><br>如下则不可以：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">window</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span> line 1<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span> line 2<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">window</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h1 id="style块"><a href="#style块" class="headerlink" title="style块"></a>style块</h1><p>在该块中，使用CSS 代码来编写窗口显示内容的样式。</p><p>以MNIST CNN插件为例，给出以上<code>&lt;window&gt;</code>块和<code>style</code>块的一个说明：<br><img src="https://user-images.githubusercontent.com/6218739/144701434-77ef0f5c-f952-4bdf-aec7-c5c7209ae7cb.png" alt="html-css"></p><h1 id="script块"><a href="#script块" class="headerlink" title="script块"></a>script块</h1><p>该块中包含实际的插件代码。<br>插件可以用 JavaScript 或 Python 编写，一个最小的插件需要实现两个函数：<code>setup()</code> 和 <code>run()</code>。有一个例外是那种辅助插件（用 <code>&quot;runnable&quot;: false</code> 指定），它不需要 <code>run()</code> 函数。<br>（1）<code>setup()</code> 函数：在插件第一次加载和初始化时执行它。<br>（2）<code>run()</code> 函数：每次执行插件时都会调用。执行时，一个带有上下文（名为“ctx”）的对象object（Javascript插件）或字典dictionary（Python插件）将被传递到函数中。返回的结果将显示为一个新窗口或传递给工作流中的下一个 <code>op</code>。更多内容请参见另一篇博客的 <a href="development?id=plugin-during-runtime">运行时插件</a> 部分。<br>（3）可选：<code>resume()</code> 函数：仅适用于带有 <code>allow-detach</code> 标志的可分离 <code>native-python</code> 插件。当ImJoy 重新连接到正在运行的插件进程时，<code>resume()</code> 将被调用（而不是 <code>setup()</code>） 。<br>（4）可选：<code>update()</code> 函数：将在操作的任何设置更改时调用。<br>（5）可选：<code>exit()</code>函数：当插件被杀死时，函数<code>exit</code> 将被调用。</p><p><code>&lt;script&gt;</code> 块的 <code>lang</code> 属性用于指定使用的编程语言：<br>（1）对于 Javascript，使用 <code>&lt;script lang=&quot;javascript&quot;&gt; ... &lt;/script&gt;</code><br>（2）对于 Python，使用 <code>&lt;script lang=&quot;python&quot;&gt; ... &lt;/script&gt;</code><br>对于 Javascript 插件，还支持 ES 模块，要启用它，将 <code>type=&quot;module&quot;</code> 添加到<code>&lt;script&gt;</code>标签中。例如：<code>&lt;script type=&quot;module&quot; lang=&quot;javascript&quot;&gt;...&lt;/script&gt;</code>。<br><code>&lt;script&gt;</code> 也支持 <code>tags</code>，有关信息参考上面的<code>tags</code>字段的解析。</p>]]></content>
    
    
    <summary type="html">参考文献
Developing Plugins for ImJoy

概览
ImJoy插件文件本质上是包括一系列自定义块的html文件（受.vue 格式启发）。
如下是一个插件文件的典型组成。需要注意的是，这些块的顺序无关紧要，因此可以将块打乱。
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23


&lt;config lang=&quot;json&quot;&gt;
   ** 该代码块以Json格式定义插件的属性**
&lt;/config&gt;

《script lang=&quot;javascript&quot;&gt;
   ** 该代码块以JavaScript 或 Pyth</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImJoy" scheme="http://qixinbo.github.io/tags/ImJoy/"/>
    
  </entry>
  
  <entry>
    <title>开源深度学习计算平台ImJoy解析：3 -- 插件概览</title>
    <link href="http://qixinbo.github.io/2021/12/01/ImJoy_3/"/>
    <id>http://qixinbo.github.io/2021/12/01/ImJoy_3/</id>
    <published>2021-11-30T16:00:00.000Z</published>
    <updated>2021-12-01T02:12:53.574Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://imjoy.io/docs/#/i2k_tutorial?id=_2-make-your-first-imjoy-plugin">I2K Workshop Tutorial</a><br><a href="https://imjoy.io/docs/#/development">Developing Plugins for ImJoy</a></p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>开发ImJoy插件既简单又快速，可直接使用运行在web上的内置的代码编辑器，而不需要额外的 IDE 或编译器。<br>ImJoy 插件系统的主要功能有：<br>（1）支持 Python 和 JavaScript</p><ul><li>JavaScript 插件与安全沙箱隔离</li><li>Python 插件在自己的进程中运行</li><li>使用 <code>async/await</code> 语法支持并发 API 调用</li><li>支持 Python 的虚拟环境和 pip 包</li><li>支持托管在 GitHub 或 CDN 上的 JavaScript 库</li></ul><p>（2）原生支持 n 维数组和张量</p><ul><li>支持来自 Numpy 或 Numjs 的 ndarrays 进行数据交换</li><li>支持用于深度学习的 Tensorflow.js 和原生 Tensorflow、PyTorch、MxNet等深度学习库</li></ul><p>（3）使用 webGL、Three.js 等3D库渲染多维数据<br>（4）使用 GitHub 部署自定义的插件</p><h1 id="ImJoy架构"><a href="#ImJoy架构" class="headerlink" title="ImJoy架构"></a>ImJoy架构</h1><p>Imjoy 包含<strong>两个主要组件</strong>：<br>（1）<strong>ImJoy Web App</strong>：这是ImJoy 的核心部分，它是一个web应用，所以可在不同操作系统和设备的浏览器中运行。它提供了一个灵活的插件系统，具有工作流和窗口管理功能。插件可以用不同的编程语言开发，包括 JavaScript 和 Python。插件及其源代码可以组织到工作区中并存储在浏览器数据库中。 Web 插件在 <code>iframe</code> 或 <code>webworker</code> 中运行，因此开发者原则上可以为每个插件独立使用任何前端框架或 javascript 库。<br>（2）<strong>Plugin Engine</strong>：这是一个可选项，其用于在 CPython 中运行计算任务，以利用本机硬件（例如 GPU）和Python软件库（例如：numpy、Tensorflow、PyTorch 等）的强大功能。实际上，该插件引擎是一个在后台运行并通过 websocket 连接到 ImJoy Web App 的 Python 包 (<a href="https://github.com/imjoy-team/imjoy-engine">GitHub</a>)。它使用 <a href="https://conda.io/">conda</a> 来管理软件包（不仅是 Python，还有 C++、Java 等）和虚拟环境。然后开发者可以将具体的<code>conda</code> 或 <code>pypi</code> 包作为需求添加到插件中，它们可以由插件引擎自动解析。同样，开发人员可以在 Python 插件中使用任何 Python 库甚至非 Python 库。<br><img src="https://user-images.githubusercontent.com/6218739/144013956-2be625bd-3a30-4c10-be13-c138513d25be.png" alt="full-arch"></p><p>Plugin Engine 通过 websockets 与 ImJoy Web App 连接， 并与一个基于 <a href="https://github.com/miguelgrinberg/python-socketio">socket.io</a> 定制化的RPC（remote procedure calls）进行通信。</p><h1 id="什么是ImJoy插件"><a href="#什么是ImJoy插件" class="headerlink" title="什么是ImJoy插件"></a>什么是ImJoy插件</h1><p>简而言之，ImJoy插件是一个脚本，它生成一组可以被ImJoy内核或其他插件调用的服务函数（又名插件 API 函数）。<br>目前有 4 种常见的插件类型：<code>window</code>、<code>web-worker</code>、<code>web-python</code>、<code>native-python</code>。<br>（1）Web 插件直接在浏览器中运行，支持如下三种类型：</p><ul><li>Window (HTML/CSS/JS)(<code>type=window</code>) 插件，用于使用 HTML5/CSS 和 JavaScript 构建丰富的交互式用户界面；</li><li>Web Worker (JS)(type=<code>web-worker</code>) 插件，用于使用 JavaScript 或 WebAssembly 执行计算任务；</li><li>Web Python(type=<code>web-python</code>) 插件，用于在浏览器中通过 WebAssembly 和 <a href="https://github.com/iodide-project/pyodide">pyodide</a> 使用 Python 执行计算任务。这样的插件用小蛇🐍图标表示。这处于开发阶段，目前仅支持选定数量的 Python 库。</li></ul><p>（2）Native插件在插件引擎中运行，目前支持：</p><ul><li>Native Python(type=<code>native-python</code>) 插件，可使用 Python 及其大量库函数来执行繁重计算任务，不过这需要额外安装插件引擎。这些插件用火箭🚀图标表示。</li></ul><h2 id="Window插件"><a href="#Window插件" class="headerlink" title="Window插件"></a>Window插件</h2><p>Window 插件用于创建一个包含 HTML/CSS 和 JavaScript 的新 Web 界面。其是在<code>iframe</code>模式下创建的，将显示为一个窗口。 <code>&lt;window&gt;</code> 和 <code>&lt;style&gt;</code>块（见以后插件文件格式的详细解析）可用于定义窗口的实际内容。<br>不同于其他插件会在 ImJoy 启动时加载和初始化，只有在使用<code>api.createWindow</code>创建实际插件或用户在菜单中单击时，才会加载<code>window</code>插件。在<code>api.createWindow</code>执行过程中，<code>setup</code>和<code>run</code>会被首先调用，并返回一个窗口api对象（包含窗口的所有api函数，包括<code>setup</code>、<code>run</code>和其他功能（如果已定义））。然后就可以使用这个window api 对象来访问所有的函数，例如通过<code>win_obj.run(&#123;&#39;data&#39;: ... &#125;)</code> 来更新窗口的内容。</p><h2 id="Web-Worker插件"><a href="#Web-Worker插件" class="headerlink" title="Web Worker插件"></a>Web Worker插件</h2><p>Web Worker插件用于在另一个线程中执行计算任务，具体途径是使用一个名为 <a href="https://en.wikipedia.org/wiki/Web_worker">web worker</a> 的新元素。<br>它没有接口，是在一个新线程中运行，并且在运行过程中不会挂起主线程。它基本上是 JavaScript 实现多线程的一种方式。<br>由于 Web Worker 旨在执行计算任务，它们无权访问 <a href="https://www.w3schools.com/whatis/whatis_htmldom.asp">html dom</a>，但是开发者可以使用<code>ImJoy API</code>来与ImJoy的图形界面或其他可以触发用户界面更改的插件进行交互。</p><h2 id="Web-Python插件"><a href="#Web-Python插件" class="headerlink" title="Web Python插件"></a>Web Python插件</h2><p>Web Python插件可以完全在浏览器中运行 python 代码和科学库。ImJoy 使用 <a href="https://github.com/iodide-project/pyodide/">pyodide</a> 来运行 python 插件，它支持通过 WebAssembly 运行带有科学库（包括 numpy、scipy、scikit-learn 等）的 Python3 代码。</p><h2 id="Native-Python插件"><a href="#Native-Python插件" class="headerlink" title="Native Python插件"></a>Native Python插件</h2><p>Native Python插件用于运行原生 Python 代码以完全访问电脑硬件（例如 GPU、NVLINK）和软件（例如 CUDA 和 CUDNN）环境。这需要在使用插件之前安装并启动<strong>Python Plugin Engine</strong>。<br>与 Web Worker 插件类似，Native Python 插件无法访问 html dom，但可以使用 <code>ImJoy API</code> 与ImJoy 的图形界面或其他可以触发用户界面更改的插件进行交互。</p><h2 id="更多插件类型"><a href="#更多插件类型" class="headerlink" title="更多插件类型"></a>更多插件类型</h2><p>插件类型可以通过插件进一步扩展。例如，作者新创建一个新的插件类型来执行Fiji/Scijava脚本，参见 <a href="https://forum.image.sc/t/making-imjoy-plugins-with-fiji-scripts-for-running-remotely/39503">这篇文章</a>。</p><h2 id="ImJoy-App和Plugin-Engine与插件的关系"><a href="#ImJoy-App和Plugin-Engine与插件的关系" class="headerlink" title="ImJoy App和Plugin Engine与插件的关系"></a>ImJoy App和Plugin Engine与插件的关系</h2><p>使用 ImJoy App 的推荐方式是通过 <a href="https://imjoy.io">https://imjoy.io</a>。<br>不过ImJoy还不是普通的web应用，它是采用了称为渐进式 Web 应用 (PWA) 的新方法。例如，在 Chrome 中，用户可以将 ImJoy 安装到 <a href="chrome://apps/">chrome://apps/</a> 并从这个仪表板中启动ImJoy（同时生成桌面快捷方式）。一旦安装，ImJoy 就可以在独立的浏览器窗口中运行（没有地址栏）。 ImJoy 的内核部分支持离线，但插件目前还不支持（作者说后面将支持）。<br>可以使用ImJoy App运行所有web插件（<code>web-worker</code>、<code>window</code>、<code>web-python</code>），但是，对于本机插件（<code>native-python</code>），需要连接到插件引擎在本地或远程运行。<br>以下是安装插件引擎的两个选项：<br>（1）本地安装：下载并安装 Anaconda 或 Miniconda with Python3，然后运行<code>pip install imjoy</code>。然后可以通过 <code>imjoy --jupyter</code> 命令启动插件引擎。更多详细信息可在 <a href="https://github.com/imjoy-team/imjoy-engine/">此处</a> 获得。<br>（2）使用Jupyter托管服务：使用<a href="https://mybinder.org/">binder</a>提供的免费Jupyter服务器，该服务是远程的，所以不需要额外安装。然而，其提供的算力也有限（比如1GB内存、无GPU支持等）。<br><img src="https://user-images.githubusercontent.com/6218739/144159316-243a6048-fb9e-4201-965c-fa11db4c9ded.png" alt="engines"></p><h1 id="ImJoy代码编辑器和开发人员工具"><a href="#ImJoy代码编辑器和开发人员工具" class="headerlink" title="ImJoy代码编辑器和开发人员工具"></a>ImJoy代码编辑器和开发人员工具</h1><p>ImJoy提供了一个内置的代码编辑器供编写插件。结合浏览器提供的调试工具（例如：Google Chrome 开发者工具），不需要额外的 IDE 或工具。<br>可以通过单击插件菜单（插件名称旁边的图标）中的“Edit”来查看和修改任何现有插件的插件代码。<br><img src="https://user-images.githubusercontent.com/6218739/144052196-ace51e31-757c-4519-988d-904bb3a1d89a.png" alt="editor"></p><p><a href="https://developers.google.com/web/tools/chrome-devtools">Chrome 开发者工具</a> 提供了不同的调试HTML/CSS/Javascript、网络等的工具。建议使用它来调试Web插件。例如，可以像正常JavaScript开发那样在JavaScript中使用 <code>console.log()</code>、<code>console.error()</code>等，然后在浏览器控制台中检查日志和错误。在Python插件中，错误追溯也会转发到浏览器控制台。<br><img src="https://user-images.githubusercontent.com/6218739/144053608-0dd72e3b-752f-4f66-98e7-52ac4ade46c5.png" alt="chrome"><br>除此之外，还可以使用ImJoy API函数，包括 <code>api.log()</code>、<code>api.error()</code>、<code>api.alert()</code>、<code>api.showMessage()</code> 等来向ImJoy应用程序显示消息。<br>特别地，对于Python插件，<code>print()</code>只会在启动插件引擎的终端中看到，因此建议开发Python插件时使用这些API函数来辅助debug。</p><h1 id="ImJoy插件文件格式"><a href="#ImJoy插件文件格式" class="headerlink" title="ImJoy插件文件格式"></a>ImJoy插件文件格式</h1><p>ImJoy插件通常是一个扩展名为<code>*.imjoy.html</code>的文本文件。其中使用HTML/XML标签，例如 <code>&lt;config&gt;</code>、<code>&lt;script&gt;</code>、<code>&lt;window&gt;</code> 来存储代码块。<br>大多数插件类型至少需要两个代码块：<code>&lt;config&gt;</code> 和<code>&lt;script&gt;</code>，例如<code>web-worker</code>、<code>web-python</code> 和<code>native-python</code>。对于<code>window</code> 插件，代码中需要额外一个<code>&lt;window&gt;</code> 块，以及一个可选<code>&lt;style&gt;</code> 块用于CSS定义。</p><p>对于<code>&lt;script&gt;</code>代码块，大多数插件至少会暴露两个特殊函数：<code>setup</code>（用于初始化）和<code>run</code>（当用户点击插件菜单按钮时调用）。在加载插件时，一个包含所有ImJoyAPI函数的<code>api</code>对象将被传递给插件，然后插件可以构建服务函数并通过调用 <code>api.export(...)</code> 函数来注册它们。</p><p>比如以下插件中定义了 3 个 API 函数：一个空的 <code>setup</code> 函数，一个 <code>choosePokemon</code> 函数，以及一个可供调用的 <code>run</code> 函数（由 ImJoy内核调用或用户点击插件菜单时）：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImJoyPlugin</span></span>&#123;</span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="title">setup</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="title">choosePokemon</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="keyword">const</span> pokemon = <span class="keyword">await</span> api.prompt(<span class="string">&quot;What is your favorite Pokémon?&quot;</span>, <span class="string">&quot;Pikachu&quot;</span>)</span><br><span class="line">        <span class="keyword">await</span> api.showMessage(<span class="string">&quot;Your have chose &quot;</span> + pokemon + <span class="string">&quot; as your Pokémon.&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="title">run</span>(<span class="params">ctx</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">await</span> <span class="built_in">this</span>.choosePokemon()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">api.export(<span class="keyword">new</span> ImJoyPlugin())</span><br></pre></td></tr></table></figure><br>关于 ImJoy 插件文件的详细说明可以在这里找到：<a href="https://imjoy.io/docs/#/development?id=plugin-file-format">插件文件格式</a>。</p><h1 id="ImJoy的Hello-World插件"><a href="#ImJoy的Hello-World插件" class="headerlink" title="ImJoy的Hello World插件"></a>ImJoy的Hello World插件</h1><p>要制作第一个 ImJoy 插件，即ImJoy的Hello World，可以单击<code>+ PLUGINS</code>，然后从<code>+ CREATE A NEW PLUGIN</code>下拉菜单中选择默认模板<code>Default template</code>。<br><img src="https://user-images.githubusercontent.com/6218739/144052725-44768110-a754-4cce-a9fb-8f70a2bcbfc7.png" alt="helloworld"><br>生成的插件代码为：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&lt;docs&gt;</span><br><span class="line">[TODO: write documentation <span class="keyword">for</span> <span class="built_in">this</span> plugin.]</span><br><span class="line">&lt;/docs&gt;</span><br><span class="line">&lt;config lang=<span class="string">&quot;json&quot;</span>&gt;</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Untitled Plugin&quot;</span>,</span><br><span class="line">  <span class="string">&quot;type&quot;</span>: <span class="string">&quot;web-worker&quot;</span>,</span><br><span class="line">  <span class="string">&quot;tags&quot;</span>: [],</span><br><span class="line">  <span class="string">&quot;ui&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">  <span class="string">&quot;version&quot;</span>: <span class="string">&quot;0.1.0&quot;</span>,</span><br><span class="line">  <span class="string">&quot;cover&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">  <span class="string">&quot;description&quot;</span>: <span class="string">&quot;[TODO: describe this plugin with one sentence.]&quot;</span>,</span><br><span class="line">  <span class="string">&quot;icon&quot;</span>: <span class="string">&quot;extension&quot;</span>,</span><br><span class="line">  <span class="string">&quot;inputs&quot;</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="string">&quot;outputs&quot;</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="string">&quot;api_version&quot;</span>: <span class="string">&quot;0.1.8&quot;</span>,</span><br><span class="line">  <span class="string">&quot;env&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">  <span class="string">&quot;permissions&quot;</span>: [],</span><br><span class="line">  <span class="string">&quot;requirements&quot;</span>: [],</span><br><span class="line">  <span class="string">&quot;dependencies&quot;</span>: []</span><br><span class="line">&#125;</span><br><span class="line">&lt;/config&gt;</span><br><span class="line">&lt;script lang=<span class="string">&quot;javascript&quot;</span>&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImJoyPlugin</span> </span>&#123;</span><br><span class="line">  <span class="keyword">async</span> <span class="function"><span class="title">setup</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    api.log(<span class="string">&#x27;initialized&#x27;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">async</span> <span class="function"><span class="title">run</span>(<span class="params">ctx</span>)</span> &#123;</span><br><span class="line">    api.alert(<span class="string">&#x27;hello world.&#x27;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">api.export(<span class="keyword">new</span> ImJoyPlugin())</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><br>上述代码的具体语法会在后面具体详述。<br>在不更改代码的情况下，可以通过单击保存图标来保存它，此时会在插件菜单中添加一个名为“Untitled Plugin”的新条目。<br>要运行这个插件，可以单击“Untitled Plugin”按钮。此时将看到一个带有“Hello World”的弹出对话框。<br><img src="https://user-images.githubusercontent.com/6218739/144055127-ffd19736-bcde-4f58-9c15-e7a976bb82ae.png" alt="hello"></p><p>如果是在本地电脑编辑的ImJoy插件文件（扩展名为 <code>*.imjoy.html</code>），那么可通过下面操作加载到ImJoy Web App中：<br>1) 转到 <a href="https://imjoy.io/#/app">https://imjoy.io/#/app</a><br>2) 将该文件拖放到浏览器中即可。</p><p>对于 Python 开发，可以使用 <a href="https://github.com/imjoy-team/imjoy-jupyter-extension">jupyter notebook 扩展</a>。该部分会在以后详细解析。</p><h1 id="部署和共享插件"><a href="#部署和共享插件" class="headerlink" title="部署和共享插件"></a>部署和共享插件</h1><p>如果你想与他人分享你的插件，可以直接发送插件文件，或者将插件上传到 Github/Gist。建议使用后者，因为它会更大范围地分发插件。<br>以下步骤可以帮助编写及部署插件：<br>（1）在 Github 上 <a href="https://github.com/imjoy-team/imjoy-starter/fork">fork imjoy-starter repo</a>（或者，如果你愿意，可以创建一个空的）。imjoy-starter仓库包含一个<a href="https://github.com/imjoy-team/imjoy-starter/tree/master/docs">docs 文件夹</a>，开发者可以在 Markdown 中做笔记，它将渲染为像这样的<a href="https://imjoy-team.github.io/imjoy-starter/">交互式的网站</a>。有关更多信息，请参阅<a href="https://docsify.js.org/#/"><strong>此处</strong></a>。可以在Markdown中添加带有一些特殊标记的插件代码，然后就可以看到<strong>Run</strong>和<strong>Edit</strong>按钮。<br>（2）然后可以将自己的插件命名为，例如，<code>hello.imjoy.html</code> 并使用 git 命令将其上传到你所fork的仓库的 <code>plugins</code> 文件夹或直接上传到仓库。<br>（3）然后单击插件文件并复制地址栏中的url，它应该类似于：<code>https://github.com/&lt;YOUR-GITHUB-USERNAME&gt;/imjoy-starter/blob/master/plugins/hello.imjoy.html</code><br>此路径可用于在ImJoy中安装插件。<br>（4）单击<strong>Run</strong>打开ImJoy Web App。要安装插件，单击<code>+PLUGINS</code>并将URL粘贴到<code>Install from URL</code>输入框中，然后按 Enter。<br>（5）现在可以构建一个URL与他人共享，只需在 <code>https://imjoy.io/#/app?plugin=</code> 后面添加 URL 即可，比如这样：<code>https://imjoy.io/#/app?plugin=https://github.com/&lt;YOUR-GITHUB-USERNAME&gt;/imjoy-starter/blob/master/plugins/hello.imjoy.html</code>。<br>如果用户单击这个插件URL，它将直接在ImJoy中打开插件并提示用户安装它。</p>]]></content>
    
    
    <summary type="html">参考文献
I2K Workshop Tutorial
Developing Plugins for ImJoy

概述
开发ImJoy插件既简单又快速，可直接使用运行在web上的内置的代码编辑器，而不需要额外的 IDE 或编译器。
ImJoy 插件系统的主要功能有：
（1）支持 Python 和 JavaScript

 * JavaScript 插件与安全沙箱隔离
 * Python 插件在自己的进程中运行
 * 使用 async/await 语法支持并发 API 调用
 * 支持 Python 的虚拟环境和 pip 包
 * 支持托管在 GitHub 或 CDN 上的 JavaScript</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImJoy" scheme="http://qixinbo.github.io/tags/ImJoy/"/>
    
  </entry>
  
  <entry>
    <title>开源深度学习计算平台ImJoy解析：2 -- 核心概念</title>
    <link href="http://qixinbo.github.io/2021/11/30/ImJoy_2/"/>
    <id>http://qixinbo.github.io/2021/11/30/ImJoy_2/</id>
    <published>2021-11-29T16:00:00.000Z</published>
    <updated>2021-11-30T07:45:44.837Z</updated>
    
    <content type="html"><![CDATA[<p>这一篇主要介绍ImJoy中的核心概念。<br>参考文献：<br><a href="https://imjoy.io/docs/#/i2k_tutorial">I2K Workshop Tutorial</a></p><h1 id="ImJoy插件"><a href="#ImJoy插件" class="headerlink" title="ImJoy插件"></a>ImJoy插件</h1><p>ImJoy 提供了一个灵活的框架来开发具有不同类型的 Web 或 Python 编程语言的插件。<br><img src="https://user-images.githubusercontent.com/6218739/143839866-7d945048-055f-4898-b65b-64af66d4d316.png" alt="plugins"><br>有四种类型的插件，其可用于不同的目的：<br>（1）Web 插件直接在浏览器中运行，支持如下三种类型：</p><ul><li>Window (HTML/CSS/JS)(<code>type=window</code>) 插件，用于使用 HTML5/CSS 和 JavaScript 构建丰富的交互式用户界面；</li><li>Web Worker (JS)(type=<code>web-worker</code>) 插件，用于使用 JavaScript 或 WebAssembly 执行计算任务；</li><li>Web Python(type=<code>web-python</code>) 插件，用于在浏览器中通过 WebAssembly 和 <a href="https://github.com/iodide-project/pyodide">pyodide</a> 使用 Python 执行计算任务。这样的插件用小蛇🐍图标表示。这处于开发阶段，目前仅支持选定数量的 Python 库。</li></ul><p>（2）Native插件在插件引擎中运行，目前支持：</p><ul><li>Native Python(type=<code>native-python</code>) 插件，可使用 Python 及其大量库函数来执行繁重计算任务，不过这需要额外安装插件引擎。这些插件用火箭🚀图标表示。</li></ul><p>可以通过单击 <code>+ PLUGINS</code> 按钮，然后从“创建新插件”下拉菜单中访问上述插件的模板，如图：<br><img src="https://user-images.githubusercontent.com/6218739/144004594-0ccaac1d-6fb0-4c83-a42d-8dc1c565f823.png" alt="4plugins"></p><p>关于插件具体怎样编写，会在后面博文中具体解析。</p><h1 id="ImJoy-API"><a href="#ImJoy-API" class="headerlink" title="ImJoy API"></a>ImJoy API</h1><p>为了允许基本的用户交互，ImJoy 提供了一组 API（应用程序编程接口）函数，这些函数可以在所有插件类型和支持的编程语言中以相同的方式调用。<br>例如，与 Javascript 函数 <code>alert()</code>等效的 ImJoy API 函数是 <code>api.alert()</code>。</p><p>可以直接访问 Javascript 插件中的 <code>api</code> 对象（使用 type=<code>window</code> 或 <code>web-worker</code>）：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">api.alert(<span class="string">&quot;Hello from ImJoy!&quot;</span>)</span><br></pre></td></tr></table></figure><br>在 Python 插件（type=<code>web-python</code> 或 <code>native-python</code>）中，需要先添加 <code>from imjoy import api</code>，然后才能访问 <code>api</code> 对象。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import api object</span></span><br><span class="line"><span class="keyword">from</span> imjoy <span class="keyword">import</span> api</span><br><span class="line">...</span><br><span class="line"><span class="comment"># use api object</span></span><br><span class="line">api.alert(<span class="string">&quot;Hello from ImJoy!&quot;</span>)</span><br></pre></td></tr></table></figure></p><p>可以在 <a href="https://imjoy.io/docs/#/api">此处</a> 中找到所有 ImJoy API 功能的详细说明。同样，后面会对这些API详细解析。</p><h1 id="ImJoy-中的远程过程调用"><a href="#ImJoy-中的远程过程调用" class="headerlink" title="ImJoy 中的远程过程调用"></a>ImJoy 中的远程过程调用</h1><p>尽管调用 <code>alert()</code> 和 <code>api.alert()</code> 会产生相同的结果（都是弹出消息），但要注意的是其底层过程是不同的。当调用<code>alert()</code>时，直接从插件启动弹出对话框，而调用<code>api.alert()</code>会从ImJoy内核（ImJoy core）中启动弹出对话框。<br>需要时刻注意的是，ImJoy 是在独立或沙盒环境（即sandboxed iframe、webworker、conda 虚拟环境或 docker 容器）中运行每个插件。简而言之，这意味着默认情况下，函数和变量不会在插件之间或插件与ImJoy内核之间进行共享。<br>当从插件中调用 ImJoy API 函数时，该函数将在 ImJoy 内核中执行。由于插件运行在不同的环境中，所以ImJoy内核中定义的所有功能都是“远程”功能。相比之下，同一个插件中定义的所有函数都是“本地”的。<br>因此，调用 ImJoy API 函数意味着执行远程过程调用 <strong>Remote Procedure Calls (RPC)</strong>。<br>（ImJoy 支持双向 RPC，不仅在插件和 ImJoy 内核之间，而且在插件之间也是如此。RPC可以在不同编程语言和不同主机之间统一地使用）<br>比如，当一个在远程服务器上运行的 Python 插件进行调用<code>api.alert()</code> 时，弹出对话框则是由用户浏览器中的 ImJoy 内核（用 Javascript 实现）来启动的。<br>RPC 允许将任务分发到以不同语言和不同位置运行的不同插件。例如，我们可以使用强大的 UI 库（例如 <a href="https://d3js.org/">D3</a> 和 <a href="https://kitware.github. io/itk-vtk-viewer/">ITK/VTK Viewer</a> )来构建用户界面，并用<a href="https://www.tensorflow.org/js">Tensorflow. js</a>中的<a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers">Web Worker</a> 来运行深度学习模型 。对于使用 GPU 来训练模型这种重型计算任务，可以在本地或远程（例如在 GPU 集群或实验室工作站上）的 Jupyter 笔记本服务器（即ImJoy插件引擎 Plugin Engine）上编写Python 插件来实现。<br>这篇博文 (<a href="http://tomerfiliba.com/blog/RPCs-Life-And-All/">RPCs, Life and All</a>) 解释了用于Python 远程过程调用的库 (<a href="https://rpyc.readthedocs.io/en/latest/">RPyC</a>)背后的想法 ，该库与 ImJoy 中提供的类似。</p><h1 id="异步编程"><a href="#异步编程" class="headerlink" title="异步编程"></a>异步编程</h1><p>由于 ImJoy API 函数是远程函数，它们的操作与同一插件中定义的本地函数略有不同。更具体地说，远程函数是异步的。<br>在ImJoy中调用异步函数有一个简化的规则：ImJoy中的所有远程功能都是异步的，可以像其他本地函数一样使用它们，只需在函数调用前添加 <code>await</code>。<br>即应该执行 <code>await api.alert(&#39;hello&#39;)</code> 来调用上面的alert函数。<br>如果API函数有返回值，例如<a href="https://imjoy.io/docs/#/api?id=apiprompt"><code>api.prompt</code></a>，应该写成：<code>result = await api.prompt( &#39;type a number&#39;)</code>。</p><p>但是需要注意的是，如果直接执行 <code>await api.alert(&#39;hello&#39;)</code>，会导致语法错误而不能执行。<br>要修复错误，需要将代码封装在一个异步函数中：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Javascript 中的异步/等待示例</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="title">sayHello</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">await</span> api.alert(<span class="string">&quot;Hello from ImJoy!&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">sayHello()</span><br></pre></td></tr></table></figure><br>因此，另一个使用 <code>async/await</code> 的简单规则是：<br>在函数中使用<code>await</code>时，在函数定义前添加<code>async</code>。</p><p>再举一个例子，使用另一个 ImJoy API 函数 <a href="https://imjoy.io/docs/#/api?id=apiprompt"><code>api.prompt</code></a> 在弹出对话框中获取用户的输入，并使用这个API <a href="https://imjoy.io/docs/#/api?id=apishowmessage"><code>api.showMessage</code></a>来显示消息。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">choosePokemon</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">const</span> pokemon = <span class="keyword">await</span> api.prompt(<span class="string">&quot;What is your favorite Pokémon?&quot;</span>,<span class="string">&quot;Pikachu&quot;</span>)</span><br><span class="line">    <span class="keyword">await</span> api.showMessage(<span class="string">&quot;Your have chose &quot;</span>+pokemon +<span class="string">&quot; as your Pokémon.&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">choosePokemon()</span><br></pre></td></tr></table></figure></p><h2 id="Python的Async-Await"><a href="#Python的Async-Await" class="headerlink" title="Python的Async/Await"></a>Python的Async/Await</h2><p><code>async/await</code> 语法在 Python 中类似。例如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Python 中的异步/等待示例</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">say_hello</span>():</span></span><br><span class="line">    <span class="keyword">await</span> api.alert(<span class="string">&quot;Hello from ImJoy!&quot;</span>)</span><br></pre></td></tr></table></figure></p><p>在 Python 中使用 asyncio 时，一个好的做法是避免直接在主线程中运行繁重的计算，而是可以使用<a href="https://pymotw.com/3/asyncio/executors.html">Executors</a> (线程和进程）。<br>还可以通过执行以下操作来使用默认线程执行器：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loop.run_in_executor(<span class="literal">None</span>, my_heavy_computation, arg1, arg2...)</span><br></pre></td></tr></table></figure></p><h2 id="Callback、Promise和Async-Await"><a href="#Callback、Promise和Async-Await" class="headerlink" title="Callback、Promise和Async/Await"></a>Callback、Promise和Async/Await</h2><p>如前所述，通过 RPC 将任务分配给不同插件的一个优势是可以并行调度和运行任务（通常在 Python、Java 和许多其他编程语言中，还有许多其他技术可以实现并发性，包括多线程和多进程）。异步编程是一种越来越流行的以更具可扩展性的方式实现并发的方式。<br>其基本思想是，我们不必总是等待一项任务完成，然后才移动到下一项。比如，当我们去一家咖啡店，点一杯卡布奇诺咖啡并获得一张取餐号，在制作咖啡的同时，我们可以拨打电话或阅读报纸。几分钟后，可以通过出示取餐号来获取卡布奇诺咖啡。<br>异步编程与多线程等其他技术的一大区别在于程序是在一个线程和进程中运行。因此，在 ImJoy 中，异步编程通常用于将任务调度到其他插件，而不是在同一插件内并行运行繁重的计算任务。<br><code>async/await</code> 并不是进行异步编程的唯一方式，事实上，它在最近几年才变得更加流行。例如， Python 3 之后才引入了它。<br>关于异步编程，可以后面再详细解析。</p><h2 id="将-RPC-与-Async-Await-结合使用"><a href="#将-RPC-与-Async-Await-结合使用" class="headerlink" title="将 RPC 与 Async/Await 结合使用"></a>将 RPC 与 Async/Await 结合使用</h2><p>另一种理解<code>await</code> 和<code>async</code> 函数的角度是：<br>1) 异步函数一旦调用将立即返回；<br>2) 返回的对象不是实际结果，而是Javascript 中称为<code>Promise</code> 或Python中称为<code>Future</code> 的特殊对象。直觉上，这就像你点了一杯咖啡后得到的取餐号；<br>3) 如果将 <code>await</code> 应用到 <code>Promise</code> 或 <code>Future</code> 对象，就会得到实际的结果。<br>如下两种异步函数是等价的：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">choosePokemon1</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="comment">// 直接申请await，我们会得到实际的结果</span></span><br><span class="line">    <span class="keyword">const</span> pokemon = <span class="keyword">await</span> api.prompt(<span class="string">&quot;What is your favorite Pokemon?&quot;</span>, <span class="string">&quot;Pikachu&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> pokemon</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">choosePokemon2</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="comment">// 如果不使用 `await`，我们会得到一个对实际结果的承诺promise</span></span><br><span class="line">    <span class="keyword">const</span> promise = api.prompt(<span class="string">&quot;What is your favorite Pokemon?&quot;</span>, <span class="string">&quot;Pikachu&quot;</span><span class="string">&quot;)</span></span><br><span class="line"><span class="string">    // 要检索实际结果，将 await 应用于 Promise</span></span><br><span class="line"><span class="string">    const pokemon = await promise</span></span><br><span class="line"><span class="string">    return pokemon</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><br>虽然上面的例子是用 Javascript 写的，当然也可以在 Python 中做同样的事情。<br>简单地为所有异步函数应用<code>await</code> 将导致顺序执行。要并行运行任务，我们可以在不立即应用 <code>await</code> 的情况下调用函数，而是可以先收集所有的 <code>Promise</code> 对象，然后一块<code>await</code>。<br>假设我们有 taskA（需要 10 分钟）、taskB（需要 5 分钟）和 taskC（需要 3 分钟），我们想使用从 A 和 B 返回的结果来完成任务 C。以下是不同的实现方式：<br>（1）在所有函数之前应用 <code>await</code>，需要 18(<code>10+5+3</code>) 分钟<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">doTasks</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="comment">// 在 A 之后执行任务 B</span></span><br><span class="line">        <span class="keyword">const</span> resultA = <span class="keyword">await</span> doTaskA() <span class="comment">// 需要 10 分钟</span></span><br><span class="line">        <span class="keyword">const</span> resultB = <span class="keyword">await</span> doTaskB() <span class="comment">// 需要 5 分钟</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">await</span> doTaskC(resultA, resultB) <span class="comment">// 需要 3 分钟</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>（2）调度这两个任务，然后对两者<code>await</code>，需要 13 (<code>max(10, 5) + 3</code>) 分钟。<br>在 Javascript 中，可以使用 <code>Promise.all</code> 将两个 promise 合二为一：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">doTasks</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="comment">// 并行运行任务 A 和 B</span></span><br><span class="line">    <span class="keyword">const</span> promiseA = doTaskA()</span><br><span class="line">    <span class="keyword">const</span> promiseB = doTaskB()</span><br><span class="line">    <span class="comment">// 收集结果</span></span><br><span class="line">    <span class="keyword">const</span> [resultA, resultB] = <span class="keyword">await</span> <span class="built_in">Promise</span>.all([promiseA, promiseB])</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> doTaskC(resultA, resultB)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>在 Python 中，可以使用 <code>asyncio.gather</code> 来收集两个 promise：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">doTasks</span>():</span></span><br><span class="line">    <span class="comment"># 并行运行任务 A 和 B</span></span><br><span class="line">    promiseA = doTaskA()</span><br><span class="line">    promiseB = doTaskB()</span><br><span class="line">    <span class="comment"># 收集结果</span></span><br><span class="line">    [resultA, resultB] = <span class="keyword">await</span> asyncio.gather(promiseA, promiseB)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> doTaskC(resultA, resultB)</span><br></pre></td></tr></table></figure></p><h1 id="外部集成"><a href="#外部集成" class="headerlink" title="外部集成"></a>外部集成</h1><p>ImJoy 插件生态系统旨在以两种方式开放：<br>（1）其他软件工具和网站应该能够轻松使用 ImJoy 及其插件；<br>（2）其他软件工具应该可以在 ImJoy 中轻松使用，通常是以插件的形式。<br>一般来说，任何使用ImJoy RPC协议来提供服务功能的软件都可以被视为ImJoy插件。这包括 ImJoy Web 应用程序本身，它可以读取插件文件并生成插件 API。同时，作者还提供了 <a href="https://github.com/imjoy-team/imjoy-rpc">imjoy-rpc</a> 库，目前支持 Python 和 Javascirpt，供其他软件或 Web 应用程序直接与 ImJoy 内核通信。<br>目前已经有几个web 应用程序可以在独立模式下运行，也可以作为 ImJoy 插件：</p><ul><li><a href="https://kitware.github.io/itk-vtk-viewer/docs/imjoy.html">ITK/VTK 查看器</a> 由 <a href="https://github.com/thewtex">Matt McCormick</a> 等人撰写。</li><li><a href="https://github.com/hms-dbmi/vizarr">vizarr</a> 由 <a href="https://github.com/manzt">Trevor Manz</a> 等人撰写。</li><li><a href="https://kaibu.org/#/app">Kaibu</a> 由 ImJoy 团队提供。</li><li><a href="https://ij.imjoy.io">ImageJ.JS</a> 由 ImJoy 团队提供。</li></ul><p>例如，<a href="https://kitware.github.io/itk-vtk-viewer/docs/imjoy.html">ITK/VTK Viewer</a> 是一个开源软件系统，用于医学和科学图像、网格和点集可视化。虽然它可以<a href="https://kitware.github.io/itk-vtk-viewer/app/?fileToLoad=https://data.kitware.com/api/v1/file/564a65d58d777f7522dbfb61/ download/data.nrrd">作为独立应用程序运行</a>，也可以<a href="https://kitware.github.io/itk-vtk-viewer/docs/imjoy.html">作为 ImJoy 插件</a>运行 。<br>可以点击<a href="http://imjoy.io/#/app?plugin=https://kitware.github.io/itk-vtk-viewer/app/">这个链接</a>进行试用。</p><p><a href="https://ij.imjoy.io">ImageJ.JS</a>是一个独立的网络应用程序，它以两种方式支持ImJoy：1) 大多数ImJoy插件可以在ImageJ.JS中直接运行； 2) ImageJ.JS可以通过其URL用作ImJoy的插件。<br>有关更多详细信息，请参阅 <a href="https://github.com/imjoy-team/imagej.js">项目存储库</a>。</p><p>比如，可以在ImageJ.JS的左上角单击ImJoy图标，然后选择加载插件，粘贴插件的Github/Gist URL，即可将自己的插件加载到ImageJ.JS中。<br><img src="https://user-images.githubusercontent.com/6218739/144003370-395d9e87-7469-4f51-9753-4bc7b6e5e00a.png" alt="imagej"></p>]]></content>
    
    
    <summary type="html">这一篇主要介绍ImJoy中的核心概念。
参考文献：
I2K Workshop Tutorial

ImJoy插件
ImJoy 提供了一个灵活的框架来开发具有不同类型的 Web 或 Python 编程语言的插件。

有四种类型的插件，其可用于不同的目的：
（1）Web 插件直接在浏览器中运行，支持如下三种类型：

 * Window (HTML/CSS/JS)(type=window) 插件，用于使用 HTML5/CSS 和 JavaScript 构建丰富的交互式用户界面；
 * Web Worker (JS)(type=web-worker) 插件，用于使用 JavaScript 或 WebA</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImJoy" scheme="http://qixinbo.github.io/tags/ImJoy/"/>
    
  </entry>
  
  <entry>
    <title>开源深度学习计算平台ImJoy解析：1 -- 介绍</title>
    <link href="http://qixinbo.github.io/2021/11/28/ImJoy_1/"/>
    <id>http://qixinbo.github.io/2021/11/28/ImJoy_1/</id>
    <published>2021-11-27T16:00:00.000Z</published>
    <updated>2021-11-29T08:38:33.670Z</updated>
    
    <content type="html"><![CDATA[<p>从该博文开始，将会对ImJoy这一开源深度学习计算平台做一详细解析。</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>（这部分是对官方文档（在<a href="https://imjoy.io/docs/#/">这里</a>）的翻译理解）<br>ImJoy是一个由插件驱动的混合计算平台，用于部署深度学习应用程序，例如高级图像分析工具。<br>ImJoy可以运行在跨操作系统的移动和桌面环境中，其中的插件可以运行在浏览器、本地主机、远程和云服务器中。<br>借助 ImJoy，凭借其灵活的插件系统和可共享的插件 URL，可以非常简单地向最终用户提供深度学习工具，免去了用户自己配置深度学习环境、安装应用程序的繁琐和痛苦。对于开发人员来说，也可以轻松地对自己现有的Python代码添加丰富的交互式 Web 界面，从而让自己的程序更加“触手可及”。<br>下面是ImJoy的整体架构图：<br><img src="https://user-images.githubusercontent.com/6218739/143673530-061125ed-4f2c-4bbd-8cef-b8ea12921c92.png" alt="arch"><br>可以看出，ImJoy系统非常灵活，体现在以下几个方面：<br>（1）跨平台获取：因为ImJoy是基于web的，所以只要是有浏览器的地方，ImJoy就可以使用，比如桌面端、移动端调用等；<br>（2）插件形式灵活：可以使用JavaScript、Python等编程语言；<br>（3）插件运行环境多样：对于不同量级的插件，可以选择其应用环境，比如一个简单的插件，可以直接在浏览器中运行；如果是一个重型的深度学习应用，可以在本地工作站中运行，也可以在远程服务器或者云服务器中运行。</p><h1 id="ImJoy特点"><a href="#ImJoy特点" class="headerlink" title="ImJoy特点"></a>ImJoy特点</h1><p>（1）小巧且灵活的插件驱动的 Web 应用程序<br>（2）具有离线支持的无服务器渐进式 Web 应用程序（PWA技术）<br>（3）支持移动设备<br>（4）基于Web的丰富的交互式用户界面：可以使用任何现有的网页设计库、使用 webGL、Three.js 等以 3D 形式呈现多维数据。<br>（5）易于使用的工作流组合<br>（6）用于分组插件的独立工作区<br>（7）方便的插件原型设计和开发：内置代码编辑器，开发不需要额外的IDE<br>（8）强大且可扩展的计算后端，可用于浏览器内计算、本地计算和云计算</p><ul><li>支持 Javascript、原生 Python 和 web Python（即直接在网页中运行Python程序，底层技术是Pyodide）</li><li>通过异步编程并发插件执行</li><li>使用 Webassembly 在浏览器中运行 Python 插件</li><li>浏览器插件与安全沙箱隔离</li><li>支持Python3 和 Javascript 的async/await语法</li><li>支持 Python 的 Conda 虚拟环境和 pip 包</li><li>支持托管在 Github 或 CDN 上的 JavaScript 库</li><li>通过 GitHub 或 Gist 轻松部署和共享插件</li><li>将开发者自己的插件仓库部署到 Github</li><li>原生支持 n 维数组和张量</li><li>支持 Numpy 的 ndarrays 用于数据交换</li></ul><p>ImJoy 大大加快了新工具的开发和传播。开发者可以在 ImJoy 中开发插件，将插件文件部署到 Github，并通过社交网络分享插件 URL。用户可以通过多种方式使用这些插件，比如在手机上单击一下即可调用。<br><img src="https://user-images.githubusercontent.com/6218739/143677962-526c570c-e61e-423e-8092-e78a013ef231.png" alt="deploy"></p><h1 id="依赖库"><a href="#依赖库" class="headerlink" title="依赖库"></a>依赖库</h1><p>ImJoy主要使用的开源库有：</p><ul><li>Joy.js（这就是ImJoy的名字由来！）</li><li>Jailed（用于隔离插件）</li><li>Vue.js（主要的前端UI使用 Vue.js 编写）</li><li>vue-grid-layout（用于窗口管理）</li><li>python-socketio（使得插件引擎可以与 ImJoy主程序进行通信）</li><li>pyodide（使用 WebAssembly 启用 web python 模式）</li><li>conda（插件引擎使用 Conda 来管理虚拟环境和包）</li><li>docsify（ImJoy 文档是用 docsify 创建的）</li></ul><h1 id="发表论文"><a href="#发表论文" class="headerlink" title="发表论文"></a>发表论文</h1><p>ImJoy的研究工作也发表在了Nature子刊 Nature Methods上，大佬就是大佬。<br>文章链接见：<a href="https://www.nature.com/articles/s41592-019-0627-0">ImJoy: an open-source computational platform for the deep learning era</a><br>也可以通过<a href="https://rdcu.be/bYbGO">这个链接</a>免费获取该论文。</p><h1 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h1><h2 id="前端界面"><a href="#前端界面" class="headerlink" title="前端界面"></a>前端界面</h2><p>可以直接在浏览器中使用ImJoy，网站在<a href="https://imjoy.io/#/app">这里</a>。<br>（也可以自己托管ImJoy，即使用GitHub上的<a href="https://github.com/imjoy-team/ImJoy">这个仓库</a>）<br>整个应用的前端界面如下：<br><img src="https://user-images.githubusercontent.com/6218739/143802507-b85944e6-4a5d-49d6-82d8-fcceb76991a3.png" alt="UI"><br>包括了插件管理区、工作区、状态栏、工具栏、插件窗口等多个部分。</p><h2 id="上手体验"><a href="#上手体验" class="headerlink" title="上手体验"></a>上手体验</h2><p>官方提供的一个demo是使用一个预训练的神经网络来进行图像识别。<br>这个插件可以通过在<a href="https://imjoy.io/repo/">插件库</a>中安装插件Image Recognition来获得，<br>也可以直接点击<a href="https://imjoy.io/#/app?plugin=imjoy-team/imjoy-plugins:Image%20Recognition&amp;w=getting-started">该链接</a>来使用。<br>安装插件后，它将出现在左侧的插件对话框中。然后单击其名称启动插件。这将打开一个窗口并加载训练好的网络。<br>然后就可以通过上传文件来预测图像中的物体。<br>注意，如果是在电脑上使用该插件，则是上传电脑中的文件，如果是在手机上使用该插件，则调用摄像头来获取图像。<br>如下是我在手机上试用的截图：<br><img src="https://user-images.githubusercontent.com/6218739/143830446-897d525c-c84e-4e85-a689-8d1fcab75b0e.jpg" alt="test"></p><p>通过此例也可以看出，ImJoy提供了一种非常方便地获取最新深度学习技术的方式，能极大地降低技术的应用门槛。</p>]]></content>
    
    
    <summary type="html">从该博文开始，将会对ImJoy这一开源深度学习计算平台做一详细解析。

简介
（这部分是对官方文档（在这里）的翻译理解）
ImJoy是一个由插件驱动的混合计算平台，用于部署深度学习应用程序，例如高级图像分析工具。
ImJoy可以运行在跨操作系统的移动和桌面环境中，其中的插件可以运行在浏览器、本地主机、远程和云服务器中。
借助 ImJoy，凭借其灵活的插件系统和可共享的插件 URL，可以非常简单地向最终用户提供深度学习工具，免去了用户自己配置深度学习环境、安装应用程序的繁琐和痛苦。对于开发人员来说，也可以轻松地对自己现有的Python代码添加丰富的交互式 Web 界面，从而让自己的程序更加“触手</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImJoy" scheme="http://qixinbo.github.io/tags/ImJoy/"/>
    
  </entry>
  
  <entry>
    <title>图神经网络入门详解</title>
    <link href="http://qixinbo.github.io/2021/11/24/gnn/"/>
    <id>http://qixinbo.github.io/2021/11/24/gnn/</id>
    <published>2021-11-23T16:00:00.000Z</published>
    <updated>2021-11-24T06:47:19.043Z</updated>
    
    <content type="html"><![CDATA[<p>本文基本是对<a href="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to Graph Neural Networks</a>这篇文章的翻译理解。<br>（注意：原文中有很多可交互的动画，更有启发性。本文对原文中的有些图像进行了调整，方便初学者理解）</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>（这部分大都来自于<a href="https://zhuanlan.zhihu.com/p/75307407">这篇参考文献</a>）<br>曾有学者将本次人工智能浪潮的兴起归因于三个条件，分别是：<br>（1）计算资源的快速发展（如GPU）<br>（2）大量训练数据的可用性<br>（3）深度学习从欧氏空间数据中提取潜在特征的有效性<br>尽管传统的深度学习方法被应用在提取欧氏空间数据的特征方面取得了巨大的成功，但许多实际应用场景中的数据是从非欧式空间生成的，传统的深度学习方法在处理非欧式空间数据上的表现却仍难以使人满意。<br>常见的欧几里得结构化数据主要包含：<br>（1）1D：声音，时间序列等；<br>（2）2D：图像等；<br>（3）3D：视频，高光谱图像等。<br>常见的非欧几里得结构化数据有：<br>（1）1D：社交网络(如Facebook，Twitter)等；<br>（2）2D：生物网络(基因，分子，大脑连接)等；<br>（3）3D：基础设施网络(如能源，交通，互联网，通信等。</p><p>例如，在电子商务中，一个基于图（Graph）的学习系统能够利用用户和产品之间的交互来做出非常准确的推荐，但图的复杂性使得现有的深度学习算法在处理时面临着巨大的挑战。这是因为图是不规则的，每个图都有一个大小可变的无序节点，图中的每个节点都有不同数量的相邻节点，导致一些重要的操作（例如卷积）在图像（Image）上很容易计算，但不再适合直接用于图。此外，现有深度学习算法的一个核心假设是数据样本之间彼此独立。然而，对于图来说，情况并非如此，图中的每个数据样本（节点）都会有边与图中其他实数据样本（节点）相关，这些信息可用于捕获实例之间的相互依赖关系。</p><p>近年来，人们对深度学习方法在图上的扩展越来越感兴趣。在多方因素的成功推动下，研究人员借鉴了卷积网络、循环网络和深度自动编码器的思想，定义和设计了用于处理图数据的神经网络结构，由此一个新的研究热点——图神经网络（Graph Neural Networks，GNN）。</p><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>什么是图？图（graph）是一系列实体（nodes）之间的关系（edges）。<br><img src="https://user-images.githubusercontent.com/6218739/142832766-879eefb5-ebb6-4edb-979a-2b8318c880a4.png" alt="graph"><br>黄色的是节点或称顶点，其属性包括节点标识、邻居数量等；<br>蓝色的是边或称链接，其属性包括边的标识、边的权重等；<br>红色线框包围的就是整张图，或称全局，该全局属性包括节点数量、图中的最长路径等特征。<br>其中，根据边的方向性还有两种情形，有向图和无向图：<br><img src="https://user-images.githubusercontent.com/6218739/142834186-f97f87f4-afb1-46c4-a5ed-6e1f22c6d68e.png" alt="edge"></p><h1 id="哪些是图"><a href="#哪些是图" class="headerlink" title="哪些是图"></a>哪些是图</h1><h2 id="社交网络作为图"><a href="#社交网络作为图" class="headerlink" title="社交网络作为图"></a>社交网络作为图</h2><p>图graph结构最简单明了的一种真实应用场景就是社交网络。<br>社交网络是用来研究人在机构、组织等集体中的行为模式的工具。我们可以通过将个人建模为节点、将人与人之间的关系建模为边来构建表示社交网络的图。<br>比如如下是莎士比亚的戏剧《奥赛罗》中的社交网络的图表达：<br><img src="https://user-images.githubusercontent.com/6218739/142959871-586a3938-6432-4b59-a5b5-c1dbf605a7c7.png" alt="social"><br>一种可视化图的连通性的方法是通过其邻接矩阵。如果人与人之间有关系，则在该矩阵中填充数值：<br><img src="https://user-images.githubusercontent.com/6218739/142960047-1590c3f0-9058-4275-8f09-4f9fef2f3b1d.png" alt="othello-matrix"></p><h2 id="引文网络作为图"><a href="#引文网络作为图" class="headerlink" title="引文网络作为图"></a>引文网络作为图</h2><p>科学家在发表论文时经常引用其他科学家的工作。我们可以将这些引文网络可视化为一个图，其中每篇论文都是一个节点，每个有向边是一篇论文和另一篇论文之间的引用。此外，我们可以将每篇论文的信息添加到每个节点中，例如摘要的词嵌入。</p><h2 id="分子作为图"><a href="#分子作为图" class="headerlink" title="分子作为图"></a>分子作为图</h2><p>分子是物质的基石，由3D空间中的原子和电子构成。所有粒子都在相互作用，但是当一对原子彼此保持稳定的距离时，我们说它们共享一个共价键。不同的原子对和键有不同的距离（例如单键、双键）。将这个3D对象描述为图是一种非常方便和常见的抽象，其中节点是原子，边是共价键。<br>如下是咖啡因因子的3D表示，及将它建模为图。<br><img src="https://user-images.githubusercontent.com/6218739/142960475-a26bf1b8-1275-4073-9135-81c4d99eb652.png" alt="Caffeine"></p><p>以上三例的数据都是异构的，由其所建的图graph中的节点的邻居数量是可变的。下面将展示两种可能认为无法建模为图的数据类型：图像和文本。这两类的数据就非常规整，表现在其邻居数量是固定的，但是它们仍然可以建模为图这一种数据结构。</p><h3 id="图像作为图"><a href="#图像作为图" class="headerlink" title="图像作为图"></a>图像作为图</h3><p>通常将图像视为具有图像通道的矩形网格，并将它们表示为数组（例如，244x244x3 浮点数）。<br>另一种方式就是将图像视为具有规则结构的图，其中每个像素代表一个节点，并通过边连接到相邻像素。每个非边界像素正好有 8 个邻居，每个节点存储的信息是一个 3 维向量，表示像素的 RGB 值。如下面的 5x5 笑脸图像：<br><img src="https://user-images.githubusercontent.com/6218739/142835438-5437aebb-e206-4165-8abc-ba0393d0f0a3.png" alt="imageasgraph"><br>在邻接矩阵中，我们对25个节点进行排序，并形成一个 $ n_{nodes} \times n_{nodes} $ 的矩阵，如果两个节点共享一条边，则在矩阵中填充数值，如下：<br><img src="https://user-images.githubusercontent.com/6218739/142958394-555a75ae-67ce-49a2-8210-3950f08ca9b7.png" alt="matrix"></p><h2 id="文本作为图"><a href="#文本作为图" class="headerlink" title="文本作为图"></a>文本作为图</h2><p>首先将文本进行“数字化”：比如对每个字符character、单词word或token都关联一个索引，然后文本就可以表示为一系列的索引（这种方式是文本在循环神经网络RNN 中经常表示的方式）。<br>这将创建一个简单的有向图，其中每个索引都是一个节点，并通过一条边连接到它后面的节点。如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/142958918-f8780d03-7f99-4794-9971-844de5c9f4c4.png" alt="text"></p><p>当然，在实践中，这通常不是文本和图像的编码方式：这种图graph的表达是冗余的，因为所有图像和所有文本都具有非常规则的结构。例如，图像在其邻接矩阵中具有带状结构，这是因为所有节点（像素）都在一个规则网格中相互连接。文本的邻接矩阵只是一条对角线，因为每个单词只连接到前一个单词和下一个单词。</p><h2 id="其他例子"><a href="#其他例子" class="headerlink" title="其他例子"></a>其他例子</h2><p>在计算机视觉中，我们有时想标记视觉场景中的对象。然后可以通过将这些对象视为节点，将它们的关系视为边来构建图。<br>机器学习模型，编程代码和数学方程也可以表述为图，其中变量是节点，边是将这些变量作为输入和输出的操作。术语“数据流图”dataflow graph就是这个意思。</p><h1 id="图能干什么"><a href="#图能干什么" class="headerlink" title="图能干什么"></a>图能干什么</h1><p>图上的预测任务一般分为三种类型：图级graph-level、节点级node-level和边级edge-level。<br>在图级任务中，我们预测整个图的单个属性。对于节点级任务，我们预测图中每个节点的一些属性。对于边级任务，我们希望预测图中边的属性或存在。</p><h2 id="图级任务"><a href="#图级任务" class="headerlink" title="图级任务"></a>图级任务</h2><p>在图级任务中，我们的目标是预测整个图的属性。例如，对于表示为图的分子，我们可能想要预测该分子的气味，或者它是否会与与疾病有关的受体结合。<br>比如下面例子，就是判断哪些分子结构有两个环。<br><img src="https://user-images.githubusercontent.com/6218739/142964879-87631629-7c46-4183-88e4-7d2160966d70.png" alt="graph-level"><br>这类似于 MNIST 和 CIFAR 的图像分类问题，我们希望将标签与整个图像相关联。对于文本，一个类似的问题是情感分析，我们希望一次识别整个句子的情绪或情感。</p><h2 id="节点级任务"><a href="#节点级任务" class="headerlink" title="节点级任务"></a>节点级任务</h2><p>节点级任务与预测图中每个节点的身份或角色有关。<br>节点级预测问题的一个经典示例是 Zach 的空手道俱乐部。该数据集是一个单一的社交网络图，整个图由在政治分歧后宣誓效忠两个空手道俱乐部之一的个人练习者组成。故事是这样的，Hi 先生（讲师）和 John H（管理员）之间的不和导致了空手道俱乐部的分裂。节点代表个人空手道练习者，边代表这些成员之间在空手道之外的互动。预测问题是对给定成员在发生争执后是变得忠诚于 Mr. Hi 还是 John H 进行分类。在这种情况下，此分类标签与节点到讲师或管理员之间的距离高度相关。<br><img src="https://user-images.githubusercontent.com/6218739/142966298-4f66bdd6-e14e-489f-87c4-0e125d3ec9fc.png" alt="zach"><br>（在左边我们有问题的初始条件，在右边我们有一个可能的解决方案，其中每个节点都基于联盟进行了分类。该数据集可用于其他图问题，如无监督学习。）</p><p>按照图像类比，节点级预测问题类似于图像分割，我们试图标记图像中每个像素的作用。对于文本，类似的任务是预测句子中每个单词的词性（例如名词、动词、副词等）。</p><h2 id="边级任务"><a href="#边级任务" class="headerlink" title="边级任务"></a>边级任务</h2><p>边级推理的一个例子是图像场景理解。除了识别图像中的对象外，深度学习模型还可用于预测它们之间的关系。我们可以将其表述为边级分类：给定代表图像中对象的节点，我们希望预测这些节点中的哪些共享一条边或该边的值是什么。如果我们希望发现实体（节点）之间的联系，可以考虑图完全连接后再根据它们的预测值修剪边以得到稀疏图。<br><img src="https://user-images.githubusercontent.com/6218739/142966575-d4257640-7739-43c6-9178-dbf09a1680b0.png" alt="edge-task"><br>（在上面的 (b) 中，原始图像 (a) 被分割为五个实体：两个格斗者、裁判、观众和垫子。(C) 显示了这些实体之间的关系。）<br><img src="https://user-images.githubusercontent.com/6218739/142966943-6f5556f6-8bf3-49d4-9fac-b1cf5d8fb2bf.png" alt="edge-2"><br>（左侧是根据之前的视觉场景构建的初始图，右侧是根据模型的输出对某些连接进行修剪后得到的该图可能的边标记。）</p><h1 id="在机器学习中使用图的挑战"><a href="#在机器学习中使用图的挑战" class="headerlink" title="在机器学习中使用图的挑战"></a>在机器学习中使用图的挑战</h1><p>那么，我们如何用神经网络解决这些不同的图任务呢？第一步是考虑我们将如何表示图以与神经网络兼容。<br>机器学习模型通常采用矩形或网格状阵列作为输入。因此，如何以与深度学习兼容的格式表示它们并不是很直观。图有多达四种类型的信息可能想要用来进行预测：节点、边、全局上下文和连通性。前三个比较简单：比如对于节点，我们可以通过为每个节点分配一个索引$i$从而组成一个节点特征矩阵$N$，然后在$N$中存储特征$node_i$。虽然这些矩阵具有可变数量的实例，但处理矩阵不需要任何特殊的技巧。<br>然而，表示图的连通性更为复杂。也许最明显的选择是使用邻接矩阵，因为它很容易张量化。然而，这种表示有一些缺点。<br>如下是一个示例数据集表：<br><img src="https://user-images.githubusercontent.com/6218739/142975690-bfdcacd4-8364-4dd1-94c8-f093f5711b87.png" alt="table"><br>从示例数据集表中，我们看到图中的节点数量可能达到数百万，每个节点的边数可能变化很大。通常，这会导致非常稀疏的邻接矩阵，这是空间效率低下的。<br>另一个问题是，有很多邻接矩阵可以编码相同的连通性，并不能保证这些不同的矩阵在深度神经网络中会产生相同的结果（也就是说，它们不是排列不变的）。<br>例如，前面的奥赛罗图可以用如下这两个邻接矩阵等价地描述。它也可以用节点的所有其他可能的排列来描述。<br><img src="https://user-images.githubusercontent.com/6218739/142975871-caa24e50-a2e0-496d-8be8-adc7c2120b92.png" alt="two-adjacent"><br>更直观一点，下面的这个小图由四个节点组成，可以表示它的邻接矩阵如下：<br><img src="https://user-images.githubusercontent.com/6218739/142976045-3d08ec6b-b460-471c-9712-69a4d6175b17.png" alt="simple-demo-adj"><br>可以看出，对于这么简单的一个小图，可以表示同样信息的邻接矩阵就很多了，更不必说有更多节点的奥赛罗图。</p><p>表示稀疏矩阵的一种优雅且节省内存的方法是邻接列表。它把节点$n_i$和节点$n_j$之间的边$e_k$的连通性表达为邻接表的第k个元素中的元组$(i,j)$。由于通常情况下边的数量远低于邻接矩阵的元素数量（$n_{nodes}^2$)，因此可以避免在图的断开部分（即没有边的部分）进行计算和存储。<br>举一个例子：<br><img src="https://user-images.githubusercontent.com/6218739/142979027-73439a11-218d-4cc3-8910-4e91e2036e5c.png" alt="adjacent-list"><br>可以看出，整个图graph中有8个节点和7个边。<br>Nodes列表里给出了8个节点的属性，取值只有两个0和1；Edges列表里给出了7个边的属性，取值为1或2；临界列表里则给出了这些边由哪两个节点形成，比如Edges里的倒数第二条边就是连接的7号节点和4号节点。Global给出了整个图的标识，这里标识为0。</p><p>需要注意的是，该图中每个节点/边/全局的属性都是标量，即都只有一个值，但大多数真实的图中的属性都是向量（或称特征向量或嵌入）。比如对于一个节点，上例中节点列表是$[n_{nodes}]$，但真实情况大概率是这样的形状$[n_{nodes}, node_{dim}]$。对于边的属性、全局属性也同理。</p><p>上述这种对于图的描述方式具有排列不变性。</p><h1 id="图神经网络"><a href="#图神经网络" class="headerlink" title="图神经网络"></a>图神经网络</h1><p>图神经网络GNN是对图的所有属性（节点、边、全局上下文）进行优化的变换，它保留了图的对称性（置换不变性）。这里使用 Gilmer 等人提出的“消息传递神经网络”框架构建 GNN。<br>GNN 采用“图入图出”架构，这意味着这些模型类型接受图作为输入，将信息加载到其节点、边和全局上下文中，并逐步转换这些嵌入，而不会改变输入图的连通性。</p><h2 id="最简单的GNN"><a href="#最简单的GNN" class="headerlink" title="最简单的GNN"></a>最简单的GNN</h2><p>一个最简单的 GNN架构如下：<br><img src="https://user-images.githubusercontent.com/6218739/142980841-566452d1-6626-4de6-a739-88a659a09fae.png" alt="gnn"><br>该GNN在图的每个组件上使用单独的多层感知器 (MLP)（或其他可微模型），我们称之为 GNN 层。比如，对于每个节点向量，我们应用 MLP 并返回一个学习到的节点向量；对每条边做同样的事情，学习每条边的嵌入（或称新的特征向量）；以及全局上下文向量，为整个图学习一个嵌入。（在该架构中学习了所有图属性（节点、边、全局）的新嵌入，但尚未使用图的连通性。）<br>然后将这些GNN层堆叠在一起。<br>因为 GNN 不会更新输入图的连通性，所以我们可以用与输入图相同的邻接表和相同数量的特征向量来描述 GNN 的输出图。但是，输出图更新了嵌入，因为 GNN 更新了每个节点、边和全局上下文表示。</p><h2 id="通过汇集信息进行-GNN-预测"><a href="#通过汇集信息进行-GNN-预测" class="headerlink" title="通过汇集信息进行 GNN 预测"></a>通过汇集信息进行 GNN 预测</h2><p>上面已经构建了一个简单的 GNN，但是如何在上述任何任务中进行预测呢？<br>这里考虑一个二元分类的情况（但这个框架可以很容易地扩展到多类或回归的情况）。如果任务是对节点进行二元预测，并且图形已经包含节点信息，则该方法很简单——对于每个节点嵌入，应用线性分类器。<br><img src="https://user-images.githubusercontent.com/6218739/142982195-8b262b41-61ff-4191-9b1a-dbe4384b56cb.png" alt="v-class"><br>然而，事情并不总是那么简单。例如，我们可能将图中的信息存储在边中，但节点中没有信息，但仍需要对节点进行预测。可以想象一个社交网络，我们希望匿名化用户数据（节点），不使用这些用户信息，而仅使用关系数据（边）来达到我们的预测目的。这种场景的一个实例就是之前在空手道俱乐部示例中，仅使用人与人之间的会面次数，而不使用任何具体的人的信息，来确定效忠于Mr. Hi还是John H.。<br>此时就需要一种从边收集信息并将它们提供给节点进行预测的方法。我们可以通过池化（或称汇集pooling）来做到这一点。池化分两步进行：<br>（1）对于要汇集的每个项目，收集它们的每个嵌入并将它们连接成一个矩阵。<br>（2）然后聚合收集到的嵌入，通常通过求和运算来实现。</p><p>用字母$\rho$表示池化操作，然后用$p_{E_n \to V_{n}}$表示从边上收集信息到节点上。<br><img src="https://user-images.githubusercontent.com/6218739/142982910-046a91f3-06e9-4e3c-9f52-8d38afb8b726.png" alt="pool"><br>因此，如果我们只有边上的特征，并且想尝试预测节点的二元分类信息，那可以使用池化将信息路由（或传递）到需要去的地方。<br>该模型如下。<br><img src="https://user-images.githubusercontent.com/6218739/142983257-cff12488-0713-4529-be70-803427f57b2e.png" alt="pool-class"></p><p>反过来，如果我们只有节点级特征，并试图预测边上的二元分类信息（这种场景的一个例子比如上面的边级任务，节点就是图像实体，想预测这些实体是否共享关系，即二元边）。此时模型看起来像这样。<br><img src="https://user-images.githubusercontent.com/6218739/142983667-4b88c3ac-b273-43d9-baee-eb51a60993ec.png" alt="pool-v2e"></p><p>如果我们只有节点级别的特征，并且需要预测一个全局的二进制属性，此时需要将所有可用的节点信息收集在一起并聚合它们。这类似于CNN 中的全局平均池化层。边缘到全局的信息也可以这样做。<br>（这是预测分子特性的常见场景。例如，我们有原子信息及其连通性，我们想知道一个分子的毒性（有毒/无毒），或者它是否有特定的气味（玫瑰/非玫瑰））<br><img src="https://user-images.githubusercontent.com/6218739/142983974-8e481cd7-b2f1-4dd0-b917-4213fc657673.png" alt="v2u"></p><p>在上面例子中，分类模型$c$可以很容易地替换为任何可微模型，或使用广义线性模型来做多分类问题。<br><img src="https://user-images.githubusercontent.com/6218739/142984209-6bd326ae-2a1f-416f-a908-831d536e4d08.png" alt="e2egnn"></p><p>上面构建了一个简单的 GNN 模型，并通过在图的不同部分之间路由信息来进行二元预测。这种池化技术将作为构建更复杂 GNN 模型的基石。如果我们有新的图属性，只需要定义如何将信息从一个属性传递到另一个属性即可。<br>请注意，在这个最简单的 GNN 公式中，没有在 GNN 层内部使用图的连通性。每个节点都是独立处理的，每个边以及全局上下文也是如此。我们只是在汇集信息进行预测时使用连通性。</p><h2 id="在图的各个部分之间传递消息"><a href="#在图的各个部分之间传递消息" class="headerlink" title="在图的各个部分之间传递消息"></a>在图的各个部分之间传递消息</h2><p>如上所述，我们仅在最后预测时使用了池化来汇聚消息。自然地，我们可以通过在 GNN 层之间使用池化来进行更复杂的预测，以使中间学习的嵌入（或称特征向量）知道图的连通性。<br>我们可以使用消息传递来做到这一点，其中相邻的节点或边交换信息，并影响彼此更新后的嵌入。<br>消息传递分三步进行：<br>（1）对于图中的每个节点，收集所有相邻节点嵌入（或消息）；<br>（2）通过聚合函数（如 sum）聚合所有消息；<br>（3）所有汇集的消息都通过一个更新函数，该函数通常是一个可学习的神经网络。<br>（第二步和第三步顺序可以调整，即先更新再聚合，这种方式也具有置换不变性）</p><p>整个过程如下所示：<br><img src="https://user-images.githubusercontent.com/6218739/142985277-0ffce405-5353-42b7-977e-f95861a0309b.png" alt="message"></p><p>正如池化可以应用于节点或边一样，消息传递可以发生在节点或边之间。<br>这些步骤是利用图形连通性的关键。我们将在 GNN 层中构建更精细的消息传递变体，从而产生具有增加表现力和能力的 GNN 模型。</p><p>这一系列操作，当应用一次时，就是消息传递 GNN 层的最简单形式。<br>这跟图像处理中的标准卷积操作类似：本质上，消息传递和卷积是聚合和处理元素邻居的信息以更新元素值的操作。在图中，元素是一个节点，而在图像中，元素是一个像素。然而，图中相邻节点的数量可以是可变的，这与每个像素具有一组固定数量相邻元素的图像不同。<br>通过将传递 GNN 层的消息堆叠在一起，一个节点最终可以合并来自整个图的信息：在三层之后，一个节点拥有距离它三步远的节点的信息。（这跟图像中的感受野类似）</p><p>于是，前面最简单的GNN架构图可以增加上面这一部分内容，即包含新的节点消息源，形成一个更复杂的GNN架构：<br><img src="https://user-images.githubusercontent.com/6218739/142985721-2aa3d0de-13af-4188-8ac2-85893ca8174f.png" alt="updated-gnn-arch"></p><h2 id="学习边的表示"><a href="#学习边的表示" class="headerlink" title="学习边的表示"></a>学习边的表示</h2><p>我们的数据集并不总是包含所有类型的信息（节点、边和全局上下文）。当我们想对节点进行预测，但我们的数据集只有边信息时，我们在上面展示了如何使用池化将信息从边路由到节点，但仅限于模型的最后预测步骤。我们可以使用消息传递在 GNN 层内的节点和边之间共享信息。<br>我们可以以与之前使用相邻节点信息相同的方式合并来自相邻边的信息，首先将边信息池化，用更新函数对其进行转换，然后存储它。<br>但是，图中存储的节点和边信息不一定具有相同的大小或形状，因此如何将它们组合起来还不是很清楚。一种方法是学习从边空间到节点空间的线性映射，反之亦然。或者，可以在更新函数之前将它们连接在一起。模型如下：<br><img src="https://user-images.githubusercontent.com/6218739/142986481-f4cf8094-d378-4690-94f6-8c87e9a9337c.png" alt="message-v-e"><br>构建GNN时一个需要设计的地方在于：更新哪些图属性以及更新它们的顺序。我们可以选择是在缘嵌入之前更新节点嵌入，或者以相反的顺序。<br>该领域仍在活跃研究中，目前有多种解决方案。例如，我们可以以“编织”方式进行更新：<br><img src="https://user-images.githubusercontent.com/6218739/142986915-9a7204b5-d4d3-4940-94bf-aa00cece8f1e.png" alt="weave"></p><h2 id="添加全局表示"><a href="#添加全局表示" class="headerlink" title="添加全局表示"></a>添加全局表示</h2><p>到目前为止，上面描述的网络存在一个缺陷：图中彼此相距很远的节点可能永远无法有效地相互传输信息，即使我们多次应用消息传递。对于一个节点，如果我们有 k 层，信息最多将传播 k 步。对于预测任务依赖于相距很远的节点或节点组的情况，这可能是一个问题。<br>一种解决方案是让所有节点都能够相互传递信息。不幸的是，对于大图来说，这很快就会变得计算成本很高（尽管称为“虚拟边”的方法已被用于分子等小图）。<br>该问题的一种解决方案是使用图 (U) 的全局表示，该图有时称为主节点master node或上下文向量。这个全局上下文向量连接到网络中的所有其他节点和边，并可以作为它们之间的桥梁来传递信息，从而为整个图构建一个表示。这创建了一个更丰富、更复杂的而不是通过其他方式学习的图表示。<br><img src="https://user-images.githubusercontent.com/6218739/142987592-8bb25c8f-7b42-493f-aebd-a1879043f834.png" alt="U"><br>上述架构称为Graph Nets。</p><p>此时，可以发现，所有的图属性都学习了表示，因此我们可以在池化过程中通过调节我们感兴趣的属性的信息来使用它们。例如，对于一个节点，我们可以考虑来自相邻节点、所连接的边和全局信息的信息。为了在所有这些可能的信息源上调整新节点嵌入，我们可以简单地将它们连接起来。此外，我们还可以通过线性映射将它们映射到相同的空间并添加它们或应用特征调制层，这可以被认为是一种特征化的注意力机制。<br><img src="https://user-images.githubusercontent.com/6218739/142988081-315d33c4-d905-4d63-8ba9-8f42c911c084.png" alt="complex"></p><h1 id="GNN游乐场"><a href="#GNN游乐场" class="headerlink" title="GNN游乐场"></a>GNN游乐场</h1><p>上面给出了GNN的各种架构和组件，到底在实践中怎么用呢？<br>作者直接给出了一个在线DEMO，即GNN游乐场，该游乐场基于tensorflow.js构建，用户在上面可以自由地玩耍和配置，从而探索上面不同的组件和架构如何用于GNN中。<br>整个DEMO展示了一个带有小分子图的图级预测任务。使用 Leffingwell 气味数据集，它由具有相关气味感知（标签）的分子组成。<br>预测分子结构（图）与其气味的关系是一个跨越化学、物理、神经科学和机器学习的百年历史问题。为了简化问题，只考虑每个分子的一个二元标签，根据专业调香师的标签，对分子图是否闻起来“刺鼻”进行分类。如果一个分子具有强烈、醒目的气味，我们就说它具有“刺鼻”气味。例如，可能含有烯丙醇分子的大蒜和芥末就具有这种性质。胡椒酮分子，通常用于薄荷味糖果，也被描述为具有刺鼻的气味。<br>这里将每个分子表示为一个图，其中原子是包含对其原子身份（碳、氮、氧、氟）进行独热编码的节点，而键是包含对其键类型（单、双、三重或芳香）进行独热编码的边。<br>针对这个问题的通用建模模板是使用GNN层序列构建，然后接一个用于分类的 sigmoid 激活函数。<br>整个GNN模型有多个超参数可供调节：<br>（1）GNN 层数，也称为深度；<br>（2）更新时每个属性的维度。更新函数是一个 1 层 MLP，其具有 relu 激活函数和用于激活归一化的标准化层；<br>（3）池化中使用的聚合函数：max、mean 或 sum；<br>（4）更新的图形属性或消息传递的样式：节点、边和全局表示。我们通过布尔切换（开或关）来控制这些。基线模型是一个与图无关的 GNN（关闭所有消息传递），它将最后的所有数据聚合到一个全局属性中。打开所有的消息传递函数就会形成一个 Graph Nets 架构（即上面添加了全局表示的GNN架构）。</p><p>为了更好地理解 GNN 如何学习图的任务优化表示，作者还查看了 GNN 的倒数第二层激活。这些“图嵌入”是 GNN 模型在预测之前的输出。由于使用广义线性模型进行预测，因此线性映射足以让用户了解如何围绕决策边界学习表示。但由于这些是高维向量，所以通过主成分分析 (PCA) 将它们简化为 2D。一个完美的模型可以很容易地将这个决策边界显示出来，但由于这里压缩了维度并且模型也不完美，因此这个边界可能很难看到。（如下截图有点那个边界的意思了）</p><p>游乐场的截图如下：<br><img src="https://user-images.githubusercontent.com/6218739/142991597-b51165df-ac35-49b6-a5c0-dad0633d2dd0.png" alt="playground"></p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to Graph Neural Networks</a><br><a href="https://zhuanlan.zhihu.com/p/75307407">图神经网络（Graph Neural Networks，GNN）综述</a><br><a href="https://cloud.tencent.com/developer/article/1479463">GNN 系列：Graph 基础知识介绍</a></p>]]></content>
    
    
    <summary type="html">本文基本是对A Gentle Introduction to Graph Neural Networks这篇文章的翻译理解。
（注意：原文中有很多可交互的动画，更有启发性。本文对原文中的有些图像进行了调整，方便初学者理解）

简介
（这部分大都来自于这篇参考文献）
曾有学者将本次人工智能浪潮的兴起归因于三个条件，分别是：
（1）计算资源的快速发展（如GPU）
（2）大量训练数据的可用性
（3）深度学习从欧氏空间数据中提取潜在特征的有效性
尽管传统的深度学习方法被应用在提取欧氏空间数据的特征方面取得了巨大的成功，但许多实际应用场景中的数据是从非欧式空间生成的，传统的深度学习方法在处理非欧式空间数</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="GNN" scheme="http://qixinbo.github.io/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析： 28 -- 三维可视化</title>
    <link href="http://qixinbo.github.io/2021/11/18/ImagePy_28/"/>
    <id>http://qixinbo.github.io/2021/11/18/ImagePy_28/</id>
    <published>2021-11-17T16:00:00.000Z</published>
    <updated>2021-11-18T08:22:51.670Z</updated>
    
    <content type="html"><![CDATA[<p>本文解析一下ImagePy的三维画布。<br>以如下例子入手：<br><img src="https://user-images.githubusercontent.com/6218739/141955577-f4a7c5c5-0a9a-409b-9fde-399a92f0c1d8.png" alt="demo"><br>首先，原始图像是一个5乘5的方形图像，其中间是4乘4的白色，周围是一圈黑色。<br>由这张原始图根据距离变换得到右上角的高程图，继而对该高程图做三维可视化。</p><h1 id="渲染插件"><a href="#渲染插件" class="headerlink" title="渲染插件"></a>渲染插件</h1><p>二维平面的三维可视化插件是这样写的：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Surface2D</span>(<span class="params">Simple</span>):</span></span><br><span class="line">    title = <span class="string">&#x27;2D Surface&#x27;</span></span><br><span class="line">    note = [<span class="string">&#x27;8-bit&#x27;</span>, <span class="string">&#x27;16-bit&#x27;</span>, <span class="string">&#x27;float&#x27;</span>]</span><br><span class="line">    para = &#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;undifine&#x27;</span>, <span class="string">&#x27;sample&#x27;</span>:<span class="number">2</span>, <span class="string">&#x27;sigma&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;h&#x27;</span>:<span class="number">0.3</span>, <span class="string">&#x27;cm&#x27;</span>:<span class="string">&#x27;gray&#x27;</span>&#125;</span><br><span class="line">    view = [(<span class="built_in">str</span>, <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">            (<span class="built_in">int</span>, <span class="string">&#x27;sample&#x27;</span>, (<span class="number">1</span>,<span class="number">10</span>), <span class="number">0</span>, <span class="string">&#x27;down sample&#x27;</span>, <span class="string">&#x27;pix&#x27;</span>),</span><br><span class="line">            (<span class="built_in">int</span>, <span class="string">&#x27;sigma&#x27;</span>, (<span class="number">0</span>,<span class="number">30</span>), <span class="number">0</span>, <span class="string">&#x27;sigma&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">            (<span class="built_in">float</span>, <span class="string">&#x27;h&#x27;</span>, (<span class="number">0.1</span>,<span class="number">10</span>), <span class="number">1</span>, <span class="string">&#x27;scale z&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">            (<span class="string">&#x27;cmap&#x27;</span>, <span class="string">&#x27;cm&#x27;</span>, <span class="string">&#x27;color map&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, ips, imgs, para = <span class="literal">None</span></span>):</span></span><br><span class="line">        ds, sigma, cm = para[<span class="string">&#x27;sample&#x27;</span>], para[<span class="string">&#x27;sigma&#x27;</span>], ColorManager.get(para[<span class="string">&#x27;cm&#x27;</span>])</span><br><span class="line">        mesh = Surface2d(ips.img, sample=ds, sigma=sigma, k=para[<span class="string">&#x27;h&#x27;</span>], cmap=cm)</span><br><span class="line">        self.app.show_mesh(mesh, para[<span class="string">&#x27;name&#x27;</span>])</span><br></pre></td></tr></table></figure><br>其界面为：<br><img src="https://user-images.githubusercontent.com/6218739/141955719-7c81041c-9c56-4f10-ba0c-1d5d68643f20.png" alt="interface"><br>即设定名字、下采样率、平滑率和z轴伸缩率，以及渲染所用的colormap。(在该demo中，就按如图中的参数进行设置)<br>然后将这些参数传给Surface2d这个ImagePy定义的Mesh对象。<br>最后调用show_mesh方法将其呈现出来。<br>下面是一步步分析这个Mesh对象及其绘制方法。</p><h1 id="Mesh对象"><a href="#Mesh对象" class="headerlink" title="Mesh对象"></a>Mesh对象</h1><p>如前所述，二维高程图传给了Surface2d这一类，具体看一下其代码实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Surface2d</span>(<span class="params">Mesh</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, img=<span class="literal">None</span>, sample=<span class="number">1</span>, sigma=<span class="number">0</span>, k=<span class="number">0.3</span>, **key</span>):</span></span><br><span class="line">self.img, self.sample, self.sigma, self.k = img, sample, sigma, k</span><br><span class="line">Mesh.__init__(self, **key)</span><br><span class="line">self.set_data(img, sample, sigma, k)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_data</span>(<span class="params">self, img=<span class="literal">None</span>, sample=<span class="literal">None</span>, sigma=<span class="literal">None</span>, k=<span class="literal">None</span>, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> img <span class="keyword">is</span> <span class="literal">None</span>: self.img = img</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> sample <span class="keyword">is</span> <span class="literal">None</span>: self.sample = sample</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> sigma <span class="keyword">is</span> <span class="literal">None</span>: self.sigma = sigma</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> k <span class="keyword">is</span> <span class="literal">None</span>: self.k = k</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">sum</span>([<span class="keyword">not</span> i <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> (img, sample, sigma, k)])&gt;<span class="number">0</span>:</span><br><span class="line"><span class="keyword">from</span> ..util <span class="keyword">import</span> meshutil</span><br><span class="line">vert, fs = meshutil.create_surface2d(self.img, self.sample, self.sigma, self.k)</span><br><span class="line">Mesh.set_data(self, verts=vert, faces=fs.astype(np.uint32), colors=vert[:,<span class="number">2</span>], **key)</span><br><span class="line"><span class="keyword">else</span>: Mesh.set_data(self, **key)</span><br></pre></td></tr></table></figure><br>可以看到，在它的初始化函数中调用了set_data方法。进一步地，在该方法中有两个核心方法：将图像转化为顶点和面，然后再转为Mesh对象。</p><h2 id="位图提取格点坐标和像素值"><a href="#位图提取格点坐标和像素值" class="headerlink" title="位图提取格点坐标和像素值"></a>位图提取格点坐标和像素值</h2><p>即如下方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vert, fs = meshutil.create_surface2d(self.img, self.sample, self.sigma, self.k)</span><br></pre></td></tr></table></figure><br>源码及注释为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_surface2d</span>(<span class="params">img, sample=<span class="number">1</span>, sigma=<span class="number">0</span>, k=<span class="number">0.3</span></span>):</span></span><br><span class="line">    <span class="keyword">from</span> scipy.ndimage <span class="keyword">import</span> gaussian_filter</span><br><span class="line">    <span class="comment">#start = time()</span></span><br><span class="line">    <span class="comment"># 以采样率为步长进行图像的重新提取</span></span><br><span class="line">    img = img[::sample, ::sample].astype(np.float32)</span><br><span class="line">    <span class="comment"># 如果指定了平滑率，则使用高斯滤波进行平滑</span></span><br><span class="line">    <span class="keyword">if</span> sigma&gt;<span class="number">0</span>: img = gaussian_filter(img, sigma)</span><br><span class="line">    <span class="comment"># 根据采样后的图像形状生成网格格点</span></span><br><span class="line">    xs, ys = np.mgrid[:img.shape[<span class="number">0</span>],:img.shape[<span class="number">1</span>]]</span><br><span class="line">    <span class="comment"># 根据采样率，将格点范围伸缩到之前的大小</span></span><br><span class="line">    xs *= sample; ys *= sample</span><br><span class="line">    <span class="comment"># 将图像像素值乘以伸缩大小，作为z轴的值，与格点坐标xy传入下面的方法</span></span><br><span class="line">    <span class="keyword">return</span> create_grid_mesh(xs, ys, img*k)</span><br></pre></td></tr></table></figure><br>在此例中，依照上面的参数，来看一下各个中间结果：<br>首先高程图在降采样后，图像矩阵为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">2.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]]</span><br></pre></td></tr></table></figure><br>然后在$\sigma=1$的高斯滤波后，图像矩阵为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.17534617</span> <span class="number">0.2415005</span>  <span class="number">0.17534617</span>]</span><br><span class="line"> [<span class="number">0.2415005</span>  <span class="number">0.3326134</span>  <span class="number">0.2415005</span> ]</span><br><span class="line"> [<span class="number">0.17534617</span> <span class="number">0.2415005</span>  <span class="number">0.17534617</span>]]</span><br></pre></td></tr></table></figure><br>其再经过k倍的伸缩，变为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.8767308</span> <span class="number">1.2075025</span> <span class="number">0.8767308</span>]</span><br><span class="line"> [<span class="number">1.2075025</span> <span class="number">1.6630671</span> <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">0.8767308</span> <span class="number">1.2075025</span> <span class="number">0.8767308</span>]]</span><br></pre></td></tr></table></figure><br>同时xs和ys即网格格点坐标，也经过了降采样，以及范围伸缩，变为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">4</span> <span class="number">4</span>]]</span><br></pre></td></tr></table></figure></p><h2 id="获取格点和面的信息"><a href="#获取格点和面的信息" class="headerlink" title="获取格点和面的信息"></a>获取格点和面的信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_grid_mesh</span>(<span class="params">xs, ys, zs</span>):</span></span><br><span class="line">    h, w = xs.shape</span><br><span class="line">    <span class="comment"># 将xy坐标位置和z值合并起来</span></span><br><span class="line">    vts = np.array([xs, ys, zs], dtype=np.float32)</span><br><span class="line">    <span class="comment"># 这一步是定义以某格点为参考点的坐标系下它与哪些点形成面</span></span><br><span class="line">    <span class="comment"># 在局部坐标系下，参考点索引为0，那么它所构成的面有两个</span></span><br><span class="line">    <span class="comment"># 分别与(1, 1+w)这两个点构成一个面，与(1+w, w)这两个点构成一个面</span></span><br><span class="line">    <span class="comment"># 比如在此例下，did的值就是[[0 1 4 0 4 3]]</span></span><br><span class="line">    did = np.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>+w, <span class="number">0</span>, <span class="number">1</span>+w, w]], dtype=np.uint32)</span><br><span class="line">    <span class="comment"># rcs由两部分构成</span></span><br><span class="line">    <span class="comment"># 第一部分是获取全局坐标系下每一排的第一个元素的索引，所以是以w为步长</span></span><br><span class="line">    <span class="comment"># 注意排除最后一排，即是w*h还要减去w，因为最后一排元素所参与的面可以通过倒数第二排来获得</span></span><br><span class="line">    <span class="comment"># 对于此例，就是[[0], [3]]，注意这里使用None来增加一个维度</span></span><br><span class="line">    <span class="comment"># 第二部分是获取全局坐标系下每一列的索引，所以是以1为步长</span></span><br><span class="line">    <span class="comment"># 注意是排除最后一列，即w要减去1，这也是因为最后一列参与的面可以通过前一列得到</span></span><br><span class="line">    <span class="comment"># 对于此例，就是[0, 1]</span></span><br><span class="line">    <span class="comment"># 最终rcs就是numpy数组的[[0],[3]]+[0, 1]</span></span><br><span class="line">    <span class="comment"># 这里用到了numpy的广播： https://qixinbo.info/2019/10/20/python-indexing/</span></span><br><span class="line">    <span class="comment"># [[0, 0],[3, 3]] + [[0, 1], [0, 1]] = [[0, 1], [3, 4]]</span></span><br><span class="line">    <span class="comment"># 代表的意思就是在全局坐标系中，第一排取索引为0和1的格点，在第二排取索引为3和4的格点</span></span><br><span class="line">    rcs = np.arange(<span class="number">0</span>,w*h-w,w)[:,<span class="literal">None</span>] + np.arange(<span class="number">0</span>,w-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 接下来就是根据上面取得的格点，得到每个格点上所形成的面</span></span><br><span class="line">    <span class="comment"># 首先第一部分是将rcs拉直为[[0], [1], [3], [4]]，即这四个格点索引拉平到一个维度上</span></span><br><span class="line">    <span class="comment"># 然后加上上面的局部坐标系下形成面的格点索引[[0 1 4 0 4 3]]</span></span><br><span class="line">    <span class="comment"># 同样根据广播原则，就得到了每个格点与相邻点所形成的面</span></span><br><span class="line">    <span class="comment"># 结果为：[[0 1 4 0 4 3], [1 2 5 1 5 4], [3 4 7 3 7 6], [4 5 8 4 8 7]] </span></span><br><span class="line">    <span class="comment"># 即每个格点上都参与形成两个面，具体每一个面的格点组成看上面的序列</span></span><br><span class="line">    faces = rcs.reshape(-<span class="number">1</span>,<span class="number">1</span>) + did</span><br><span class="line">    <span class="comment"># 返回值是两个</span></span><br><span class="line">    <span class="comment"># 第一个就是格点坐标及其上面的值，并按这三个值合并起来算一个重新改变形状</span></span><br><span class="line">    <span class="comment"># 第二个就是由格点所形成的面的信息</span></span><br><span class="line">    <span class="keyword">return</span> vts.reshape(<span class="number">3</span>,-<span class="number">1</span>).T.copy(), faces.reshape(-<span class="number">1</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>具体的解析过程见上面源码。<br>最后说一下最终返回的格点信息和面信息，分别是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.</span>        <span class="number">0.</span>        <span class="number">0.8767308</span>]</span><br><span class="line"> [<span class="number">0.</span>        <span class="number">2.</span>        <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">0.</span>        <span class="number">4.</span>        <span class="number">0.8767308</span>]</span><br><span class="line"> [<span class="number">2.</span>        <span class="number">0.</span>        <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">2.</span>        <span class="number">2.</span>        <span class="number">1.6630671</span>]</span><br><span class="line"> [<span class="number">2.</span>        <span class="number">4.</span>        <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">4.</span>        <span class="number">0.</span>        <span class="number">0.8767308</span>]</span><br><span class="line"> [<span class="number">4.</span>        <span class="number">2.</span>        <span class="number">1.2075025</span>]</span><br><span class="line"> [<span class="number">4.</span>        <span class="number">4.</span>        <span class="number">0.8767308</span>]]</span><br></pre></td></tr></table></figure><br>以第一个格点为例，它是在(0, 0)坐标，同时上面的值是0.8767308。<br>以及面信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">1</span> <span class="number">4</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">4</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">2</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">5</span> <span class="number">4</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">7</span> <span class="number">6</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span> <span class="number">8</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">8</span> <span class="number">7</span>]]</span><br></pre></td></tr></table></figure><br>以第一个面为例，它由(0, 1, 4)号格点组成。</p><h2 id="构建Mesh对象"><a href="#构建Mesh对象" class="headerlink" title="构建Mesh对象"></a>构建Mesh对象</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传入上面的格点、面、颜色（这里取的是格点上的z值）以及cmap</span></span><br><span class="line">Mesh.set_data(self, verts=vert, faces=fs.astype(np.uint32), colors=vert[:,<span class="number">2</span>], **key)</span><br></pre></td></tr></table></figure><p>上述代码是调用了Mesh对象的set_data方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mesh</span>:</span></span><br><span class="line"><span class="comment"># 在初始化函数中传入一个Mesh对象所需要的信息</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, verts=<span class="literal">None</span>, faces=<span class="literal">None</span>, colors=<span class="literal">None</span>, cmap=<span class="literal">None</span>, **key</span>):</span></span><br><span class="line"><span class="comment"># 如果有格点信息，但没有面信息</span></span><br><span class="line"><span class="keyword">if</span> faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> verts <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line"><span class="comment"># 则直接按格点个数-1生成面，即两个相邻格点相连，就成为面</span></span><br><span class="line">faces = np.arange(<span class="built_in">len</span>(verts), dtype=np.uint32)</span><br><span class="line"><span class="comment"># 传入格点信息</span></span><br><span class="line">self.verts = verts.astype(np.float32, copy=<span class="literal">False</span>) <span class="keyword">if</span> <span class="keyword">not</span> verts <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="comment"># 传入面信息</span></span><br><span class="line">self.faces = faces.astype(np.uint32, copy=<span class="literal">False</span>) <span class="keyword">if</span> <span class="keyword">not</span> faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="comment"># 传入颜色信息</span></span><br><span class="line">self.colors = colors</span><br><span class="line"><span class="comment"># 设置模式、可见性和dirty属性等</span></span><br><span class="line">self.mode, self.visible, self.dirty = <span class="string">&#x27;mesh&#x27;</span>, <span class="literal">True</span>, <span class="string">&#x27;geom&#x27;</span></span><br><span class="line"><span class="comment"># 设置alpha透明度和边信息</span></span><br><span class="line">self.alpha = <span class="number">1</span>; self.edges = <span class="literal">None</span></span><br><span class="line"><span class="comment"># 设置高光、colormap</span></span><br><span class="line">self.high_light = <span class="literal">False</span>; self.cmap = <span class="string">&#x27;gray&#x27;</span> <span class="keyword">if</span> cmap <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> cmap</span><br><span class="line"><span class="comment"># 调用set_data方法</span></span><br><span class="line">self.set_data(**key)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_data</span>(<span class="params">self, verts=<span class="literal">None</span>, faces=<span class="literal">None</span>, colors=<span class="literal">None</span>, **key</span>):</span></span><br><span class="line"><span class="comment"># 同上面的初始化功能近似，区别是可以直接调用它来配置信息</span></span><br><span class="line"><span class="keyword">if</span> faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> verts <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">faces = np.arange(<span class="built_in">len</span>(verts), dtype=np.uint32)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> verts <span class="keyword">is</span> <span class="literal">None</span>: self.verts = verts.astype(np.float32, copy=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> faces <span class="keyword">is</span> <span class="literal">None</span>: self.faces = faces.astype(np.uint32, copy=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> colors <span class="keyword">is</span> <span class="literal">None</span>: self.colors = colors</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> faces <span class="keyword">is</span> <span class="literal">None</span>: self.edge = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">sum</span>([i <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> [verts, faces, colors]])&lt;<span class="number">3</span>: self.dirty = <span class="string">&#x27;geom&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> self.faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> self.faces.ndim==<span class="number">1</span>: key[<span class="string">&#x27;mode&#x27;</span>] = <span class="string">&#x27;points&#x27;</span></span><br><span class="line"><span class="keyword">elif</span> <span class="keyword">not</span> self.faces <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> self.faces.shape[<span class="number">1</span>]==<span class="number">2</span>: </span><br><span class="line"><span class="keyword">if</span> key.get(<span class="string">&#x27;mode&#x27;</span>, self.mode)==<span class="string">&#x27;mesh&#x27;</span>: key[<span class="string">&#x27;mode&#x27;</span>] = <span class="string">&#x27;grid&#x27;</span></span><br><span class="line"><span class="keyword">if</span> key.get(<span class="string">&#x27;mode&#x27;</span>, self.mode) != self.mode: self.dirty = <span class="string">&#x27;geom&#x27;</span></span><br><span class="line">self.mode = key.get(<span class="string">&#x27;mode&#x27;</span>, self.mode)</span><br><span class="line">self.visible = key.get(<span class="string">&#x27;visible&#x27;</span>, self.visible)</span><br><span class="line">self.alpha = key.get(<span class="string">&#x27;alpha&#x27;</span>, self.alpha)</span><br><span class="line">self.high_light = key.get(<span class="string">&#x27;high_light&#x27;</span>, <span class="literal">False</span>)</span><br><span class="line">self.cmap = key.get(<span class="string">&#x27;cmap&#x27;</span>, self.cmap)</span><br><span class="line">self.dirty = self.dirty <span class="keyword">or</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure></p><h1 id="可视化Mesh"><a href="#可视化Mesh" class="headerlink" title="可视化Mesh"></a>可视化Mesh</h1><p>即将Mesh对象通过三维画布展示出来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.app.show_mesh(mesh, para[<span class="string">&#x27;name&#x27;</span>])</span><br></pre></td></tr></table></figure><br>这里就是调用了app的show_mesh方法。<br>ImagePy的三维画布是基于VisPy的，同时又进行了封装，最底层的是如下这个类：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Canvas3D</span>(<span class="params">scene.SceneCanvas</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>(<span class="params">cls, parent, scene3d=<span class="literal">None</span></span>):</span></span><br><span class="line">        self = <span class="built_in">super</span>().__new__(cls)</span><br><span class="line">        scene.SceneCanvas.__init__(self, app=<span class="string">&quot;wx&quot;</span>, parent=parent, keys=<span class="string">&#x27;interactive&#x27;</span>, show=<span class="literal">True</span>, dpi=<span class="number">150</span>)</span><br><span class="line">        canvas = parent.GetChildren()[-<span class="number">1</span>]</span><br><span class="line">        self.unfreeze()</span><br><span class="line">        self.canvas = weakref.ref(canvas)</span><br><span class="line">        self.view = self.central_widget.add_view()</span><br><span class="line">        self.set_scene(scene3d <span class="keyword">or</span> Scene())</span><br><span class="line">        self.visuals = &#123;&#125;</span><br><span class="line">        self.curobj = <span class="literal">None</span></span><br><span class="line">        self.freeze()</span><br><span class="line">        canvas.Bind(wx.EVT_IDLE, self.on_idle)</span><br><span class="line">        canvas.tool = <span class="literal">None</span></span><br><span class="line">        canvas.camera = scene.cameras.TurntableCamera(parent=self.view.scene, fov=<span class="number">45</span>, name=<span class="string">&#x27;Turntable&#x27;</span>)</span><br><span class="line">        canvas.set_camera = self.set_camera</span><br><span class="line">        canvas.fit = <span class="keyword">lambda</span> : self.set_camera(auto=<span class="literal">True</span>)</span><br><span class="line">        canvas.at = self.at</span><br><span class="line">        self.view.camera = canvas.camera</span><br><span class="line">        <span class="keyword">return</span> canvas</span><br></pre></td></tr></table></figure><br>VisPy的教程略微有点少，留坑待填。</p>]]></content>
    
    
    <summary type="html">本文解析一下ImagePy的三维画布。
以如下例子入手：

首先，原始图像是一个5乘5的方形图像，其中间是4乘4的白色，周围是一圈黑色。
由这张原始图根据距离变换得到右上角的高程图，继而对该高程图做三维可视化。

渲染插件
二维平面的三维可视化插件是这样写的：
1
2
3
4
5
6
7
8
9
10
11
12
13
14


class Surface2D(Simple):
    title = &#39;2D Surface&#39;
    note = [&#39;8-bit&#39;, &#39;16-bit&#39;, &#39;float&#39;]
    para = {&#39;name&#39;:&#39;undifine&#39;, &#39;sample&#39;:2, &#39;</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>Electron初探：基于Web的跨平台桌面应用开发</title>
    <link href="http://qixinbo.github.io/2021/11/15/electron/"/>
    <id>http://qixinbo.github.io/2021/11/15/electron/</id>
    <published>2021-11-14T16:00:00.000Z</published>
    <updated>2021-11-15T06:37:55.565Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://juejin.cn/post/6844904055236460558">你能分得清楚 Chromium, V8, Blink, Gecko, WebKit 之间的区别吗？</a><br><a href="https://msyfls123.github.io/blog/2020/11/02/%E4%B8%9D%E8%88%AC%E9%A1%BA%E6%BB%91%E7%9A%84Electron%E8%B7%A8%E7%AB%AF%E5%BC%80%E5%8F%91%E4%BD%93%E9%AA%8C/">丝般顺滑的 Electron 跨端开发体验</a><br><a href="https://jspang.com/detailed?id=62#toc34">Electron 免费视频教程-用前端技术开发桌面应用</a><br><a href="https://weishuai.gitbooks.io/electron-/content/tutorial/quick-start.html">Electron 快速入门</a></p><h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><h2 id="引擎"><a href="#引擎" class="headerlink" title="引擎"></a>引擎</h2><p>JavaScript引擎的作用是解释和编译JavaScript代码。<br>而浏览器引擎不仅负责管理网页的布局，同时其包括JavaScript引擎。<br>当前市场上只有 3 个主要的浏览器引擎：Mozilla 的 Gecko、Google 的 Blink、还有苹果的的 WebKit（Blink 的近亲）。<br>Blink 是 Google Chrome浏览器及Chromium开源浏览器（可以理解为：Chromium + 集成 Google 产品 = Google Chrome）的渲染引擎，V8 是 Blink 内置的 JavaScript 引擎。具体来说，V8 对 DOM（文档对象模型）一无所知，因为它仅用于处理 JavaScript；而Blink 内置的布局引擎负责处理网页布局和展示。</p><h2 id="后端"><a href="#后端" class="headerlink" title="后端"></a>后端</h2><p>Node.js 就是运行在服务端的 JavaScript，类比Java后端、Python后端等。<br>因为 Node.js 不需要使用 DOM，所以 Node.js 只使用了 V8 引擎，而没有把整个 Blink 引擎都搬过来用。</p><h2 id="Electron"><a href="#Electron" class="headerlink" title="Electron"></a>Electron</h2><p>Electron = Chromium + Node.js + Native API<br>（1）Chromium : 为Electron提供了强大的UI能力，可以不考虑兼容性的情况下，利用强大的Web生态来开发界面。<br>（2）Node.js ：让Electron有了底层的操作能力，比如文件的读写，甚至是集成C++等等操作，并可以使用大量开源的npm包来完成开发需求。<br>（3）Native API ： Native API让Electron有了跨平台和桌面端的原生能力，比如说它有统一的原生界面，窗口、托盘这些。</p><p>Electron作用是用Web前端技术来开发桌面应用。</p><p>具体原理：<br>Electron 就是 Chromium（Chrome 内核）、Node.js 和系统原生 API 的结合。它做的事情很简单，整个应用跑在一个 main process（主进程） 上，需要提供 GUI 界面时则创建一个 renderer process（渲染进程）去开启一个 Chromium 里的 BrowserWindow/BrowserView，实际就像是 Chrome 的一个窗口或者 Tab 页一样，而其中展示的既可以是本地网页也可以是线上网页，主进程和渲染进程间通过 IPC 进行通讯，主进程可以自由地调用 Electron 提供的系统 API 以及 Node.js 模块，可以控制其所辖渲染进程的生命周期。</p><h3 id="主进程"><a href="#主进程" class="headerlink" title="主进程"></a>主进程</h3><p>在 Electron 里，运行 package.json 里 main 脚本的进程被称为主进程。在主进程运行的脚本可以以创建 web 页面的形式展示 GUI。</p><h3 id="渲染进程"><a href="#渲染进程" class="headerlink" title="渲染进程"></a>渲染进程</h3><p>由于 Electron 使用 Chromium 来展示页面，所以 Chromium 的多进程结构也被充分利用。每个 Electron 的页面都在运行着自己的进程，这样的进程我们称之为渲染进程。<br>在一般浏览器中，网页通常会在沙盒环境下运行，并且不允许访问原生资源。然而，Electron 用户拥有在网页中调用 Node.js 的 APIs 的能力，可以与底层操作系统直接交互。</p><h3 id="主进程与渲染进程的区别"><a href="#主进程与渲染进程的区别" class="headerlink" title="主进程与渲染进程的区别"></a>主进程与渲染进程的区别</h3><p>主进程使用 BrowserWindow 实例创建页面。每个 BrowserWindow 实例都在自己的渲染进程里运行页面。当一个 BrowserWindow 实例被销毁后，相应的渲染进程也会被终止。<br>主进程管理所有页面和与之对应的渲染进程。每个渲染进程都是相互独立的，并且只关心他们自己的页面。<br>由于在页面里管理原生 GUI 资源是非常危险而且容易造成资源泄露，所以在页面调用 GUI 相关的 APIs 是不被允许的。如果你想在网页里使用 GUI 操作，其对应的渲染进程必须与主进程进行通讯，请求主进程进行相关的 GUI 操作。<br>在 Electron，我们提供几种方法用于主进程和渲染进程之间的通讯。像 ipcRenderer 和 ipcMain 模块用于发送消息， remote 模块用于 RPC 方式通讯。</p><h1 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h1><h2 id="安装Electron"><a href="#安装Electron" class="headerlink" title="安装Electron"></a>安装Electron</h2><p>可以全局安装：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g electron</span><br></pre></td></tr></table></figure><br>或者仅项目安装：新建一个文件夹，然后，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install electron --save-dev</span><br></pre></td></tr></table></figure><br>然后使用以下命令查看是否安装成功：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npx electron -v</span><br><span class="line">或</span><br><span class="line">./node_modules/.<span class="built_in">bin</span>/electron -v</span><br></pre></td></tr></table></figure></p><h1 id="Electron的Hello-World"><a href="#Electron的Hello-World" class="headerlink" title="Electron的Hello World"></a>Electron的Hello World</h1><h2 id="新建index-html文件"><a href="#新建index-html文件" class="headerlink" title="新建index.html文件"></a>新建index.html文件</h2><p>在项目的根目录中新建一个index.html文件，相当于UI都写在html中（可以在sublimetext输入html自动生成）：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=<span class="string">&quot;utf-8&quot;</span>&gt;</span><br><span class="line">    &lt;meta name=<span class="string">&quot;viewport&quot;</span> content=<span class="string">&quot;width=device-width, initial-scale=1&quot;</span>&gt;</span><br><span class="line">    &lt;title&gt;Hello World&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">    hello World</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p><h2 id="新建main-js文件"><a href="#新建main-js文件" class="headerlink" title="新建main.js文件"></a>新建main.js文件</h2><p>在根目录下新建一个main.js文件，这个就是Electron的主进程文件。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">var electron = require(<span class="string">&#x27;electron&#x27;</span>)  //引入electron模块</span><br><span class="line"></span><br><span class="line">var app = electron.app   // 创建electron引用</span><br><span class="line"></span><br><span class="line">var BrowserWindow = electron.BrowserWindow;  //创建窗口引用</span><br><span class="line"></span><br><span class="line">var mainWindow = null ;  //声明要打开的主窗口</span><br><span class="line">app.on(&#x27;ready&#x27;,()=&gt;&#123;</span><br><span class="line">    mainWindow = new BrowserWindow(&#123;width:<span class="number">400</span>,height:<span class="number">400</span>&#125;)   //设置打开的窗口大小</span><br><span class="line"></span><br><span class="line">    mainWindow.loadFile(<span class="string">&#x27;index.html&#x27;</span>)  //加载那个页面</span><br><span class="line"></span><br><span class="line">    //监听关闭事件，把主窗口设置为null</span><br><span class="line">    mainWindow.on(&#x27;closed&#x27;,()=&gt;&#123;</span><br><span class="line">        mainWindow = null</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p><h2 id="创建package-json文件"><a href="#创建package-json文件" class="headerlink" title="创建package.json文件"></a>创建package.json文件</h2><p>在终端使用命令：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm init --yes</span><br></pre></td></tr></table></figure><br>这时候main的值为main.js就正确了。</p><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>终端下运行：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\node_modules\.<span class="built_in">bin</span>\electron .</span><br></pre></td></tr></table></figure></p><p>然后结果为：<br><img src="https://user-images.githubusercontent.com/6218739/141733207-8ae86b3e-95ab-4c5d-8e49-6f11c5721fd7.png" alt="hello"></p><p>试了这个最小例子，感觉使用electron来开发桌面应用的话，既能跨平台，比如Windows、Linux、MacOS，一处水源供全球，还能直接转化成Web应用，即不让用户安装软件，给他一个链接直接访问。<br>这样就可进可退，一次开发，到处使用，但前提是得熟悉JS开发，这个坑待填。。</p>]]></content>
    
    
    <summary type="html">参考文献
你能分得清楚 Chromium, V8, Blink, Gecko, WebKit 之间的区别吗？
丝般顺滑的 Electron 跨端开发体验
Electron 免费视频教程-用前端技术开发桌面应用
Electron 快速入门

基础概念
引擎
JavaScript引擎的作用是解释和编译JavaScript代码。
而浏览器引擎不仅负责管理网页的布局，同时其包括JavaScript引擎。
当前市场上只有 3 个主要的浏览器引擎：Mozilla 的 Gecko、Google 的 Blink、还有苹果的的 WebKit（Blink 的近亲）。
Blink 是 Google Chrome浏览</summary>
    
    
    
    <category term="digitalization" scheme="http://qixinbo.github.io/categories/digitalization/"/>
    
    
    <category term="GUI" scheme="http://qixinbo.github.io/tags/GUI/"/>
    
  </entry>
  
  <entry>
    <title>NLP霸主Transformer及CV新秀Vision Transformer解析</title>
    <link href="http://qixinbo.github.io/2021/11/09/transformer/"/>
    <id>http://qixinbo.github.io/2021/11/09/transformer/</id>
    <published>2021-11-08T16:00:00.000Z</published>
    <updated>2021-11-09T07:58:46.805Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://cuijiahua.com/blog/2021/01/dl-basics-3.html">保姆级教程：图解Transformer</a><br><a href="https://terrifyzhao.github.io/2019/01/11/Transformer%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.html">Transformer模型详解</a><br><a href="https://wmathor.com/index.php/archives/1438/">Transformer 详解</a><br><a href="https://picture.iczhiku.com/weixin/message1610942723056.html">盘点 | 2021年paper大热的Transformer (ViT)</a><br><a href="https://zhuanlan.zhihu.com/p/356155277">“未来”的经典之作ViT：transformer is all you need!</a><br><a href="https://paddlepedia.readthedocs.io/en/latest/tutorials/computer_vision/classification/ViT.html">ViT( Vision Transformer)</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention Is All You Need</a>是一篇Google于2017年提出的将Attention思想发挥到极致的论文。这篇论文中提出一个全新的模型，叫 Transformer，抛弃了以往深度学习任务里面使用到的 CNN 和 RNN ，目前大热的Bert、GPT和DALL-E就是基于Transformer构建的，这个模型广泛应用于NLP领域，例如机器翻译，问答系统，文本摘要和语音识别等等方向。<br><img src="https://user-images.githubusercontent.com/6218739/140851930-34149770-8d8b-4fed-bdf2-43cce255f0b1.png" alt="1"></p><p>相比于NLP领域，在CV领域中，卷积神经网络CNN却是绝对的霸主。对于图像问题，CNN具有天然的先天优势（inductive bias）：平移不变性（translation equivariance）和局部性（locality）。而transformer虽然不并具备这些优势，但是transformer的核心self-attention的优势不像卷积那样有固定且有限的感受野，self-attention操作可以获得long-range信息（相比之下CNN要通过不断堆积Conv layers来获取更大的感受野），但训练的难度就比CNN要稍大一些。<br>仍然是Google，<a href="https://arxiv.org/pdf/2010.11929.pdf">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a>这篇2020年的论文将Transformer引入了CV中，形成了Vision Transformer，简称为ViT。<br>本文尝试理解一下原始Transformer及其衍生品ViT。</p><h1 id="Transformer架构"><a href="#Transformer架构" class="headerlink" title="Transformer架构"></a>Transformer架构</h1><p>Transformer 的内部，在本质上是一个 Encoder-Decoder 的结构，即 编码器-解码器。<br><img src="https://user-images.githubusercontent.com/6218739/140852001-0fbc70ae-83f7-40c7-b784-4ed205ac30a9.png" alt="2"><br>Transformer 中抛弃了传统的 CNN 和 RNN，整个网络结构完全由 Attention 机制组成，并且采用了 6 层 Encoder-Decoder 结构。<br><img src="https://user-images.githubusercontent.com/6218739/140852095-d48c5aaa-d167-4169-8b56-5451a8db4416.png" alt="3"><br>显然，Transformer 主要分为两大部分，分别是编码器和解码器。<br>整个 Transformer 是由 6 个这样的结构组成，为了方便理解，我们只看其中一个Encoder-Decoder 结构。<br>以一个简单的例子进行说明：<br><img src="https://user-images.githubusercontent.com/6218739/140852188-a8f1dee3-5b59-489b-ba4e-df8d6664f6da.png" alt="4"></p><p>Why do we work?，我们为什么工作？<br>左侧红框是编码器，右侧红框是解码器，<br>编码器负责把自然语言序列映射成为隐藏层（上图第2步），即含有自然语言序列的数学表达。<br>解码器把隐藏层再映射为自然语言序列，从而使我们可以解决各种问题，如情感分析、机器翻译、摘要生成、语义关系抽取等。<br>简单说下，上图每一步都做了什么：<br>（1）输入自然语言序列到编码器: Why do we work?；<br>（2）编码器输出的隐藏层，再输入到解码器；<br>（3）输入 $&lt;𝑠𝑡𝑎𝑟𝑡&gt;$符号到解码器；<br>（4）解码器得到第一个字”为”；<br>（5）将得到的第一个字”为”落下来再输入到解码器；<br>（6）解码器得到第二个字”什”；<br>（7）将得到的第二字再落下来，直到解码器输出 $&lt;𝑒𝑛𝑑&gt;$，即序列生成完成。</p><h2 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h2><p>编码器即是把自然语言序列映射为隐藏层的数学表达的过程。<br>为了方便学习，编码器可以分为 4 个部分：<br><img src="https://user-images.githubusercontent.com/6218739/140853558-6b30feb1-7ca3-495b-8c6f-a1456d67be8d.png" alt="5"></p><h3 id="位置嵌入（𝑝𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝑎𝑙-𝑒𝑛𝑐𝑜𝑑𝑖𝑛𝑔）"><a href="#位置嵌入（𝑝𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝑎𝑙-𝑒𝑛𝑐𝑜𝑑𝑖𝑛𝑔）" class="headerlink" title="位置嵌入（𝑝𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝑎𝑙 𝑒𝑛𝑐𝑜𝑑𝑖𝑛𝑔）"></a>位置嵌入（𝑝𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝑎𝑙 𝑒𝑛𝑐𝑜𝑑𝑖𝑛𝑔）</h3><p>我们输入数据 X 维度为[batch size, sequence length]的数据，比如我们为什么工作。<br>batch size 就是 batch 的大小，这里只有一句话，所以 batch size 为 1，sequence length 是句子的长度，一共 7 个字，所以输入的数据维度是 [1, 7]。<br>我们不能直接将这句话输入到编码器中，因为 Tranformer 不认识，我们需要先进行字嵌入，即得到图中的$X_{embedding}$。</p><p>简单点说，就是文字到字向量的转换，这种转换是将文字转换为计算机认识的数学表示，用到的方法就是Word2Vec，Word2Vec的具体细节，对于初学者暂且不用了解，这个是可以直接使用的。</p><p>得到的$X{embedding}$的维度是[batch size, sequence length, embedding dimension]，embedding dimension 的大小由 Word2Vec 算法决定，Tranformer 采用 512 长度的字向量。所以$X_{embedding}$的维度是[1, 7, 512]。</p><p>至此，输入的我们为什么工作，可以用一个矩阵来简化表示。<br><img src="https://user-images.githubusercontent.com/6218739/140853602-a6f68d15-8308-4b0d-b067-abb5d9a7e098.png" alt="6"><br>我们知道，文字的先后顺序，很重要。<br>比如吃饭没、没吃饭、没饭吃、饭吃没、饭没吃，同样三个字，顺序颠倒，所表达的含义就不同了。<br>文字的位置信息很重要，Tranformer 没有类似 RNN 的循环结构，没有捕捉顺序序列的能力。<br>为了保留这种位置信息交给 Tranformer 学习，我们需要用到位置嵌入。<br>加入位置信息的方式非常多，最简单的可以是直接将绝对坐标 0,1,2 编码。<br>Tranformer 采用的是 sin-cos 规则，使用了 sin 和 cos 函数的线性变换来提供给模型位置信息：</p><script type="math/tex; mode=display">\begin{aligned} P E_{(p o s, 2 i)} &=\sin \left(p o s / 10000^{2 i / d_{\text {model }}}\right) \\ P E_{(\text {pos }, 2 i+1)} &=\cos \left(\text { pos } / 10000^{2 i / d_{\text {model }}}\right) \end{aligned}</script><p>上式中 pos 指的是句中字的位置，取值范围是 [0, 𝑚𝑎𝑥 𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 𝑙𝑒𝑛𝑔𝑡ℎ)，i 指的是字嵌入的维度, 取值范围是 [0, 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑑𝑖𝑚𝑒𝑛𝑠𝑖𝑜𝑛)。<br>上面有 sin 和 cos 一组公式，也就是对应着 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑑𝑖𝑚𝑒𝑛𝑠𝑖𝑜𝑛 维度的一组奇数和偶数的序号的维度，从而产生不同的周期性变化。<br>可以用代码，简单看下效果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入依赖库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_positional_encoding</span>(<span class="params">max_seq_len, embed_dim</span>):</span></span><br><span class="line">    <span class="comment"># 初始化一个positional encoding</span></span><br><span class="line">    <span class="comment"># embed_dim: 字嵌入的维度</span></span><br><span class="line">    <span class="comment"># max_seq_len: 最大的序列长度</span></span><br><span class="line">    positional_encoding = np.array([</span><br><span class="line">        [pos / np.power(<span class="number">10000</span>, <span class="number">2</span> * i / embed_dim) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(embed_dim)]</span><br><span class="line">        <span class="keyword">if</span> pos != <span class="number">0</span> <span class="keyword">else</span> np.zeros(embed_dim) <span class="keyword">for</span> pos <span class="keyword">in</span> <span class="built_in">range</span>(max_seq_len)])</span><br><span class="line">    positional_encoding[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(positional_encoding[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>])  <span class="comment"># dim 2i 偶数</span></span><br><span class="line">    positional_encoding[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(positional_encoding[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>])  <span class="comment"># dim 2i+1 奇数</span></span><br><span class="line">    <span class="comment"># 归一化, 用位置嵌入的每一行除以它的模长</span></span><br><span class="line">    <span class="comment"># denominator = np.sqrt(np.sum(position_enc**2, axis=1, keepdims=True))</span></span><br><span class="line">    <span class="comment"># position_enc = position_enc / (denominator + 1e-8)</span></span><br><span class="line">    <span class="keyword">return</span> positional_encoding</span><br><span class="line">    </span><br><span class="line">positional_encoding = get_positional_encoding(max_seq_len=<span class="number">100</span>, embed_dim=<span class="number">16</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">sns.heatmap(positional_encoding)</span><br><span class="line">plt.title(<span class="string">&quot;Sinusoidal Function&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;hidden dimension&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;sequence length&quot;</span>)</span><br></pre></td></tr></table></figure><br>可以看到，位置嵌入在 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑑𝑖𝑚𝑒𝑛𝑠𝑖𝑜𝑛 （也是hidden dimension ）维度上随着维度序号增大，周期变化会越来越慢，而产生一种包含位置信息的纹理。<br><img src="https://user-images.githubusercontent.com/6218739/140854019-3e363d94-cefe-4772-a7f2-fa87de1eb41b.png" alt="embed"><br>就这样，产生独一的纹理位置信息，模型从而学到位置之间的依赖关系和自然语言的时序特性。<br>最后，将$X_{\text {embedding }}$和 位置嵌入 相加（维度相同，可以直接相加），得到该字真正的向量表示，然后送给下一层。</p><h3 id="自注意力层（𝑠𝑒𝑙𝑓-𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛-𝑚𝑒𝑐ℎ𝑎𝑛𝑖𝑠𝑚）"><a href="#自注意力层（𝑠𝑒𝑙𝑓-𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛-𝑚𝑒𝑐ℎ𝑎𝑛𝑖𝑠𝑚）" class="headerlink" title="自注意力层（𝑠𝑒𝑙𝑓 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 𝑚𝑒𝑐ℎ𝑎𝑛𝑖𝑠𝑚）"></a>自注意力层（𝑠𝑒𝑙𝑓 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 𝑚𝑒𝑐ℎ𝑎𝑛𝑖𝑠𝑚）</h3><p>这部分介绍来自于<a href="https://terrifyzhao.github.io/2019/01/11/Transformer%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.html">这篇博客</a><br>self-attention，其思想和attention类似，但是self-attention是Transformer用来将其他相关单词的“理解”转换成我们正在处理的单词的一种思路，我们看个例子： The animal didn’t cross the street because it was too tired 这里的it到底代表的是animal还是street呢，对于我们来说能很简单的判断出来，但是对于机器来说，是很难判断的，self-attention就能够让机器把it和animal联系起来，接下来我们看下详细的处理过程。<br>（1）首先，self-attention会计算出三个新的向量，在论文中，向量的维度是512维，我们把这三个向量分别称为Query、Key、Value，这三个向量是用embedding向量与一个矩阵相乘得到的结果，这个矩阵是随机初始化的，维度为（64，512），注意第二个维度需要和embedding的维度一样，其值在BP的过程中会一直进行更新，得到的这三个向量的维度是64低于embedding维度的。<br><img src="https://user-images.githubusercontent.com/6218739/140857139-71ca395e-ec3a-40c4-8c0d-4c815ceb9e09.png" alt="qkv"><br>那么Query、Key、Value这三个向量又是什么呢？这三个向量对于attention来说很重要，当你理解了下文后，你将会明白这三个向量扮演者什么的角色。<br>（2）计算self-attention的分数值，该分数值决定了当我们在某个位置encode一个词时，对输入句子的其他部分的关注程度。这个分数值的计算方法是Query与Key做点乘，以下图为例，首先我们需要针对Thinking这个词，计算出其他词对于该词的一个分数值，首先是针对于自己本身即$q1·k1$，然后是针对于第二个词即$q1·k2$。<br><img src="https://user-images.githubusercontent.com/6218739/140857357-91caf198-e459-471b-a800-8ae705ef1434.png" alt="score"><br>（3）接下来，把点乘的结果除以一个常数，这里我们除以8，这个值一般是采用上文提到的矩阵的第一个维度的开方即64的开方8，当然也可以选择其他的值，然后把得到的结果做一个softmax的计算。得到的结果即是每个词对于当前位置的词的相关性大小，当然，当前位置的词相关性肯定会很大。<br><img src="https://user-images.githubusercontent.com/6218739/140857512-c22f2546-25e5-449d-8632-6cdffd1dc4fe.png" alt="score2"><br>（4）下一步就是把Value和softmax得到的值进行相乘，并相加，得到的结果即是self-attention在当前节点的值。<br><img src="https://user-images.githubusercontent.com/6218739/140857653-468ca02a-3dfb-4d33-a8b9-36f8596f9f15.png" alt="score3"><br>在实际的应用场景，为了提高计算速度，我们采用的是矩阵的方式，直接计算出Query, Key, Value的矩阵，然后把embedding的值与三个矩阵直接相乘，把得到的新矩阵Q与K相乘，乘以一个常数，做softmax操作，最后乘上V矩阵：<br><img src="https://user-images.githubusercontent.com/6218739/140857883-d06b029d-99ec-4a28-8711-35b0d4425f53.png" alt="attention"><br><img src="https://user-images.githubusercontent.com/6218739/140857941-c6f16054-2104-4205-850b-d15bc96a6659.png" alt="attention2"><br>这种通过 query 和 key 的相似性程度来确定 value 的权重分布的方法被称为scaled dot-product attention。</p><h4 id="Multi-Headed-Attention"><a href="#Multi-Headed-Attention" class="headerlink" title="Multi-Headed Attention"></a>Multi-Headed Attention</h4><p>这篇论文更牛的地方是给self-attention加入了另外一个机制，被称为“multi-headed” attention，该机制理解起来很简单，就是说不仅仅只初始化一组Q、K、V的矩阵，而是初始化多组，tranformer是使用了8组，所以最后得到的结果是8个矩阵。<br><img src="https://user-images.githubusercontent.com/6218739/140868505-278beff7-e9dc-440d-87ad-b2a021310a59.png" alt="multihead1"><br><img src="https://user-images.githubusercontent.com/6218739/140868544-311c039e-252c-425f-b957-3d1f2eece542.png" alt="multihead2"><br>这给我们留下了一个小的挑战，前馈神经网络没法输入8个矩阵呀，这该怎么办呢？所以我们需要一种方式，把8个矩阵降为1个，首先，我们把8个矩阵连在一起，这样会得到一个大的矩阵，再随机初始化一个矩阵和这个组合好的矩阵相乘，最后得到一个最终的矩阵。<br><img src="https://user-images.githubusercontent.com/6218739/140868642-638e7a9f-6543-4068-b569-12984bc7b5be.png" alt="multihead3"><br>这就是multi-headed attention的全部流程了，这里其实已经有很多矩阵了，我们把所有的矩阵放到一张图内看一下总体的流程。<br><img src="https://user-images.githubusercontent.com/6218739/140868817-3f900670-e211-4395-bb5a-2e9625ed3644.png" alt="multihead4"></p><h3 id="残差链接和层归一化"><a href="#残差链接和层归一化" class="headerlink" title="残差链接和层归一化"></a>残差链接和层归一化</h3><p>加入了残差设计和层归一化操作，目的是为了防止梯度消失，加快收敛。</p><h4 id="残差设计"><a href="#残差设计" class="headerlink" title="残差设计"></a>残差设计</h4><p>我们在上一步得到了经过注意力矩阵加权之后的 $𝑉$， 也就是$𝐴𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛(𝑄, 𝐾, 𝑉)$，我们对它进行一下转置，使其和$X_{\text {embedding }}$ 的维度一致, 也就是 [𝑏𝑎𝑡𝑐ℎ 𝑠𝑖𝑧𝑒, 𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 𝑙𝑒𝑛𝑔𝑡ℎ, 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑑𝑖𝑚𝑒𝑛𝑠𝑖𝑜𝑛]，然后把他们加起来做残差连接，直接进行元素相加，因为他们的维度一致:</p><script type="math/tex; mode=display">X_{embedding} + Attention(Q, \ K, \ V)</script><p>在之后的运算里，每经过一个模块的运算，都要把运算之前的值和运算之后的值相加，从而得到残差连接，训练的时候可以使梯度直接走捷径反传到最初始层：</p><script type="math/tex; mode=display">X + SubLayer(X)</script><h4 id="层归一化"><a href="#层归一化" class="headerlink" title="层归一化"></a>层归一化</h4><p>Normalization有很多种，但是它们都有一个共同的目的，那就是把输入转化成均值为0方差为1的数据。我们在把数据送入激活函数之前进行normalization（归一化），因为我们不希望输入数据落在激活函数的饱和区。<br>说到 normalization，那就肯定得提到 Batch Normalization。BN的主要思想就是：在每一层的每一批数据上进行归一化。我们可能会对输入数据进行归一化，但是经过该网络层的作用后，我们的数据已经不再是归一化的了。随着这种情况的发展，数据的偏差越来越大，我的反向传播需要考虑到这些大的偏差，这就迫使我们只能使用较小的学习率来防止梯度消失或者梯度爆炸。<br>BN的具体做法就是对每一小批数据，在批这个方向上做归一化。如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/140869917-059093b6-d8c7-462e-9926-ecdb6101f898.png" alt="BN"><br>可以看到，右半边求均值是沿着数据 batch_size的方向进行的，其计算公式如下：</p><script type="math/tex; mode=display">BN(x_i)=\alpha × \frac{x_i-\mu_b}{\sqrt{\sigma^2_B+\epsilon}}+\beta</script><p>那么什么是 Layer normalization 呢？它也是归一化数据的一种方式，不过 LN 是在每一个样本上计算均值和方差，而不是BN那种在批方向计算均值和方差！<br><img src="https://user-images.githubusercontent.com/6218739/140870020-f7fb5f4e-d6de-4838-9dbb-e809e0f2fdec.png" alt="LN"><br>LN的公式为：</p><script type="math/tex; mode=display">LN(x_i)=\alpha × \frac{x_i-\mu_L}{\sqrt{\sigma^2_L+\epsilon}}+\beta</script><h3 id="前馈网络"><a href="#前馈网络" class="headerlink" title="前馈网络"></a>前馈网络</h3><p>前馈网络FeedForward，其实就是两层线性映射并用激活函数激活。<br>然后经过这个网络激活后，再经过一个残差连接和层归一化，即可输出。<br>直接看代码可能更直观：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionwiseFeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; A two-feed-forward-layer module &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_in, d_hid, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 两个fc层，对最后的512维度进行变换</span></span><br><span class="line">        self.w_1 = nn.Linear(d_in, d_hid) <span class="comment"># position-wise</span></span><br><span class="line">        self.w_2 = nn.Linear(d_hid, d_in) <span class="comment"># position-wise</span></span><br><span class="line">        self.layer_norm = nn.LayerNorm(d_in, eps=<span class="number">1e-6</span>)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        residual = x</span><br><span class="line"></span><br><span class="line">        x = self.w_2(F.relu(self.w_1(x)))</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x += residual</span><br><span class="line"></span><br><span class="line">        x = self.layer_norm(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p><h3 id="编码器总结"><a href="#编码器总结" class="headerlink" title="编码器总结"></a>编码器总结</h3><p>经过上面 3 个步骤，我们已经基本了解了 Encoder 的主要构成部分。<br>用一个更直观的图表示如下：<br><img src="https://user-images.githubusercontent.com/6218739/140872426-955ab9c0-842e-444c-947b-b6d9292a4fe1.png" alt="encoder"><br>文字描述为：<br>输入$x_1,x_2$经 self-attention 层之后变成$z_1,z_2$ ，然后和输入$x_1,x_2$进行残差连接，经过 LayerNorm 后输出给全连接层。全连接层也有一个残差连接和一个 LayerNorm，最后再输出给下一个 Encoder（每个 Encoder Block 中的 FeedForward 层权重都是共享的）<br>公式描述为：<br>（1）字向量与位置编码</p><script type="math/tex; mode=display">X = \text{Embedding-Lookup}(X) + \text{Positional-Encoding}</script><p>（2）自注意力机制</p><script type="math/tex; mode=display">\begin{align}Q &= \text{Linear}_q(X) = XW_{Q}\\K &= \text{Linear}_k(X) = XW_{K}\\V &= \text{Linear}_v(X) = XW_{V}\\X_{attention} &= \text{Self-Attention}(Q,K,V)\end{align}</script><p>（3）self-attention 残差连接与 Layer Normalization</p><script type="math/tex; mode=display">\begin{align}X_{attention} &= X + X_{attention}\\X_{attention} &= \text{LayerNorm}(X_{attention})\end{align}</script><p>（4）前馈网络FeedForward</p><script type="math/tex; mode=display">X_{hidden} = \text{Linear}(\text{ReLU}(\text{Linear}(X_{attention})))</script><p>（5）FeedForward 残差连接与 Layer Normalization</p><script type="math/tex; mode=display">\begin{align}X_{hidden} &= X_{attention} + X_{hidden}\\X_{hidden} &= \text{LayerNorm}(X_{hidden})\end{align}</script><p>其中：</p><script type="math/tex; mode=display">X_{hidden} \in \mathbb{R}^{batch\_size  \ * \  seq\_len. \  * \  embed\_dim}</script><h2 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h2><p>见<a href="https://wmathor.com/index.php/archives/1438/">原文</a>。<br>Decoder架构如下：<br><img src="https://user-images.githubusercontent.com/6218739/140873135-92be1693-5efe-4998-9c6b-9071a3c96fae.png" alt="decoder"><br>我们先从 HighLevel 的角度观察一下 Decoder 结构，从下到上依次是：<br>（1）Masked Multi-Head Self-Attention<br>（2）Multi-Head Encoder-Decoder Attention<br>（3）FeedForward Network<br>和 Encoder 一样，上面三个部分的每一个部分，都有一个残差连接，后接一个 Layer Normalization。Decoder 的中间部件并不复杂，大部分在前面 Encoder 里我们已经介绍过了，但是 Decoder 由于其特殊的功能，因此在训练时会涉及到一些细节。</p><h3 id="Masked-Self-Attention"><a href="#Masked-Self-Attention" class="headerlink" title="Masked Self-Attention"></a>Masked Self-Attention</h3><p>具体来说，传统 Seq2Seq 中 Decoder 使用的是 RNN 模型，因此在训练过程中输入$t$时刻的词，模型无论如何也看不到未来时刻的词，因为循环神经网络是时间驱动的，只有当$t$时刻运算结束了，才能看到$t+1$时刻的词。而 Transformer Decoder 抛弃了 RNN，改为 Self-Attention，由此就产生了一个问题，在训练过程中，整个 ground truth 都暴露在 Decoder 中，这显然是不对的，我们需要对 Decoder 的输入进行一些处理，该处理被称为 Mask。<br>举个例子，Decoder 的 ground truth 为 “start起始符号 I am fine”，我们将这个句子输入到 Decoder 中，经过 WordEmbedding 和 Positional Encoding 之后，将得到的矩阵做三次线性变换$W_Q,W_K,W_V$。然后进行 self-attention 操作，首先通过$\frac {Q\times K^T}{\sqrt {d_k}}$得到 Scaled Scores，接下来非常关键，我们要对 Scaled Scores 进行 Mask，举个例子，当我们输入 “I” 时，模型目前仅知道包括 “I” 在内之前所有字的信息，即 “start起始符号” 和 “I” 的信息，不应该让其知道 “I” 之后词的信息。道理很简单，我们做预测的时候是按照顺序一个字一个字的预测，怎么能这个字都没预测完，就已经知道后面字的信息了呢？Mask 非常简单，首先生成一个下三角全 0，上三角全为负无穷的矩阵，然后将其与 Scaled Scores 相加即可：<br><img src="https://user-images.githubusercontent.com/6218739/140873707-8ab175f3-df87-40bc-901f-62305d01b2cd.png" alt="mask"><br>之后再做 softmax，就能将 - inf 变为 0，得到的这个矩阵即为每个字之间的权重：<br><img src="https://user-images.githubusercontent.com/6218739/140873785-a14ea99e-09c5-4610-a97f-39039bd99ad6.png" alt="unmask"><br>Multi-Head Self-Attention 无非就是并行的对上述步骤多做几次，前面 Encoder 也介绍了，这里就不多赘述了。</p><h3 id="Masked-Encoder-Decoder-Attention"><a href="#Masked-Encoder-Decoder-Attention" class="headerlink" title="Masked Encoder-Decoder Attention"></a>Masked Encoder-Decoder Attention</h3><p>其实这一部分的计算流程和前面 Masked Self-Attention 很相似，结构也一摸一样，唯一不同的是这里的$K,V$为 Encoder 的输出（不然Encoder辛辛苦苦做的输出就没用了），$Q$为 Decoder 中 Masked Self-Attention 的输出。<br><img src="https://user-images.githubusercontent.com/6218739/140874351-f075901e-7869-4f2d-8c03-c94b12116938.png" alt="e-d"></p><h1 id="Vision-Transformer"><a href="#Vision-Transformer" class="headerlink" title="Vision Transformer"></a>Vision Transformer</h1><p>使用Transformer进行视觉任务的研究已经成了一个新的热点，大家为了更低的模型复杂度以及训练的效率，都在研究如何将这一技术应用在视觉任务上。<br>通常来说，在所有的关于Transformer的论文以及工作中，有两个比较大的架构，其中一个就是传统的CNNs加Transformer组合而成的结构，另一种是纯粹的Transformers。<br>ViT使用的就是纯粹的Transformer去完成视觉任务，也就是说，它没有使用任何的CNNs。这也是它的价值所在，谷歌大脑团队在几乎没有修改任何基于NLP的Transformer的结构基础之上，只是将输入进行了一个适配，将图片切分成许多的小格，然后将这些作为序列输入到模型，最终完成了分类任务，并且效果可以直追基于CNNs的SOTA。<br>ViT的思路很简单：直接把图像分成固定大小的patchs，然后通过线性变换得到patch embedding，这就类比NLP的words和word embedding，由于transformer的输入就是a sequence of token embeddings，所以将图像的patch embeddings送入transformer后就能够进行特征提取从而分类了。ViT模型原理如下图所示，其实ViT模型只是用了transformer的Encoder来提取特征（原始的transformer还有decoder部分，用于实现sequence to sequence，比如机器翻译）。<br><img src="https://user-images.githubusercontent.com/6218739/140877989-64b07f86-fe4f-45df-8f4c-a30a11391cb0.png" alt="ViT"></p><p>ViT架构相对于原始Transformer，有一些特殊处理：</p><h2 id="图像分块嵌入"><a href="#图像分块嵌入" class="headerlink" title="图像分块嵌入"></a>图像分块嵌入</h2><p>考虑到在Transformer结构中，输入是一个二维的矩阵，矩阵的形状可以表示为$(N,D)$，其中$N$是sequence的长度，而$D$是sequence中每个向量的维度。因此，在ViT算法中，首先需要设法将$H \times W \times C$的三维图像转化为$(N,D)$的二维输入。<br>ViT中的具体实现方式为：将$H \times W \times C$的图像，变为一个$N \times (P^2 \times C)$的序列。这个序列可以看作是一系列展平的图像块，也就是将图像切分成小块后，再将其展平。该序列中一共包含了$N=HW/P^2$个图像块，每个图像块的维度则是$(P^2\times C)$。其中$P$是图像块的大小，$C$是通道数量。经过如上变换，就可以将$N$视为sequence的长度了。但是，此时每个图像块的维度是$(P^2\times C)$，而我们实际需要的向量维度是$D$，因此我们还需要对图像块进行 Embedding。这里 Embedding 的方式非常简单，只需要对每个$(P^2 \times C)$的图像块做一个线性变换，将维度压缩为$D$即可。</p><h2 id="Class-Token"><a href="#Class-Token" class="headerlink" title="Class Token"></a>Class Token</h2><p>ViT借鉴BERT增加了一个特殊的class token。transformer的encoder输入是a sequence patch embeddings，输出也是同样长度的a sequence patch features，但图像分类最后需要获取image feature，简单的策略是采用pooling，比如求patch features的平均来获取image feature，但是ViT并没有采用类似的pooling策略，而是直接增加一个特殊的class token，其最后输出的特征加一个linear classifier就可以实现对图像的分类（ViT的pre-training时是接一个MLP head），所以输入ViT的sequence长度是$N+1$。<br>class token对应的embedding在训练时随机初始化，然后通过训练得到。</p><h2 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h2><p>按照 Transformer 结构中的位置编码习惯，这个工作也使用了位置编码。不同的是，ViT 中的位置编码没有采用原版 Transformer 中的 sin-cos编码，而是直接设置为可学习的 Positional Encoding。对训练好的 Positional Encoding 进行可视化，可以看到，位置越接近，往往具有更相似的位置编码。此外，出现了行列结构，同一行/列中的 patch 具有相似的位置编码。<br><img src="https://user-images.githubusercontent.com/6218739/140884681-87fb368e-87a6-4e6a-a9df-3ea19a31012b.png" alt="vit-pos"></p>]]></content>
    
    
    <summary type="html">参考文献
保姆级教程：图解Transformer
Transformer模型详解
Transformer 详解
盘点 | 2021年paper大热的Transformer (ViT)
“未来”的经典之作ViT：transformer is all you need!
ViT( Vision Transformer)

简介
Attention Is All You Need是一篇Google于2017年提出的将Attention思想发挥到极致的论文。这篇论文中提出一个全新的模型，叫 Transformer，抛弃了以往深度学习任务里面使用到的 CNN 和 RNN ，目前大热的Bert、GPT和D</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="Transformer" scheme="http://qixinbo.github.io/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>Python爱浏览器，但浏览器不爱它：如何让Python运行在浏览器上</title>
    <link href="http://qixinbo.github.io/2021/11/05/python-on-web/"/>
    <id>http://qixinbo.github.io/2021/11/05/python-on-web/</id>
    <published>2021-11-04T16:00:00.000Z</published>
    <updated>2021-11-05T08:37:11.546Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>一直以来，网页浏览器编程所用的编程语言主力就是JavaScript，浏览器就是一个JavaScript的原生解释器。<br>那么Python能不能直接运行在浏览器上呢，或者说Python能不能作为浏览器开发的编程语言？<br>本文对这一问题做了详细的调研，结果可以用一句话总结：可以，但很鸡肋。</p><h1 id="可用方案"><a href="#可用方案" class="headerlink" title="可用方案"></a>可用方案</h1><p>调研过程中，发现了很多有趣的解决方案，总结起来可以有两类：<br>（1）将Python语言编译成JavaScript<br>即将现成的Python语言翻译成JavaScript，然后在浏览器网页中运行，比如：<br><a href="https://brython.info/index.html">Brython</a><br><a href="https://skulpt.org/">Skulpt</a><br><a href="https://www.transcrypt.org/">Transcrypt</a><br>（2）在浏览器中内置Python解释器<br>即将Python解释器放在浏览器中，这样就能直接运行Python代码，比如：<br><a href="https://pyodide.org/en/stable/">Pyodide</a><br><a href="https://pypyjs.org/">PyPy.js</a></p><p>我觉得这两类各自的重点不一样：<br>第一种是为了用Python来代替JavaScript，即用Python操作网页DOM（Document Object Model）元素，让不熟悉JS的编程人员也能用Python来做一个简单的动态交互网页；<br>第二种，比如Pyodide，它的野心很大，即将Python的科学计算生态搬到浏览器中，比如numpy、scipy、matplotlib等科学计算常用的函数库直接放进浏览器中，而不是常见的比如作为浏览器服务器后端来调用。这样实现的效果就是不需要部署服务器，直接在浏览器中做复杂的函数计算，并反映到网页上。<br>下面详细介绍一下两类实现中的代表：Brython和Pyodide。</p><h1 id="Brython"><a href="#Brython" class="headerlink" title="Brython"></a>Brython</h1><p>先看一下用Brython写的Hello World：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;meta name=<span class="string">&quot;description&quot;</span> content=<span class="string">&quot;Hello world demo written in Brython www.brython.info&quot;</span>&gt;</span><br><span class="line">&lt;meta name=<span class="string">&quot;keywords&quot;</span> content=<span class="string">&quot;Python,Brython&quot;</span>&gt;</span><br><span class="line">&lt;meta charset=<span class="string">&quot;iso-8859-1&quot;</span>&gt;</span><br><span class="line">&lt;title&gt;Hello world&lt;/title&gt;</span><br><span class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;/src/brython.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">&lt;script type=&quot;text/python&quot; src=&quot;show_source.py&quot;&gt;&lt;/script&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line"></span><br><span class="line">// ------------注意看这一块-------------</span><br><span class="line">&lt;body onload=<span class="string">&quot;brython(1)&quot;</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">&quot;text/python&quot;</span>&gt;</span><br><span class="line"><span class="keyword">from</span> browser <span class="keyword">import</span> document, alert</span><br><span class="line"><span class="keyword">from</span> browser.widgets.dialog <span class="keyword">import</span> InfoDialog</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">echo</span>(<span class="params">ev</span>):</span></span><br><span class="line">    InfoDialog(<span class="string">&quot;Hello&quot;</span>, <span class="string">f&quot;Hello <span class="subst">&#123;document[<span class="string">&#x27;zone&#x27;</span>].value&#125;</span> !&quot;</span>)</span><br><span class="line"></span><br><span class="line">document[<span class="string">&quot;test&quot;</span>].bind(<span class="string">&quot;click&quot;</span>, echo)</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">// ------------注意看结束-------------</span><br><span class="line"></span><br><span class="line">&lt;p&gt;Your name <span class="keyword">is</span> : &lt;<span class="built_in">input</span> <span class="built_in">id</span>=<span class="string">&quot;zone&quot;</span> autocomplete=<span class="string">&quot;off&quot;</span>&gt;</span><br><span class="line">&lt;button id=&quot;test&quot;&gt;click !&lt;/button&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line"></span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><br>从上面片段很显而易见，Brython就是用Python来替代JavaScript的写法，比如获取网页上的元素并改变其值。<br>如果想快速开发一个动态网页，同时不懂JavaScript，可以使用Brython来写。<br>但注意Brython没法使用Python的整个生态，只能使用部分标准库，比如sys。</p><h1 id="Pyodide"><a href="#Pyodide" class="headerlink" title="Pyodide"></a>Pyodide</h1><p>简言之，Pyodide就是在浏览器中运行Python，且能调用Python的数值计算库。<br>Pyodide解决的痛点是无法在浏览器中进行科学计算：<br>（1）一方面，现在越来越多的软件都Web化、浏览器化。而浏览器的通用编程语言是JavaScript，但其没有成熟的数据科学处理库，也缺乏一些数值计算很有用的功能和数据结构。<br>（2）另一方面，Python具有成熟且活跃的科学计算生态，比如基本上所有函数库都依赖的numpy数据结构，但其无法在浏览器运行。<br>Pyodide 项目则是通过将现有的 CPython 解释器编译为 WebAssembly 并在浏览器的 JavaScript 环境中运行这个编译出来的二进制文件，这提供了一种在浏览器中运行 Python 的方法。</p><p>Pyodide有一些非常炫的功能点：</p><h2 id="在Python和JavaScript之间进行交互"><a href="#在Python和JavaScript之间进行交互" class="headerlink" title="在Python和JavaScript之间进行交互"></a>在Python和JavaScript之间进行交互</h2><p>如果所有Pyodide能做的就只是运行Python代码并写出到标准输出上，它将会增长成为一个不错的很酷的技巧，但是不会成为一个用于实际工作的实用工具。真正的力量源于它与浏览器API以及其它运行在浏览器中的JavaScript库交互的能力。由于我们已经将Python解释器编译为了WebAssembly，它也与JavaScript端具有深度的交互。<br>Pyodide会在许多Python与JavaScript之间的内建数据类型之间进行隐式转换。其中一些转换时很直接明显的，但如往常一样，那就是很有趣的极端情况。<br><img src="https://user-images.githubusercontent.com/6218739/140268286-c89f066f-72fc-4cc9-8709-c95fc6d98096.png" alt="data"></p><h2 id="访问Web-API和DOM"><a href="#访问Web-API和DOM" class="headerlink" title="访问Web API和DOM"></a>访问Web API和DOM</h2><p>可以通过以下方式获得Web页面上的文档对象模型DOM：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> js <span class="keyword">import</span> document</span><br></pre></td></tr></table></figure><br>这会将document对象作为一个代理从JavaScript端导入到Python端。你可以开始从Python中对其调用方法:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">document.getElementById(<span class="string">&quot;myElement&quot;</span>)</span><br></pre></td></tr></table></figure></p><h2 id="多维数组"><a href="#多维数组" class="headerlink" title="多维数组"></a>多维数组</h2><p>在Python中， NumPy 数组是最常用的多维数组的实现。JavaScript具有TypedArrays，其仅含有一个单一的数值类型，但是是一维的，因此需要在其之上构建多维索引。<br>由于实际上这些数组可能会非常大，我们不想在语言运行时间拷贝它们。那不仅仅会花相当长的时间，而且在内存中同时保留两个拷贝将会加重浏览器所具有的被限制的内存的负担。<br>幸运的是，我们可以不用拷贝来共享数据。多维数组通常是用少量用于描述值类型和数组形状及内存分布的元数据来实现的。数据本身是从元数据中通过指针访问的另一个内存区域。该内存处于一个叫作“WebAssembly堆”的区域，这带来一个优势，因为其可以从JavaScript和Python中同时访问。我们可以简单地在语言之间拷贝元数据(其本身非常小)，并保持指针指向WebAssembly堆中的数据。<br><img src="https://user-images.githubusercontent.com/6218739/140268781-ab70c08a-1821-4a06-b7de-d65633d54b31.png" alt="numpy"></p><h2 id="实时交互可视化"><a href="#实时交互可视化" class="headerlink" title="实时交互可视化"></a>实时交互可视化</h2><p>在浏览器中进行数据科学计算相比于如Jupyter一样在远程内核中进行计算的一大优势就是，交互式可视化不用通过网络来传输数据并重新处理和展示这些数据。这很大程度地减少了延迟—用户移动鼠标的时刻与屏幕更新并显示图案的时刻之间的间隔时间。</p><p>要使得其能工作需要上面描述到的所有的技术片段能够很好地协同工作。我们使用matplotlib来看一下用于展示正态分布如何工作的交互性示例。首先，通过Python的Numpy产生随机数据。接下来，Matplotlib接管该数据，并使用内建的软件渲染器来将其绘出。它使用Pyodide对零拷贝共享数组的支持来将像素回馈给JavaScript端，在这里数据最终被渲染为HTML的画布。然后浏览器接管工作，将像素显示到屏幕上。用来支持交互性操作的鼠标和键盘事件通过从Web浏览器到Python的回调函数的调用来处理。<br><img src="https://user-images.githubusercontent.com/6218739/140269007-b21d4a82-4def-4581-8631-331f570917e4.gif" alt="matplotlib-interacting-with-plots"></p><p>但需要注意的是Pyodide有两个缺点：<br>（1）包体积巨大，在浏览器中第一次访问内含Pyodide的网页时，会下载相应的python包，最基础的pyodide也有22MB大小，更不用说如果有额外的包，比如matplotlib，会更加巨大，导致长时间加载不出来页面；<br>（2）对于Python日渐火热的深度学习生态，Pyodide也没法直接利用，毕竟那些函数库会更大。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>JavaScript作为浏览器的原住民，其在基于网页的应用开发中的地位不可撼动，虽然Python能通过各种方式部分取代它的功能，但目前还很不成熟，开发简易功能尚可，但重度和高阶应用则基本不可能。期待以后的技术发展能将浏览器和Python结合得更加紧密。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://python.freelycode.com/contribution/detail/1567">在浏览器中用Python做数据科学：Pyodide</a><br><a href="https://jishuin.proginn.com/p/763bfbd5bd1e">LWN: Pyodide - 浏览器中的Python！</a><br><a href="https://hacks.mozilla.org/2019/04/pyodide-bringing-the-scientific-python-stack-to-the-browser/">Pyodide: Bringing the scientific Python stack to the browser</a><br><a href="https://www.bilibili.com/video/BV1X541187XK">把python装进浏览器，需要几个步骤？</a><br><a href="https://www.youtube.com/watch?v=iUqVgykaF-k&amp;t=91s">Iodide and Pyodide: Bringing Data Science Computation to the Web Browser - Michael Droettboom</a></p>]]></content>
    
    
    <summary type="html">简介
一直以来，网页浏览器编程所用的编程语言主力就是JavaScript，浏览器就是一个JavaScript的原生解释器。
那么Python能不能直接运行在浏览器上呢，或者说Python能不能作为浏览器开发的编程语言？
本文对这一问题做了详细的调研，结果可以用一句话总结：可以，但很鸡肋。

可用方案
调研过程中，发现了很多有趣的解决方案，总结起来可以有两类：
（1）将Python语言编译成JavaScript
即将现成的Python语言翻译成JavaScript，然后在浏览器网页中运行，比如：
Brython
Skulpt
Transcrypt
（2）在浏览器中内置Python解释器
即将Py</summary>
    
    
    
    <category term="digitalization" scheme="http://qixinbo.github.io/categories/digitalization/"/>
    
    
    <category term="GUI" scheme="http://qixinbo.github.io/tags/GUI/"/>
    
  </entry>
  
  <entry>
    <title>经典图像特征点提取SIFT算法详解</title>
    <link href="http://qixinbo.github.io/2021/10/26/sift/"/>
    <id>http://qixinbo.github.io/2021/10/26/sift/</id>
    <published>2021-10-25T16:00:00.000Z</published>
    <updated>2021-10-29T02:32:54.361Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://liuchang.men/2020/02/24/SIFT%E7%AE%97%E6%B3%95%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/">SIFT算法深入理解</a><br><a href="https://blog.csdn.net/lhanchao/article/details/52345845">特征点匹配——SIFT算法详解</a><br><a href="https://www.cnblogs.com/wj-1314/p/11981974.html">图像金字塔（高斯金字塔，拉普拉斯金字塔，图像缩放resize函数）</a><br><a href="https://blog.csdn.net/zddblog/article/details/7521424">SIFT算法详解</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>SIFT（Scale Invariant Feature Transform），尺度不变特征变换匹配算法，是由David G. Lowe在1999年（《Object Recognition from Local Scale-Invariant Features》）提出的高效区域检测算法，在2004年（《Distinctive Image Features from Scale-Invariant Keypoints》）得以完善。<br>SIFT算子是把图像中检测到的特征点用一个128维的特征向量进行描述，因此一幅图像经过SIFT算法后表示为一个128维的特征向量集。<br>SIFT算法的实质是在不同的尺度空间上查找关键点(特征点)，并计算出关键点的方向。SIFT所查找到的关键点是一些十分突出，不会因光照、仿射变换和噪音等因素而变化的点，如角点、边缘点、暗区的亮点及亮区的暗点等。<br>SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，对于光照、仿射和投影变换也有一定的不变性，是非常稳定的局部特征，现在应用很广泛。</p><p>Lowe将SIFT算法分解为如下四步：</p><ol><li>尺度空间极值检测：搜索所有尺度上的图像位置。通过高斯微分函数来识别潜在的对于尺度和旋转不变的兴趣点。</li><li>特征点精确定位：在每个候选的位置上，通过一个拟合精细的模型来确定位置和尺度。特征点的选择依据于它们的稳定程度。</li><li>方向确定：基于图像局部的梯度方向，分配给每个特征点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而提供对于这些变换的不变性。</li><li>特征点描述：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变化。</li></ol><h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h1><h2 id="尺度空间极值检测"><a href="#尺度空间极值检测" class="headerlink" title="尺度空间极值检测"></a>尺度空间极值检测</h2><h3 id="尺度空间理论"><a href="#尺度空间理论" class="headerlink" title="尺度空间理论"></a>尺度空间理论</h3><p>尺度越大图像越模糊。<br>用机器视觉系统分析未知场景时，计算机并不预先知道图像中物体的尺度。我们需要同时考虑图像在多尺度下的描述，获知感兴趣物体的最佳尺度。另外如果不同的尺度下都有同样的关键点，那么在不同的尺度的输入图像下就都可以检测出来关键点匹配，也就是尺度不变性。 图像的尺度空间表达就是图像在所有尺度下的描述。</p><h3 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h3><p>高斯核是唯一可以产生多尺度空间的核。<br>一个图像的尺度空间$L(x,y,\sigma)$，定义为原始图像$I(x,y)$与一个可变尺度的2维高斯函数$G(x,y,\sigma)$的卷积运算。<br>二维空间高斯函数：</p><script type="math/tex; mode=display">G(x_i,y_i,\sigma)=\frac{1}{2\pi\sigma^2}exp\lgroup-\frac{(x-x_i)^2+(y-y_i)^2}{2\sigma^2}\rgroup</script><p>那么尺度空间就是：</p><script type="math/tex; mode=display">L(x,y,\sigma)=G(x,y,\sigma)*I(x,y)</script><p>在二维空间中，这个公式生成的曲面的等高线是从中心开始呈正态分布的同心圆。分布不为零的像素组成的卷积矩阵与原始图像做变换。每个像素的值都是周围相邻像素值的高斯加权平均。中心像素的值有最大的高斯分布值，所以有最大的权重，相邻像素随着距离中心像素越来越远，其权重也越来越小。这样进行模糊处理比其它的均衡模糊滤波器更高地保留了边缘效果。$\sigma$越大，中心像素的权重与周围像素就会相对越小，加权平均后就会越模糊；反之，$\sigma$越小，中心像素权重相对越大，当$\sigma=0$时，就是原图的样子，相当于周围像素对新图没有贡献。换句话说，大尺度对应于图像的概貌特征，小尺度对应于图像的细节特征。<br>理论上来讲，图像中每点的分布都不为零，这也就是说每个像素的计算都需要包含整幅图像。在实际应用中，在计算高斯函数的离散近似时，在大概$3\sigma$距离之外的像素都可以看作不起作用，这些像素的计算也就可以忽略。通常，图像处理程序只需要计算$(6\sigma+1)\cdot(6\sigma+1)$的矩阵就可以保证相关像素影响。</p><h3 id="金字塔多分辨率"><a href="#金字塔多分辨率" class="headerlink" title="金字塔多分辨率"></a>金字塔多分辨率</h3><p>与多尺度空间相对的，金字塔是早期图像多尺度的表示方式。图像金字塔化一般两个步骤：<br>(1) 使用低通滤波器（LPF）平滑图像；<br>(2) 平滑图像降采样（通常$\frac{1}{2}$）<br>该方式能得到系列尺寸缩小的图片。</p><p>尺度空间表达和金字塔分辨率表达的明显区别有：<br>（1）尺度空间表达是由不同高斯核平滑卷积得到的，在所有尺度上分辨率相同；<br>（2）金字塔多分辨率表达每层分辨率减少固定比率。<br>因此，金字塔多分辨率生成快，空间少，但局部特征描述单一；多尺度空间的图片局部特征可以在不同尺度描述，但随尺度参数增加会增加冗余信息。</p><h3 id="高斯金字塔"><a href="#高斯金字塔" class="headerlink" title="高斯金字塔"></a>高斯金字塔</h3><p>高斯金字塔是最基本的图像塔。原理：首先将原图像作为最底层图像 level0（高斯金字塔的第0层），利用高斯核（$5*5$）对其进行卷积，然后对卷积后的图像进行下采样（去除偶数行和列）得到上一层图像G1，将此图像作为输入，重复卷积和下采样操作得到更上一层的图像，反复迭代多次，形成一个金字塔形的图像数据结构，即高斯金字塔。<br>高斯金字塔是在sift算子中提出来的概念，首先高斯金字塔并不是一个金字塔，而是由很多组（Octave）金字塔构成，并且每组金字塔都包含若干层（Interval），即在同一组的金字塔中，使用不同$\sigma$进行高斯模糊，然后再不同组的金字塔中，使用下采样，获得不同分辨率的图像。<br>高斯金字塔的构建过程：<br>（1）先将原图像扩大一倍之后作为高斯金字塔的第1组第1层，将第1组第1层图像经高斯卷积（高斯平滑或称高斯滤波）之后作为第1组金字塔的第2层。对于参数$\sigma$，在SIFT算子中取的是固定值 1.6；<br>（2）将$\sigma$乘以一个比例系数k，等到一个新的平滑因子$\sigma = k *\sigma$，用它来平滑第1组第2层图像，结果图像作为第3层。<br>（3）如此重复，最后得到L层图像，在同一组中，每一层图像的尺寸都是一样的，只是平滑系数不一样。它们对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。<br>（4）将第1组倒数第三层图像作为比例因子为2的降采样，得到的图像作为第2组的第1层，然后对第2组的第1层图像作平滑因子为 $\sigma$的高斯平滑，得到第2组的第2层，就像步骤2中一样，如此得到第2组的L层图像，同组内它们的尺寸是一样的，对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。但是在尺寸方面第2组是第1组图像的一半。<br>这样反复执行，就可以得到一共O组，每组L层，共计$O*L$个图像，这些图像一起就构成了高斯金字塔。<br>在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子$\sigma$是前一层图像平滑因子的$k$倍；<br>在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半。</p><h3 id="高斯拉普拉斯金字塔"><a href="#高斯拉普拉斯金字塔" class="headerlink" title="高斯拉普拉斯金字塔"></a>高斯拉普拉斯金字塔</h3><p>LoG（Laplace of Gaussian）是对高斯函数进行拉普拉斯变换：</p><script type="math/tex; mode=display">L(x,y,\sigma)=\frac{\partial^2G}{\partial x^2} + \frac{\partial^2G}{\partial y^2}</script><p>拉普拉斯金字塔用于重建图形，也就是预测残差，对图像进行最大程度的还原。比如一幅小图像重建为一幅大图。原理：用高斯金字塔的每一层图像减去其上一层图像上采样并高斯卷积之后的预测图像，得到一系列的差值图像，即为Laplacian分解图像。<br>LoG第$i$层的数学定义：</p><script type="math/tex; mode=display">\begin{align}L_i &= G_i-Up(G_{i+1})\otimes g \\&=G_i - PyrUp(G_{i+1}) \\\end{align}</script><p>式中，$G_i$表示高斯金字塔中第$i$层图像。也就是说，拉普拉斯金字塔是通过高斯金字塔图像减去先缩小（即上一层图像）后再放大（即上采样操作）并高斯卷积后的图像的一系列图像构成的。</p><h3 id="高斯差分金字塔"><a href="#高斯差分金字塔" class="headerlink" title="高斯差分金字塔"></a>高斯差分金字塔</h3><p>LoG的主要缺点是需要求二阶导，计算较复杂，因此我们就想用别的算子去近似它。DoG（Difference of Gaussian），相当于对LoG的近似计算，SIFT算法中建议某一尺度的特征检测，可以通过两个相邻高斯尺度空间的图像相减，得到DoG的响应值图像。DoG和LoG的关系如下述所示： </p><script type="math/tex; mode=display">\sigma\nabla^2G = \frac{\partial G}{\partial\sigma} \approx \frac{G(x,y,k\sigma) - G(x,y,\sigma)}{k\sigma - \sigma}</script><p>因此，有：</p><script type="math/tex; mode=display">G(x,y,k\sigma) - G(x,y,y\sigma) \approx (k-1)\sigma^2\nabla^2G</script><p>而$\sigma^2\nabla^2G$正是尺度归一化算子的表达形式。在所有的尺度中$k-1$是一个常数，当$k$趋近于1的时候误差趋近于0，但实际上这种误差对于极值的位置检测并没有什么影响（不过前人的实验证明LoG提取的特征稳定性最强）。<br><img src="https://user-images.githubusercontent.com/6218739/138830197-52b6d1f1-ffb1-474e-abfa-d204cace5c57.png" alt="dog"></p><h3 id="空间极值点检测（关键点的初步探查）"><a href="#空间极值点检测（关键点的初步探查）" class="headerlink" title="空间极值点检测（关键点的初步探查）"></a>空间极值点检测（关键点的初步探查）</h3><p>SIFT关键点是由DOG空间的局部极值点组成的，关键点的初步探查是通过同一组内各DoG相邻两层图像之间比较完成的。<br>极值点定义：每一个像素点与它所有相邻点比较，当其大于（或小于）它的图像域和尺度域的所有相邻点时，即为极值点。<br>为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。<br><img src="https://user-images.githubusercontent.com/6218739/138831439-2566a884-59cf-45df-a11a-7aa319584b64.png" alt="peak-detect"><br>由于要在相邻尺度进行比较，那么对于高斯差分金子塔中的每一组的所有层，只能在中间两层中进行两个尺度的极值点检测，其它尺度则只能在不同组中进行。为了在每组中检测$S$个尺度的极值点，则DOG金字塔每组需$S+2$层图像，而DOG金字塔由高斯金字塔相邻两层相减得到，则高斯金字塔每组需$S+3$层图像，实际计算时S在3到5之间。<br>当然这样产生的极值点并不全都是稳定的特征点，因为某些极值点响应较弱，而且DOG算子会产生较强的边缘响应。</p><p>到这里，总结一下，构建DOG尺度空间金字塔的三个重要参数是：尺度$\sigma$、组(octave)数$O$和组内层数$S$。</p><h2 id="特征点点精确定位"><a href="#特征点点精确定位" class="headerlink" title="特征点点精确定位"></a>特征点点精确定位</h2><p>计算机中存储的图像数据是离散的，而我们之前找到的极值点也就是离散空间中的极值点，但是离散空间中的极值点并不是真实的连续空间中的极值点。所以需要对DoG空间进行拟合处理，以找到极值点的精确位置和尺度。另外，我们还需要去除那些在边缘位置的极值点，以提高关键点的稳定性。</p><h3 id="精确定位"><a href="#精确定位" class="headerlink" title="精确定位"></a>精确定位</h3><p><img src="https://user-images.githubusercontent.com/6218739/138843995-feea3390-c7fd-4f40-8fb1-88660ed06b1d.png" alt="fit"><br>利用已知的离散空间点插值得到连续空间极值点的方法叫做子像元插值。<br>在Lowe的论文中，使用的是泰勒展开式作为拟合函数。<br>通过上步的极值点检测，我们得到的极值点是一个三维向量，包括它所在的尺度$\sigma$以及所在尺度图像中的位置坐标$(x, y)$。<br>设$X_0 = (x_0,y_0,\sigma_0)$，则泰勒展开的矩阵表示为：</p><script type="math/tex; mode=display">f(\left[\begin{matrix}x\\y\\\sigma\end{matrix}\right]) \approx f(\left[\begin{matrix}x_0\\y_0\\\sigma_0\end{matrix}\right]) + [\frac{\partial f}{\partial x}    \frac{\partial f}{\partial y} \frac{\partial f}{\partial \sigma}]\left(\left[\begin{matrix}x\\y\\\sigma\end{matrix}\right]-\left[\begin{matrix}x_0\\y_0\\\sigma_0\end{matrix}\right]\right) + \\\frac{1}{2}\left(\left[x \quad y \quad \sigma\right] - \left[x_0 \quad y_0 \quad \sigma_0\right]\right)\left[\begin{matrix}\frac{\partial^2 f}{\partial x \partial x} & \frac{\partial^2 f}{\partial x \partial y} & \frac{\partial^2 f}{\partial x \partial \sigma} \\ \frac{\partial^2 f}{\partial x \partial y}&\frac{\partial^2 f}{\partial y \partial y}&\frac{\partial^2 f}{\partial y \partial \sigma}\\\frac{\partial^2 f}{\partial x \partial \sigma}&\frac{\partial^2 f}{\partial y \partial \sigma}&\frac{\partial^2 f}{\partial \sigma \partial \sigma}\end{matrix}\right]\left(\left[\begin{matrix}x\\y\\\sigma\end{matrix}\right]-\left[\begin{matrix}x_0\\y_0\\\sigma_0\end{matrix}\right]\right)</script><p>若写成矢量形式，则为 ：</p><script type="math/tex; mode=display">f(X) = f(X_0）+\frac{\partial f^T}{\partial X}(X- X_0)+\frac{1}{2}(X-X_0)^T\frac{\partial^2 f}{\partial X^2}(X-X_0)</script><p>在这里$X_0$表示离散的插值中心，$X$表示拟合后连续空间的插值点坐标，则设$\hat{X} = X - X_0$，表示偏移量，带入上式，另求得的导数为0（求一阶导等于0得到的点就是极值点），则有 </p><script type="math/tex; mode=display">\hat{X} = -\frac{\partial^2 f^{-1}}{\partial X^2}\frac{\partial f}{\partial X}</script><p>只要上式中得到的偏移量大于0.5，则认为偏移量过大，需要把位置移动到拟合后的新位置，继续进行迭代求偏移量，若迭代过一定次数后偏移量仍然大于0.5，则抛弃该点。如果迭代过程中有偏移量小于0.5，则停止迭代。 </p><p>把该极值点带入到原公式中，则得到极值点所在的函数值：</p><script type="math/tex; mode=display">f(\hat{X}) = f(X_0) + \frac{1}{2}\frac{\partial f^T}{\partial X} \hat{X}</script><p>如果上式中得到的$f(\hat{X})$过小，即其响应值过小，这样的点易受噪声的干扰而变得不稳定，所以也要被删除，Lowe论文中阈值为0.03（设灰度值为0~1）。</p><h3 id="消除边缘响应"><a href="#消除边缘响应" class="headerlink" title="消除边缘响应"></a>消除边缘响应</h3><p>有些极值点的位置是在图像的边缘位置的，因为图像的边缘点很难定位，同时也容易受到噪声的干扰，我们把这些点看做是不稳定的极值点，需要进行去除。<br>由于图像中的物体的边缘位置的点的主曲率一般会比较高，因此我们可以通过主曲率来判断该点是否在物体的边缘位置。<br>某像素点位置处的主曲率可以由二维的Hessian矩阵计算得到：</p><script type="math/tex; mode=display">H = \left[\begin{matrix}D_{xx}(x,y)&D_{xy}(x,y)\\D_{xy}(x,y)&D_{yy}(x,y)\end{matrix}\right]</script><p>设该矩阵的两个特征值分别为$\alpha$和$\beta$，其中$\alpha = \gamma\beta$，有如下公式：</p><script type="math/tex; mode=display">Tr(H) = \alpha +\beta</script><p>和</p><script type="math/tex; mode=display">Det(H) = \alpha\beta</script><p>其中$Tr(H)$表示矩阵的迹，$Det(H)$表示的矩阵的行列式。<br>首先需要去除行列式为负的点。接下来需要去掉主曲率比较大的点，Lowe中使用如下判断规则：</p><script type="math/tex; mode=display">\frac{Tr(H)^2}{Det(H)} = \frac{(\gamma\beta+\beta)^2}{\gamma\beta^2} = \frac{(\gamma+1)^2}{\gamma}</script><p>这里$\gamma$越大，则表示该点越有可能在边缘，因此要检查主曲率是否超过一定的阈值$\gamma_0$，只需要判断：</p><script type="math/tex; mode=display">\frac{Tr(H)^2}{Det(H)} < \frac{(\gamma_0+1)^2}{\gamma_0}</script><p>Lowe论文中阈值为10。 </p><h2 id="特征点方向确定"><a href="#特征点方向确定" class="headerlink" title="特征点方向确定"></a>特征点方向确定</h2><p>上面我们已经找到了特征点。为了实现图像旋转不变性，需要根据检测到的特征点局部图像结构为特征点方向赋值。我们使用图像的梯度直方图法求特征点局部结构的稳定方向。</p><h3 id="梯度方向和幅值"><a href="#梯度方向和幅值" class="headerlink" title="梯度方向和幅值"></a>梯度方向和幅值</h3><p>在前文中，精确定位关键点后也找到特征点的尺度值$\sigma$，根据这一尺度值，得到最接近这一尺度值的高斯图像： </p><script type="math/tex; mode=display">L(x,y) = G(x,y,\sigma)\otimes I(x,y)</script><p>使用有限差分，计算以特征点为中心，以$3\times1.5\sigma$为半径的区域内图像梯度的幅值$m(x,y)$和幅角$\theta(x,y)$，公式如下： </p><script type="math/tex; mode=display">\begin{align}m(x,y) &= \sqrt{(L(x+1, y) - L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2} \\\theta(x,y)&=arctan(\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)})\end{align}</script><h3 id="梯度直方图"><a href="#梯度直方图" class="headerlink" title="梯度直方图"></a>梯度直方图</h3><p>在完成特征点邻域内高斯图像梯度计算后，使用直方图统计邻域内像素对应的梯度方向和幅值。<br>梯度方向直方图的横轴是梯度方向角，纵轴是梯度方向角对应的梯度幅值累加值（(为简化，图中只画了八个方向的直方图)）。梯度方向直方图将0°~360°的范围分为36个柱，每10°为一个柱。可看作一定区域内的图像像素点对特征点方向生成所作的贡献。<br><img src="https://user-images.githubusercontent.com/6218739/138852341-c6e124e1-3cad-43e6-9b1d-af995d9a7bb6.png" alt="hist"><br>在计算直方图时，每个加入直方图的采样点都使用圆形高斯函数函数进行了加权处理，也就是进行高斯平滑。Lowe建议子区域的像素的梯度大小$\sigma=0.5d$的高斯加权计算。这主要是因为SIFT算法只考虑了尺度和旋转不变形，没有考虑仿射不变性。通过高斯平滑，可以使关键点附近的梯度幅值有较大权重，从而部分弥补没考虑仿射不变形产生的特征点不稳定。<br>通常离散的梯度直方图要进行插值拟合处理，以求取更精确的方向角度值。</p><h3 id="特征点方向"><a href="#特征点方向" class="headerlink" title="特征点方向"></a>特征点方向</h3><p>直方图峰值代表该特征点处邻域内图像梯度的主方向，也就是该特征点的主方向。在梯度方向直方图中，当存在另一个相当于主峰值$80\%$能量的峰值时，则将这个方向认为是该特征点的辅方向。<br>所以一个特征点可能检测得到多个方向，这可以增强匹配的鲁棒性。Lowe的论文指出大概有$15\%$特征点具有多方向，但这些点对匹配的稳定性至为关键。<br>获得图像特征点主方向后，每个特征点有三个信息$(x,y,\sigma,\theta)$：位置、尺度、方向。<br>由此我们可以确定一个SIFT特征区域。通常使用一个带箭头的圆或直接使用箭头表示SIFT区域的三个值：中心表示特征点位置，半径表示特征点尺度（$r=2.5\sigma$），箭头表示主方向。<br>具有多个方向的特征点可以复制成多份，然后将方向值分别赋给复制后的特征点。如下图：<br><img src="https://user-images.githubusercontent.com/6218739/138855713-27783685-f694-4aca-a641-9bef8c823c56.png" alt="fea1"></p><h2 id="特征点描述"><a href="#特征点描述" class="headerlink" title="特征点描述"></a>特征点描述</h2><p>上文找到的SIFT特征点包含位置、尺度和方向的信息。接下来的步骤是特征点描述，即用一组向量将这个特征点描述出来，这个描述子不但包括特征点，也包括特征点周围对其有贡献的像素点，用来作为目标匹配的依据（所以描述子应该有较高的独特性，以保证匹配率），也可使特征点具有更多的不变特性，如光照变化、3D视点变化等。<br>SIFT描述子$h(x,y,\theta)$是对特征点附近邻域内高斯图像梯度统计的结果，是一个三维矩阵，但通常用一个矢量来表示。特征向量通过对三维矩阵按一定规律排列得到。</p><h3 id="描述子采样区域"><a href="#描述子采样区域" class="headerlink" title="描述子采样区域"></a>描述子采样区域</h3><p>特征描述子与特征点所在尺度有关，因此对梯度的求取应在特征点对应的高斯图像上进行。<br>将特征点附近划分成$d\times d$个子区域，每个子区域尺寸为$m\sigma$个像元（$d=4$，$m=3$，$\sigma$为特征点的尺度值）。考虑到实际计算时需要双线性插值，故计算的图像区域为$m\sigma(d+1)$，再考虑旋转，则实际计算的图像区域为$\frac{\sqrt{2}}{2}m\sigma(d+1)$，如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/138855575-3dc7b05b-90af-4bc7-82b5-6228406161df.png" alt="area"></p><h3 id="区域坐标轴旋转"><a href="#区域坐标轴旋转" class="headerlink" title="区域坐标轴旋转"></a>区域坐标轴旋转</h3><p>为了保证特征矢量具有旋转不变性，要以特征点为中心，在附近邻域内旋转$\theta$角，即旋转为特征点的方向。<br><img src="https://user-images.githubusercontent.com/6218739/138855946-d33c2c3c-7d7e-4f73-b441-24184c7d2ed1.png" alt="rotate"><br>旋转后区域内采样点新的坐标为： </p><script type="math/tex; mode=display">\begin{pmatrix} x' \\ y'\end{pmatrix} = \begin{pmatrix} cos\theta & -sin\theta \\ sin\theta & cos\theta\end{pmatrix} \begin{pmatrix} x \\ y\end{pmatrix}</script><h3 id="计算采样区域梯度直方图"><a href="#计算采样区域梯度直方图" class="headerlink" title="计算采样区域梯度直方图"></a>计算采样区域梯度直方图</h3><p>将旋转后区域划分为$d\times d$个子区域（每个区域间隔为$m\sigma$像元），在子区域内计算8个方向的梯度直方图，绘制每个方向梯度方向的累加值，形成一个种子点。 与求主方向不同的是，此时，每个子区域梯度方向直方图将0°~360°划分为8个方向区间，每个区间为45°。即每个种子点有8个方向区间的梯度强度信息。由于存在$d\times d$，即$4\times 4$个子区域，所以最终共有$4\times 4 \times 8 = 128$个数据（Lowe建议的数据），形成128维SIFT特征矢量。<br><img src="https://user-images.githubusercontent.com/6218739/138856347-869aa2f0-2669-4e70-9251-52b34f034439.png" alt="final"><br>对特征矢量需要加权处理，加权采用$\frac{m\sigma d}{2}$的标准高斯函数。为了除去光照变化影响，还有进一步归一化处理。</p><p>至此SIFT描述子生成，SIFT算法也基本完成了。</p>]]></content>
    
    
    <summary type="html">参考文献
SIFT算法深入理解
特征点匹配——SIFT算法详解
图像金字塔（高斯金字塔，拉普拉斯金字塔，图像缩放resize函数）
SIFT算法详解

简介
SIFT（Scale Invariant Feature Transform），尺度不变特征变换匹配算法，是由David G. Lowe在1999年（《Object Recognition from Local Scale-Invariant Features》）提出的高效区域检测算法，在2004年（《Distinctive Image Features from Scale-Invariant Keypoints》）得以完善。
SIFT</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="Image" scheme="http://qixinbo.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>GAN系列算法原理及极简代码解析</title>
    <link href="http://qixinbo.github.io/2021/10/21/gan/"/>
    <id>http://qixinbo.github.io/2021/10/21/gan/</id>
    <published>2021-10-20T16:00:00.000Z</published>
    <updated>2021-10-21T08:38:46.620Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h1><p><a href="https://alberthg.github.io/2018/05/05/introduction-gan/">生成对抗网络——原理解释和数学推导</a><br>首先有一个“生成器(Generator)”：其实就是一个神经网络，或者是更简单的理解，他就是一个函数(Function)。输入一组向量，经由生成器，产生一组目标矩阵（如果你要生成图片，那么矩阵就是图片的像素集合，具体的输出视你的任务而定）。它的目的就是使得自己造样本的能力尽可能强，强到什么程度呢，强到你判别网络没法判断我是真样本还是假样本。<br>同时还有一个“判别器(Discriminator)”：判别器的目的就是能判别出来一张图它是来自真实样本集还是假样本集。假如输入的是真样本，网络输出就接近 1，输入的是假样本，网络输出接近 0，那么很完美，达到了很好判别的目的。<br>那为什么需要这两个组件呢？GAN在结构上受博弈论中的二人零和博弈 （即二人的利益之和为零，一方的所得正是另一方的所失）的启发，系统由一个生成模型（G）和一个判别模型（D）构成。G 捕捉真实数据样本的潜在分布，并生成新的数据样本；D 是一个二分类器，判别输入是真实数据还是生成的样本。生成器和判别器均可以采用深度神经网络。GAN的优化过程是一个极小极大博弈(Minimax game)问题，优化目标是达到纳什均衡。</p><h1 id="原始GAN"><a href="#原始GAN" class="headerlink" title="原始GAN"></a>原始GAN</h1><p>这里用的网络非常简单，仅有二层，且还不是卷积神经网络，而是全连接层。后面的GAN变种会使用更加强大的深度网络。<br>首先先看一下判别器和生成器的分别的损失函数：<br><img src="https://user-images.githubusercontent.com/6218739/136900996-05cfa37c-96f4-48cf-9f5b-7f7aa6a074b8.png" alt="loss-d"><br><img src="https://user-images.githubusercontent.com/6218739/136901466-4f4a85d8-92db-4eaf-9e05-6b8b206df7d7.png" alt="loss-g"></p><p>最终实现的效果就是：生成器能够凭空（也不是完全凭空，它的输入是一个具有隐参量维度的噪声图像）生成一张与训练图片极为类似的虚假图片。</p><p>代码在：<br><a href="https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/GANs">Machine-Learning-Collection/ML/Pytorch/GANs</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter  <span class="comment"># to print to tensorboard</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 判别器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_features</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 非常小的网络</span></span><br><span class="line">        self.disc = nn.Sequential(</span><br><span class="line">            nn.Linear(in_features, <span class="number">128</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.01</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.disc(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># z是隐空间参量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, z_dim, img_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.gen = nn.Sequential(</span><br><span class="line">            nn.Linear(z_dim, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.01</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, img_dim),</span><br><span class="line">            <span class="comment"># 输入会标准化为[-1, 1]，所以这里的输出也要标准化到[-1, 1]</span></span><br><span class="line">            nn.Tanh(), </span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.gen(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 超参数设置</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">lr = <span class="number">3e-4</span> <span class="comment"># 学习率</span></span><br><span class="line">z_dim = <span class="number">64</span> <span class="comment"># 隐参量的维度</span></span><br><span class="line">image_dim = <span class="number">28</span> * <span class="number">28</span> * <span class="number">1</span>  <span class="comment"># 784，MNIST</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">num_epochs = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">disc = Discriminator(image_dim).to(device)</span><br><span class="line">gen = Generator(z_dim, image_dim).to(device)</span><br><span class="line"><span class="comment"># 这里加入噪声是为了看出在迭代过程中的变化</span></span><br><span class="line">fixed_noise = torch.randn((batch_size, z_dim)).to(device)</span><br><span class="line">transforms = transforms.Compose(</span><br><span class="line">    <span class="comment"># 按道理应该采用与MNist相同的均值和标准差(0.1307, 0.3081)</span></span><br><span class="line">    <span class="comment"># 但上面的超参数的设置是作者用(0.5, 0.5)时调出来的，所以这里如果改了就会发散</span></span><br><span class="line">    <span class="comment"># 这也说明GAN对参数非常敏感，非常难以训练</span></span><br><span class="line">    [transforms.ToTensor(), transforms.Normalize((<span class="number">0.5</span>,), (<span class="number">0.5</span>,)),]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">dataset = datasets.MNIST(root=<span class="string">&quot;dataset/&quot;</span>, transform=transforms, download=<span class="literal">True</span>)</span><br><span class="line">loader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 判别器的优化算法</span></span><br><span class="line">opt_disc = optim.Adam(disc.parameters(), lr=lr)</span><br><span class="line"><span class="comment"># 生成器的优化算法</span></span><br><span class="line">opt_gen = optim.Adam(gen.parameters(), lr=lr)</span><br><span class="line"><span class="comment"># 损失函数设为Binary Cross Entropy</span></span><br><span class="line"><span class="comment"># 公式为-[y*logx + (1-y)log(1-x)]</span></span><br><span class="line"><span class="comment"># 注意公式前面的负号，后面计算损失时该负号将最大化改为了最小化</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line">writer_fake = SummaryWriter(<span class="string">f&quot;logs/fake&quot;</span>)</span><br><span class="line">writer_real = SummaryWriter(<span class="string">f&quot;logs/real&quot;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># 从加载器里取出的是real图像</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (real, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        real = real.view(-<span class="number">1</span>, <span class="number">784</span>).to(device)</span><br><span class="line">        batch_size = real.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">########## 训练判别器：最大化log(D(x)) + log(1 - D(G(z))) ###############</span></span><br><span class="line">        <span class="comment">## 即：log(D(real)) + log(1 - D(G(latent_noise)))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 事先准备隐空间的噪声数据</span></span><br><span class="line">        noise = torch.randn(batch_size, z_dim).to(device)</span><br><span class="line">        <span class="comment"># 将噪声数据传给生成器，生成假的图像</span></span><br><span class="line">        fake = gen(noise)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#### 计算log(D(x))损失 ####</span></span><br><span class="line">        <span class="comment"># 将真实图像传给判别器，即计算D(x)</span></span><br><span class="line">        disc_real = disc(real).view(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将D(x)与1分别作为预测值和目标值放到BCE中进行计算</span></span><br><span class="line">        <span class="comment"># 根据BCE的公式-[y*logx + (1-y)log(1-x)]，这里y为1，因此此处计算的就是-log(D(x))</span></span><br><span class="line">        <span class="comment"># 也可以这样理解，此处的损失就是看看判别器对于真实图像的预测是不是接近1，即判别器对于真实图像的性能怎么样</span></span><br><span class="line">        lossD_real = criterion(disc_real, torch.ones_like(disc_real))</span><br><span class="line"></span><br><span class="line">        <span class="comment">#### 计算log(1-D(G(z)))损失</span></span><br><span class="line">        <span class="comment"># 将生成器生成的虚假图像传给判别器，即计算D(G(z))</span></span><br><span class="line">        disc_fake = disc(fake).view(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将D(G(z))与0分别作为预测值和目标值放到BCE中进行计算</span></span><br><span class="line">        <span class="comment"># 根据BCE的公式-[y*logx + (1-y)log(1-x)]，这里y为0，因此此处计算的就是-log(1-D(G(z)))</span></span><br><span class="line">        <span class="comment"># 也可以这样理解，此处的损失就是看看判别器对于虚假图像的预测是不是接近0，即判别器对于虚假图像的性能怎么样</span></span><br><span class="line">        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 总损失</span></span><br><span class="line">        lossD = (lossD_real + lossD_fake) / <span class="number">2</span></span><br><span class="line">        <span class="comment"># 判别器的反向传播</span></span><br><span class="line">        disc.zero_grad()</span><br><span class="line">        <span class="comment"># 注意，这里将retain_graph设为True，是为了保留该过程中计算的梯度，后续生成器网络更新时使用</span></span><br><span class="line">        <span class="comment"># 否则这里判别器网络构建了正向计算图后，反向传播结束后就将其销毁</span></span><br><span class="line">        lossD.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line">        opt_disc.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">########## 训练生成器：最小化log(1 - D(G(z)))，等价于最大化log(D(G(z)) ###############</span></span><br><span class="line">        <span class="comment">## 第二种损失不会遇到梯度饱和的问题</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将生成器生成的虚假图像传给判别器，即计算D(G(z))</span></span><br><span class="line">        <span class="comment"># 这里的disc是经过了升级后的判别器，所以与第99行的D(G(z))计算不同</span></span><br><span class="line">        <span class="comment"># 但fake这个量还是上面的fake = gen(noise)</span></span><br><span class="line">        output = disc(fake).view(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将D(G(z))与1分别作为预测值和目标值放到BCE中进行计算</span></span><br><span class="line">        <span class="comment"># 根据BCE的公式-[y*logx + (1-y)log(1-x)]，这里y为1，因此此处计算的就是-log(D(G(z)))</span></span><br><span class="line">        <span class="comment"># 也可以这样理解，此处的损失就是看看判别器对于生成器生成的虚假图像的预测是不是接近1，即生成器有没有骗过判别器</span></span><br><span class="line">        <span class="comment"># 这里log(D(G(z))的计算与上面的log(D(G(z))的计算不重复，是因为生成器和判别器是分开训练的，两者都要有各自的损失函数</span></span><br><span class="line">        lossG = criterion(output, torch.ones_like(output))</span><br><span class="line">        <span class="comment"># 生成器的反向传播</span></span><br><span class="line">        gen.zero_grad()</span><br><span class="line">        lossG.backward()</span><br><span class="line">        opt_gen.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下面就是用于tenshorboard的可视化</span></span><br><span class="line">        <span class="keyword">if</span> batch_idx == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(</span><br><span class="line">                <span class="string">f&quot;Epoch [<span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>] Batch <span class="subst">&#123;batch_idx&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(loader)&#125;</span> \</span></span><br><span class="line"><span class="string">                      Loss D: <span class="subst">&#123;lossD:<span class="number">.4</span>f&#125;</span>, loss G: <span class="subst">&#123;lossG:<span class="number">.4</span>f&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                fake = gen(fixed_noise).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">                data = real.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">                img_grid_fake = torchvision.utils.make_grid(fake, normalize=<span class="literal">True</span>)</span><br><span class="line">                img_grid_real = torchvision.utils.make_grid(data, normalize=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">                writer_fake.add_image(</span><br><span class="line">                    <span class="string">&quot;Mnist Fake Images&quot;</span>, img_grid_fake, global_step=step</span><br><span class="line">                )</span><br><span class="line">                writer_real.add_image(</span><br><span class="line">                    <span class="string">&quot;Mnist Real Images&quot;</span>, img_grid_real, global_step=step</span><br><span class="line">                )</span><br><span class="line">                step += <span class="number">1</span></span><br></pre></td></tr></table></figure></p><h1 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h1><p>DCGAN，深度卷积生成对抗网络，全名“Deep Convolutional Generative Adversarial Networks”。<br>DCGAN的生成器和判别器的网络架构如下：<br><img src="https://user-images.githubusercontent.com/6218739/136920307-cfbf4981-6576-4bad-9a31-866b8465ece4.png" alt="dcgan"><br>与上面的原生的GAN类似，DCGAN是将网络架构换成了深度卷积网络，其参数也要小心调节。</p><h1 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h1><p><a href="https://zhuanlan.zhihu.com/p/25071913">令人拍案叫绝的Wasserstein GAN</a><br>（该文章下面的评论也很有见解）<br>自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进DCGAN依靠的是对判别器和生成器的架构进行实验枚举，最终找到一组比较好的网络架构设置，但是实际上是治标不治本，没有彻底解决问题。而Wasserstein GAN（下面简称WGAN）成功地做到了以下爆炸性的几点：<br>（1）彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度<br>（2）基本解决了collapse mode的问题，确保了生成样本的多样性（collapse mode就是模式倒塌。比如我们知道人民币有好几个面额的纸币。假钞制造团伙发现如果他们将全部精力都放在制造一种面值的货币时最容易获得成功。而这时候，模式倒塌也就发生了。虽然这个假钞制造团伙能够制造出十分真实的货币，但却只有一种，而这有时并不是我们希望的。我们希望假钞制造团伙能生成所有的币值人民币。）<br>（3）训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高<br>（4）以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到。<br>那以上好处来自哪里？这就是令人拍案叫绝的部分了——实际上作者整整花了两篇论文，在第一篇《Towards Principled Methods for Training Generative Adversarial Networks》里面推了一堆公式定理，从理论上分析了原始GAN的问题所在，从而针对性地给出了改进要点；在这第二篇《Wasserstein GAN》里面，又再从这个改进点出发推了一堆公式定理，最终给出了改进的算法实现流程，而改进后相比原始GAN的算法实现流程却只改了四点：<br>（1）判别器最后一层去掉sigmoid<br>（2）生成器和判别器的loss不取log<br>（3）每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c<br>（4）不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行。</p><p>上述是工程上的改进，但为什么这样改进，需要非常深厚的数学知识推导。从宏观上理解就是如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/137093439-169e8c77-debc-46cb-982f-d91502574eb4.png" alt="distance"><br>GAN的目的是使得生成图像的样本分布与真实图像的样本分布尽可能相近，即数学上怎样表达这两种分布的距离。原始GAN使用了JS散度来衡量该距离（更新loss后的GAN使用的是KL散度），WGAN则使用的是Wasserstein距离。<br>因为对于JS散度，无论真实样本分布跟生成样本分布是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数$log 2$，而这对于梯度下降方法意味着——梯度为0！此时对于最优判别器来说，生成器肯定是得不到一丁点梯度信息的；即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。 原始GAN不稳定的原因是：判别器训练得太好，生成器梯度消失，生成器loss降不下去；判别器训练得不好，生成器梯度不准，四处乱跑。只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样，所以GAN才那么难训练。<br>Ian Goodfellow提出的原始GAN两种形式有各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。<br>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。<br>其具体定义如下：<br><img src="https://user-images.githubusercontent.com/6218739/137243663-49a15547-9972-4daf-95ea-5a78751e10af.png" alt="em"><br>（注意，Wasserstein距离本身是一个距离的概念，上式中的下界意思是从这两个分布中采样时取得的最小距离，就是Wasserstein距离）<br>在实际使用Wasserstein距离时，无法直接应用，作者将其通过某一定理改变成了如下条件：<br><img src="https://user-images.githubusercontent.com/6218739/137256384-4c8ed599-a4e0-46b3-9b1f-d8546bfc53fb.png" alt="wgan-1"><br><img src="https://user-images.githubusercontent.com/6218739/137256914-76caca0f-c705-4973-aa5e-b492ba1910f6.png" alt="wgan-2"><br>即这里不知道函数f的具体形式，用一组参数w来定义这些f，这里就是深度学习中的常用套路，“什么东西如果不知道，就用神经网络来学到”，因此f就是参数为w的一套网络，这里原作者命名为Critic。（至于上式中K施加的限制，是通过对权重参数w的裁剪来实现的。）<br>注意上式中是尽可能最大化才能获得Wasserstein距离，因此网络f的作用是一个测距网络，它的最大化max的过程就是为了找到Wasserstein距离，即该网络逐步优化成为一个准确的Wasserstein距离测量尺。<br>因此，最好不把它称为判别网络，而是称为测距网络。它的训练过程就是最小化下面的损失（因为它是为了近似拟合Wasserstein距离，属于回归任务，所以要把最后一层的sigmoid拿掉）：<br><img src="https://user-images.githubusercontent.com/6218739/137257689-06b20ed0-fd71-411e-b3c2-17798a574b3d.png" alt="wgan-loss-1"><br>那么接下来，因为测距网络已经将Wasserstein距离计算了出来，下一步就是将该距离尽可能地减小，从而使得生成图像的分布尽可能地与真实图像的分布类似，这就是生成器网络要干的事情。<br>回到公式14中Wasserstein距离的定义，该距离由两部分构成，第一项是真实图像分布的贡献，第二项是生成图像分布的贡献，而第一项与生成器网络无关，因此要使得Wasserstein距离变得小一些（注意不要受式中的max影响，max是为了计算Wasserstein距离），就要使第二项（注意带前面的负号）变小，即：<br><img src="https://user-images.githubusercontent.com/6218739/137263288-aa414595-7a8d-4b78-97ed-83c134835975.png" alt="wgan-loss-2"><br>至于代码实现，大部分都可以复用之前的，只是针对上面说的四点改动一下即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测距网络，看着跟原始GAN的判别网络类似，但核心意义不同，这里仍然沿用那个网络架构，但改个名字以示区别</span></span><br><span class="line">critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    <span class="comment"># Target labels not needed! &lt;3 unsupervised</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        data = data.to(device)</span><br><span class="line">        cur_batch_size = data.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">### 训练测距网络，最大化E[critic(real)] - E[critic(fake)]</span></span><br><span class="line">        <span class="comment">### 即最小化-(E[critic(real)] - E[critic(fake)])</span></span><br><span class="line">        <span class="comment"># Critic训练得越好，对Generator的提升更有利，因此多训练几轮Critic。</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(CRITIC_ITERATIONS):</span><br><span class="line">            noise = torch.randn(cur_batch_size, Z_DIM, <span class="number">1</span>, <span class="number">1</span>).to(device)</span><br><span class="line">            fake = gen(noise)</span><br><span class="line">            critic_real = critic(data).reshape(-<span class="number">1</span>)</span><br><span class="line">            critic_fake = critic(fake).reshape(-<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 测距网络的损失函数</span></span><br><span class="line">            <span class="comment"># 两个期望值相减</span></span><br><span class="line">            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))</span><br><span class="line">            critic.zero_grad()</span><br><span class="line">            loss_critic.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line">            opt_critic.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 裁剪网络权重</span></span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> critic.parameters():</span><br><span class="line">                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)</span><br><span class="line"></span><br><span class="line">        <span class="comment">########## 训练生成器网络 ################</span></span><br><span class="line">        <span class="comment">## 最大化E[critic(gen_fake)]</span></span><br><span class="line">        <span class="comment">## 即最小化-E[critic(gen_fake)]</span></span><br><span class="line">        gen_fake = critic(fake).reshape(-<span class="number">1</span>)</span><br><span class="line">        loss_gen = -torch.mean(gen_fake)</span><br><span class="line">        gen.zero_grad()</span><br><span class="line">        loss_gen.backward()</span><br><span class="line">        opt_gen.step()</span><br></pre></td></tr></table></figure></p><h2 id="WGAN-GP"><a href="#WGAN-GP" class="headerlink" title="WGAN-GP"></a>WGAN-GP</h2><p><a href="https://zhuanlan.zhihu.com/p/58260684">WGAN的来龙去脉</a><br>作者们发现WGAN有时候也会伴随样本质量低、难以收敛等问题。WGAN为了保证Lipschitz限制，采用了weight clipping的方法，然而这样的方式可能过于简单粗暴了，因此他们认为这是上述问题的罪魁祸首。<br>具体而言，他们通过简单的实验，发现weight clipping会导致两大问题：模型建模能力弱化，以及梯度爆炸或消失。<br>他们提出的替代方案是给Critic loss加入gradient penalty (GP)，这样，新的网络模型就叫WGAN-GP。<br>新的Loss为：<br><img src="https://user-images.githubusercontent.com/6218739/137277767-786bce8c-7f5c-4c2a-aca2-41cb80fcde85.png" alt="wgan-gp-loss"><br>另一个值得注意的地方是，用于计算GP的样本是生成样本和真实样本的线性插值。<br>GP部分的代码为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_penalty</span>(<span class="params">critic, real, fake, device=<span class="string">&quot;cpu&quot;</span></span>):</span></span><br><span class="line">    BATCH_SIZE, C, H, W = real.shape</span><br><span class="line">    alpha = torch.rand((BATCH_SIZE, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)).repeat(<span class="number">1</span>, C, H, W).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 线性插值</span></span><br><span class="line">    interpolated_images = real * alpha + fake * (<span class="number">1</span> - alpha)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算判别网络（测距网络）得分</span></span><br><span class="line">    mixed_scores = critic(interpolated_images)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算梯度</span></span><br><span class="line">    gradient = torch.autograd.grad(</span><br><span class="line">        inputs=interpolated_images,</span><br><span class="line">        outputs=mixed_scores,</span><br><span class="line">        grad_outputs=torch.ones_like(mixed_scores),</span><br><span class="line">        create_graph=<span class="literal">True</span>,</span><br><span class="line">        retain_graph=<span class="literal">True</span>,</span><br><span class="line">    )[<span class="number">0</span>]</span><br><span class="line">    gradient = gradient.view(gradient.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 2范数</span></span><br><span class="line">    gradient_norm = gradient.norm(<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">    gradient_penalty = torch.mean((gradient_norm - <span class="number">1</span>) ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> gradient_penalty</span><br></pre></td></tr></table></figure></p><h1 id="CGAN"><a href="#CGAN" class="headerlink" title="CGAN"></a>CGAN</h1><p><a href="https://zhuanlan.zhihu.com/p/61464846">李宏毅GAN2018笔记 Conditional GAN</a><br>Conditional，意思是条件，所以 Conditional GAN 的意思就是有条件的GAN。Conditional GAN 可以让 GAN 产生的结果符合一定的条件，即可以通过人为改变输入的向量（记不记得我们让生成器生成结果需要输入一个低维向量），控制最终输出的结果。<br>这种网络与普通 GAN 的区别在于输入加入了一个额外的 condition（比如在 text-to-image 任务中的描述文本），并且在训练的时候使得输出的结果拟合这个 condition。<br>所以现在判别器不仅要对生成结果的质量打分，还要对结果与输入 condition 的符合程度打分。<br>Conditional GAN 的判别器有两种常见架构，前者更为常用，但李宏毅老师认为后者更加合理，它用两个神经网络分别对输出结果的质量以及条件符合程度独立进行判别。<br><img src="https://user-images.githubusercontent.com/6218739/137661146-99fb337c-9d64-4740-ab9a-5b232a1aafdb.png" alt="cgan"></p><h1 id="Pix2Pix"><a href="#Pix2Pix" class="headerlink" title="Pix2Pix"></a>Pix2Pix</h1><p><a href="https://blog.csdn.net/u014380165/article/details/98453672">pix2pix算法笔记</a><br><a href="https://zhuanlan.zhihu.com/p/90300175">Pix2Pix图图转换网络原理分析与pytorch实现</a><br>自动图图转换任务被定义为：在给定充足的数据下，从一种场景转换到另一种场景。从功能实现上来看，网络需要学会“根据像素预测像素”（predict pixels from pixels）。<br>CNNs的研究已经给图图转换问题提供了一种简便的思路，比如设计一个编码解码网络AE，AE的输入 是白天的图像，AE的期望输出是黑夜的图像。那么可以使用MSE损失，来最小化网络输出的黑夜图像和真实黑夜图像之间的差异，实现白天到黑夜的图图转换。<br>然而，CNN需要我们去设计特定的损失函数，比如使用欧氏距离会导致预测的图像出现模糊。所以，需要去设计一种网络，这种网络不需要精心选择损失函数。<br>更确切地说，是用一种通用的损失函数形式来自动学习特定任务的损失函数，即GAN架构里判别器和生成器的损失函数是通用形式，它可以用来作为所有图图转换任务的统一损失，而具体任务的损失则是在训练过程中自动学习到的，这样就不用手动准确设定损失函数。</p><p>论文Image-to-Image Translation with Conditional Adversarial Networks发表在CVPR2017，简称pix2pix，是将GAN应用于有监督的“图像到图像”翻译的经典论文，有监督表示训练数据是成对的。图像到图像翻译（image-to-image translation）是GAN很重要的一个应用方向，什么叫图像到图像翻译呢？其实就是基于一张输入图像得到想要的输出图像的过程，可以看做是图像和图像之间的一种映射（mapping），我们常见的图像修复、超分辨率其实都是图像到图像翻译的例子。（节选为CSDN博主「AI之路」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明）<br>pix2pix基于GAN实现图像翻译，更准确地讲是基于cGAN（conditional GAN，也叫条件GAN），因为cGAN可以通过添加条件信息来指导图像生成，因此在图像翻译中就可以将输入图像作为条件，学习从输入图像到输出图像之间的映射，从而得到指定的输出图像。而其他基于GAN来做图像翻译的，因为GAN算法的生成器是基于一个随机噪声生成图像，难以控制输出，因此基本上都是通过其他约束条件来指导图像生成，而不是利用cGAN，这是pix2pix和其他基于GAN做图像翻译的差异。</p><p>生成器采用U-Net，这是在图像分割领域应用非常广泛的网络结构，能够充分融合特征；而原本GAN中常用的生成器结构是encoder-decoder类型。<br>判别器采用PatchGAN。通常判断都是对生成样本整体进行判断，比如对一张图片来说，就是直接看整张照片是否真实。而且Image-to-Image Translation中很多评价是像素对像素的，所以在这里提出了分块判断的算法，在图像的每个块上去判断是否为真，最终平均给出结果。PatchGAN的差别主要是在于Discriminator上，一般的GAN是只需要输出一个true or fasle 的矢量，这是代表对整张图像的评价；但是PatchGAN输出的是一个N x N的矩阵，这个N x N的矩阵的每一个元素，比如a(i,j) 只有True or False 这两个选择（label 是 N x N的矩阵，每一个元素是True 或者 False），这样的结果往往是通过卷积层来达到的，因为逐次叠加的卷积层最终输出的这个N x N 的矩阵，其中的每一个元素，实际上代表着原图中的一个比较大的感受野，也就是说对应着原图中的一个Patch，因此具有这样结构以及这样输出的GAN被称之为Patch GAN。这么设计的原因是依靠L1项来保证低频的准确性。为了对高频信息建模（即细节），关注对局部图像块（patches）就已经足够了。</p><p>损失函数沿用了最原始的GAN的损失，即有log作用：<br><img src="https://user-images.githubusercontent.com/6218739/137694646-69faa7ab-913e-4cdc-9f6f-6e97faf30da7.png" alt="pix2pix-loss-1"><br>同时加入了一个L1损失，使生成图像不仅要像真实图片，也要更接近于输入的条件图片：<br><img src="https://user-images.githubusercontent.com/6218739/137695208-19578014-4dcf-448d-8781-35a33a519441.png" alt="pix2pix-loss-2"><br>将对抗损失和L1损失相加，就得到了最终的整体损失函数：<br><img src="https://user-images.githubusercontent.com/6218739/137695374-7ee625bb-6593-4391-8d0b-10a407d1642d.png" alt="pix2pix-loss"></p><p>pix2pix的代码实现与之前的GAN大同小异，不同的地方就是上面的模型架构和损失函数，不再赘述。</p><h1 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h1><p><a href="https://zhuanlan.zhihu.com/p/26332365">异父异母的三胞胎：CycleGAN, DiscoGAN, DualGAN</a><br><a href="https://zhuanlan.zhihu.com/p/26995910">CycleGAN</a></p><p>pix2pix的模型是在成对的数据上训练的，也就是说，对于线条到猫的应用，我们训练的时候就需要提供一对一对的数据：一个线条画，和对应的真实的猫图片。<br>然而在很多情况下，我们并没有这样完美的成对的训练数据。比如说如果你想把马变成斑马，并没有这样对应的一个马对应一个斑马。然而，马的图片和斑马的图片却很多。所以这篇论文就是希望，能够通过不成对的训练数据，来学到变换。<br>一个普通的GAN只有一个生成器和一个判别器。而在CycleGAN里，分别有两个生成器和判别器。如下图所示：<br><img src="https://user-images.githubusercontent.com/6218739/138195026-c3033357-122f-4448-90b8-bd4814cf2e9c.png" alt="cyclegan"><br>一个生成器将X域的图片转换成Y域的图片（用G表示），而另一个生成器做相反的事情，用F表示。而两个判别器$D_x$和$D_y$试图分辨两个域中真假图片。（这里假图片指的是从真照片transform来的）<br>看上图，X通过G生成Y，Y再通过F生成X，构成了一个循环，所以叫CycleGAN。整个cycle可以看成是一个autoencoder，两个generator看成是encoder和decoder。而两个discriminator则是准则。<br>损失函数分为两部分：<br>（1）对抗损失Adversarial Loss：<br>从X到Y的对抗损失为：<br><img src="https://user-images.githubusercontent.com/6218739/138197675-43f6916f-3730-4836-b962-dce030489cfe.png" alt="cyclegan-loss-1"><br>从Y到X的对抗损失反之亦然。<br>（2）Cycle Consistency 损失<br>Cycle consistency是为了使得transform能成功。讲道理，如果你能从X转换到Y，然后再从Y转换到X，最后的结果应该和输入相似。这里他们用最后输出和输入的L1距离来作为另外的惩罚项。<br>这个惩罚项防止了mode collapse的问题。如果没有这个cycle consistency项，网络会输出更真实的图片，但是无论什么输入，都会是一样的输出。而如果加了cycle consistency，一样的输出会导致cycle consistency的直接失败。所以这规定了在经过了变换之后的图片不仅需要真实，且包含原本图片的信息。<br><img src="https://user-images.githubusercontent.com/6218739/138223001-01e048e8-1f0d-4ae0-aa39-5cb518809809.png" alt="cyclegan-loss-2"></p><p>制作数据集时，比如想把马和斑马进行转换，那么就准备马的数据集X，斑马的数据集Y，两者不需要数量相等，也不需要一一对应。训练时，上面的损失会保证马转换成相同体型和姿态的斑马。</p><h1 id="ProGAN"><a href="#ProGAN" class="headerlink" title="ProGAN"></a>ProGAN</h1><p><a href="https://zhuanlan.zhihu.com/p/93748098">ProGAN：Step by step, better than better</a><br>ProGAN 中的 Pro 并非 Professional，而是 Progressive，即逐渐的意思，这篇 paper 主要想解决的问题是高清图像难以生成的问题，图像生成主要的技术路线有：（1）Autoregressive Model: PixelRNN，（2）VAEs，（3）GANs。<br>GAN最大的好处在于生成的图像十分Sharp，而弱点则在于训练麻烦，容易崩，而且生成的数据分布只是训练集数据分布的一个子集，即多样性不足。ProGAN 最大的贡献在于提出了一种新的训练方式，即，我们不要一上来就学那么难的高清图像生成，这样会让 Generator 直接崩掉，而是从低清开始学起，学好了再提升分辨率学更高分辨率下的图片生成。从4x4到8x8一直提升到1024x1024，循序渐进，即能有效且稳定地训练出一个高质量的高分辨率生成器模型。<br>这样做的好处主要有二：<br>（1）毫无疑问，比直接学生成 1024x1024 的图像稳定多了。<br>（2）另外，节省时间，训练低分辨率阶段下的生成器快得不知道哪里去了，大大节省整体训练时间。</p><h1 id="SRGAN"><a href="#SRGAN" class="headerlink" title="SRGAN"></a>SRGAN</h1><p><a href="https://perper.site/2019/03/01/SRGAN-%E8%AF%A6%E8%A7%A3/">SRGAN 详解</a><br>SRGAN目标从一个低分辨率的图片中生成它的高分辨率版本。<br>传统CNN方法：基于深度学习的高分辨率图像重建已经取得了很好的效果，其方法是通过一系列低分辨率图像和与之对应的高分辨率图像作为训练数据，学习一个从低分辨率图像到高分辨率图像的映射函数。但是当图像的放大倍数在4以上时，很容易使得到的结果显得过于平滑，而缺少一些细节上的真实感。这是因为传统的方法使用的代价函数一般是最小均方差（MSE），使得生成的图像有较高的信噪比，但是缺少了高频信息，出现过度平滑的纹理。作者还做了实验，证明并不是信噪比越高超分辨率效果越好。<br>本文的做法：应当使重建的高分辨率图像与真实的高分辨率图像无论是低层次的像素值上，还是高层次的抽象特征上，和整体概念和风格上，都应当接近。因此在loss部分，SRGAN加上了feature map部分的MSE loss。<br>网络结构有：<br>生成网络部分：SRResnet，输入是低分辨率图像（注意与原始GAN输入是噪声进行对比），由残差结构，BN，PReLU组成，用于实现高分辨率的生成。<br>判别器部分：由大量卷积层，Leaky ReLU,BN等结构组成，用于判别图像的真实性。<br>损失函数由两部分组成：（1）content loss：传统算法使用的是还原图像与GT图像之间的MSE损失，作者为了避免放大后特征过于平滑，认为高层次（features map）也应当相似。因此定义了VGG feature map loss。（2）adversarial loss：对抗网络部分的loss为判别器判别loss，即当生成器生成的图片，判别器认为为真实的图片时，该loss取得最小。<br>因此，SRGAN是一个监督式算法，它需要Ground Truth的输入。</p><h2 id="ESRGAN"><a href="#ESRGAN" class="headerlink" title="ESRGAN"></a>ESRGAN</h2><p><a href="https://zhuanlan.zhihu.com/p/338646051">ESRGAN超分辨网络</a><br>ESRGAN就是Enhanced Super-Resolution Generative Adversarial Networks，作者主要从三个方面对SRGAN进行改进：网络结构、对抗损失、感知损失。<br>（1）网络结构：引入了 Residual-in-Residual Dense Block (RRDB)来代替SRGAN中的resblock；移除了网络单元的BN层；增加了residual scaling，来消除部分因移除BN层对深度网络训练稳定性的影响。<br>（2）对抗损失：SRGAN的对抗损失的目的是为了让真实图像的判决概率更接近1，让生成图像的判决概率更接近0。而改进的ESRGAN的目标是，让生成图像和真实图像之间的距离保持尽可能大，这是引入了真实图像和生成图像间的相对距离（Relativistic average GAN简称RaGAN），而不是SRGAN中的衡量和0或1间的绝对距离。（具体说来，ESRGAN目的是：让真实图像的判决分布减去生成图像的平均分布，再对上述结果做sigmoid处理，使得结果更接近于1；让生成图像的判决分布减去真实图像的平均分布，再对上述结果做sigmoid处理，使得结果更接近于0。）<br>（3）感知损失：（基于特征空间的计算，而非像素空间）使用VGG网络激活层前的特征图，而不像SRGAN中使用激活层后的特征图。因为激活层后的特征图有更稀疏的特征，而激活前的特征图有更详细的细节，因此可以带来更强的监督。并且，通过使用激活后的特征图作为感知损失的计算，可以带来更加锐化的边缘和更好视觉体验。</p>]]></content>
    
    
    <summary type="html">基本思想
生成对抗网络——原理解释和数学推导
首先有一个“生成器(Generator)”：其实就是一个神经网络，或者是更简单的理解，他就是一个函数(Function)。输入一组向量，经由生成器，产生一组目标矩阵（如果你要生成图片，那么矩阵就是图片的像素集合，具体的输出视你的任务而定）。它的目的就是使得自己造样本的能力尽可能强，强到什么程度呢，强到你判别网络没法判断我是真样本还是假样本。
同时还有一个“判别器(Discriminator)”：判别器的目的就是能判别出来一张图它是来自真实样本集还是假样本集。假如输入的是真样本，网络输出就接近 1，输入的是假样本，网络输出接近 0，那么很完美，达到了</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="GAN" scheme="http://qixinbo.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>YOLO系列算法原理及极简代码解析</title>
    <link href="http://qixinbo.github.io/2021/09/25/yolo3/"/>
    <id>http://qixinbo.github.io/2021/09/25/yolo3/</id>
    <published>2021-09-24T16:00:00.000Z</published>
    <updated>2021-09-25T15:15:16.864Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>物体检测的两个步骤可以概括为：<br>步骤一：检测目标位置（生成矩形框）<br>步骤二：对目标物体进行分类<br>物体检测主流的算法框架大致分为one-stage与two-stage。two-stage算法代表有R-CNN系列，one-stage算法代表有Yolo系列。two-stage算法将步骤一与步骤二分开执行，输入图像先经过候选框生成网络（例如faster rcnn中的RPN网络），再经过分类网络；one-stage算法将步骤一与步骤二同时执行，输入图像只经过一个网络，生成的结果中同时包含位置与类别信息。two-stage与one-stage相比，精度高，但是计算量更大，所以运算较慢。</p><h1 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h1><h2 id="YOLOv1"><a href="#YOLOv1" class="headerlink" title="YOLOv1"></a>YOLOv1</h2><p><a href="https://zhuanlan.zhihu.com/p/70387154">【论文解读】Yolo三部曲解读——Yolov1</a><br>YOLOv1的网络架构如下图：<br><img src="https://user-images.githubusercontent.com/6218739/133874079-e9c89d7b-f8f3-4078-8d9a-30e9f0451df3.png" alt="yolov1"><br>直接上结构图，输入图像大小为448乘448，经过若干个卷积层与池化层，变为7乘7乘1024张量（图一中倒数第三个立方体），最后经过两层全连接层，输出张量维度为7乘7乘30，这就是Yolo v1的整个神经网络结构，和一般的卷积物体分类网络没有太多区别，最大的不同就是：分类网络最后的全连接层，一般连接于一个一维向量，向量的不同位代表不同类别，而这里的输出向量是一个三维的张量（7乘7乘30）。上图中Yolo的backbone网络结构，受启发于GoogLeNet，也是v2、v3中Darknet的先锋。本质上来说没有什么特别，没有使用BN层，用了一层Dropout。除了最后一层的输出使用了线性激活函数，其他层全部使用Leaky Relu激活函数。网络结构没有特别的东西，不再赘述。</p><p>输出张量维度的意义：<br>（1）7乘7的含义<br>7乘7是指图片被分成了7乘7个格子，如下图：<br><img src="https://user-images.githubusercontent.com/6218739/133877539-5d2fe916-a712-4676-9a5e-06a3657a27cf.png" alt="grid-yolov1"><br>在Yolo中，如果一个物体的中心点，落在了某个格子中，那么这个格子将负责预测这个物体。而那些没有物体中心点落进来的格子，则不负责预测任何物体。这个设定就好比该网络在一开始，就将整个图片上的预测任务进行了分工，一共设定7乘7个按照方阵列队的检测人员，每个人员负责检测一个物体，大家的分工界线，就是看被检测物体的中心点落在谁的格子里。当然，是7乘7还是9乘9，是上图中的参数S，可以自己修改，精度和性能会随之有些变化。<br>（2）30的含义<br>刚才设定了49个检测人员，那么每个人员负责检测的内容，就是这里的30（注意，30是张量最后一维的长度）。在Yolo v1论文中，30是由$(4+1) \times 2 +20$得到的。其中$4+1$是矩形框的中心点坐标(x,y)、长宽(w,h)以及是否属于被检测物体的置信度c；2是一个格子共回归两个矩形框，每个矩形框分别产生5个预测值（每个格子预测矩形框个数，是可调超参数；论文中选择了2个框，当然也可以只预测1个框，具体预测几个矩形框，无非是在计算量和精度之间取一个权衡。如果只预测一个矩形框，计算量会小很多，但是如果训练数据都是小物体，那么网络学习到的框，也会普遍比较小，测试时如果物体较大，那么预测效果就会不理想；如果每个格子多预测几个矩形框，如上文中讲到的，每个矩形框的学习目标会有所分工，有些学习小物体特征，有些学习大物体特征等；在Yolov2、v3中，这个数目都有一定的调整。）；20代表预测20个类别。这里有几点需要注意：1. 每个方格（grid） 产生2个预测框，2也是参数，可以调，但是一旦设定为2以后，那么每个方格只产生两个矩形框，最后选定置信度更大的矩形框作为输出，也就是最终每个方格只输出一个预测矩形框。2. 每个方格只能预测一个物体。虽然可以通过调整参数，产生不同的矩形框，但这只能提高矩形框的精度。所以当有很多个物体的中心点落在了同一个格子里，该格子只能预测一个物体。也就是格子数为7乘7时，该网络最多预测49个物体。<br>如上述原文中提及，在强行施加了格点限制以后，每个格点只能输出一个预测结果，所以该算法最大的不足，就是对一些邻近小物体的识别效果不是太好，例如成群结队的小鸟。</p><p>损失函数：<br><img src="https://user-images.githubusercontent.com/6218739/133877787-e073a763-b371-4908-8456-60f6329974b7.png" alt="loss-yolov1"><br>论文中Loss函数，密密麻麻的公式初看可能比较难懂。其实论文中给出了比较详细的解释。所有的损失都是使用平方和误差公式。<br>（1）预测框的中心点(x,y)。造成的损失是上图中的第一行。其中$\mathbb{I}_{ij}^{obj}$为控制函数，在标签中包含物体的那些格点处，该值为 1 ；若格点不含有物体，该值为 0。也就是只对那些有真实物体所属的格点进行损失计算，若该格点不包含物体，那么预测数值不对损失函数造成影响。（x,y）数值与标签用简单的平方和误差。<br>（2）预测框的宽高。造成的损失是上图的第二行。$\mathbb{I}_{ij}^{obj}$的含义一样，也是使得只有真实物体所属的格点才会造成损失。这里对在损失函数中的处理分别取了根号，原因在于，如果不取根号，损失函数往往更倾向于调整尺寸比较大的预测框。例如，20个像素点的偏差，对于800乘600的预测框几乎没有影响，此时的IOU数值还是很大，但是对于30乘40的预测框影响就很大。取根号是为了尽可能的消除大尺寸框与小尺寸框之间的差异。<br>（3）第三行与第四行，都是预测框的置信度C。当该格点不含有物体时，该置信度的标签为0；若含有物体时，该置信度的标签为预测框与真实物体框的IOU数值（IOU计算公式为：两个框交集的面积除以并集的面积）。<br>（4）第五行为物体类别概率P，对应的类别位置，该标签数值为1，其余位置为0，与分类网络相同。<br>此时再来看$\lambda_{coord}$与$\lambda_{noobj}$，Yolo面临的物体检测问题，是一个典型的类别数目不均衡的问题。其中49个格点，含有物体的格点往往只有3、4个，其余全是不含有物体的格点。此时如果不采取点措施，那么物体检测的mAP不会太高，因为模型更倾向于不含有物体的格点。$\lambda_{coord}$与$\lambda_{noobj}$的作用，就是让含有物体的格点，在损失函数中的权重更大，让模型更加“重视”含有物体的格点所造成的损失。在论文中， 取值分别为5与0.5。</p><p>一些技巧：<br>（1）回归offset代替直接回归坐标<br>不直接回归中心点坐标数值，而是回归相对于格点左上角坐标的位移值。例如，第一个格点中物体坐标为$(2.3, 3.6)$，另一个格点中的物体坐标为$(5.4, 6.3)$，这四个数值让神经网络暴力回归，有一定难度。所以这里的offset是指，既然格点已知，那么物体中心点的坐标一定在格点正方形里，相对于格点左上角的位移值一定在区间$[0, 1)$中。让神经网络去预测$(0.3, 0.6)$与$(0.4, 0.3)$会更加容易，在使用时，加上格点左上角坐标$(2, 3)$、$(5, 6)$即可。</p><p>（2）同一格点的不同预测框有不同作用<br>前文中提到，每个格点预测两个或多个矩形框。此时假设每个格点预测两个矩形框。那么在训练时，见到一个真实物体，我们是希望两个框都去逼近这个物体的真实矩形框，还是只用一个去逼近？或许通常来想，让两个人一起去做同一件事，比一个人做一件事成功率要高，所以可能会让两个框都去逼近这个真实物体。但是作者没有这样做，在损失函数计算中，只对和真实物体最接近的框计算损失，其余框不进行修正。这样操作之后作者发现，一个格点的两个框在尺寸、长宽比、或者某些类别上逐渐有所分工，总体的召回率有所提升<br>（3）使用非极大抑制生成预测框<br>通常来说，在预测的时候，格点与格点并不会冲突，但是在预测一些大物体或者邻近物体时，会有多个格点预测了同一个物体。此时采用非极大抑制技巧，过滤掉一些重叠的矩形框。不过此时mAP提升并没有像在RCNN或DPM中那样显著提升。<br>（4）推理时将类别预测最大值乘以预测框最大值作为输出置信度<br>在推理时，使用物体的类别预测最大值p乘以预测框的最大值c，作为输出预测物体的置信度。这样也可以过滤掉一些大部分重叠的矩形框。输出检测物体的置信度，同时考虑了矩形框与类别，满足阈值的输出更加可信。</p><h2 id="YOLOv2"><a href="#YOLOv2" class="headerlink" title="YOLOv2"></a>YOLOv2</h2><p><a href="https://zhuanlan.zhihu.com/p/74540100">【论文解读】Yolo三部曲解读——Yolov2</a><br>Yolov2论文标题就是更好，更快，更强。Yolov1发表之后，计算机视觉领域出现了很多trick，例如批归一化、多尺度训练，v2也尝试借鉴了R-CNN体系中的anchor box，所有的改进提升，下面逐一介绍。</p><ol><li>Batch Normalization（批归一化）<br>检测系列的网络结构中，BN逐渐变成了标配。在Yolo的每个卷积层中加入BN之后，mAP提升了2%，并且去除了Dropout。</li><li>High Resolution Classifier（分类网络高分辨率预训练）<br>在Yolov1中，网络的backbone部分会在ImageNet数据集上进行预训练，训练时网络输入图像的分辨率为224乘224。在v2中，将分类网络在输入图片分辨率为448乘448的ImageNet数据集上训练10个epoch，再使用检测数据集（例如coco）进行微调。高分辨率预训练使mAP提高了大约4%。</li><li>Convolutional With Anchor Boxes（Anchor Box替换全连接层）<br>第一篇解读v1时提到，每个格点预测两个矩形框，在计算loss时，只让与ground truth最接近的框产生loss数值，而另一个框不做修正。这样规定之后，作者发现两个框在物体的大小、长宽比、类别上逐渐有了分工。在v2中，神经网络不对预测矩形框的宽高的绝对值进行预测，而是预测与Anchor框的偏差（offset），每个格点指定n个Anchor框。在训练时，最接近ground truth的框产生loss，其余框不产生loss。在引入Anchor Box操作后，mAP由69.5下降至69.2，原因在于，每个格点预测的物体变多之后，召回率大幅上升，准确率有所下降，总体mAP略有下降。<br>v2中移除了v1最后的两层全连接层，全连接层计算量大，耗时久。文中没有详细描述全连接层的替换方案，这里笔者猜测是利用1乘1的卷积层代替（欢迎指正），具体的网络结构原文中没有提及，官方代码也被yolo v3替代了。v2主要是各种trick引入后的效果验证，建议不必纠结于v2的网络结构。</li><li>Dimension Clusters（Anchor Box的宽高由聚类产生）<br>这里算是作者的一个创新点。Faster R-CNN中的九个Anchor Box的宽高是事先设定好的比例大小，一共设定三个面积大小的矩形框，每个矩形框有三个宽高比：1:1，2:1，1:2，总共九个框。而在v2中，Anchor Box的宽高不经过人为获得，而是将训练数据集中的矩形框全部拿出来，用kmeans聚类得到先验框的宽和高。例如使用5个Anchor Box, 那么kmeans聚类的类别中心个数设置为5。<br>加入了聚类操作之后，引入Anchor Box之后，mAP上升。<br>需要强调的是，聚类必须要定义聚类点（矩形框）之间的距离函数，文中使用（1-IOU）数值作为两个矩形框的的距离函数，这里的运用也是非常的巧妙。</li><li>Direct location prediction（绝对位置预测）<br>Yolo中的位置预测方法很清晰，就是相对于左上角的格点坐标预测偏移量。这里的Direct具体含义，应该是和其他算法框架对比后得到的。比如其他流行的位置预测公式是先预测一个系数，系数又需要与先验框的宽高相乘才能得到相较于参考点的位置偏移，而在yolov2中，系数通过一个激活函数直接产生偏移位置数值，与矩形框的宽高独立开，变得更加直接。</li><li>Fine-Grained Features（细粒度特征）<br>在26乘26的特征图，经过卷积层等，变为13乘13的特征图后，作者认为损失了很多细粒度的特征，导致小尺寸物体的识别效果不佳，所以在此加入了passthrough层。passthrough层就是将26乘26乘1的特征图，变成13乘13乘4的特征图，在这一次操作中不损失细粒度特征。</li><li>Multi-Scale Training（多尺寸训练）<br>很关键的一点是，Yolo v2中只有卷积层与池化层，所以对于网络的输入大小，并没有限制，整个网络的降采样倍数为32，只要输入的特征图尺寸为32的倍数即可，如果网络中有全连接层，就不是这样了。所以Yolo v2可以使用不同尺寸的输入图片训练。<br>作者使用的训练方法是，在每10个batch之后，就将图片resize成{320, 352, …, 608}中的一种。不同的输入，最后产生的格点数不同，比如输入图片是320乘320，那么输出格点是10乘10，如果每个格点的先验框个数设置为5，那么总共输出500个预测结果；如果输入图片大小是608乘608，输出格点就是19乘19，共1805个预测结果。<br>在引入了多尺寸训练方法后，迫使卷积核学习不同比例大小尺寸的特征。当输入设置为544乘544甚至更大，Yolo v2的mAP已经超过了其他的物体检测算法。</li></ol><h2 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h2><p><a href="https://zhuanlan.zhihu.com/p/76802514">【论文解读】Yolo三部曲解读——Yolov3</a><br><img src="https://user-images.githubusercontent.com/6218739/133880395-2f580763-b4fc-4aea-b36e-2d745834a1da.png" alt="yolov3"><br>Yolov3使用Darknet-53作为整个网络的分类骨干部分（见上图虚线部分）。<br>Darknet-53的架构如下图：<br><img src="https://user-images.githubusercontent.com/6218739/133880487-984b7259-6b63-42e4-8d6a-7ae420fb4591.png" alt="darknet53"><br>backbone部分由Yolov2时期的Darknet-19进化至Darknet-53，加深了网络层数，引入了Resnet中的跨层加和操作。Darknet-53处理速度每秒78张图，比Darknet-19慢不少，但是比同精度的ResNet快很多。Yolov3依然保持了高性能。</p><p>网络结构解析：</p><ol><li>Yolov3中，只有卷积层，通过调节卷积步长控制输出特征图的尺寸。所以对于输入图片尺寸没有特别限制。</li><li>Yolov3借鉴了金字塔特征图思想，小尺寸特征图用于检测大尺寸物体，而大尺寸特征图检测小尺寸物体。特征图的输出维度为$N \times N \times [3 \times (4+1+80)]$， $N \times N$为输出特征图格点数，一共3个Anchor框，每个框有4维预测框数值和1维预测框置信度，80维物体类别数。</li><li>Yolov3总共输出3个特征图，第一个特征图下采样32倍，第二个特征图下采样16倍，第三个下采样8倍。输入图像经过Darknet-53（无全连接层），再经过Yoloblock生成的特征图被当作两用，第一用为经过3乘3卷积层、1乘1卷积之后生成特征图一，第二用为经过1乘1卷积层加上采样层，与Darnet-53网络的中间层输出结果进行拼接，产生特征图二。同样的循环之后产生特征图三。</li><li>concat操作与加和操作的区别：加和操作来源于ResNet思想，将输入的特征图，与输出特征图对应维度进行相加，即$y=f(x)+x$；而concat操作源于DenseNet网络的设计思路，将特征图按照通道维度直接进行拼接，例如8乘8乘16的特征图与8乘8乘16的特征图拼接后生成8乘8乘32的特征图。</li><li>上采样层(upsample)：作用是将小尺寸特征图通过插值等方法，生成大尺寸图像。例如使用最近邻插值算法，将8乘8的图像变换为16乘16。上采样层不改变特征图的通道数。</li></ol><p>Yolo的整个网络，吸取了Resnet、Densenet、FPN的精髓，可以说是融合了目标检测当前业界最有效的全部技巧。</p><p>YOLOv3与YOLOv2和YOLOv1相比最大的改善就是对boundingbox进行了跨尺度预测(Prediction Across Scales)，提高YOLO模型对不同尺度对象的预测精度。<br><img src="https://user-images.githubusercontent.com/6218739/133882919-4d3ede76-ff3d-4435-a4c0-a577c181bd2d.png" alt="yolov3-output"><br><a href="https://zhuanlan.zhihu.com/p/75811997">YOLO_v3论文解读</a></p><p>结合上图看，卷积网络在79层后，经过下方几个黄色的卷积层得到一种尺度的检测结果。相比输入图像，这里用于检测的特征图有32倍的下采样。比如输入是416乘416的话，这里的特征图就是13乘13了。由于下采样倍数高，这里特征图的感受野比较大，因此适合检测图像中尺寸比较大的对象。<br>为了实现细粒度的检测，第79层的特征图又开始作上采样（从79层往右开始上采样卷积），然后与第61层特征图拼接（Concatenation），这样得到第91层较细粒度的特征图，同样经过几个卷积层后得到相对输入图像16倍下采样的特征图。它具有中等尺度的感受野，适合检测中等尺度的对象。<br>最后，第91层特征图再次上采样，并与第36层特征图拼接（Concatenation），最后得到相对输入图像8倍下采样的特征图。它的感受野最小，适合检测小尺寸的对象。<br>随着输出的特征图的数量和尺度的变化，先验框的尺寸也需要相应的调整。YOLO2已经开始采用K-means聚类得到先验框的尺寸，YOLO3延续了这种方法，为每种下采样尺度设定3种先验框，总共聚类出9种尺寸的先验框。在COCO数据集这9个先验框是：</p><script type="math/tex; mode=display">(10 \times 13)，(16 \times 30)，(33 \times 23)，(30 \times 61)，(62 \times 45)，(59 \times 119)，(116 \times 90)，(156 \times 198)，(373 \times 326)</script><p>分配上，在最小的13乘13特征图上（有最大的感受野）应用较大的先验框$(116 \times 90)，(156 \times 198)，(373 \times 326)$，适合检测较大的对象。中等的26乘26特征图上（中等感受野）应用中等的先验框$(30 \times 61)，(62 \times 45)，(59 \times 119)$，适合检测中等大小的对象。较大的52乘52特征图上（较小的感受野）应用较小的先验框$(10 \times 13)，(16 \times 30)，(33 \times 23)$，适合检测较小的对象。</p><p>YOLOv3前向解码过程：<br>根据不同的输入尺寸，会得到不同大小的输出特征图，以图二中输入图片$256 \times 256 \times 3$为例，输出的特征图为$8 \times 8 \times 255$、$16 \times 16 \times 255$、$32 \times 32 \times 255$。在Yolov3的设计中，每个特征图的每个格子中，都配置3个不同的先验框（就是下面的锚框），所以最后三个特征图，这里暂且reshape为$8 \times 8 \times 3 \times 85$、$16 \times 16 \times 3 \times 85$、$32 \times 32 \times 3 \times 85$，这样更容易理解，在代码中也是reshape成这样之后更容易操作。<br>三张特征图就是整个Yolo输出的检测结果，检测框位置（4维）、检测置信度（1维）、类别（80维）都在其中，加起来正好是85维。特征图最后的维度85，代表的就是这些信息，而特征图其他维度$N \times N \times 3$，$N \times N$代表了检测框的参考位置信息，3是3个不同尺度的先验框。</p><p>三个特征图一共可以解码出 $8 × 8 × 3 + 16 × 16 × 3 + 32 × 32 × 3 = 4032$ 个box以及相应的类别、置信度。这4032个box，在训练和推理时，使用方法不一样：</p><ol><li>训练时4032个box全部送入打标签函数，进行后一步的标签以及损失函数的计算。</li><li>推理时，选取一个置信度阈值，过滤掉低阈值box，再经过nms（非极大值抑制），就可以输出整个网络的预测结果了。</li></ol><p>YOLOv3训练策略（反向过程）：</p><ol><li>预测框一共分为三种情况：正例（positive）、负例（negative）、忽略样例（ignore）。</li><li>正例：任取一个ground truth，与4032个框全部计算IOU，IOU最大的预测框，即为正例。并且一个预测框，只能分配给一个ground truth。例如第一个ground truth已经匹配了一个正例检测框，那么下一个ground truth，就在余下的4031个检测框中，寻找IOU最大的检测框作为正例。ground truth的先后顺序可忽略。正例产生置信度loss、检测框loss、类别loss。预测框为对应的ground truth box标签；类别标签对应类别为1，其余为0；置信度标签为1。</li><li>忽略样例：正例除外，与任意一个ground truth的IOU大于阈值（论文中使用0.5），则为忽略样例。忽略样例不产生任何loss。</li><li>负例：正例除外（与ground truth计算后IOU最大的检测框，但是IOU小于阈值，仍为正例），与全部ground truth的IOU都小于阈值（0.5），则为负例。负例只有置信度产生loss，置信度标签为0。</li></ol><h1 id="YOLOv3源码"><a href="#YOLOv3源码" class="headerlink" title="YOLOv3源码"></a>YOLOv3源码</h1><p>从头实现YOLOv3的源码见：<br><a href="https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/object_detection/YOLOv3">YOLOv3 in PyTorch</a><br>该源码的视频讲解见：<br><a href="https://www.bilibili.com/video/BV1bo4y1X78v?spm_id_from=333.999.0.0">YOLOv3 from Scratch</a></p><h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><p>整个YOLOv3的模型架构如下配置：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于里面的元素</span></span><br><span class="line"><span class="comment"># 如果是元组，代表：(输出通道, 卷积核尺寸, 步长)</span></span><br><span class="line"><span class="comment"># YOLOv3中所有的卷积块（注意是卷积块，它由卷积层+批标准化层+LeakyReLU层构成）都是相同的，在下面的代码中用CNNBlock类实现</span></span><br><span class="line"><span class="comment"># 如果是列表，&quot;B&quot;代表残差块Residual Block，后面的次数代表重复次数，在下面用ResidualBlock类实现</span></span><br><span class="line"><span class="comment"># 如果是字符，那么&quot;S&quot;代表Scale不同尺度预测块，在此处计算损失，在下面用ScalePrediction类实现</span></span><br><span class="line"><span class="comment"># &quot;U&quot;代表Upsampling上采样，且与上一层进行连接，生成新的尺度预测</span></span><br><span class="line">config = [</span><br><span class="line">    (<span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">64</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">1</span>],</span><br><span class="line">    (<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">2</span>],</span><br><span class="line">    (<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">8</span>],</span><br><span class="line">    (<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">8</span>],</span><br><span class="line">    (<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    [<span class="string">&quot;B&quot;</span>, <span class="number">4</span>],  <span class="comment"># 到这里就是Darknet-53 backbone，53是全部卷积层的个数，它会在imagenet上进行预训练</span></span><br><span class="line">    (<span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;S&quot;</span>,</span><br><span class="line">    (<span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;U&quot;</span>,</span><br><span class="line">    (<span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;S&quot;</span>,</span><br><span class="line">    (<span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;U&quot;</span>,</span><br><span class="line">    (<span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">&quot;S&quot;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><br>首先看一下CNN卷积块的实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNNBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 此处会加上一个BN层的开关，如果关了BN层，就相当于是只有卷积层，而不是卷积块</span></span><br><span class="line">   <span class="comment"># 不加BN和ReLU层的纯卷积层是会在尺度预测的地方用到，即网络末端的卷积是纯卷积层</span></span><br><span class="line">   <span class="comment"># 同时使用kwargs参数接收其他参数，比如kerneal size，stride，padding等参数</span></span><br><span class="line">   <span class="comment"># 在整个网络中图像的宽高变化即维度压缩，是通过卷积块的stride参数来实现的</span></span><br><span class="line">   <span class="comment"># 由下面的分析可知，在残差块中图像宽高不变，但两个残差块中间的卷积块的stride为2，此时会对图像的宽高进行压缩减半</span></span><br><span class="line">   <span class="comment"># 整个网络中压缩最厉害的分支是一共压缩了5次，即压缩了32倍，另外两支分别压缩了16倍和8倍</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, bn_act=<span class="literal">True</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">       <span class="comment"># 如果使用了BN，那么偏置这个参数就没必要了，所以此处会根据BN层的有无进行偏置bias参数的开关</span></span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, bias=<span class="keyword">not</span> bn_act, **kwargs)</span><br><span class="line">        self.bn = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.leaky = nn.LeakyReLU(<span class="number">0.1</span>)</span><br><span class="line">        self.use_bn_act = bn_act</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.use_bn_act:</span><br><span class="line">            <span class="keyword">return</span> self.leaky(self.bn(self.conv(x)))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure><br>再看一下残差块的实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResidualBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 这里给出了是否使用残差连接的开关，在darknet-53部分都是打开残差连接，但到了尺度预测部分，该残差块是关闭了残差连接</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, channels, use_residual=<span class="literal">True</span>, num_repeats=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 整个残差块是一个ModuleList</span></span><br><span class="line">        self.layers = nn.ModuleList()</span><br><span class="line">       <span class="comment"># 根据重复次数进行循环</span></span><br><span class="line">        <span class="keyword">for</span> repeat <span class="keyword">in</span> <span class="built_in">range</span>(num_repeats):</span><br><span class="line">            self.layers += [</span><br><span class="line">                <span class="comment"># 每个残差块中的第一个卷积块都是通道数减半，卷积核尺寸为1，步长是默认的1，填充是默认的0，因此图像的输入和输出宽高不变</span></span><br><span class="line">            <span class="comment"># 第二个卷积块通道数变为两倍，卷积核尺寸为3，填充为1，步长仍是默认的1，因此图像的输入和输出宽高不变</span></span><br><span class="line">            <span class="comment"># 所以，总的来说，经过一个残差块后，图像的通道数、宽和高都不会变</span></span><br><span class="line">                nn.Sequential(</span><br><span class="line">                    CNNBlock(channels, channels // <span class="number">2</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">                    CNNBlock(channels // <span class="number">2</span>, channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                )</span><br><span class="line">            ]</span><br><span class="line"></span><br><span class="line">        self.use_residual = use_residual</span><br><span class="line">        self.num_repeats = num_repeats</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            <span class="comment"># 如果启用残差连接，那么就直接将x和经过处理后的x相加</span></span><br><span class="line">            <span class="keyword">if</span> self.use_residual:</span><br><span class="line">                x = x + layer(x)</span><br><span class="line">            <span class="comment"># 如果没有启用残差连接，那么就直接处理x，不管作为输入的x</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x = layer(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p><p>再来看不同尺度预测的类实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScalePrediction</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.pred = nn.Sequential(</span><br><span class="line">            <span class="comment"># 在每个尺度预测块中，先用一个卷积块将通道数加倍，同时通过设置卷积核尺寸为3，填充为1，步长是默认的1，来保持宽高不变</span></span><br><span class="line">            CNNBlock(in_channels, <span class="number">2</span> * in_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            <span class="comment"># 然后将得到的特征图通过一个卷积块转化为最终想要的向量的模样</span></span><br><span class="line">         <span class="comment"># 3指的是对于对于每一个grid cell，都有3个anchor boxes</span></span><br><span class="line">         <span class="comment"># 对于每一个anchor box，都需要有num_classes+5个元素，前面是类别数目，比如20，5是包含了x, y, w, h和置信度</span></span><br><span class="line">         <span class="comment"># 注意这里不使用BN层，同时卷积核为1，步长是默认的1，填充是默认的0，因此宽高不变</span></span><br><span class="line">            CNNBlock(</span><br><span class="line">                <span class="number">2</span> * in_channels, (num_classes + <span class="number">5</span>) * <span class="number">3</span>, bn_act=<span class="literal">False</span>, kernel_size=<span class="number">1</span></span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            self.pred(x)</span><br><span class="line">            <span class="comment"># 对x进行预测后，需要对结果进行reshape，形状依次为batch size、3、类别数+5、特征图宽度、特征图高度</span></span><br><span class="line">            .reshape(x.shape[<span class="number">0</span>], <span class="number">3</span>, self.num_classes + <span class="number">5</span>, x.shape[<span class="number">2</span>], x.shape[<span class="number">3</span>])</span><br><span class="line">            <span class="comment"># 再交换一下维度，把宽、高提到(类别数+5)的前面</span></span><br><span class="line">         <span class="comment"># 比如某一个尺度预测后，得到的向量形状为N x 3 x 13 x 13 x (5+num_classes)，grid cell就是13x13大小</span></span><br><span class="line">            .permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line">        )</span><br></pre></td></tr></table></figure></p><p>最后看整个模型的架构，即将上面的组件组合起来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YOLOv3</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 输入通道默认为3， 类别数默认为80</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, num_classes=<span class="number">80</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.layers = self._create_conv_layers()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_conv_layers</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 将所有模型组件都放在ModuleList中</span></span><br><span class="line">        layers = nn.ModuleList()</span><br><span class="line">        in_channels = self.in_channels</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 开始解析上面的config配置</span></span><br><span class="line">        <span class="keyword">for</span> module <span class="keyword">in</span> config:</span><br><span class="line">            <span class="comment"># 如果元素是个元组，代表它是个卷积块</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(module, <span class="built_in">tuple</span>):</span><br><span class="line">                <span class="comment"># 取出卷积块的相应配置</span></span><br><span class="line">                out_channels, kernel_size, stride = module</span><br><span class="line">                <span class="comment"># 往整个网络里添加卷积块</span></span><br><span class="line">                layers.append(</span><br><span class="line">                    CNNBlock(</span><br><span class="line">                        in_channels,</span><br><span class="line">                        out_channels,</span><br><span class="line">                        kernel_size=kernel_size,</span><br><span class="line">                        stride=stride,</span><br><span class="line">                        <span class="comment"># 如果卷积核为3，则填充为1，否则就填充为0，这样是为了当卷积核为3、步长为2时，填充设为1，此时宽高减半</span></span><br><span class="line">                  <span class="comment"># Pytorch默认卷积层的尺寸计算是向下取整，即(k+2*1-3)/2+1=k/2+floor(-0.5)+1=k/2-1+1=k/2</span></span><br><span class="line">                        padding=<span class="number">1</span> <span class="keyword">if</span> kernel_size == <span class="number">3</span> <span class="keyword">else</span> <span class="number">0</span>,</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line">                <span class="comment"># 更新通道数</span></span><br><span class="line">                in_channels = out_channels</span><br><span class="line"></span><br><span class="line">         <span class="comment"># 如果元素是个列表，代表是残差块</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(module, <span class="built_in">list</span>):</span><br><span class="line">                <span class="comment"># 取出残差块的相应配置</span></span><br><span class="line">                num_repeats = module[<span class="number">1</span>]</span><br><span class="line">                <span class="comment"># 往整个网络里添加残差块</span></span><br><span class="line">                layers.append(ResidualBlock(in_channels, num_repeats=num_repeats,))</span><br><span class="line"></span><br><span class="line">         <span class="comment"># 如果元素是个字符，那么就进入尺度预测模块</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(module, <span class="built_in">str</span>):</span><br><span class="line">                <span class="comment"># 如果是S，代表要进行在某一尺度上的预测了</span></span><br><span class="line">                <span class="keyword">if</span> module == <span class="string">&quot;S&quot;</span>:</span><br><span class="line">                    layers += [</span><br><span class="line">                        <span class="comment"># 下面这三块的网络架构参考下面那张YOLOv3的架构图</span></span><br><span class="line">                  <span class="comment"># 原码中残差块只重复了1次，为了与下面架构图中的YoloBlock相对应，这里改为重复2次，影响不大，因为在残差块中不改变图像大小</span></span><br><span class="line">                  <span class="comment"># 同时注意此时残差块关闭了残差连接</span></span><br><span class="line">                        ResidualBlock(in_channels, use_residual=<span class="literal">False</span>, num_repeats=<span class="number">2</span>),</span><br><span class="line">                        CNNBlock(in_channels, in_channels // <span class="number">2</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">                        ScalePrediction(in_channels // <span class="number">2</span>, num_classes=self.num_classes),</span><br><span class="line">                    ]</span><br><span class="line">                    <span class="comment"># 更新一下通道数</span></span><br><span class="line">                    in_channels = in_channels // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">             <span class="comment"># 如果是U，则进入上采样</span></span><br><span class="line">                <span class="keyword">elif</span> module == <span class="string">&quot;U&quot;</span>:</span><br><span class="line">                    layers.append(nn.Upsample(scale_factor=<span class="number">2</span>),)</span><br><span class="line">                    <span class="comment"># 通道数变为3倍，原因是这个地方进行了通道连接concatenation操作</span></span><br><span class="line">               <span class="comment"># 特别注意的是，不要在这个地方推导图像在整个模型中的处理过程，因为此时会发现前后通道数是不符的，因为通道一下从256跳到了768</span></span><br><span class="line">               <span class="comment"># 这个地方不是forward函数，并不是真正的数据处理过程，可以理解成这个地方仅是模型架构定义</span></span><br><span class="line">                    in_channels = in_channels * <span class="number">3</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 每一个尺度下都有一个output，这里用一个列表来承载三个output</span></span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="comment"># 存放进入不同预测分支的中间计算结果</span></span><br><span class="line">        route_connections = []</span><br><span class="line">        <span class="comment"># 对网络中的每一层进行遍历</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            <span class="comment"># 如果是尺度预测层，表示进入某一尺度的预测阶段，即进入某一个预测分支</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer, ScalePrediction):</span><br><span class="line">                <span class="comment"># 将预测结果添加进outputs中，注意这个地方是对x的一个分叉计算</span></span><br><span class="line">            <span class="comment"># 即x在这里走了两条路，一条路是进入尺度预测模块进行计算，另一条路是继续呆在主分支中，用于后续计算</span></span><br><span class="line">                outputs.append(layer(x))</span><br><span class="line">                <span class="comment"># 返回到主分支中</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">         <span class="comment"># 对常规的网络层进行计算，包含卷积块和重复次数不为8的残差块</span></span><br><span class="line">            x = layer(x)</span><br><span class="line"></span><br><span class="line">         <span class="comment"># 对于重复次数为8的残差块，由架构图可知，都是在这里进入不同的尺度预测分支</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer, ResidualBlock) <span class="keyword">and</span> layer.num_repeats == <span class="number">8</span>:</span><br><span class="line">                <span class="comment"># 将需要进入某分支的结果存放起来</span></span><br><span class="line">                route_connections.append(x)</span><br><span class="line"></span><br><span class="line">         <span class="comment"># 如果是遇到上采样模块</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(layer, nn.Upsample):</span><br><span class="line">                <span class="comment"># 就会将当前x与存放中间结果的route中的最后一个中间结果进行连接concatenation</span></span><br><span class="line">            <span class="comment"># 这个地方会将通道数变为3倍，因为上采样后的图像为n_channel，原主分支中的图像为2*n_channel，连接后就变为3*n_channel</span></span><br><span class="line">                x = torch.cat([x, route_connections[-<span class="number">1</span>]], dim=<span class="number">1</span>)</span><br><span class="line">                <span class="comment"># 用完最后一个元素就把它丢了，这样就能在下一次取到上一个存储的中间结果</span></span><br><span class="line">                route_connections.pop()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 最终outputs里是存放了三个尺度的预测模型</span></span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><br>YOLOv3架构图重新贴一下：<br><img src="https://user-images.githubusercontent.com/6218739/133880395-2f580763-b4fc-4aea-b36e-2d745834a1da.png" alt="yolov3"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>作者提供了YOLO格式的PASCAL VOC和MS COCO数据集的下载，分别在下面链接：<br><a href="https://www.kaggle.com/aladdinpersson/pascal-voc-dataset-used-in-yolov3-video">Pascal voc dataset used in YOLOv3 video</a><br><a href="https://www.kaggle.com/dataset/79abcc2659dc745fddfba1864438afb2fac3fabaa5f37daa8a51e36466db101e">MS-COCO-YOLOv3</a><br>关于数据集的格式可以参见下面的介绍：<br><a href="https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data">Train Custom Data</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YOLODataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">        self,</span></span></span><br><span class="line"><span class="function"><span class="params">        csv_file, <span class="comment"># csv文件路径</span></span></span></span><br><span class="line"><span class="function"><span class="params">        img_dir, <span class="comment"># 图像文件路径</span></span></span></span><br><span class="line"><span class="function"><span class="params">        label_dir, <span class="comment"># 标签文件路径</span></span></span></span><br><span class="line"><span class="function"><span class="params">        anchors, <span class="comment"># 九个锚框</span></span></span></span><br><span class="line"><span class="function"><span class="params">        image_size=<span class="number">416</span>, <span class="comment"># 图像尺寸</span></span></span></span><br><span class="line"><span class="function"><span class="params">        S=[<span class="number">13</span>, <span class="number">26</span>, <span class="number">52</span>], <span class="comment"># 三个特征图大小</span></span></span></span><br><span class="line"><span class="function"><span class="params">        C=<span class="number">20</span>, <span class="comment"># 类别数</span></span></span></span><br><span class="line"><span class="function"><span class="params">        transform=<span class="literal">None</span>, <span class="comment"># 图像变换</span></span></span></span><br><span class="line"><span class="function"><span class="params">    </span>):</span></span><br><span class="line">        self.annotations = pd.read_csv(csv_file) <span class="comment"># 图像和标签成对出现</span></span><br><span class="line">        self.img_dir = img_dir</span><br><span class="line">        self.label_dir = label_dir</span><br><span class="line">        self.image_size = image_size</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.S = S</span><br><span class="line">        self.anchors = torch.tensor(anchors[<span class="number">0</span>] + anchors[<span class="number">1</span>] + anchors[<span class="number">2</span>])  <span class="comment"># 将三个尺度下的三个锚框连起来，注意两个list相加就是join的效果</span></span><br><span class="line">        self.num_anchors = self.anchors.shape[<span class="number">0</span>]</span><br><span class="line">        self.num_anchors_per_scale = self.num_anchors // <span class="number">3</span></span><br><span class="line">        self.C = C</span><br><span class="line">        self.ignore_iou_thresh = <span class="number">0.5</span> <span class="comment"># 这个阈值用来区分忽略样例和负例，详见上面的解析</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.annotations)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        label_path = os.path.join(self.label_dir, self.annotations.iloc[index, <span class="number">1</span>]) <span class="comment"># 1就是代表第二列，即标签列</span></span><br><span class="line">        bboxes = np.roll(np.loadtxt(fname=label_path, delimiter=<span class="string">&quot; &quot;</span>, ndmin=<span class="number">2</span>), <span class="number">4</span>, axis=<span class="number">1</span>).tolist() <span class="comment"># 得到的边界框格式为(x, y, w, h, 类别)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读入图像文件</span></span><br><span class="line">        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, <span class="number">0</span>])</span><br><span class="line">        image = np.array(Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&quot;RGB&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 图像增强变换</span></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            augmentations = self.transform(image=image, bboxes=bboxes)</span><br><span class="line">            image = augmentations[<span class="string">&quot;image&quot;</span>]</span><br><span class="line">            bboxes = augmentations[<span class="string">&quot;bboxes&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最终目标是在三个特征图尺度上，每个尺度的每个格点上都有(self.num_anchors // 3)个预测框，每个预测框上都有6个分量，即[置信度标签, x, y, w, h, 类别]</span></span><br><span class="line">        <span class="comment"># 置信度标签为1，代表正例；标签为-1，代表忽略样例；标签为0，代表负例。</span></span><br><span class="line">        targets = [torch.zeros((self.num_anchors // <span class="number">3</span>, S, S, <span class="number">6</span>)) <span class="keyword">for</span> S <span class="keyword">in</span> self.S]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对该图像中的所有的边界框进行循环，目的是为了确定哪个锚框、哪个格点与其对应</span></span><br><span class="line">        <span class="keyword">for</span> box <span class="keyword">in</span> bboxes: </span><br><span class="line">            <span class="comment"># 确定与边界框对应的锚框是通过计算两者之间的IoU</span></span><br><span class="line">            <span class="comment"># box的第2、3元素就是宽度和高度</span></span><br><span class="line">            <span class="comment"># 这里的IoU计算相当于将锚框和边界框的中心放在一块，然后根据它们的宽高来计算</span></span><br><span class="line">            <span class="comment"># 即为了确定哪一种形状的锚框与该边界框最相近</span></span><br><span class="line">            iou_anchors = iou(torch.tensor(box[<span class="number">2</span>:<span class="number">4</span>]), self.anchors)</span><br><span class="line">            <span class="comment"># 找出重合度最大的即最好的锚框</span></span><br><span class="line">            anchor_indices = iou_anchors.argsort(descending=<span class="literal">True</span>, dim=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 取出该边界框的x, y, w, h</span></span><br><span class="line">            x, y, width, height, class_label = box</span><br><span class="line">            <span class="comment"># 下面这个列表初始化为False，但最终目的是变为True，即保证在每个尺度下该边界框都有对应的锚框</span></span><br><span class="line">            has_anchor = [<span class="literal">False</span>] * <span class="number">3</span>  <span class="comment"># each scale should have one anchor</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 因为一共有9个锚框，但分布在3个尺度下，下面就是将具体的锚框与它所属的尺度对应起来，即找到在每个尺度下的最好的锚框是哪个，将其判断为正例，其他不好的锚框进一步判断为负例还是忽略样例</span></span><br><span class="line">            <span class="comment"># 即对所有的锚框都会做判断，正例的锚框就会计算置信度loss、检测框loss、类别loss，负例只会计算置信度loss，忽略样例则什么loss都不计算</span></span><br><span class="line">            <span class="comment"># 先从9个锚框中重合度最大的锚框开始进行循环</span></span><br><span class="line">            <span class="keyword">for</span> anchor_idx <span class="keyword">in</span> anchor_indices:</span><br><span class="line">                <span class="comment"># 根据锚框的索引和每个尺度下拥有的锚框数量，就可以确定锚框所在的尺度</span></span><br><span class="line">                <span class="comment"># 比如如果锚框索引为8，且每个尺度下有3个锚框，那么scale_idx就是2，即第3个尺度，因此scale_idx就是该锚框所属的尺度的索引</span></span><br><span class="line">                scale_idx = anchor_idx // self.num_anchors_per_scale</span><br><span class="line">                <span class="comment"># 上述锚框索引为8，指的是该锚框在所有锚框中的索引，下面就是计算该锚框在该尺度下的索引，即anchor_on_scale就是2，也就是该尺度下该锚框是第3个</span></span><br><span class="line">                anchor_on_scale = anchor_idx % self.num_anchors_per_scale</span><br><span class="line">                <span class="comment"># 获取该尺度下的grid cell的个数，即格点个数</span></span><br><span class="line">                S = self.S[scale_idx]</span><br><span class="line">                <span class="comment"># 提醒一下：边界框的x和y坐标是其中心相对于整张图像的位置</span></span><br><span class="line">                <span class="comment"># 下面就是计算边界框属于图像中的哪个格点</span></span><br><span class="line">                <span class="comment"># 比如假设整个图像宽为W，那么边界框绝对位置就在W*x，而每个格点的宽度为W/S，那么在哪个格点就是W*x/(W/S)=S*x</span></span><br><span class="line">                <span class="comment"># 这里需要注意的是x是宽，但在矩阵中是列，即j,</span></span><br><span class="line">                <span class="comment"># 而y是高，在矩阵中是行，即i</span></span><br><span class="line">                i, j = <span class="built_in">int</span>(S * y), <span class="built_in">int</span>(S * x)  <span class="comment"># which cell</span></span><br><span class="line">                <span class="comment"># 下面这一行就是对于这一边界框，取出某一尺度下的锚框、格点及置信度（0元素就是代表是一个物体的可能性即置信度）</span></span><br><span class="line">                <span class="comment"># 刚开始anchor_taken都是0，表明在该尺度的该锚框没有被取走或说没有被判断，非0的话又有两种，1是代表是正例，-1代表是忽略样例</span></span><br><span class="line">                anchor_taken = targets[scale_idx][anchor_on_scale, i, j, <span class="number">0</span>]</span><br><span class="line">                <span class="comment"># 如果该尺度下（或称该格点）的该锚框没有被判断，且该尺度上之前没有确定锚框（即还没有出现正例）</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> anchor_taken <span class="keyword">and</span> <span class="keyword">not</span> has_anchor[scale_idx]:</span><br><span class="line">                    <span class="comment"># 就把第0个元素，即是一个物体的置信度置为1</span></span><br><span class="line">                    targets[scale_idx][anchor_on_scale, i, j, <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">                    <span class="comment"># 计算边界框的中心在格点中的相对位置</span></span><br><span class="line">                    x_cell, y_cell = S * x - j, S * y - i  <span class="comment"># both between [0,1]</span></span><br><span class="line">                    <span class="comment"># 计算边界框的宽高相对于格点的大小</span></span><br><span class="line">                    <span class="comment"># 仍然假设整张图像宽为W，边界框的绝对宽度就是W*width，那么它相对于格点的大小就是W*width/(W/S)=width*S</span></span><br><span class="line">                    width_cell, height_cell = (</span><br><span class="line">                        width * S,</span><br><span class="line">                        height * S,</span><br><span class="line">                    )  <span class="comment"># can be greater than 1 since it&#x27;s relative to cell</span></span><br><span class="line">                    box_coordinates = torch.tensor(</span><br><span class="line">                        [x_cell, y_cell, width_cell, height_cell]</span><br><span class="line">                    )</span><br><span class="line">                    <span class="comment"># 然后把上面的边界框相对于格点的相对位置和相对大小信息都存储到targets相应元素中，与具体的尺度、锚框和格点进行匹配。</span></span><br><span class="line">                    targets[scale_idx][anchor_on_scale, i, j, <span class="number">1</span>:<span class="number">5</span>] = box_coordinates</span><br><span class="line">                    <span class="comment"># 将物体类别也存储到相应元素</span></span><br><span class="line">                    targets[scale_idx][anchor_on_scale, i, j, <span class="number">5</span>] = <span class="built_in">int</span>(class_label)</span><br><span class="line">                    <span class="comment"># 将该尺度下是否确定了锚框置为True，即该锚框为正例</span></span><br><span class="line">                    has_anchor[scale_idx] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 如果已经出现了正例，但该锚框还没有被判断，即anchor_taken=0</span></span><br><span class="line">                <span class="comment"># 此时再判断该锚框与边界框的IoU是否大于阈值，如果大于阈值，且因为其不是正例，那么就将其置信度标签置为-1，即它为忽略样例，不参与损失计算</span></span><br><span class="line">                <span class="comment"># 这种情况出现在在该尺度上（或称在该格点上），有多个锚框都能与边界框吻合较好，但只取最好的那个</span></span><br><span class="line">                <span class="comment"># 但如果IoU小于阈值，那么其置信度标签仍为0，代表负例，会产生置信度loss，但不会产生其他类型的损失</span></span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> anchor_taken <span class="keyword">and</span> iou_anchors[anchor_idx] &gt; self.ignore_iou_thresh:</span><br><span class="line">                    targets[scale_idx][anchor_on_scale, i, j, <span class="number">0</span>] = -<span class="number">1</span>  <span class="comment"># ignore prediction</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image, <span class="built_in">tuple</span>(targets)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="损失计算"><a href="#损失计算" class="headerlink" title="损失计算"></a>损失计算</h2><p>YOLOv3中的损失有三种，一种是xywh带来的误差，即检测框loss；一种是置信度带来的误差，即是否是个物体obj带来的loss，称为置信度loss；一种是类别带来的误差，称为类别loss。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YoloLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.mse = nn.MSELoss() <span class="comment"># 均方差损失计算</span></span><br><span class="line">        self.bce = nn.BCEWithLogitsLoss() <span class="comment"># 加了Sigmoid的二进制交叉熵损失</span></span><br><span class="line">        self.entropy = nn.CrossEntropyLoss() <span class="comment"># 交叉熵损失</span></span><br><span class="line">        self.sigmoid = nn.Sigmoid() </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 确定损失函数中的各个权重常数，用来控制不同loss之间的比例</span></span><br><span class="line">        self.lambda_class = <span class="number">1</span> <span class="comment"># 类别损失权重常数</span></span><br><span class="line">        self.lambda_noobj = <span class="number">10</span> <span class="comment"># 负例损失权重常数</span></span><br><span class="line">        self.lambda_obj = <span class="number">1</span> <span class="comment"># 正例损失权重常数</span></span><br><span class="line">        self.lambda_box = <span class="number">10</span> <span class="comment"># 检测框损失权重常数</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, predictions, target, anchors</span>):</span></span><br><span class="line">        <span class="comment"># 判断每个尺度上的格点上是否是物体，即正例还是负例</span></span><br><span class="line">        <span class="comment"># 1为正例，0为负例，-1则为忽略样例</span></span><br><span class="line">        obj = target[..., <span class="number">0</span>] == <span class="number">1</span>  <span class="comment"># in paper this is Iobj_i</span></span><br><span class="line">        noobj = target[..., <span class="number">0</span>] == <span class="number">0</span>  <span class="comment"># in paper this is Inoobj_i</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ======================= #</span></span><br><span class="line">        <span class="comment">#   负例造成的置信度损失    #</span></span><br><span class="line">        <span class="comment"># ======================= #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用二进制交叉熵计算损失</span></span><br><span class="line">        no_object_loss = self.bce(</span><br><span class="line">            <span class="comment"># 取出置信度数值，即第0个元素</span></span><br><span class="line">            <span class="comment"># 这里使用0:1的形式，而不是直接使用0来取得元素，是为了保持维度不变</span></span><br><span class="line">            <span class="comment"># [noobj] 是使用了numpy的布尔索引，从而取出那些负例</span></span><br><span class="line">            (predictions[..., <span class="number">0</span>:<span class="number">1</span>][noobj]), (target[..., <span class="number">0</span>:<span class="number">1</span>][noobj]),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ==================== #</span></span><br><span class="line">        <span class="comment">#   正例造成的置信度损失 #</span></span><br><span class="line">        <span class="comment"># ==================== #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这个地方正例损失按上面的解析应该使用一个简单的bce即可，同时置信度标签在yolov3中是1和0二分类，而这里原作者使用的是IoU来作为置信度标签，即如下形式：</span></span><br><span class="line">        object_loss = self.bce(</span><br><span class="line">            (predictions[..., <span class="number">0</span>:<span class="number">1</span>][obj]), (target[..., <span class="number">0</span>:<span class="number">1</span>][obj]),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># # 原来的代码中是如下形式，这里先不仔细研究异同了</span></span><br><span class="line">        <span class="comment"># anchors = anchors.reshape(1, 3, 1, 1, 2)</span></span><br><span class="line">        <span class="comment"># box_preds = torch.cat([self.sigmoid(predictions[..., 1:3]), torch.exp(predictions[..., 3:5]) * anchors], dim=-1)</span></span><br><span class="line">        <span class="comment"># ious = intersection_over_union(box_preds[obj], target[..., 1:5][obj]).detach()</span></span><br><span class="line">        <span class="comment"># object_loss = self.mse(self.sigmoid(predictions[..., 0:1][obj]), ious * target[..., 0:1][obj])</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ======================== #</span></span><br><span class="line">        <span class="comment">#  检测框损失               #</span></span><br><span class="line">        <span class="comment"># ======================== #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这个地方涉及检测框的解码部分</span></span><br><span class="line">        <span class="comment"># 注意只取出正例造成的损失</span></span><br><span class="line">        predictions[..., <span class="number">1</span>:<span class="number">3</span>] = self.sigmoid(predictions[..., <span class="number">1</span>:<span class="number">3</span>])  <span class="comment"># x, y坐标</span></span><br><span class="line">        target[..., <span class="number">3</span>:<span class="number">5</span>] = torch.log(</span><br><span class="line">            (<span class="number">1e-16</span> + target[..., <span class="number">3</span>:<span class="number">5</span>] / anchors)</span><br><span class="line">        )  <span class="comment"># width, height coordinates</span></span><br><span class="line">        box_loss = self.mse(predictions[..., <span class="number">1</span>:<span class="number">5</span>][obj], target[..., <span class="number">1</span>:<span class="number">5</span>][obj])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ================== #</span></span><br><span class="line">        <span class="comment">#   类别损失   #</span></span><br><span class="line">        <span class="comment"># ================== #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算交叉熵损失，注意只取出正例造成的损失</span></span><br><span class="line">        class_loss = self.entropy(</span><br><span class="line">            (predictions[..., <span class="number">5</span>:][obj]), (target[..., <span class="number">5</span>][obj].long()),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment">#print(&quot;__________________________________&quot;)</span></span><br><span class="line">        <span class="comment">#print(self.lambda_box * box_loss)</span></span><br><span class="line">        <span class="comment">#print(self.lambda_obj * object_loss)</span></span><br><span class="line">        <span class="comment">#print(self.lambda_noobj * no_object_loss)</span></span><br><span class="line">        <span class="comment">#print(self.lambda_class * class_loss)</span></span><br><span class="line">        <span class="comment">#print(&quot;\n&quot;)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            self.lambda_box * box_loss</span><br><span class="line">            + self.lambda_obj * object_loss</span><br><span class="line">            + self.lambda_noobj * no_object_loss</span><br><span class="line">            + self.lambda_class * class_loss</span><br><span class="line">        )</span><br></pre></td></tr></table></figure></p><h2 id="超参数配置文件"><a href="#超参数配置文件" class="headerlink" title="超参数配置文件"></a>超参数配置文件</h2><p>此处就是将超参数配置都摘出来放在一个统一的配置文件中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">DATASET = <span class="string">&#x27;PASCAL_VOC&#x27;</span></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="comment"># seed_everything()  # If you want deterministic behavior</span></span><br><span class="line">NUM_WORKERS = <span class="number">4</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">IMAGE_SIZE = <span class="number">416</span></span><br><span class="line">NUM_CLASSES = <span class="number">20</span> <span class="comment">#类别数</span></span><br><span class="line">LEARNING_RATE = <span class="number">1e-5</span></span><br><span class="line">WEIGHT_DECAY = <span class="number">1e-4</span></span><br><span class="line">NUM_EPOCHS = <span class="number">100</span></span><br><span class="line">CONF_THRESHOLD = <span class="number">0.05</span></span><br><span class="line">MAP_IOU_THRESH = <span class="number">0.5</span></span><br><span class="line">NMS_IOU_THRESH = <span class="number">0.45</span></span><br><span class="line">S = [IMAGE_SIZE // <span class="number">32</span>, IMAGE_SIZE // <span class="number">16</span>, IMAGE_SIZE // <span class="number">8</span>]</span><br><span class="line">PIN_MEMORY = <span class="literal">True</span></span><br><span class="line">LOAD_MODEL = <span class="literal">True</span></span><br><span class="line">SAVE_MODEL = <span class="literal">True</span></span><br><span class="line">CHECKPOINT_FILE = <span class="string">&quot;checkpoint.pth.tar&quot;</span></span><br><span class="line">IMG_DIR = DATASET + <span class="string">&quot;/images/&quot;</span></span><br><span class="line">LABEL_DIR = DATASET + <span class="string">&quot;/labels/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过在训练集上kmeans聚类得到的锚框的大小</span></span><br><span class="line">ANCHORS = [</span><br><span class="line">    [(<span class="number">0.28</span>, <span class="number">0.22</span>), (<span class="number">0.38</span>, <span class="number">0.48</span>), (<span class="number">0.9</span>, <span class="number">0.78</span>)],</span><br><span class="line">    [(<span class="number">0.07</span>, <span class="number">0.15</span>), (<span class="number">0.15</span>, <span class="number">0.11</span>), (<span class="number">0.14</span>, <span class="number">0.29</span>)],</span><br><span class="line">    [(<span class="number">0.02</span>, <span class="number">0.03</span>), (<span class="number">0.04</span>, <span class="number">0.07</span>), (<span class="number">0.08</span>, <span class="number">0.06</span>)],</span><br><span class="line">]  <span class="comment"># Note these have been rescaled to be between [0, 1]</span></span><br></pre></td></tr></table></figure></p><h2 id="训练函数"><a href="#训练函数" class="headerlink" title="训练函数"></a>训练函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fn</span>(<span class="params">train_loader, model, optimizer, loss_fn, scaler, scaled_anchors</span>):</span></span><br><span class="line">    <span class="comment"># 显示进度条</span></span><br><span class="line">    loop = tqdm(train_loader, leave=<span class="literal">True</span>)</span><br><span class="line">    losses = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loop):</span><br><span class="line">        x = x.to(config.DEVICE)</span><br><span class="line">        <span class="comment"># 三个不同尺度下的目标</span></span><br><span class="line">        y0, y1, y2 = (</span><br><span class="line">            y[<span class="number">0</span>].to(config.DEVICE),</span><br><span class="line">            y[<span class="number">1</span>].to(config.DEVICE),</span><br><span class="line">            y[<span class="number">2</span>].to(config.DEVICE),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.cuda.amp.autocast():</span><br><span class="line">            out = model(x)</span><br><span class="line">            <span class="comment"># 前面的损失函数需要在三个尺度下都要计算一遍</span></span><br><span class="line">            loss = (</span><br><span class="line">                loss_fn(out[<span class="number">0</span>], y0, scaled_anchors[<span class="number">0</span>])</span><br><span class="line">                + loss_fn(out[<span class="number">1</span>], y1, scaled_anchors[<span class="number">1</span>])</span><br><span class="line">                + loss_fn(out[<span class="number">2</span>], y2, scaled_anchors[<span class="number">2</span>])</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        losses.append(loss.item())</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        scaler.scale(loss).backward()</span><br><span class="line">        scaler.step(optimizer)</span><br><span class="line">        scaler.update()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update progress bar</span></span><br><span class="line">        mean_loss = <span class="built_in">sum</span>(losses) / <span class="built_in">len</span>(losses)</span><br><span class="line">        loop.set_postfix(loss=mean_loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># 定义模型</span></span><br><span class="line">    model = YOLOv3(num_classes=config.NUM_CLASSES).to(config.DEVICE)</span><br><span class="line">    <span class="comment"># 优化器</span></span><br><span class="line">    optimizer = optim.Adam(</span><br><span class="line">        model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 损失函数</span></span><br><span class="line">    loss_fn = YoloLoss()</span><br><span class="line">    scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据加载器</span></span><br><span class="line">    train_loader, test_loader, train_eval_loader = get_loaders(</span><br><span class="line">        train_csv_path=config.DATASET + <span class="string">&quot;/train.csv&quot;</span>, test_csv_path=config.DATASET + <span class="string">&quot;/test.csv&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可以加载已训练好的模型</span></span><br><span class="line">    <span class="keyword">if</span> config.LOAD_MODEL:</span><br><span class="line">        load_checkpoint(</span><br><span class="line">            config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    scaled_anchors = (</span><br><span class="line">        torch.tensor(config.ANCHORS)</span><br><span class="line">        * torch.tensor(config.S).unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">    ).to(config.DEVICE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始迭代训练</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config.NUM_EPOCHS):</span><br><span class="line">        <span class="comment">#plot_couple_examples(model, test_loader, 0.6, 0.5, scaled_anchors)</span></span><br><span class="line">        train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#if config.SAVE_MODEL:</span></span><br><span class="line">        <span class="comment">#    save_checkpoint(model, optimizer, filename=f&quot;checkpoint.pth.tar&quot;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#print(f&quot;Currently epoch &#123;epoch&#125;&quot;)</span></span><br><span class="line">        <span class="comment">#print(&quot;On Train Eval loader:&quot;)</span></span><br><span class="line">        <span class="comment">#print(&quot;On Train loader:&quot;)</span></span><br><span class="line">        <span class="comment">#check_class_accuracy(model, train_loader, threshold=config.CONF_THRESHOLD)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch &gt; <span class="number">0</span> <span class="keyword">and</span> epoch % <span class="number">3</span> == <span class="number">0</span>:</span><br><span class="line">            check_class_accuracy(model, test_loader, threshold=config.CONF_THRESHOLD)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 得到预测框和真实的边界框的对比</span></span><br><span class="line">            <span class="comment"># 因为对于一张图像，在三个尺度上会有多个预测框与之吻合挺好，这里使用了NMS非极大值抑制来选择出最好的一个预测框</span></span><br><span class="line">            pred_boxes, true_boxes = get_evaluation_bboxes(</span><br><span class="line">                test_loader,</span><br><span class="line">                model,</span><br><span class="line">                iou_threshold=config.NMS_IOU_THRESH,</span><br><span class="line">                anchors=config.ANCHORS,</span><br><span class="line">                threshold=config.CONF_THRESHOLD,</span><br><span class="line">            )</span><br><span class="line">            <span class="comment"># 计算mAP</span></span><br><span class="line">            mapval = mean_average_precision(</span><br><span class="line">                pred_boxes,</span><br><span class="line">                true_boxes,</span><br><span class="line">                iou_threshold=config.MAP_IOU_THRESH,</span><br><span class="line">                box_format=<span class="string">&quot;midpoint&quot;</span>,</span><br><span class="line">                num_classes=config.NUM_CLASSES,</span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;MAP: <span class="subst">&#123;mapval.item()&#125;</span>&quot;</span>)</span><br><span class="line">            model.train()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">介绍
物体检测的两个步骤可以概括为：
步骤一：检测目标位置（生成矩形框）
步骤二：对目标物体进行分类
物体检测主流的算法框架大致分为one-stage与two-stage。two-stage算法代表有R-CNN系列，one-stage算法代表有Yolo系列。two-stage算法将步骤一与步骤二分开执行，输入图像先经过候选框生成网络（例如faster rcnn中的RPN网络），再经过分类网络；one-stage算法将步骤一与步骤二同时执行，输入图像只经过一个网络，生成的结果中同时包含位置与类别信息。two-stage与one-stage相比，精度高，但是计算量更大，所以运算较慢。

YOLO
</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="YOLO" scheme="http://qixinbo.github.io/tags/YOLO/"/>
    
  </entry>
  
  <entry>
    <title>顶级开源商业智能BI开发软件Superset————开发篇</title>
    <link href="http://qixinbo.github.io/2021/09/06/superset_dev/"/>
    <id>http://qixinbo.github.io/2021/09/06/superset_dev/</id>
    <published>2021-09-05T16:00:00.000Z</published>
    <updated>2021-09-13T07:11:36.495Z</updated>
    
    <content type="html"><![CDATA[<p>%%%%% 2021-9-13 update %%%%%<br>更新了地图部分和行业模板<br>%%%%%%%%%%%%%%%%%%%%%%%%%%%%%=</p><p><a href="https://qixinbo.info/2021/08/28/superset/">上一篇</a>介绍了怎样搭建和运行superset，这一篇着重于怎样对superset进行特殊配置和二次开发。</p><h1 id="更新并重新编译前端代码"><a href="#更新并重新编译前端代码" class="headerlink" title="更新并重新编译前端代码"></a>更新并重新编译前端代码</h1><p>前面已经说到，使用pip安装的是已经编译好的superset，无法修改前端源码，所以这里如果想对前端源码做改动，需要使用docker方式安装。<br>参考资料：<br><a href="https://github.com/apache/superset/blob/master/CONTRIBUTING.md">superset/CONTRIBUTING.md</a></p><h2 id="使用docker安装superset"><a href="#使用docker安装superset" class="headerlink" title="使用docker安装superset"></a>使用docker安装superset</h2><p>这一部分可以参考<a href="https://qixinbo.info/2021/08/28/superset/">入门篇</a>的docker安装部分。<br>但是需要万分注意的是，第一步拉取的docker镜像需要是dev分支，比如latest-dev，而不能是不带dev的分支，这里具体原理不清楚，但是我尝试时选择不带dev的分支，编译好多次都编译不成功。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull apache/superset:latest-dev</span><br></pre></td></tr></table></figure></p><h2 id="安装nodejs和npm"><a href="#安装nodejs和npm" class="headerlink" title="安装nodejs和npm"></a>安装nodejs和npm</h2><p>有两种方式，一种是使用nvm来管理：<br>（这个地方遇到一个坑，第一次使用了root账户安装了nvm，结果后面在使用npm时报“拒绝权限”错误，换用普通用户安装nvm后解决了）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0<span class="number">.37</span><span class="number">.0</span>/install.sh | bash</span><br><span class="line">cd superset-frontend</span><br><span class="line">nvm install --lts</span><br><span class="line">nvm use --lts</span><br><span class="line"></span><br><span class="line">npm install -g npm@<span class="number">7</span></span><br></pre></td></tr></table></figure><br>另一种是手动安装nodejs和npm：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wget https://nodejs.org/dist/v10<span class="number">.9</span><span class="number">.0</span>/node-v10<span class="number">.9</span><span class="number">.0</span>-linux-x64.tar.xz    // 下载，如果下载慢，就去nodejs.cn上找国内链接</span><br><span class="line">tar xf  node-v10<span class="number">.9</span><span class="number">.0</span>-linux-x64.tar.xz       // 解压</span><br><span class="line">cd node-v10<span class="number">.9</span><span class="number">.0</span>-linux-x64/                  // 进入解压目录</span><br><span class="line">./<span class="built_in">bin</span>/node -v                               // 执行node命令 查看版本</span><br><span class="line"></span><br><span class="line"><span class="comment">## 解压文件的 bin 目录底下包含了 node、npm 等命令，我们可以使用 ln 命令来设置软连接：</span></span><br><span class="line">ln -s /usr/software/nodejs/<span class="built_in">bin</span>/npm   /usr/local/<span class="built_in">bin</span>/ </span><br><span class="line">ln -s /usr/software/nodejs/<span class="built_in">bin</span>/node   /usr/local/<span class="built_in">bin</span>/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置npm镜像为国内的淘宝源</span></span><br><span class="line"><span class="comment"># 不过有时会显示该源里没有一些库，此时可以再切回官方源</span></span><br><span class="line"><span class="comment"># npm config set registry https://registry.npmjs.org/</span></span><br><span class="line">npm config <span class="built_in">set</span> registry http://registry.npm.taobao.org</span><br></pre></td></tr></table></figure></p><h2 id="安装相关依赖"><a href="#安装相关依赖" class="headerlink" title="安装相关依赖"></a>安装相关依赖</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确保安装的时npm 7</span></span><br><span class="line">npm install -g npm@<span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入前端文件夹</span></span><br><span class="line">cd superset-frontend</span><br><span class="line"><span class="comment"># 从package-lock.json安装依赖</span></span><br><span class="line">npm ci</span><br></pre></td></tr></table></figure><h2 id="编译资源文件"><a href="#编译资源文件" class="headerlink" title="编译资源文件"></a>编译资源文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm run build</span><br></pre></td></tr></table></figure><p>编译时遇到了如下问题：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: EPIPE: broken pipe</span><br></pre></td></tr></table></figure><br>多试几次。</p><h2 id="需要注意的问题"><a href="#需要注意的问题" class="headerlink" title="需要注意的问题"></a>需要注意的问题</h2><p>（1）再强调一遍，拉取docker镜像时选择dev分支。<br>（2）superset有很多种编译的方式，上面用到的是编译成生产环境所需的资源，还有其他，比如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">npm run build: the production assets, CSS/JSS minified <span class="keyword">and</span> optimized</span><br><span class="line">npm run dev-server: local development assets, <span class="keyword">with</span> sourcemaps <span class="keyword">and</span> hot refresh support</span><br><span class="line">npm run build-instrumented: instrumented application code <span class="keyword">for</span> collecting code coverage <span class="keyword">from</span> Cypress tests</span><br><span class="line">npm run build-dev: build assets <span class="keyword">in</span> development mode.</span><br><span class="line">npm run dev: built dev assets <span class="keyword">in</span> watch mode, will automatically rebuild when a file changes</span><br></pre></td></tr></table></figure><br>然而只尝试成功了第一个。。<br>（3）编译完后，要注意重启docker容器、强制刷新（不适用缓存）页面来使得修改生效。</p><h1 id="开启Prophet时间序列预测算法"><a href="#开启Prophet时间序列预测算法" class="headerlink" title="开启Prophet时间序列预测算法"></a>开启Prophet时间序列预测算法</h1><p><a href="https://www.modb.pro/db/50442">Facebook 在2017年开源了一个叫fbprophet的时间序列预测的算法该算法支持自定义季节和节假日，解决了像春节、618和双十一这种周期性节假日的指标预测难题</a>。prophet不仅可以处理时间序列存在一些异常值的情况，也可以处理部分缺失值的情形，还能够几乎全自动地预测时间序列未来的走势。而且Prophet包提供了直观易调的参数，即使是对缺乏模型知识的人来说，也可以据此对各种商业问题做出有意义的预测。<br>新版Superset（比如1.3版本）中对Time series这类图表（包括Line Chart、Area Chart、Bar Chart、Scatter plot）已经支持了prophet的调用，但是默认prophet包是不自动安装的，所以需要另外将prophet安装一下即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install pystan==<span class="number">2.19</span><span class="number">.1</span><span class="number">.1</span></span><br><span class="line">pip install prophet</span><br></pre></td></tr></table></figure><br>然后在上面这些图表的explore中的Predictive Analytics进行开启。</p><h1 id="配置PostgreSQL远程访问"><a href="#配置PostgreSQL远程访问" class="headerlink" title="配置PostgreSQL远程访问"></a>配置PostgreSQL远程访问</h1><p>（1）修改postgresql.conf<br>确保数据库可以接受来自任意IP的连接：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listen_addresses = <span class="string">&#x27;*&#x27;</span></span><br></pre></td></tr></table></figure><br>（2）修改pg_hba.conf<br>默认pg只允许本机通过密码认证登录，修改为以下内容后即可以对任意IP访问进行密码验证：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">host  <span class="built_in">all</span>  <span class="built_in">all</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span> md5</span><br></pre></td></tr></table></figure><br>（3）配置防火墙端口<br>在防火墙的入站规则里添加一条规则，使外部能够访问数据库端口。<br>（如果通过路由器的话，还要在路由器中设置一下端口规则）<br>（4）重启PostgreSQL服务<br>在windows的services中重启服务。</p><h1 id="权限控制"><a href="#权限控制" class="headerlink" title="权限控制"></a>权限控制</h1><p>Superset初始化权限之后，会创建5个角色，分别为Admin、Alpha、Gamma、sql_lab以及Public（现在又新增了一个granter角色）。Admin，Alpha和Gamma角色，分配了很多的菜单/视图权限，如果手工去修改，改错的可能性很大，加之Superset并没有说明每一项权限的完整文档，所以不建议去修改这些角色的定义。灵活使用预置的角色，可以快速满足业务上安全控制需求。<br>角色权限介绍：<br>（1）Admin：拥有所有权限，包括授予或取消其他用户的权限，以及更改其他用户的切片和仪表板。<br>（2）Alpha：能访问所有数据源，增加或者更改数据源，但不能更改其他用户权限。<br>（3）Gamma：只能使用来自数据源的数据，这些数据源是通过另一个补充角色授予他们访问权限的。只能查看由他们有权访问的数据源生成的切片和仪表板，无法更改或添加数据源。还要注意，当Gamma用户查看仪表板和切片列表视图时，他们将只看到他们有权访问的对象。<br>（4）sql_lab：能访问SQL Lab菜单。请注意，虽然默认情况下管理员用户可以访问所有数据库，但Alpha和Gamma用户都需要根据每个数据库授予访问权限。<br>（5）Public：默认没有任何权限。允许已注销的用户访问某些Superset功能是可能的。</p><h2 id="公开看板"><a href="#公开看板" class="headerlink" title="公开看板"></a>公开看板</h2><p>目前分享看板时都是需要登录某个用户，而对权限控制进行更改后就能使得匿名用户或未登录用户也能正常查看看板。<br>首先在superset的配置文件config.py中更改Public角色的权限：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUBLIC_ROLE_LIKE = <span class="string">&quot;Gamma&quot;</span></span><br></pre></td></tr></table></figure><br>即向Public角色授予与Gamma角色相同的权限。<br>然后：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">superset init</span><br></pre></td></tr></table></figure><br>重新初始化角色和权限，使上述更改生效。<br>此时在后台可以看到public角色拥有了与Gamma相同的权限集。<br>然后对public权限手动新增如下权限：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">all</span> datasource access on all_datasource_access</span><br></pre></td></tr></table></figure><br>才能正常公开查看看板。</p><p>参考文献：<br><a href="https://superset.apache.org/docs/security">Security</a><br><a href="https://cloud.tencent.com/developer/article/1031496">Superset权限使用场景</a></p><h1 id="多个数据源"><a href="#多个数据源" class="headerlink" title="多个数据源"></a>多个数据源</h1><h2 id="在多个数据源中查询"><a href="#在多个数据源中查询" class="headerlink" title="在多个数据源中查询"></a>在多个数据源中查询</h2><p>默认superset只能在一张表中进行数据可视化。<br>可以通过superset的SQL Lab工具箱进行连接查询（JOIN关键字）、合并查询（UNION关键字）和多表查询（注意这种多表查询又称笛卡尔查询，使用时要非常小心，因为结果集是目标表的行数乘积）等。（但是仍然需要所有的tables都在同一个数据库的同一个schema中）<br>然后将查询到的结果explore存储为虚拟virtual数据集。该数据集能和physical的数据集一样地进行explore。<br>这个地方需要注意的是需要对database进行额外设置，编辑database，然后勾选“Allow DML”。<br>（在SQL Lab调试时注意查看报错信息）</p><p>可参考preset上的教程：<br><a href="https://docs.preset.io/docs/sql-editor">https://docs.preset.io/docs/sql-editor</a><br><a href="https://docs.preset.io/docs/table-joins">https://docs.preset.io/docs/table-joins</a></p><h2 id="合并图表"><a href="#合并图表" class="headerlink" title="合并图表"></a>合并图表</h2><p>如果想在一张图表内制作多张图表，比如将拥有相同x坐标轴的折线图和柱状图放在一块，可以使用Mixed Time-Series。</p><h1 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h1><p>可以通过添加过滤器Filter Box对数据进行筛选，比如对特定时间、特定数值、特定字段等。<br>方式就是从图表中选择Filter Box，并对其进行配置即可。<br>配置时，会对过滤器指定具体的Column。默认情况下，过滤器会作用在有该Column的所有数据源上（即使是来自于多种数据库、多张数据表，只要该Column相同就可被过滤。当然某个数据集的该Column需要设定为filterable）。<br>默认情况下过滤器也会作用在dashboard中的所有图表上，可以配置哪些图表使用这些过滤器，有两种方式设置：<br>一种是图形化设置，在Edit Dashboard的Set Filter Mapping中就可以对具体哪个过滤器作用在哪个图表上进行配置，推荐这种方式，简单方便；<br>另一种是通过参数设置，在dashboard的JSON元数据配置中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;filter_immune_slices&quot;</span>: [<span class="number">324</span>, <span class="number">65</span>, <span class="number">92</span>],</span><br><span class="line">    <span class="string">&quot;filter_immune_slice_fields&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;177&quot;</span>: [<span class="string">&quot;country_name&quot;</span>, <span class="string">&quot;__time_range&quot;</span>],</span><br><span class="line">        <span class="string">&quot;32&quot;</span>: [<span class="string">&quot;__time_range&quot;</span>]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;timed_refresh_immune_slices&quot;</span>: [<span class="number">324</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>那些数字就是图表在该看板中的slice id，这些id可以通过Export Dashboard（回到总的dashboards页面）形成的json文件中查看。</p><h1 id="实时数据更新"><a href="#实时数据更新" class="headerlink" title="实时数据更新"></a>实时数据更新</h1><p>Superset可以设置以多长时间刷新看板，在”Set Auto Refresh Interval”中，默认有10s、30s、1min等，此处最小间隔为10s，最大间隔为24hours。<br>虽然从该入口处可选择的时间间隔种类有限，但可以在此处随意选择一个间隔，然后再在该看板的JSON元数据中进行更加细致的设置：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;timed_refresh_immune_slices&quot;</span>: [<span class="number">86</span>, <span class="number">89</span>, <span class="number">165</span>, <span class="number">166</span>, <span class="number">172</span>, <span class="number">191</span>],</span><br><span class="line">  <span class="string">&quot;refresh_frequency&quot;</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>比如上面将刷新频率设置为1s，同时设置哪些slices可以不刷新（默认是所有图表都刷新）。<br>但是需要注意的是，目前版本的superset（1.3.0）中每刷新一次，都会在界面上显示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">This dashboard <span class="keyword">is</span> currently force refreshing ....</span><br></pre></td></tr></table></figure><br>这样的弹窗，非常影响观感。<br>目前github上也有一个issue提到了该问题，开发人员正在修改该部分的设计：<br><a href="https://github.com/apache/superset/issues/13242">Make possible to disable the annoying “This dashboard is currently force refreshing” message #13242</a><br>如果等不到新的版本，可以手动修改如下地方的源码：<br><a href="https://github.com/apache/superset/blob/master/superset-frontend/src/dashboard/components/Header/index.jsx">superset/superset-frontend/src/dashboard/components/Header/index.jsx</a></p><p>以下是Youtube上一个演讲，使用Kafaka消息队列+Druid数据存储+Superset可视化的方案：<br><a href="https://www.youtube.com/watch?v=HOk7WtxBMzM">Interactive real-time dashboards on data streams using Kafka, Druid, and Superset</a></p><h1 id="查看stl模型文件"><a href="#查看stl模型文件" class="headerlink" title="查看stl模型文件"></a>查看stl模型文件</h1><p>stl文件是一种常用的描述三维物体的文件格式。superset没法直接展示这种文件格式，不过这里可以采用iframe的方式嵌入外部的stl阅读器来实现。<br>找了一圈后，发现viewstl这个网站提供优雅的渲染stl文件的功能，同时能免费嵌入其他网页中。网址见：<br><a href="https://www.viewstl.com/">View 3D STL files directly in your browser - no software installation is required</a><br>具体的嵌入功能见：<br><a href="https://www.viewstl.com/embed/">https://www.viewstl.com/embed/</a><br>进行一番配置后，复制其产生的代码即可，比如：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;iframe id=&quot;vs_iframe&quot; src=&quot;https://www.viewstl.com/?embedded&quot; style=&quot;border:0;margin:0;width:100%;height:100%;&quot;&gt;&lt;/iframe&gt;</span><br></pre></td></tr></table></figure><br>其中的stl文件可以由本地手动选择、本地服务托管、外部文件加载等多种方式。<br>本地服务托管就是本地建一个服务器放置stl文件，然后把内网地址作为参数传入即可，这样可以解决有时文件不能传到外网上这种问题。<br>外部文件加载需要提供文件URL地址，测试了几个网盘，比如google drive、百度网盘等，都有这样那样的问题无法解析，这里推荐使用阿里云的OSS存储服务。</p><h1 id="地图"><a href="#地图" class="headerlink" title="地图"></a>地图</h1><h2 id="deck-gl"><a href="#deck-gl" class="headerlink" title="deck.gl"></a>deck.gl</h2><p>deck.gl是由uber开发并开源出来的基于WebGL的大数据可视化框架。它具有提供不同类型可视化图层、GPU渲染的高性能，集成Mapbox展示地理信息数据（GIS）等特点。</p><h2 id="Mapbox"><a href="#Mapbox" class="headerlink" title="Mapbox"></a>Mapbox</h2><p>Mapbox是一个开源的地图制作系统，superset也与其进行了良好的集成，只需一个token，就可在superset中进行地图相关的操作。<br>获取token只需在Mapbox官网上注册一个账号，然后在superset的配置文件中设置环境变量即可（或者自己export或set该环境变量）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAPBOX_API_KEY = <span class="string">&quot;your token&quot;</span></span><br></pre></td></tr></table></figure></p><h2 id="GeoJson"><a href="#GeoJson" class="headerlink" title="GeoJson"></a>GeoJson</h2><p>deck.gl中的polygon图形需要使用某个区域的经纬度信息，它接收的可以是JSON格式的多边形数据，这种数据就是GeoJson数据。<br>获取GeoJson数据，可以使用在线的地图编辑器来获取，比如：<br><a href="http://geojson.io">http://geojson.io</a></p><p>关于GeoJson，其他有用的一些资源如下：<br><a href="https://echarts-maps.github.io/echarts-geomapping-book-zh/">地图工匠秘籍，其中的实战部分非常有用</a><br><a href="https://github.com/echarts-maps/echarts-geomapping-book-zh">上面这个网站的github</a><br><a href="https://github.com/echarts-maps">echarts-maps，上面这个网站的资源所在</a><br><a href="https://asmcn.icopy.site/awesome/awesome-geojson/">awesome geojson</a><br><a href="https://datav.aliyun.com/tools/atlas/index.html">高德的地图选择器，可以到区县级别</a></p><h2 id="内置地图"><a href="#内置地图" class="headerlink" title="内置地图"></a>内置地图</h2><p>superset也内置了两种地图：<br>（1）World Map：可以显示各个国家相关数据，国家代码可以有四种形式，比如Full name、code International Olympics Committee、code ISO 3166-1 alpha-2和code ISO 3166-1 alpha-3；<br>（2）Country Map：可以显示某个具体国家的省市的相关数据，具体省市的代码需要遵循ISO 3166-2标准。</p><h1 id="CSS模板"><a href="#CSS模板" class="headerlink" title="CSS模板"></a>CSS模板</h1><p>superset可以通过CSS方便地改变整个dashboard的样式。<br>CSS的语法可以通过如下教程快速上手：<br><a href="https://www.runoob.com/css/css-tutorial.html">菜鸟CSS教程</a><br>具体改变哪个元素或哪个类的样式，可以通过浏览器的Inspect检查功能，定位到想改变的元素上，然后通过临时修改其css查看效果，再在superset中添加css模板配置。</p><h1 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h1><p>Markdown组件可以允许添加Markdown语法的资源，以及html格式的资源。<br>比如可以加入图片、超链接、文本等。</p><h1 id="最大化看板"><a href="#最大化看板" class="headerlink" title="最大化看板"></a>最大化看板</h1><p>可以通过”Enter Fullscreen”来使看板最大化，但这种方式仍然会存在看板的标题栏。<br>通过在看板链接中配置standalone这个参数等于2，则可以将标题栏也给去掉，即：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;localhost:5000&#x2F;superset&#x2F;dashboard&#x2F;al-lca&#x2F;?standalone&#x3D;2</span><br></pre></td></tr></table></figure></p><h1 id="行业模板"><a href="#行业模板" class="headerlink" title="行业模板"></a>行业模板</h1><p>做看板是一门艺术，怎样提供数据洞察的同时又能做得好看，就是一门手艺活。<br>可以通过观摩和学习其他人的作品来提高自己的制作水平。<br>BAT三家互联网大厂都提供了自己的数据可视化低代码制作服务，里面也有很多的行业模板可供参考，是一个不错的学习地方：<br><a href="https://cn.aliyun.com/product/bigdata/datav">阿里云——DataV数据可视化</a><br><a href="https://cloud.baidu.com/product/sugar.html">百度云——数据可视化Sugar</a><br><a href="https://cloud.tencent.com/product/tcv">腾讯云——腾讯云图</a></p>]]></content>
    
    
    <summary type="html">%%%%% 2021-9-13 update %%%%%
更新了地图部分和行业模板
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%=

上一篇介绍了怎样搭建和运行superset，这一篇着重于怎样对superset进行特殊配置和二次开发。

更新并重新编译前端代码
前面已经说到，使用pip安装的是已经编译好的superset，无法修改前端源码，所以这里如果想对前端源码做改动，需要使用docker方式安装。
参考资料：
superset/CONTRIBUTING.md

使用docker安装superset
这一部分可以参考入门篇的docker安装部分。
但是需要万分注意的是，第一步</summary>
    
    
    
    <category term="digitalization" scheme="http://qixinbo.github.io/categories/digitalization/"/>
    
    
    <category term="Visualization" scheme="http://qixinbo.github.io/tags/Visualization/"/>
    
  </entry>
  
  <entry>
    <title>顶级开源商业智能BI开发软件Superset————入门篇</title>
    <link href="http://qixinbo.github.io/2021/08/28/superset/"/>
    <id>http://qixinbo.github.io/2021/08/28/superset/</id>
    <published>2021-08-27T16:00:00.000Z</published>
    <updated>2021-09-02T07:47:35.160Z</updated>
    
    <content type="html"><![CDATA[<p>%%%%%2021-9-2更新%%%%%%<br>更新使用docker安装连接宿主机的数据库</p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Apache Superset是一个现代的、企业级的商业智能（Business Intelligence）网络应用程序，它使得用户可以使用无代码可视化构建器和SQL编辑器来轻松探索和可视化自己的数据。<br>其最初由Airbnb开源，后来由Apache进行孵化，并且于今年（2021年）1 月 21 日宣布毕业并成为 Apache 软件基金会（ASF）的顶级项目（Top-Level Project），截止到现在（2021年8月25日）已经在GitHub上收获了超过4万颗star。<br>官网地址在<a href="https://superset.apache.org/">这里</a>。<br>示例看板在<a href="https://superset.apache.org/gallery">这里</a>。<br>有一句评价非常中肯：<a href="https://xie.infoq.cn/article/ff7e60ae303e0de531f0b4bf5">对开发人员最大的吸引力在于：支持的数据源足够多，界面足够花里胡哨！</a>。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>有多种方式安装superset，比如使用docker、使用pip安装等方式。<br>使用docker安装是最简单的一种方式，因为它已经将相关依赖都做成了一个镜像，同时其包含了github上的源码，有最大的自由度可供开发。<br>使用pip安装也较为方便，但是pip包本质上是一个已经编译好的包，没法修改源码，尤其是没法修改前端ui相关的代码。<br>下面介绍两种安装方式。</p><h2 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h2><h3 id="安装docker软件"><a href="#安装docker软件" class="headerlink" title="安装docker软件"></a>安装docker软件</h3><p>可以参考此处的<a href="https://www.runoob.com/docker/windows-docker-install.html">教程</a>。</p><h3 id="拉取superset镜像"><a href="#拉取superset镜像" class="headerlink" title="拉取superset镜像"></a>拉取superset镜像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull apache/superset</span><br></pre></td></tr></table></figure><h3 id="使用镜像"><a href="#使用镜像" class="headerlink" title="使用镜像"></a>使用镜像</h3><p>（1）开启一个superset实例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p <span class="number">8080</span>:<span class="number">8088</span> --name superset apache/superset</span><br></pre></td></tr></table></figure><br>（2）初始化实例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置管理员账号</span></span><br><span class="line">docker <span class="built_in">exec</span> -it superset superset fab create-admin \</span><br><span class="line">               --username admin \</span><br><span class="line">               --firstname Superset \</span><br><span class="line">               --lastname Admin \</span><br><span class="line">               --email admin@superset.com \</span><br><span class="line">               --password admin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迁移数据库</span></span><br><span class="line">docker <span class="built_in">exec</span> -it superset superset db upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载实例</span></span><br><span class="line">docker <span class="built_in">exec</span> -it superset superset load_examples</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">docker <span class="built_in">exec</span> -it superset superset init</span><br></pre></td></tr></table></figure><br>（3）登录：<br>在浏览器中的地址为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:<span class="number">8080</span>/login/ </span><br></pre></td></tr></table></figure></p><h3 id="连接宿主机的数据库"><a href="#连接宿主机的数据库" class="headerlink" title="连接宿主机的数据库"></a>连接宿主机的数据库</h3><p>（具体怎样连接数据库是在下面一节，但是因为docker安装方式会有一点不同，这里先说明一下，后面具体连接时注意这点即可）<br>如果数据库也是安装在同一个docker容器中，就没有如下特殊操作；<br>而如果数据库是在本地宿主机中，而superset安装在docker容器中，这样直接使用localhost是不能连接到宿主机的。还需要进行如下配置才可以。<br>（1）设置宿主机的数据库可外部访问<br>（1.1）修改postgresql.conf<br>确保数据库可以接受来自任意IP的连接：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listen_addresses = <span class="string">&#x27;*&#x27;</span></span><br></pre></td></tr></table></figure><br>（1.2）修改pg_hba.conf<br>默认pg只允许本机通过密码认证登录，修改为以下内容后即可以对任意IP访问进行密码验证：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">host  <span class="built_in">all</span>  <span class="built_in">all</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span> md5</span><br></pre></td></tr></table></figure><br>（1.3）重启PostgreSQL服务<br>在windows的services中重启服务。</p><p>（2）连接数据库时主机名更改<br>如上所述，连接数据库时主机名不能使用localhost，而需要使用特定名称。<br>对于Mac和Windows系统，docker有一个自动的解析，使用：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">host.docker.internal</span><br></pre></td></tr></table></figure><br>作为主机名即可。<br>对于Linux，可以先尝试：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">172.18</span><span class="number">.0</span><span class="number">.1</span></span><br></pre></td></tr></table></figure><br>作为主机名。如果这个不行，可以用以下命令：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect &lt;container-<span class="built_in">id</span>-<span class="keyword">or</span>-name&gt; | grep Gateway</span><br></pre></td></tr></table></figure><br>查看一下docker容器指向的宿主机的ip地址。</p><h2 id="pip安装"><a href="#pip安装" class="headerlink" title="pip安装"></a>pip安装</h2><h3 id="创建虚拟环境"><a href="#创建虚拟环境" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h3><p>使用virtualenv或Conda。<br>使用虚拟环境主要是为了安装环境的独立性，防止里面的库的版本混乱。这一步不详述了。</p><h3 id="安装必要的包"><a href="#安装必要的包" class="headerlink" title="安装必要的包"></a>安装必要的包</h3><p>大部分的包都能自动下载，但是下面这两个有可能会在自动安装时出现错误，导致整个安装出错（我在windows平台上安装时遇到了这两个问题）。<br>建议是自动安装，如果出错，再手动安装一下看看是不是这两个出现的问题。<br>（1）安装Sasl:<br>下载Sasl的wheel文件:<br><a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#sasl">https://www.lfd.uci.edu/~gohlke/pythonlibs/#sasl</a><br>然后：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install</span><br></pre></td></tr></table></figure><br>（2）安装python-geohash package:<br>下载wheel包，然后pip install。<br><a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-geohash">https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-geohash</a></p><h3 id="安装Superset"><a href="#安装Superset" class="headerlink" title="安装Superset"></a>安装Superset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最好确保一下superset是最新版</span></span><br><span class="line"><span class="comment"># 第一次安装时1.1.0版本有个注释层的bug</span></span><br><span class="line"><span class="comment"># 更新到1.3.0版本后就好了</span></span><br><span class="line">pip install apache-superset</span><br></pre></td></tr></table></figure><h3 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">superset db upgrade</span><br></pre></td></tr></table></figure><h3 id="配置superset"><a href="#配置superset" class="headerlink" title="配置superset"></a>配置superset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将Flask默认的app设置为superset，这样flask就能找到它</span></span><br><span class="line">export FLASK_APP=superset <span class="comment"># 在windows上就是set命令</span></span><br><span class="line"><span class="comment"># 创建管理员账户</span></span><br><span class="line">superset fab create-admin</span><br><span class="line"><span class="comment"># 加载一些示例看板</span></span><br><span class="line">superset load_examples</span><br><span class="line"><span class="comment"># 初始化superset</span></span><br><span class="line">superset init</span><br></pre></td></tr></table></figure><h3 id="启动superset"><a href="#启动superset" class="headerlink" title="启动superset"></a>启动superset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">superset run -p <span class="number">8088</span> --<span class="keyword">with</span>-threads --reload --debugger</span><br></pre></td></tr></table></figure><h1 id="连接数据库"><a href="#连接数据库" class="headerlink" title="连接数据库"></a>连接数据库</h1><p>Superset本身不提供数据库，其需要连接已有的数据库来作为数据存储的容器。<br>Superset支持各种数据库，包括MySQL，Presto，Hive，Postgres，Dremio，Snowflake，Teradata和其他数PB级的。由于Superset后端是用Python编写的，因此本质上是Python后端的Flask应用程序……在Python中，所有数据库都有很多驱动程序支持。<br>这里我们选用PostgreSQL数据库作为后端。</p><h2 id="安装PostgreSQL"><a href="#安装PostgreSQL" class="headerlink" title="安装PostgreSQL"></a>安装PostgreSQL</h2><p>可以通过下面的链接进行下载安装：<br><a href="https://www.enterprisedb.com/downloads/postgres-postgresql-downloads">PostgreSQL Database Download</a><br>里面自带了pgAdmin图形管理工具来操作PostgreSQL数据库。</p><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><p>安装好pgAdmin后，再通过它来手动创建一个自己的数据库，用于后续存储数据。<br>具体可以参考如下教程：<br><a href="https://www.runoob.com/postgresql/postgresql-create-database.html">PostgreSQL 创建数据库</a><br>特别注意的是该数据库的用户名username、密码password、主机地址host（本机就是localhost）、端口号port（默认是5432）和名称database。</p><p>初次创建后该数据库就直接跑起来后，但后面电脑关机后，有可能出现明明信息都正确，但是启动不起来的问题，比如出现下面这个问题：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Is the server running on host &quot;localhost&quot; (::1) and accepting TCP/IP connections on port 5432?</span><br></pre></td></tr></table></figure><br>这是因为后台的数据库服务没有启动。解决方法是在windows的Services中找到postgresql-x64-13这个服务，然后启动它。</p><h2 id="安装数据库驱动"><a href="#安装数据库驱动" class="headerlink" title="安装数据库驱动"></a>安装数据库驱动</h2><p>首先需要安装一个额外的库：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install psycopg2</span><br></pre></td></tr></table></figure></p><h2 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h2><p>在上面的启动的superset的web页面中，选择添加一个数据库，然后根据PostgreSQL的连接语法与前面创建的数据库进行连接，语法格式为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">postgresql://&#123;username&#125;:&#123;password&#125;@&#123;host&#125;:&#123;port&#125;/&#123;database&#125;</span><br></pre></td></tr></table></figure><br>然后点击“测试连接”，连接成功后即表明可以正确添加该数据库。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>有了底层数据库，还需要提取里面的数据。<br>对于本来就存在数据的数据库，可以在superset的“数据集”中进行添加选择，按照提示进行相关操作就行。<br>对于初次创建的数据库，里面是空的，没有任何的数据。此时可以通过上传csv文件进行添加，这样既在superset中添加了数据集，也在底层PostgreSQL数据库中添加了数据。<br>开启上传csv功能需要首先在数据库中进行设置，在superset的某个数据库的Extra/扩展选项卡中勾选“Allow Data Upload”/“允许数据上传”。<br>然后再在“数据”菜单中选择“上传CSV文件”。</p><p>额外福利：如果手头没有可玩的数据，可以通过下面三个链接获取一些示例数据（第三个时superset教程中的示例数据）：<br><a href="https://github.com/plotly/datasets">https://github.com/plotly/datasets</a><br><a href="https://github.com/fivethirtyeight/data">https://github.com/fivethirtyeight/data</a><br><a href="https://github.com/apache-superset/examples-data">https://github.com/apache-superset/examples-data</a></p><p>导入数据集后，可以对数据集的属性进行配置，比如哪一列是时间条件、是否可被过滤等。<br>需要注意的是superset对数据集加了一个语义层semantic layer，它存储了两种类型的计算数据：<br>（1）虚拟指标：对应Metrics这一标签页，可以编写不同列之间的聚合SQL查询，然后使得结果作为“列”来使用。这里可以使用并且鼓励使用SQL的聚合函数，如COUNT、SUM等；<br>（2）虚拟计算列：对应Calculated Columns这一标签页，可以对某一特定的列编写SQL语句来定制它的行为。在这里不能使用SQL的聚合函数。 </p><h1 id="可视化数据"><a href="#可视化数据" class="headerlink" title="可视化数据"></a>可视化数据</h1><p>Superset有两种探索数据的方式：<br>（1）Explore：零代码可视化编辑器，只需选择数据集，选定相应图表，配置一些外观属性，然后就可以创建可视化图表；只需点击相应的数据集，就可以进入Explore模式；Save Chart时可以选择添加到新看板或者某一个已存在的看板。<br>（2）SQL Lab：SQL工具箱，可以提供强大的SQL语言编辑功能，用于清洗、联合和准备数据，可以用于下一步的Explore流程。</p><p>superset的官方教程中给出了一个详细地Explore模式的使用教程，其使用的示例数据来自以下链接：<br><a href="https://github.com/apache-superset/examples-data/blob/master/tutorial_flights.csv">flights</a><br>强烈建议根据官方教程一步步走一遍，教程在<a href="https://superset.apache.org/docs/creating-charts-dashboards/exploring-data">这里</a>。<br>这里列举一下自己跑教程时踩的一些坑：<br>（1）上传CSV文件时，一定要在“Parse Dates”解析日期那里手动填上“Travel Date”，否则如果不明确指定时间的话，在数据库里存的该项的数据类型是Text，无法进行后面的时间序列的计算。<br>（2）在添加“指标Metrics”时，保存的指标指的是“编辑数据集”时的“指标Metrics”那个选项卡的指标。<br>（3）配置“分组Group by”时，选择“Time”这一项，就会自动使用之前在Time那块定义的时间列、时间粒度等。<br>（4）添加“注释层annotation layer”那一块时，注意使用最新版的superset，已测试1.1版本会有bug，1.3版本已经修复该bug，见该<a href="https://github.com/apache/superset/pull/13969">PR</a>。<br>（5）在Advanced Analystics一项中，有对时间序列数据的更强大的操作，比如求平均、时间平移、使用python函数重新采样等操作。</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>superset开发团队基于开源的superset推出了SaaS云服务Preset，可以使得用户在无需安装任何软件的情况下直接使用superset。<br>Preset除了提供开箱即用的superset，其官网上的教程也比superset官网上的要详细很多，所以可以参考preset的文档来学习superset，如下：<br><a href="https://docs.preset.io/">https://docs.preset.io/</a></p>]]></content>
    
    
    <summary type="html">%%%%%2021-9-2更新%%%%%%
更新使用docker安装连接宿主机的数据库

介绍
Apache Superset是一个现代的、企业级的商业智能（Business Intelligence）网络应用程序，它使得用户可以使用无代码可视化构建器和SQL编辑器来轻松探索和可视化自己的数据。
其最初由Airbnb开源，后来由Apache进行孵化，并且于今年（2021年）1 月 21 日宣布毕业并成为 Apache 软件基金会（ASF）的顶级项目（Top-Level Project），截止到现在（2021年8月25日）已经在GitHub上收获了超过4万颗star。
官网地址在这里。
示例看板</summary>
    
    
    
    <category term="digitalization" scheme="http://qixinbo.github.io/categories/digitalization/"/>
    
    
    <category term="Visualization" scheme="http://qixinbo.github.io/tags/Visualization/"/>
    
  </entry>
  
  <entry>
    <title>一键深度学习：将常用深度学习算法集成在ImagePy软件</title>
    <link href="http://qixinbo.github.io/2021/08/16/onebuttondl/"/>
    <id>http://qixinbo.github.io/2021/08/16/onebuttondl/</id>
    <published>2021-08-15T16:00:00.000Z</published>
    <updated>2021-08-16T07:45:35.143Z</updated>
    
    <content type="html"><![CDATA[<h1 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h1><p>日常工作中，调用深度学习算法通常需要在命令行中进行，该过程通常涉及复杂的流程，比如修改配置文件、指定文件路径、打开命令行调用算法运行。此时如果能有一个图形界面软件实现“一键调用”，就会极大地节省工作量，提高工作效率，避免来来回回地反复修改文件、执行命令等。</p><p>最近新写了一个库，就是把常用的深度学习算法都集成在了ImagePy中，这样用户和开发者就能直接在ImagePy中愉快地“玩”算法了。</p><h1 id="OneButtonDeepLearning"><a href="#OneButtonDeepLearning" class="headerlink" title="OneButtonDeepLearning"></a>OneButtonDeepLearning</h1><p>该仓库在<a href="https://github.com/qixinbo/OneButtonDeepLearning">这里https://github.com/qixinbo/OneButtonDeepLearning</a>。<br>宗旨就是：让深度学习算法触手可及、一键调用，不必每次在命令行进行复杂配置。</p><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>只需将要使用的模型文件夹复制到<code>imagepy/plugins</code>文件夹下，再次启动ImagePy后即可在菜单栏看到该算法。</p><h2 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h2><p>如果运行深度学习算法的环境没有事先搭建好，那么在模型的<code>menus</code> 下都有一个配置文件，直接运行:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><br>即可下载相应的依赖包。</p><h1 id="当前模型"><a href="#当前模型" class="headerlink" title="当前模型"></a>当前模型</h1><h2 id="光学字符识别OCR"><a href="#光学字符识别OCR" class="headerlink" title="光学字符识别OCR"></a>光学字符识别OCR</h2><p><a href="https://github.com/PaddlePaddle/PaddleOCR">PaddleOCR</a> aims to create multilingual, awesome, leading, and practical OCR tools that help users train better models and apply them into practice.</p><p><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/OCR/menus/OCR/demo.png" alt="ocr-demo"></p><h2 id="目标检测YOLOv5"><a href="#目标检测YOLOv5" class="headerlink" title="目标检测YOLOv5"></a>目标检测YOLOv5</h2><p><a href="https://github.com/ultralytics/yolov5">YOLOv5</a> is a family of compound-scaled object detection models trained on the COCO dataset.</p><p><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/YOLOv5/menus/YOLOv5/demo.png" alt="yolov5-demo"></p><h2 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h2><p><a href="https://github.com/deepinsight/insightface">InsightFace</a> is an open source 2D&amp;3D deep face analysis toolbox, and efficiently implements a rich variety of state of the art algorithms of face recognition, face detection and face alignment, which optimized for both training and deployment.</p><p><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/FaceAnalysis/menus/Face/demo.png" alt="face-demo"></p><h2 id="胞状物体分割Cellpose"><a href="#胞状物体分割Cellpose" class="headerlink" title="胞状物体分割Cellpose"></a>胞状物体分割Cellpose</h2><p><a href="https://github.com/MouseLand/cellpose">Cellpose</a> is a generalist algorithm for cell and nucleus segmentation.</p><p><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/Cellpose/menus/Cellpose/demo.png" alt="cellpose-demo"></p><h2 id="胞状物体分割BulkSeg"><a href="#胞状物体分割BulkSeg" class="headerlink" title="胞状物体分割BulkSeg"></a>胞状物体分割BulkSeg</h2><p><a href="https://github.com/qixinbo/BulkSeg">BulkSeg</a> which is inspired by Cellpose, is a fast and generalist algorithm for segmenting bulk-like objects.<br><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/BulkSeg/menus/BulkSeg/demo.png" alt="bulkseg-demo"></p><h2 id="物体分割DeepLab"><a href="#物体分割DeepLab" class="headerlink" title="物体分割DeepLab"></a>物体分割DeepLab</h2><p><a href="https://github.com/pytorch/vision/blob/master/torchvision/models/segmentation/deeplabv3.py">DeepLab</a> is a state-of-art deep learning model for semantic image segmentation, where the goal is to assign semantic labels (e.g., person, dog, cat and so on) to every pixel in the input image.<br><img src="https://raw.githubusercontent.com/qixinbo/OneButtonDeepLearning/main/DeepLab/menus/DeepLab/demo.png" alt="deeplab-demo"></p><h1 id="计划"><a href="#计划" class="headerlink" title="计划"></a>计划</h1><p>下一步计划添加的模型有：</p><ul><li>图像生成</li><li>风格迁移</li></ul>]]></content>
    
    
    <summary type="html">起因
日常工作中，调用深度学习算法通常需要在命令行中进行，该过程通常涉及复杂的流程，比如修改配置文件、指定文件路径、打开命令行调用算法运行。此时如果能有一个图形界面软件实现“一键调用”，就会极大地节省工作量，提高工作效率，避免来来回回地反复修改文件、执行命令等。

最近新写了一个库，就是把常用的深度学习算法都集成在了ImagePy中，这样用户和开发者就能直接在ImagePy中愉快地“玩”算法了。

OneButtonDeepLearning
该仓库在这里https://github.com/qixinbo/OneButtonDeepLearning。
宗旨就是：让深度学习算法触手可及、一键调用</summary>
    
    
    
    <category term="machine learning" scheme="http://qixinbo.github.io/categories/machine-learning/"/>
    
    
    <category term="Machine Learning" scheme="http://qixinbo.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析： 27 -- 工作流workflow组件</title>
    <link href="http://qixinbo.github.io/2021/07/10/ImagePy_27/"/>
    <id>http://qixinbo.github.io/2021/07/10/ImagePy_27/</id>
    <published>2021-07-09T16:00:00.000Z</published>
    <updated>2021-07-09T05:48:56.278Z</updated>
    
    <content type="html"><![CDATA[<p>ImagePy的工作流worflow功能能够以可视化的方式逐步执行已定义的一系列图像处理动作，即有机地将复杂的图像处理步骤串联起来，也提供了可视化便捷的交互方式，可以认为是更人性化的“宏命令”。<br><img src="https://user-images.githubusercontent.com/6218739/125029058-a4018000-e0bb-11eb-841c-58f2cffa19c8.png" alt="image"><br>本文就是解析一下这个组件的底层原理。</p><h1 id="文本解析"><a href="#文本解析" class="headerlink" title="文本解析"></a>文本解析</h1><p>如下parse函数是读取描述workflow的文件，然后根据每行的标识对其进行解析，比如如果是两个井号开头，则这一行代表是chapter，以及在某个chapter下面还有若干section及其提示信息hint。在底层来说，就是将这些文件信息存储为有层级的python字典。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">cont</span>):</span></span><br><span class="line">ls = cont.split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">workflow = &#123;<span class="string">&#x27;title&#x27;</span>:ls[<span class="number">0</span>], <span class="string">&#x27;chapter&#x27;</span>:[]&#125;</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> ls[<span class="number">2</span>:]:</span><br><span class="line">line = line.strip()</span><br><span class="line"><span class="keyword">if</span> line == <span class="string">&#x27;&#x27;</span>:<span class="keyword">continue</span></span><br><span class="line"><span class="keyword">if</span> line.startswith(<span class="string">&#x27;## &#x27;</span>):</span><br><span class="line">chapter = &#123;<span class="string">&#x27;title&#x27;</span>:line[<span class="number">3</span>:], <span class="string">&#x27;section&#x27;</span>:[]&#125;</span><br><span class="line">workflow[<span class="string">&#x27;chapter&#x27;</span>].append(chapter)</span><br><span class="line"><span class="keyword">elif</span> line[<span class="number">1</span>:<span class="number">3</span>] == <span class="string">&#x27;. &#x27;</span>:</span><br><span class="line">section = &#123;<span class="string">&#x27;title&#x27;</span>:line[<span class="number">3</span>:]&#125;</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">section[<span class="string">&#x27;hint&#x27;</span>] = line</span><br><span class="line">chapter[<span class="string">&#x27;section&#x27;</span>].append(section)</span><br><span class="line"><span class="keyword">return</span> workflow</span><br></pre></td></tr></table></figure></p><h1 id="界面实现"><a href="#界面实现" class="headerlink" title="界面实现"></a>界面实现</h1><p>先来看整体的界面布局图：<br><img src="https://user-images.githubusercontent.com/6218739/125015230-aa82fe00-e0a1-11eb-9bdb-623c5516413f.png" alt="Untitled"><br>可以看出，整个界面由三部分构成：<br>（1）微调按钮<br>它使用的组件是wxPython的SpinButton：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.spn_scroll = wx.SpinButton( self, wx.ID_ANY, wx.DefaultPosition, wx.DefaultSize, wx.SP_HORIZONTAL )</span><br></pre></td></tr></table></figure><br>它是用来切换后面的工作流中包含的各个Chapter控件的显示，具体看一下它绑定的事件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">self.spn_scroll.Bind( wx.EVT_SPIN, self.on_spn )</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">on_spn</span>(<span class="params">self, event</span>):</span></span><br><span class="line">v = self.spn_scroll.GetValue()</span><br><span class="line">self.scr_workflow.Scroll(v, <span class="number">0</span>)</span><br><span class="line">self.spn_scroll.SetValue(self.scr_workflow.GetViewStart()[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></p><p>（2）工作流组件显示<br>这个部分是核心，是用来显示工作流中包含的各个图像处理功能组件，并赋予相应的功能。<br>因为事先不知道一个工作流中具体包含多少个图像处理功能，因此，需要使用可以滚动显示的方式来承载未知个数的组件，具体应用的是wxPython的ScrolledCanvas这种画布：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.scr_workflow = wx.ScrolledCanvas( self, wx.ID_ANY, wx.DefaultPosition, wx.DefaultSize)</span><br></pre></td></tr></table></figure><br>然后再将之前解析的工作流一个个添加到该Canvas中。<br>第一层级是以chapter为单位，多个chapter用水平排列的方式添加到canvas中；<br>第二层级是在每个chapter中，以垂直排列的方式依次添加chapter的标题、包含的Sections（即具体图像处理功能）及下面的Snap、load等等（目前这两个没有实际功能）。<br>添加的Section要与具体的图像处理操作绑定，所以要给它添加鼠标事件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> section <span class="keyword">in</span> chapter[<span class="string">&#x27;section&#x27;</span>]:</span><br><span class="line">btn = wx.Button( self.pan_chapter, wx.ID_ANY, section[<span class="string">&#x27;title&#x27;</span>], wx.DefaultPosition, wx.DefaultSize, wx.BU_EXACTFIT )</span><br><span class="line">sizer_section.Add( btn, <span class="number">0</span>, wx.ALL, <span class="number">3</span> )</span><br><span class="line">btn.Bind(wx.EVT_BUTTON, <span class="keyword">lambda</span> e, x=section[<span class="string">&#x27;title&#x27;</span>]: self.f(x))</span><br><span class="line">btn.Bind( wx.EVT_ENTER_WINDOW, <span class="keyword">lambda</span> e, info=section[<span class="string">&#x27;hint&#x27;</span>]: self.info(info))</span><br></pre></td></tr></table></figure><br>可以看出，有两个事件绑定，一个是鼠标单击事件，与一个匿名函数进行了绑定，该函数所做的是将section的title传入self.f函数中，并执行它（默认的f函数就是print）。另一个事件是当鼠标进入该button时，会在右侧的info窗口显示hint内容。<br>这个地方需要深究一下鼠标单击事件，即这个button是怎样执行具体的图像处理功能的：<br>首先，刚才已提到，该button与self.f是绑定的，即点击button时，会将title传入f函数来执行，那么就看一下f函数是啥。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Bind</span>(<span class="params">self, event, f=<span class="built_in">print</span></span>):</span> self.f = f</span><br></pre></td></tr></table></figure><br>从这个Bind函数可知，可以从外部传入一个f函数，然后赋值给该workflow组件的f函数。<br>那进一步探究外部是怎样传入f函数的。<br>具体看一下imagepy这个app中的实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_show_workflow</span>(<span class="params">self, cont, title=<span class="string">&#x27;ImagePy&#x27;</span></span>):</span></span><br><span class="line">    pan = WorkFlowPanel(self)</span><br><span class="line">    pan.SetValue(cont)</span><br><span class="line">    pan.Bind(<span class="literal">None</span>, <span class="keyword">lambda</span> x:self.run_macros([<span class="string">&#x27;%s&gt;None&#x27;</span>%x]))</span><br></pre></td></tr></table></figure><br>在imagepy这个app中，f函数就是一个匿名函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lambda</span> x:self.run_macros([<span class="string">&#x27;%s&gt;None&#x27;</span>%x])</span><br></pre></td></tr></table></figure><br>它执行了imagepy的宏执行命令，关键就是在这个地方了，它巧妙地将工作流中地命令映射到了执行宏命令上。<br>同时需要注意地是，这里的宏命令中的参数那一项是None，即默认不传入参数，因此就会跳出GUI窗口来让用户输入自己的参数，这正是宏命令与工作流的区别：底层都是宏命令，但一个是带参数的，一个是不带参数的。<br>（3）消息窗口<br>最右边就是消息提示窗口：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.txt_info = wx.TextCtrl( self, wx.ID_ANY, wx.EmptyString, wx.DefaultPosition, wx.DefaultSize, wx.TE_AUTO_URL|wx.TE_MULTILINE|wx.TE_READONLY )</span><br></pre></td></tr></table></figure><br>前面已经说了，当鼠标进入某个button时，会在这里显示该button的提示消息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">btn.Bind( wx.EVT_ENTER_WINDOW, <span class="keyword">lambda</span> e, info=section[<span class="string">&#x27;hint&#x27;</span>]: self.info(info))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">info</span>(<span class="params">self, info</span>):</span></span><br><span class="line">self.txt_info.SetValue(info)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">ImagePy的工作流worflow功能能够以可视化的方式逐步执行已定义的一系列图像处理动作，即有机地将复杂的图像处理步骤串联起来，也提供了可视化便捷的交互方式，可以认为是更人性化的“宏命令”。

本文就是解析一下这个组件的底层原理。

文本解析
如下parse函数是读取描述workflow的文件，然后根据每行的标识对其进行解析，比如如果是两个井号开头，则这一行代表是chapter，以及在某个chapter下面还有若干section及其提示信息hint。在底层来说，就是将这些文件信息存储为有层级的python字典。
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15


d</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>ImagePy解析： 26 -- 矢量图形的操作</title>
    <link href="http://qixinbo.github.io/2021/03/31/ImagePy_26/"/>
    <id>http://qixinbo.github.io/2021/03/31/ImagePy_26/</id>
    <published>2021-03-30T16:00:00.000Z</published>
    <updated>2021-03-31T09:18:59.187Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本文是对ImagePy的矢量图形绘制工具进行深度解析。<br>矢量图形相对于位图来说，有其特有的操作，比如两个矢量进行求交集、求并集、求差等。<br>阅读本文之前，可以先参考<a href="https://qixinbo.info/2020/06/14/imagepy_20/">之前的这篇文章</a>，以对ImagePy的矢量图形有初步了解。</p><h1 id="功能函数"><a href="#功能函数" class="headerlink" title="功能函数"></a>功能函数</h1><h2 id="将矢量图形转化为点集"><a href="#将矢量图形转化为点集" class="headerlink" title="将矢量图形转化为点集"></a>将矢量图形转化为点集</h2><p>该函数的作用是将矢量图形转换为点集，这里的点作为锚点，可以供后续编辑。<br>比如对于矩形这一矢量，在shp中定义了它的起始点和长宽，通过该函数，可以将该矩形转为9个点的点集，即将该矩形分成田字格。<br>（具体到语法上，使用了numpy的mgrid函数，其中的步长设为了复数的形式，具体可以参考<a href="https://numpy.org/doc/stable/reference/generated/numpy.mgrid.html">这里</a>）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mark</span>(<span class="params">shp, types = <span class="string">&#x27;all&#x27;</span></span>):</span></span><br><span class="line">pts = []</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (types==<span class="string">&#x27;all&#x27;</span> <span class="keyword">or</span> shp.dtype <span class="keyword">in</span> types): <span class="keyword">return</span> pts</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;point&#x27;</span>:</span><br><span class="line">pts.append([shp.body])</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;points&#x27;</span>:</span><br><span class="line">pts.append(shp.body)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;line&#x27;</span>:</span><br><span class="line">pts.append(shp.body)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;lines&#x27;</span>:</span><br><span class="line">pts.extend(shp.body)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;polygon&#x27;</span> <span class="keyword">and</span> <span class="built_in">len</span>(shp.body)==<span class="number">1</span>:</span><br><span class="line">pts.append(shp.body[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;polygons&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(i) != <span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line">pts.append(i[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangle&#x27;</span>:</span><br><span class="line">l,t,w,h = shp.body</span><br><span class="line">ps = np.mgrid[l:l+w:<span class="number">3j</span>, t:t+h:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts.append(ps)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangles&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(shp.body)):</span><br><span class="line">l,t,w,h = shp.body[i]</span><br><span class="line">ps = np.mgrid[l:l+w:<span class="number">3j</span>, t:t+h:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts.append(ps)</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;ellipse&#x27;</span>:</span><br><span class="line">x0, y0, l1, l2, ang = shp.body</span><br><span class="line">mat = np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">  [np.sin(-ang),np.cos(-ang)]])</span><br><span class="line">ps = np.mgrid[-l1:l1:<span class="number">3j</span>, -l2:l2:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts.append(mat.dot(ps.T).T + (x0, y0))</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;ellipses&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(shp.body)):</span><br><span class="line">x0, y0, l1, l2, ang = shp.body[i]</span><br><span class="line">mat = np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">  [np.sin(-ang),np.cos(-ang)]])</span><br><span class="line">ps = np.mgrid[-l1:l1:<span class="number">3j</span>, -l2:l2:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts.append(mat.dot(ps.T).T + (x0, y0))</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;layer&#x27;</span>:</span><br><span class="line">minl, obj = <span class="number">1e8</span>, <span class="literal">None</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line">pts.extend(mark(i, types))</span><br><span class="line"><span class="keyword">return</span> pts</span><br></pre></td></tr></table></figure></p><h2 id="选择对象"><a href="#选择对象" class="headerlink" title="选择对象"></a>选择对象</h2><p>该函数的功能是选择与鼠标点击位置距离在一定范围内且距离最近的那个矢量对象。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pick_obj</span>(<span class="params">shp, x, y, lim, types=<span class="string">&#x27;all&#x27;</span></span>):</span></span><br><span class="line">obj, minl = <span class="literal">None</span>, lim</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (types==<span class="string">&#x27;all&#x27;</span> <span class="keyword">or</span> shp.dtype <span class="keyword">in</span> types): </span><br><span class="line"><span class="keyword">return</span> m, obj, minl</span><br><span class="line"><span class="comment"># 如果是layer类型，那么就遍历里面的元素</span></span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;layer&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line">o, l = pick_obj(i, x, y, lim, types)</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">obj, minl = o, l</span><br><span class="line"><span class="keyword">elif</span> shp.dtype <span class="keyword">in</span> <span class="string">&#x27;polygons&#x27;</span>:</span><br><span class="line">b = shp.to_geom().contains(Point([x, y]).to_geom())</span><br><span class="line"><span class="keyword">if</span> b : <span class="keyword">return</span> shp, <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment"># 首先将鼠标位置传给ImagePy的Point这一结构</span></span><br><span class="line"><span class="comment"># 然后调用to_geom方法就转换为shapely的Point对象</span></span><br><span class="line"><span class="comment"># 然后通过distance函数计算shp中的矢量与鼠标所在位置的Point矢量的距离</span></span><br><span class="line">d = shp.to_geom().distance(Point([x, y]).to_geom())</span><br><span class="line"><span class="comment"># 找到最近的或小于阈值minl的矢量，然后返回它</span></span><br><span class="line"><span class="keyword">if</span> d&lt;minl: obj, minl = shp, d</span><br><span class="line"><span class="keyword">return</span> obj, minl</span><br></pre></td></tr></table></figure></p><h2 id="选择锚点"><a href="#选择锚点" class="headerlink" title="选择锚点"></a>选择锚点</h2><p>该函数的功能是选择与鼠标所在位置小于某个距离的那个锚点。<br>如果锚点被选中，就会返回该锚点所在的矢量对象，同时表示该锚点的一个标识。比如对于椭圆上一个锚点，有“lt”左上、“rt”右上、“o”中心点等多种锚点。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pick_point</span>(<span class="params">shp, x, y, lim, types=<span class="string">&#x27;all&#x27;</span></span>):</span></span><br><span class="line">m, obj, minl = <span class="literal">None</span>, <span class="literal">None</span>, lim</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (types==<span class="string">&#x27;all&#x27;</span> <span class="keyword">or</span> shp.dtype <span class="keyword">in</span> types): </span><br><span class="line"><span class="keyword">return</span> m, obj, minl</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;point&#x27;</span>:</span><br><span class="line">l = ((shp.body-(x, y))**<span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, shp.body, l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;points&#x27;</span>:</span><br><span class="line">l = norm(shp.body-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, shp.body[n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;line&#x27;</span>:</span><br><span class="line">l = norm(shp.body-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, shp.body[n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;lines&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> shp.body:</span><br><span class="line">l = norm(line-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, line[n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;polygon&#x27;</span> <span class="keyword">and</span> <span class="built_in">len</span>(shp.body)==<span class="number">1</span>:</span><br><span class="line">l = norm(shp.body[<span class="number">0</span>]-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, shp.body[<span class="number">0</span>][n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;polygons&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(i) != <span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line">l = norm(i[<span class="number">0</span>]-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line">l = l[n]</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = shp, i[<span class="number">0</span>][n], l</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangle&#x27;</span>:</span><br><span class="line">l,t,w,h = shp.body</span><br><span class="line">pts = np.mgrid[l:l+w:<span class="number">3j</span>, t:t+h:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">names = [<span class="string">&#x27;lt&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;rt&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;lb&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>]</span><br><span class="line">l = norm(pts-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line"><span class="keyword">if</span> l[n] &lt; minl:</span><br><span class="line">m, obj, minl = shp, names[n], l[n]</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangles&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(shp.body)):</span><br><span class="line">l,t,w,h = shp.body[i]</span><br><span class="line">pts = np.mgrid[l:l+w:<span class="number">3j</span>, t:t+h:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">names = [<span class="string">&#x27;lt&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;rt&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;lb&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>]</span><br><span class="line">l = norm(pts-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line"><span class="keyword">if</span> l[n] &lt; minl:</span><br><span class="line">m, obj, minl = shp, (names[n], i), l[n]</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;ellipse&#x27;</span>:</span><br><span class="line">x0, y0, l1, l2, ang = shp.body</span><br><span class="line">mat = np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">  [np.sin(-ang),np.cos(-ang)]])</span><br><span class="line">pts = np.mgrid[-l1:l1:<span class="number">3j</span>, -l2:l2:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts = mat.dot(pts.T).T + (x0, y0)</span><br><span class="line">names = [<span class="string">&#x27;lt&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;rt&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;lb&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>]</span><br><span class="line">l = norm(pts-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line"><span class="keyword">if</span> l[n] &lt; minl:</span><br><span class="line">m, obj, minl = shp, names[n], l[n]</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;ellipses&#x27;</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(shp.body)):</span><br><span class="line">x0, y0, l1, l2, ang = shp.body[i]</span><br><span class="line">mat = np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">  [np.sin(-ang),np.cos(-ang)]])</span><br><span class="line">pts = np.mgrid[-l1:l1:<span class="number">3j</span>, -l2:l2:<span class="number">3j</span>].T.reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">pts = mat.dot(pts.T).T + (x0, y0)</span><br><span class="line">names = [<span class="string">&#x27;lt&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;rt&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;lb&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>]</span><br><span class="line">l = norm(pts-(x,y), axis=<span class="number">1</span>)</span><br><span class="line">n = np.argmin(l)</span><br><span class="line"><span class="keyword">if</span> l[n] &lt; minl:</span><br><span class="line">m, obj, minl = shp, (names[n], i), l[n]</span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;layer&#x27;</span>:</span><br><span class="line"><span class="comment"># minl, obj = 1e8, None</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body:</span><br><span class="line">h, o, l = pick_point(i, x, y, lim, types)</span><br><span class="line"><span class="keyword">if</span> l &lt; minl: </span><br><span class="line">m, obj, minl = h, o, l</span><br><span class="line"><span class="keyword">return</span> m, obj, minl</span><br></pre></td></tr></table></figure></p><h2 id="拖动锚点"><a href="#拖动锚点" class="headerlink" title="拖动锚点"></a>拖动锚点</h2><p>这个函数接收当前的矢量对象、它的某个锚点以及当前鼠标位置，然后通过该锚点的类型，来对该矢量对象的范围进行调整。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drag</span>(<span class="params">shp, pt, x, y, types=<span class="string">&#x27;all&#x27;</span></span>):</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (types==<span class="string">&#x27;all&#x27;</span> <span class="keyword">or</span> shp.dtype <span class="keyword">in</span> types): <span class="keyword">return</span></span><br><span class="line"><span class="keyword">if</span> shp.dtype == <span class="string">&#x27;rectangle&#x27;</span>:</span><br><span class="line">body = shp.body</span><br><span class="line"><span class="keyword">if</span> pt == <span class="string">&#x27;o&#x27;</span>:body[:<span class="number">2</span>] = (x, y) - body[<span class="number">2</span>:]/<span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;l&#x27;</span> <span class="keyword">in</span> pt:body[[<span class="number">0</span>,<span class="number">2</span>]] = x, body[<span class="number">0</span>]+body[<span class="number">2</span>]-x</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;r&#x27;</span> <span class="keyword">in</span> pt:body[<span class="number">2</span>] = x - body[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;t&#x27;</span> <span class="keyword">in</span> pt:body[[<span class="number">1</span>,<span class="number">3</span>]] = y, body[<span class="number">1</span>]+body[<span class="number">3</span>]-y</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> pt:body[<span class="number">3</span>] = y - body[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">elif</span> shp.dtype == <span class="string">&#x27;rectangles&#x27;</span>:</span><br><span class="line">pt, i = pt</span><br><span class="line">body = shp.body[i]</span><br><span class="line"><span class="keyword">if</span> pt == <span class="string">&#x27;o&#x27;</span>:body[:<span class="number">2</span>] = (x, y) - body[<span class="number">2</span>:]/<span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;l&#x27;</span> <span class="keyword">in</span> pt:body[[<span class="number">0</span>,<span class="number">2</span>]] = x, body[<span class="number">0</span>]+body[<span class="number">2</span>]-x</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;r&#x27;</span> <span class="keyword">in</span> pt:body[<span class="number">2</span>] = x - body[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;t&#x27;</span> <span class="keyword">in</span> pt:body[[<span class="number">1</span>,<span class="number">3</span>]] = y, body[<span class="number">1</span>]+body[<span class="number">3</span>]-y</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> pt:body[<span class="number">3</span>] = y - body[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">elif</span> shp.dtype == <span class="string">&#x27;ellipse&#x27;</span>:</span><br><span class="line"><span class="keyword">if</span> pt == <span class="string">&#x27;o&#x27;</span>: </span><br><span class="line">shp.body[:<span class="number">2</span>] = x, y</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">x0, y0, l1, l2, ang = shp.body</span><br><span class="line">v1, v2 = (np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">[np.sin(-ang),np.cos(-ang)]]) * (l1, l2)).T</span><br><span class="line">l, r, t, b = np.array([-v1, v1, -v2, v2]) + (x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;l&#x27;</span> <span class="keyword">in</span> pt: l = v1.dot([x-x0, y-y0])*v1/l1**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;r&#x27;</span> <span class="keyword">in</span> pt: r = v1.dot([x-x0, y-y0])*v1/l1**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;t&#x27;</span> <span class="keyword">in</span> pt: t = v2.dot([x-x0, y-y0])*v2/l2**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> pt: b = v2.dot([x-x0, y-y0])*v2/l2**<span class="number">2</span>+(x0, y0)</span><br><span class="line">k = np.linalg.inv(np.array([-v2,v1]).T).dot((l+r-t-b)/<span class="number">2</span>)</span><br><span class="line">shp.body[:<span class="number">2</span>] = (l+r)/<span class="number">2</span> + v2*k[<span class="number">0</span>]</span><br><span class="line">shp.body[<span class="number">2</span>:<span class="number">4</span>] = np.dot(r-l, v1)/l1/<span class="number">2</span>, np.dot(b-t, v2)/l2/<span class="number">2</span></span><br><span class="line"><span class="keyword">elif</span> shp.dtype == <span class="string">&#x27;ellipses&#x27;</span>:</span><br><span class="line">pt, i = pt</span><br><span class="line">body = shp.body[i]</span><br><span class="line"><span class="keyword">if</span> pt == <span class="string">&#x27;o&#x27;</span>: </span><br><span class="line">body[:<span class="number">2</span>] = x, y</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">x0, y0, l1, l2, ang = body</span><br><span class="line">v1, v2 = (np.array([[np.cos(-ang),-np.sin(-ang)],</span><br><span class="line">[np.sin(-ang),np.cos(-ang)]]) * (l1, l2)).T</span><br><span class="line">l, r, t, b = np.array([-v1, v1, -v2, v2]) + (x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;l&#x27;</span> <span class="keyword">in</span> pt: l = v1.dot([x-x0, y-y0])*v1/l1**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;r&#x27;</span> <span class="keyword">in</span> pt: r = v1.dot([x-x0, y-y0])*v1/l1**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;t&#x27;</span> <span class="keyword">in</span> pt: t = v2.dot([x-x0, y-y0])*v2/l2**<span class="number">2</span>+(x0, y0)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> pt: b = v2.dot([x-x0, y-y0])*v2/l2**<span class="number">2</span>+(x0, y0)</span><br><span class="line">k = np.linalg.inv(np.array([-v2,v1]).T).dot((l+r-t-b)/<span class="number">2</span>)</span><br><span class="line">body[:<span class="number">2</span>] = (l+r)/<span class="number">2</span> + v2*k[<span class="number">0</span>]</span><br><span class="line">body[<span class="number">2</span>:<span class="number">4</span>] = np.dot(r-l, v1)/l1/<span class="number">2</span>, np.dot(b-t, v2)/l2/<span class="number">2</span></span><br><span class="line"><span class="keyword">else</span>: pt[:] = x, y</span><br></pre></td></tr></table></figure></p><h2 id="移动对象"><a href="#移动对象" class="headerlink" title="移动对象"></a>移动对象</h2><p>该函数目的是对矢量对象进行移动。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">offset</span>(<span class="params">shp, dx, dy</span>):</span></span><br><span class="line"><span class="keyword">if</span> shp.dtype <span class="keyword">in</span> &#123;<span class="string">&#x27;rectangle&#x27;</span>, <span class="string">&#x27;ellipse&#x27;</span>, <span class="string">&#x27;circle&#x27;</span>&#125;:</span><br><span class="line">shp.body[:<span class="number">2</span>] += dx, dy</span><br><span class="line"><span class="keyword">elif</span> shp.dtype <span class="keyword">in</span> &#123;<span class="string">&#x27;rectangles&#x27;</span>, <span class="string">&#x27;ellipses&#x27;</span>, <span class="string">&#x27;circles&#x27;</span>&#125;:</span><br><span class="line">shp.body[:,:<span class="number">2</span>] += dx, dy</span><br><span class="line"><span class="keyword">elif</span> <span class="built_in">isinstance</span>(shp, np.ndarray):</span><br><span class="line">shp += dx, dy</span><br><span class="line"><span class="keyword">elif</span> <span class="built_in">isinstance</span>(shp.body, <span class="built_in">list</span>):</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> shp.body: offset(i, dx, dy)</span><br></pre></td></tr></table></figure></p><h1 id="BaseEditor鼠标动作"><a href="#BaseEditor鼠标动作" class="headerlink" title="BaseEditor鼠标动作"></a>BaseEditor鼠标动作</h1><h2 id="鼠标中键拖动"><a href="#鼠标中键拖动" class="headerlink" title="鼠标中键拖动"></a>鼠标中键拖动</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line">self.p = x, y</span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">2</span>:</span><br><span class="line">self.status = <span class="string">&#x27;move&#x27;</span></span><br><span class="line">self.oldxy = key[<span class="string">&#x27;px&#x27;</span>], key[<span class="string">&#x27;py&#x27;</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line">self.cursor = <span class="string">&#x27;arrow&#x27;</span></span><br><span class="line"><span class="keyword">if</span> self.status == <span class="string">&#x27;move&#x27;</span>:</span><br><span class="line">ox, oy = self.oldxy</span><br><span class="line">up = (<span class="number">1</span>,-<span class="number">1</span>)[key[<span class="string">&#x27;canvas&#x27;</span>].up]</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].move(key[<span class="string">&#x27;px&#x27;</span>]-ox, (key[<span class="string">&#x27;py&#x27;</span>]-oy)*up)</span><br><span class="line">self.oldxy = key[<span class="string">&#x27;px&#x27;</span>], key[<span class="string">&#x27;py&#x27;</span>]</span><br></pre></td></tr></table></figure><h2 id="alt-右键以删除一个shape"><a href="#alt-右键以删除一个shape" class="headerlink" title="alt+右键以删除一个shape"></a>alt+右键以删除一个shape</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">3</span>:</span><br><span class="line">obj, l = pick_obj(shp, x, y, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line"><span class="keyword">if</span> obj <span class="keyword">is</span> <span class="literal">None</span>: <span class="keyword">del</span> shp.body[:]</span><br><span class="line"><span class="keyword">else</span>: shp.body.remove(obj)</span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br></pre></td></tr></table></figure><h2 id="shift-右键以合并shape"><a href="#shift-右键以合并shape" class="headerlink" title="shift+右键以合并shape"></a>shift+右键以合并shape</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">3</span>:</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">layer = geom2shp(geom_union(shp.to_geom()))</span><br><span class="line">shp.body = layer.body</span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br></pre></td></tr></table></figure><h2 id="右键根据当前区域大小缩放"><a href="#右键根据当前区域大小缩放" class="headerlink" title="右键根据当前区域大小缩放"></a>右键根据当前区域大小缩放</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">3</span>:</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">or</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">or</span> key[<span class="string">&#x27;ctrl&#x27;</span>]):</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].fit()</span><br></pre></td></tr></table></figure><h2 id="alt-ctrl以显示锚点"><a href="#alt-ctrl以显示锚点" class="headerlink" title="alt+ctrl以显示锚点"></a>alt+ctrl以显示锚点</h2><p>（注意该组合键是放在鼠标移动这个事件中，所以此时要鼠标移动一下，才会看到锚点）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;ctrl&#x27;</span>]:</span><br><span class="line">self.status = <span class="string">&#x27;pick&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="string">&#x27;anchor&#x27;</span> <span class="keyword">in</span> key[<span class="string">&#x27;canvas&#x27;</span>].marks: </span><br><span class="line">pts = mark(shp)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>: </span><br><span class="line">pts = Points(np.vstack(pts), color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = pts</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;anchor&#x27;</span> <span class="keyword">in</span> key[<span class="string">&#x27;canvas&#x27;</span>].marks:</span><br><span class="line">m, obj, l = pick_point(key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>], x, y, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> m <span class="keyword">is</span> <span class="literal">None</span>: self.cursor = <span class="string">&#x27;hand&#x27;</span></span><br></pre></td></tr></table></figure><br>最开始时，画布中是没有锚点的，此时就会将矢量对象通过mark函数转为锚点的点集，然后在画布上显示出来（具体原理可以见上面的mark函数解析）。<br>当画布中有了锚点后，如果鼠标靠近了某个锚点，通过pick_point这个函数捕捉到该锚点，就会将鼠标的样式设置为“手形”。</p><h2 id="alt-ctrl-鼠标左键拖动锚点"><a href="#alt-ctrl-鼠标左键拖动锚点" class="headerlink" title="alt+ctrl+鼠标左键拖动锚点"></a>alt+ctrl+鼠标左键拖动锚点</h2><p>需要提前非常注意的一点是，当同时按住alt和ctrl后，就会在鼠标移动事件中将此时的status设为pick模式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.status = <span class="string">&#x27;pick&#x27;</span></span><br></pre></td></tr></table></figure><br>此时在鼠标按下事件中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line">self.p = x, y</span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> self.status==<span class="string">&#x27;pick&#x27;</span>:</span><br><span class="line">m, obj, l = pick_point(shp, x, y, <span class="number">5</span>)</span><br><span class="line">self.pick_m, self.pick_obj = m, obj</span><br></pre></td></tr></table></figure><br>如果是捕捉到了某锚点，那么self.pick_m和self.pick_obj都会有值。<br>此时如果移动鼠标，那么：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> self.pick_obj <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> self.pick_m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">drag(self.pick_m, self.pick_obj, x, y)</span><br><span class="line">pts = mark(self.pick_m)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>:</span><br><span class="line">pts = np.vstack(pts)</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = Points(pts, color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">self.pick_m.dirty = <span class="literal">True</span></span><br><span class="line">shp.dirty = <span class="literal">True</span></span><br></pre></td></tr></table></figure><br>就会触发drag这个函数来对锚点进行拖动。</p><h2 id="alt-ctrl-鼠标左键拖动整个矢量对象"><a href="#alt-ctrl-鼠标左键拖动整个矢量对象" class="headerlink" title="alt+ctrl+鼠标左键拖动整个矢量对象"></a>alt+ctrl+鼠标左键拖动整个矢量对象</h2><p>上面拖动锚点，是因为在鼠标按下时能够捕捉到锚点，而如果捕捉不到锚点（即与锚点离得较远），此时就会尝试选择整个对象，即：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_down</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> btn==<span class="number">1</span> <span class="keyword">and</span> self.pick_m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">m, l = pick_obj(shp, x, y, <span class="number">5</span>)</span><br><span class="line">self.pick_m, self.pick_obj = m, <span class="literal">None</span></span><br></pre></td></tr></table></figure><br>（注意到此时self.pick_m是None，即没有捕捉到锚点的前提下）<br>此时如果探测到了矢量对象，那么self.pick_m就会有值，但self.pick_obj没有值。<br>此时如果移动鼠标，那么：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouse_move</span>(<span class="params">self, shp, x, y, btn, **key</span>):</span></span><br><span class="line"><span class="keyword">if</span> self.pick_obj <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> self.pick_m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">offset(self.pick_m, x-self.p[<span class="number">0</span>], y-self.p[<span class="number">1</span>])</span><br><span class="line">pts = mark(self.pick_m)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pts)&gt;<span class="number">0</span>:</span><br><span class="line">pts = np.vstack(pts)</span><br><span class="line">key[<span class="string">&#x27;canvas&#x27;</span>].marks[<span class="string">&#x27;anchor&#x27;</span>] = Points(pts, color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">self.p = x, y</span><br><span class="line">self.pick_m.dirty =shp.dirty = <span class="literal">True</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h1 id="特定形状Editor的鼠标动作"><a href="#特定形状Editor的鼠标动作" class="headerlink" title="特定形状Editor的鼠标动作"></a>特定形状Editor的鼠标动作</h1><h2 id="调用BaseEditor"><a href="#调用BaseEditor" class="headerlink" title="调用BaseEditor"></a>调用BaseEditor</h2><p>BaseEditor中有预置的鼠标动作，何时调用它。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inbase</span>(<span class="params">key, btn</span>):</span></span><br><span class="line">status = key[<span class="string">&#x27;ctrl&#x27;</span>], key[<span class="string">&#x27;alt&#x27;</span>], key[<span class="string">&#x27;shift&#x27;</span>]</span><br><span class="line"><span class="keyword">return</span> status == (<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>) <span class="keyword">or</span> btn <span class="keyword">in</span> &#123;<span class="number">2</span>,<span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure><br>即同时按住Ctrl和alt，或点击了鼠标中键或右键，就先响应BaseEditor中的行为。</p><h2 id="自定义动作"><a href="#自定义动作" class="headerlink" title="自定义动作"></a>自定义动作</h2><p>有几个特定的矢量图形绘制时都有如下动作，即：<br>（1）按住alt，求差集；<br>（2）按住shift，求并集；<br>（3）同时按住shift和alt，求交集。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">or</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">obj = shp.body.pop(-<span class="number">1</span>)</span><br><span class="line">rst = geom_union(shp.to_geom())</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;alt&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;shift&#x27;</span>]:</span><br><span class="line">rst = rst.difference(obj.to_geom())</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">and</span> <span class="keyword">not</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">rst = rst.union(obj.to_geom())</span><br><span class="line"><span class="keyword">if</span> key[<span class="string">&#x27;shift&#x27;</span>] <span class="keyword">and</span> key[<span class="string">&#x27;alt&#x27;</span>]:</span><br><span class="line">rst = rst.intersection(obj.to_geom())</span><br><span class="line">layer = geom2shp(geom_flatten(rst))</span><br><span class="line">shp.body = layer.body</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">简介
本文是对ImagePy的矢量图形绘制工具进行深度解析。
矢量图形相对于位图来说，有其特有的操作，比如两个矢量进行求交集、求并集、求差等。
阅读本文之前，可以先参考之前的这篇文章，以对ImagePy的矢量图形有初步了解。

功能函数
将矢量图形转化为点集
该函数的作用是将矢量图形转换为点集，这里的点作为锚点，可以供后续编辑。
比如对于矩形这一矢量，在shp中定义了它的起始点和长宽，通过该函数，可以将该矩形转为9个点的点集，即将该矩形分成田字格。
（具体到语法上，使用了numpy的mgrid函数，其中的步长设为了复数的形式，具体可以参考这里）
1
2
3
4
5
6
7
8
9
10
11
</summary>
    
    
    
    <category term="computer vision" scheme="http://qixinbo.github.io/categories/computer-vision/"/>
    
    
    <category term="ImagePy" scheme="http://qixinbo.github.io/tags/ImagePy/"/>
    
  </entry>
  
  <entry>
    <title>算法赏析——判断某点是否在某区域内</title>
    <link href="http://qixinbo.github.io/2021/03/28/algorithm-contain/"/>
    <id>http://qixinbo.github.io/2021/03/28/algorithm-contain/</id>
    <published>2021-03-27T16:00:00.000Z</published>
    <updated>2021-03-29T08:44:14.706Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>给定一个多边形区域，怎样判断某个点是否在该区域内？<br>如下图所示的蓝色多边形框，判断某点是否在该框内。<br><img src="https://user-images.githubusercontent.com/6218739/112778360-f66fe100-9076-11eb-9ec4-5e197aebdebd.png" alt="area"></p><h1 id="定义域"><a href="#定义域" class="headerlink" title="定义域"></a>定义域</h1><p>先写出该蓝色框的坐标序列：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">poly = np.array([(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">1</span>,<span class="number">0</span>),(<span class="number">0.7</span>,<span class="number">0.7</span>),(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">0</span>,<span class="number">1</span>),(<span class="number">0.5</span>,<span class="number">0.5</span>),(<span class="number">0</span>,<span class="number">0</span>)])</span><br></pre></td></tr></table></figure><br>注意，该坐标序列是首尾相接的。<br>然后，定义出任意数量、任意位置的随机点：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pts = np.random.rand(<span class="number">80</span>).reshape((<span class="number">40</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><br>这里给出了40个随机点。</p><h1 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h1><p>为了简单起见，以随机点[0.3, 0.4]为例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">o = np.array([(<span class="number">0.3</span>, <span class="number">0.4</span>)])</span><br></pre></td></tr></table></figure></p><h2 id="计算点与区域边界点形成的向量"><a href="#计算点与区域边界点形成的向量" class="headerlink" title="计算点与区域边界点形成的向量"></a>计算点与区域边界点形成的向量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vs = poly - o</span><br></pre></td></tr></table></figure><p>可以看作是以随机点为中心，区域边界点指向该中心的向量。<br>此例中，vs的值就是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[-<span class="number">0.3</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.7</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.4</span>  <span class="number">0.3</span>]</span><br><span class="line"> [ <span class="number">0.7</span>  <span class="number">0.6</span>]</span><br><span class="line"> [-<span class="number">0.3</span>  <span class="number">0.6</span>]</span><br><span class="line"> [ <span class="number">0.2</span>  <span class="number">0.1</span>]</span><br><span class="line"> [-<span class="number">0.3</span> -<span class="number">0.4</span>]]</span><br></pre></td></tr></table></figure></p><h2 id="计算点与区域边界点的距离"><a href="#计算点与区域边界点的距离" class="headerlink" title="计算点与区域边界点的距离"></a>计算点与区域边界点的距离</h2><p>然后计算该向量的绝对长度：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls = np.linalg.norm(vs, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><br>ls的值为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0.5</span>        <span class="number">0.80622577</span>     <span class="number">0.5</span>        <span class="number">0.92195445</span>   <span class="number">0.67082039</span>    <span class="number">0.2236068</span>  <span class="number">0.5</span>]</span><br></pre></td></tr></table></figure></p><h2 id="计算相邻向量的外积"><a href="#计算相邻向量的外积" class="headerlink" title="计算相邻向量的外积"></a>计算相邻向量的外积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cs = np.cross(vs[:-<span class="number">1</span>], vs[<span class="number">1</span>:])</span><br></pre></td></tr></table></figure><p>这一步是计算以随机点为中心所形成的向量中，两个相邻向量所形成的外积。<br>可以详细看看numpy的cross函数的两个输入：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[-<span class="number">0.3</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.7</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.4</span>  <span class="number">0.3</span>]</span><br><span class="line"> [ <span class="number">0.7</span>  <span class="number">0.6</span>]</span><br><span class="line"> [-<span class="number">0.3</span>  <span class="number">0.6</span>]</span><br><span class="line"> [ <span class="number">0.2</span>  <span class="number">0.1</span>]]</span><br></pre></td></tr></table></figure><br>和<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[ <span class="number">0.7</span> -<span class="number">0.4</span>]</span><br><span class="line"> [ <span class="number">0.4</span>  <span class="number">0.3</span>]</span><br><span class="line"> [ <span class="number">0.7</span>  <span class="number">0.6</span>]</span><br><span class="line"> [-<span class="number">0.3</span>  <span class="number">0.6</span>]</span><br><span class="line"> [ <span class="number">0.2</span>  <span class="number">0.1</span>]</span><br><span class="line"> [-<span class="number">0.3</span> -<span class="number">0.4</span>]]</span><br></pre></td></tr></table></figure><br>即第一个输入是排除了vs的最后一个向量，而第二个输入是排除了vs的第一个向量，这样两者一交错，就是在cross时计算的就是两个相邻向量的外积。<br>外积的概念可以参见<a href="https://zh.wikipedia.org/zh-cn/%E5%8F%89%E7%A7%AF">维基百科</a><br><img src="https://user-images.githubusercontent.com/6218739/112794912-4d3ae200-909a-11eb-8fa4-cda6b524613e.png" alt="cross"><br>而numpy的具体cross函数的计算方式见<a href="https://numpy.org/doc/stable/reference/generated/numpy.cross.html">这里</a>。<br>因为这里输入的两个向量都是二维的，因此计算出来的虽然应该仍然是个向量，但这里只返回它的z轴长度（In cases where both input vectors have dimension 2, the z-component of the cross product is returned）。<br>因此，cs的值为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ <span class="number">0.4</span>   <span class="number">0.37</span>  <span class="number">0.03</span>  <span class="number">0.6</span>  -<span class="number">0.15</span> -<span class="number">0.05</span>]</span><br></pre></td></tr></table></figure><br>这里比较重要的是数值的符号。</p><h2 id="计算相邻向量的内积"><a href="#计算相邻向量的内积" class="headerlink" title="计算相邻向量的内积"></a>计算相邻向量的内积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dot = (vs[:-<span class="number">1</span>]*vs[<span class="number">1</span>:]).<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>这一步是计算以随机点为中心所形成的向量中，两个相邻向量所形成的内积。<br>内积的概念可以参见<a href="https://zh.wikipedia.org/zh-cn/%E7%82%B9%E7%A7%AF">维基百科</a>。<br><img src="https://user-images.githubusercontent.com/6218739/112796213-42814c80-909c-11eb-98bd-a62fd9a24ba1.png" alt="dot"><br>里面重要的一点：从代数角度看，先对两个数字序列中的每组对应元素求积，再对所有积求和，结果即为点积。从几何角度看，点积则是两个向量的长度与它们夹角余弦的积。这两种定义在笛卡尔坐标系中等价。</p><h2 id="计算相邻向量的长度乘积"><a href="#计算相邻向量的长度乘积" class="headerlink" title="计算相邻向量的长度乘积"></a>计算相邻向量的长度乘积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls = ls[:-<span class="number">1</span>] * ls[<span class="number">1</span>:]</span><br></pre></td></tr></table></figure><p>这句简单，就是相邻两个向量的长度的乘积。</p><h2 id="计算相邻向量的角度"><a href="#计算相邻向量的角度" class="headerlink" title="计算相邻向量的角度"></a>计算相邻向量的角度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ang = np.arccos(dot/ls) * np.sign(cs)</span><br></pre></td></tr></table></figure><p>该行有两部分组成：<br>（1）前一部分就是两个向量的点积除以这两个向量的长度乘积。由点积的定义可知，这样的除法得到了角度的余弦值。这样求反余弦后，就可以得到两个向量之间的角度。<br>（2）第二部分就是对上面的角度赋予符号，这个符号的正负是通过相邻向量的外积来得到的。</p><h2 id="计算角度之和"><a href="#计算角度之和" class="headerlink" title="计算角度之和"></a>计算角度之和</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ang.<span class="built_in">sum</span>() &gt; np.pi</span><br></pre></td></tr></table></figure><p>对上述角度求和，然后判断其大小。<br>这里就是整个算法的点睛之笔，假设一个人站在了这个随机点上，然后他在原地转圈：<br>（1）如果随机点在区域内部，那么这个人转一圈，其转过的角度就是2*pi；<br>（2）如果随机点在区域外部，那么这个人没法转一个完整的圈，而是转一个角度，然后又转回来，因此最终转过的角度就是0。<br>所以就可以根据这个角度之和来判断随机点与区域的关系。</p><p>将以上函数封装成一个统一的函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">contain</span>(<span class="params">poly, o</span>):</span></span><br><span class="line">    vs = poly - o</span><br><span class="line">    ls = np.linalg.norm(vs, axis=<span class="number">1</span>)</span><br><span class="line">    cs = np.cross(vs[:-<span class="number">1</span>], vs[<span class="number">1</span>:])</span><br><span class="line">    dot = (vs[:-<span class="number">1</span>]*vs[<span class="number">1</span>:]).<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">    ls = ls[:-<span class="number">1</span>] * ls[<span class="number">1</span>:]</span><br><span class="line">    ang = np.arccos(dot/ls) * np.sign(cs)</span><br><span class="line">    <span class="keyword">return</span> ang.<span class="built_in">sum</span>() &gt; np.pi</span><br></pre></td></tr></table></figure></p><h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">msk = np.array([contain(poly, i) <span class="keyword">for</span> i <span class="keyword">in</span> pts])</span><br><span class="line"></span><br><span class="line">plt.plot(*poly.T)</span><br><span class="line">plt.plot(*pts[msk].T, <span class="string">&#x27;go&#x27;</span>)</span><br><span class="line">plt.plot(*pts[~msk].T, <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果为：<br><img src="https://user-images.githubusercontent.com/6218739/112799536-11574b00-90a1-11eb-812e-21cdbdf4f45e.png" alt="vis"></p>]]></content>
    
    
    <summary type="html">问题描述
给定一个多边形区域，怎样判断某个点是否在该区域内？
如下图所示的蓝色多边形框，判断某点是否在该框内。


定义域
先写出该蓝色框的坐标序列：
1
2
3
4


import numpy as np
import matplotlib.pyplot as plt

poly = np.array([(0,0),(1,0),(0.7,0.7),(1,1),(0,1),(0.5,0.5),(0,0)])



注意，该坐标序列是首尾相接的。
然后，定义出任意数量、任意位置的随机点：
1


pts = np.random.rand(80).reshape((40,2))



这里给出了</summary>
    
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/categories/algorithm/"/>
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>算法赏析——寻找线条的转折点</title>
    <link href="http://qixinbo.github.io/2021/03/27/algorithm-find-peak/"/>
    <id>http://qixinbo.github.io/2021/03/27/algorithm-find-peak/</id>
    <published>2021-03-26T16:00:00.000Z</published>
    <updated>2021-03-29T08:44:33.703Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>图像中有一条线，如何判断这条线的转折点？<br>比如下面一张图：<br><img src="https://user-images.githubusercontent.com/6218739/112800422-35fff280-90a2-11eb-8a43-45d6a4682e3a.png" alt="test"><br>目的是找到图中的三个转折点。</p><h1 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h1><h2 id="找到轮廓线"><a href="#找到轮廓线" class="headerlink" title="找到轮廓线"></a>找到轮廓线</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">&#x27;test.png&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">conts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">xs, ys = conts[:,:,<span class="number">0</span>], conts[:,:,<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>这一步实际作用是通过寻找轮廓线，从像素类型的位图中提取有意义的这条线的坐标序列，即矢量序列。<br>同时将横坐标和纵坐标分别提取出来。</p><h2 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gxs = ndimg.gaussian_filter(xs, <span class="number">15</span>, mode=<span class="string">&#x27;wrap&#x27;</span>)</span><br><span class="line">gys = ndimg.gaussian_filter(ys, <span class="number">15</span>, mode=<span class="string">&#x27;wrap&#x27;</span>)</span><br></pre></td></tr></table></figure><p>对横纵坐标分别做高斯模糊，相当于对一维数据做高斯模糊，同时注意上面的轮廓线寻找到的序列是首尾相连，要用到wrap这个模式。</p><h2 id="新旧坐标对比"><a href="#新旧坐标对比" class="headerlink" title="新旧坐标对比"></a>新旧坐标对比</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ds = ((xs-gxs)**<span class="number">2</span>+(ys-gys)**<span class="number">2</span>)**<span class="number">0.5</span></span><br></pre></td></tr></table></figure><p>将高斯模糊后的坐标与之前的坐标进行对比，用标准差来衡量差距大小。</p><h2 id="寻找局部极大值"><a href="#寻找局部极大值" class="headerlink" title="寻找局部极大值"></a>寻找局部极大值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">maxds = ndimg.maximum_filter(ds, <span class="number">100</span>, mode=<span class="string">&#x27;wrap&#x27;</span>)</span><br><span class="line">idx = np.where((ds &gt; ds.std()*<span class="number">3</span>) &amp; (ds==maxds))[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>这个地方首先使用一个极大值滤波，然后再通过两个判断条件：是否大于标准差的3倍以及同时等于局部极大值。<br>这样就找到了局部极大值点所在的位置。<br>当然也可以直接用那种寻找局部极值的算法，但不如这种“极大值滤波+大于某个阈值”的方法来得简单直接。</p><h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ax = plt.subplot(<span class="number">211</span>)</span><br><span class="line">ax.plot(xs, ys)</span><br><span class="line">ax.plot(gxs, gys)</span><br><span class="line">plt.plot(xs[idx], ys[idx], <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">212</span>)</span><br><span class="line">ax.plot(ds)</span><br><span class="line">ax.plot(maxds)</span><br><span class="line">ax.plot(ds/ds*ds.std()*<span class="number">3</span>)</span><br><span class="line">ax.plot(idx, ds[idx], <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>将结果可视化出来：<br><img src="https://user-images.githubusercontent.com/6218739/112804493-115a4980-90a7-11eb-8992-f2f8fb80b3b9.png" alt="vis_peak"></p>]]></content>
    
    
    <summary type="html">问题描述
图像中有一条线，如何判断这条线的转折点？
比如下面一张图：

目的是找到图中的三个转折点。

解法
找到轮廓线
1
2
3


img = cv2.imread(&#39;test.png&#39;, 0)
conts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0][0]
xs, ys = conts[:,:,0], conts[:,:,1]


这一步实际作用是通过寻找轮廓线，从像素类型的位图中提取有意义的这条线的坐标序列，即矢量序列。
同时将横坐标和纵坐标分别提取出来。

高斯模糊
1
2


gxs = </summary>
    
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/categories/algorithm/"/>
    
    
    <category term="algorithm" scheme="http://qixinbo.github.io/tags/algorithm/"/>
    
  </entry>
  
</feed>
